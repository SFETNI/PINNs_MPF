
[notice] A new release of pip is available: 23.2.1 -> 23.3.1
[notice] To update, run: /usr/bin/python3 -m pip install --upgrade pip
2023-10-29 00:46:35.676582: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-29 00:46:37.114329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-10-29 00:46:42.603592: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
X_f_train: (20000, 3), X_ini_all: (4225, 3), X_lb_train: (400, 3), X_ub_train: (400, 3), X_ltb_train: (400, 3), X_rtb_train: (400, 3), phi_ini_all: (4225, 1)

 ! Initilization of all workers pinns 

File 'intercations_file.txt' has been successfully removed.
debug:epoch, flag_reduce_batches, flag:  0 0 0

 -------------------------------------------------------------
  -----  Epoch: 0 <==> N_batches: 4, self.pinns: 4    -------
  ----- time domain:  t_min: 0.00000, t_max: 0.01000
--------------------------------------------------------------


 !!!  Tranfer of learning  !!! 


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  0 !!! 

WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.
WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.
WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.
WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.
WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.
! Caution --- no data for scipy for the batch  0200  at Epoch  0
! Caution --- no data for scipy for the batch  0000  at Epoch  0
! Caution --- no data for scipy for the batch  0300  at Epoch  0
! Caution --- no data for scipy for the batch  0100  at Epoch  0

==> Epoch: 0, Mean_loss of pinns: 2.596e-05, loss_BC: 0.000e+00, loss_IC: 1.217e-05, loss_f: 5.126e-06
 => minimum loss: 1.741e-05, corresponding pinn/batch index: 0300
 => maximum loss: 3.057e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4

==> Epoch: 10, Mean_loss of pinns: 3.176e-05, loss_BC: 4.990e-06, loss_IC: 1.228e-05, loss_f: 5.828e-06
 => minimum loss: 2.562e-05, corresponding pinn/batch index: 0300
 => maximum loss: 3.722e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 3.571e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 17, total_loss: 3.037e-05, loss_BC: 4.261e-06, loss_IC: 1.245e-05, loss_f: 4.986e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.01000, t_max: 0.02000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  18 0 1

 -------------------------------------------------------------
  -----  Epoch: 18 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.01000, t_max: 0.02000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  18 !!! 


==> Epoch: 20, Mean_loss of pinns: 2.773e+00, loss_BC: 3.750e-06, loss_IC: 5.242e-08, loss_f: 2.773e+00
 => minimum loss: 2.254e+00, corresponding pinn/batch index: 0100
 => maximum loss: 4.093e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 30, Mean_loss of pinns: 2.301e+00, loss_BC: 4.417e-06, loss_IC: 1.848e-06, loss_f: 2.301e+00
 => minimum loss: 1.837e+00, corresponding pinn/batch index: 0100
 => maximum loss: 3.444e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 40, Mean_loss of pinns: 1.914e+00, loss_BC: 4.029e-06, loss_IC: 5.983e-06, loss_f: 1.914e+00
 => minimum loss: 1.503e+00, corresponding pinn/batch index: 0100
 => maximum loss: 2.897e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 50, Mean_loss of pinns: 1.603e+00, loss_BC: 4.653e-06, loss_IC: 1.210e-05, loss_f: 1.603e+00
 => minimum loss: 1.227e+00, corresponding pinn/batch index: 0300
 => maximum loss: 2.447e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 60, Mean_loss of pinns: 1.355e+00, loss_BC: 5.204e-06, loss_IC: 1.989e-05, loss_f: 1.355e+00
 => minimum loss: 9.942e-01, corresponding pinn/batch index: 0300
 => maximum loss: 2.082e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 70, Mean_loss of pinns: 1.157e+00, loss_BC: 4.653e-06, loss_IC: 2.909e-05, loss_f: 1.157e+00
 => minimum loss: 8.171e-01, corresponding pinn/batch index: 0300
 => maximum loss: 1.787e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 80, Mean_loss of pinns: 9.974e-01, loss_BC: 5.356e-06, loss_IC: 3.945e-05, loss_f: 9.974e-01
 => minimum loss: 6.810e-01, corresponding pinn/batch index: 0300
 => maximum loss: 1.549e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 90, Mean_loss of pinns: 8.683e-01, loss_BC: 6.264e-06, loss_IC: 5.071e-05, loss_f: 8.682e-01
 => minimum loss: 5.755e-01, corresponding pinn/batch index: 0300
 => maximum loss: 1.355e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 100, Mean_loss of pinns: 7.626e-01, loss_BC: 5.969e-06, loss_IC: 6.260e-05, loss_f: 7.625e-01
 => minimum loss: 4.927e-01, corresponding pinn/batch index: 0300
 => maximum loss: 1.196e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 110, Mean_loss of pinns: 6.751e-01, loss_BC: 6.707e-06, loss_IC: 7.488e-05, loss_f: 6.750e-01
 => minimum loss: 4.269e-01, corresponding pinn/batch index: 0300
 => maximum loss: 1.064e+00, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  117

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 3.805e-05, loss_BC: 0.000e+00, loss_IC: 1.699e-06,loss_f: 2.034e-05
pinn: 0000, Iter: 100, total_loss: 7.956e-05, loss_BC: 0.000e+00, loss_IC: 3.365e-06,loss_f: 5.115e-05
pinn: 0200, Iter: 100, total_loss: 2.189e-04, loss_BC: 0.000e+00, loss_IC: 1.280e-05,loss_f: 1.575e-04
pinn: 0300, Iter: 100, total_loss: 2.836e-05, loss_BC: 0.000e+00, loss_IC: 1.783e-06,loss_f: 1.777e-05
pinn: 0000, Iter: 200, total_loss: 1.613e-05, loss_BC: 0.000e+00, loss_IC: 3.864e-07,loss_f: 8.059e-06
pinn: 0100, Iter: 200, total_loss: 1.522e-05, loss_BC: 0.000e+00, loss_IC: 5.783e-07,loss_f: 4.813e-06
pinn: 0300, Iter: 200, total_loss: 9.249e-06, loss_BC: 0.000e+00, loss_IC: 7.924e-07,loss_f: 3.852e-06
pinn: 0200, Iter: 200, total_loss: 2.432e-05, loss_BC: 0.000e+00, loss_IC: 1.133e-06,loss_f: 1.513e-05
pinn: 0000, Iter: 300, total_loss: 1.063e-05, loss_BC: 0.000e+00, loss_IC: 3.331e-07,loss_f: 2.713e-06
pinn: 0100, Iter: 300, total_loss: 1.282e-05, loss_BC: 0.000e+00, loss_IC: 5.585e-07,loss_f: 2.651e-06
pinn: 0300, Iter: 300, total_loss: 6.455e-06, loss_BC: 0.000e+00, loss_IC: 4.638e-07,loss_f: 1.903e-06
pinn: 0200, Iter: 300, total_loss: 1.226e-05, loss_BC: 0.000e+00, loss_IC: 2.769e-07,loss_f: 4.927e-06
pinn: 0000, Iter: 400, total_loss: 9.542e-06, loss_BC: 0.000e+00, loss_IC: 2.383e-07,loss_f: 2.191e-06
pinn: 0100, Iter: 400, total_loss: 1.118e-05, loss_BC: 0.000e+00, loss_IC: 5.325e-07,loss_f: 2.229e-06
pinn: 0200, Iter: 400, total_loss: 1.005e-05, loss_BC: 0.000e+00, loss_IC: 1.176e-07,loss_f: 3.309e-06
pinn: 0300, Iter: 400, total_loss: 5.754e-06, loss_BC: 0.000e+00, loss_IC: 5.406e-07,loss_f: 1.425e-06
pinn: 0000, Iter: 500, total_loss: 8.870e-06, loss_BC: 0.000e+00, loss_IC: 2.421e-07,loss_f: 1.903e-06
pinn: 0100, Iter: 500, total_loss: 1.008e-05, loss_BC: 0.000e+00, loss_IC: 3.972e-07,loss_f: 2.655e-06
pinn: 0300, Iter: 500, total_loss: 5.386e-06, loss_BC: 0.000e+00, loss_IC: 5.396e-07,loss_f: 1.324e-06
pinn: 0200, Iter: 500, total_loss: 8.865e-06, loss_BC: 0.000e+00, loss_IC: 1.486e-07,loss_f: 2.515e-06
pinn: 0000, Iter: 600, total_loss: 8.001e-06, loss_BC: 0.000e+00, loss_IC: 2.832e-07,loss_f: 1.869e-06
pinn: 0100, Iter: 600, total_loss: 8.396e-06, loss_BC: 0.000e+00, loss_IC: 1.835e-07,loss_f: 2.724e-06
pinn: 0200, Iter: 600, total_loss: 7.430e-06, loss_BC: 0.000e+00, loss_IC: 1.926e-07,loss_f: 2.130e-06
pinn: 0300, Iter: 600, total_loss: 5.174e-06, loss_BC: 0.000e+00, loss_IC: 4.627e-07,loss_f: 1.766e-06
pinn: 0000, Iter: 700, total_loss: 7.438e-06, loss_BC: 0.000e+00, loss_IC: 3.969e-07,loss_f: 2.021e-06
pinn: 0100, Iter: 700, total_loss: 7.719e-06, loss_BC: 0.000e+00, loss_IC: 1.316e-07,loss_f: 2.699e-06
pinn: 0200, Iter: 700, total_loss: 6.746e-06, loss_BC: 0.000e+00, loss_IC: 2.985e-07,loss_f: 2.145e-06
pinn: 0300, Iter: 700, total_loss: 4.129e-06, loss_BC: 0.000e+00, loss_IC: 3.148e-07,loss_f: 1.145e-06
pinn: 0000, Iter: 800, total_loss: 7.014e-06, loss_BC: 0.000e+00, loss_IC: 3.953e-07,loss_f: 1.939e-06
pinn: 0100, Iter: 800, total_loss: 7.427e-06, loss_BC: 0.000e+00, loss_IC: 1.375e-07,loss_f: 2.746e-06
pinn: 0200, Iter: 800, total_loss: 6.337e-06, loss_BC: 0.000e+00, loss_IC: 3.008e-07,loss_f: 2.062e-06
pinn: 0300, Iter: 800, total_loss: 4.457e-06, loss_BC: 0.000e+00, loss_IC: 2.274e-07,loss_f: 2.135e-06
pinn: 0000, Iter: 900, total_loss: 6.161e-06, loss_BC: 0.000e+00, loss_IC: 4.512e-07,loss_f: 2.020e-06
pinn: 0100, Iter: 900, total_loss: 7.120e-06, loss_BC: 0.000e+00, loss_IC: 1.564e-07,loss_f: 2.824e-06
pinn: 0200, Iter: 900, total_loss: 6.054e-06, loss_BC: 0.000e+00, loss_IC: 3.667e-07,loss_f: 1.988e-06
pinn: 0300, Iter: 900, total_loss: 3.142e-06, loss_BC: 0.000e+00, loss_IC: 2.003e-07,loss_f: 9.669e-07
pinn: 0000, Iter: 1000, total_loss: 5.693e-06, loss_BC: 0.000e+00, loss_IC: 5.025e-07,loss_f: 2.081e-06
pinn: 0100, Iter: 1000, total_loss: 6.310e-06, loss_BC: 0.000e+00, loss_IC: 3.003e-07,loss_f: 2.350e-06
pinn: 0200, Iter: 1000, total_loss: 5.830e-06, loss_BC: 0.000e+00, loss_IC: 3.997e-07,loss_f: 2.184e-06
pinn: 0300, Iter: 1000, total_loss: 2.891e-06, loss_BC: 0.000e+00, loss_IC: 2.011e-07,loss_f: 8.082e-07
pinn: 0000, Iter: 1100, total_loss: 5.494e-06, loss_BC: 0.000e+00, loss_IC: 4.578e-07,loss_f: 2.028e-06
pinn: 0100, Iter: 1100, total_loss: 5.911e-06, loss_BC: 0.000e+00, loss_IC: 4.262e-07,loss_f: 2.268e-06
pinn: 0200, Iter: 1100, total_loss: 5.490e-06, loss_BC: 0.000e+00, loss_IC: 3.848e-07,loss_f: 2.065e-06
pinn: 0300, Iter: 1100, total_loss: 2.724e-06, loss_BC: 0.000e+00, loss_IC: 2.990e-07,loss_f: 7.404e-07
pinn: 0000, Iter: 1200, total_loss: 5.203e-06, loss_BC: 0.000e+00, loss_IC: 4.928e-07,loss_f: 2.007e-06
pinn: 0100, Iter: 1200, total_loss: 5.725e-06, loss_BC: 0.000e+00, loss_IC: 4.749e-07,loss_f: 2.235e-06
pinn: 0200, Iter: 1200, total_loss: 5.166e-06, loss_BC: 0.000e+00, loss_IC: 5.337e-07,loss_f: 1.994e-06
pinn: 0300, Iter: 1200, total_loss: 2.651e-06, loss_BC: 0.000e+00, loss_IC: 3.200e-07,loss_f: 7.274e-07
pinn: 0000, Iter: 1300, total_loss: 4.880e-06, loss_BC: 0.000e+00, loss_IC: 6.119e-07,loss_f: 1.924e-06
pinn: 0100, Iter: 1300, total_loss: 5.439e-06, loss_BC: 0.000e+00, loss_IC: 5.241e-07,loss_f: 2.022e-06
pinn: 0200, Iter: 1300, total_loss: 4.877e-06, loss_BC: 0.000e+00, loss_IC: 4.922e-07,loss_f: 1.974e-06
pinn: 0300, Iter: 1300, total_loss: 2.594e-06, loss_BC: 0.000e+00, loss_IC: 3.242e-07,loss_f: 6.943e-07
pinn: 0000, Iter: 1400, total_loss: 4.267e-06, loss_BC: 0.000e+00, loss_IC: 5.619e-07,loss_f: 1.603e-06
pinn: 0100, Iter: 1400, total_loss: 4.950e-06, loss_BC: 0.000e+00, loss_IC: 6.073e-07,loss_f: 1.896e-06
pinn: 0200, Iter: 1400, total_loss: 4.620e-06, loss_BC: 0.000e+00, loss_IC: 4.993e-07,loss_f: 1.944e-06
pinn: 0300, Iter: 1400, total_loss: 2.462e-06, loss_BC: 0.000e+00, loss_IC: 3.640e-07,loss_f: 6.423e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 117, Mean_loss of pinns: 4.042e-06, loss_BC: 0.000e+00, loss_IC: 5.176e-07, loss_f: 1.517e-06
 => minimum loss: 2.458e-06, corresponding pinn index: 0300
 => maximum loss: 4.913e-06, corresponding pinn  index: 0100

 max_loss: 1.068e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 119, total_loss: 9.629e-06, loss_BC: 5.531e-06, loss_IC: 5.207e-07, loss_f: 1.568e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.02000, t_max: 0.03000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  120 0 1

 -------------------------------------------------------------
  -----  Epoch: 120 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.02000, t_max: 0.03000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  120 !!! 


==> Epoch: 120, Mean_loss of pinns: 1.603e+00, loss_BC: 5.199e-06, loss_IC: 0.000e+00, loss_f: 1.603e+00
 => minimum loss: 1.260e+00, corresponding pinn/batch index: 0000
 => maximum loss: 2.088e+00, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 130, Mean_loss of pinns: 1.351e+00, loss_BC: 4.820e-06, loss_IC: 8.847e-07, loss_f: 1.351e+00
 => minimum loss: 1.089e+00, corresponding pinn/batch index: 0000
 => maximum loss: 1.754e+00, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 140, Mean_loss of pinns: 1.139e+00, loss_BC: 5.451e-06, loss_IC: 3.568e-06, loss_f: 1.139e+00
 => minimum loss: 9.416e-01, corresponding pinn/batch index: 0000
 => maximum loss: 1.475e+00, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 150, Mean_loss of pinns: 9.635e-01, loss_BC: 5.091e-06, loss_IC: 8.129e-06, loss_f: 9.635e-01
 => minimum loss: 8.173e-01, corresponding pinn/batch index: 0000
 => maximum loss: 1.243e+00, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 160, Mean_loss of pinns: 8.198e-01, loss_BC: 6.127e-06, loss_IC: 1.464e-05, loss_f: 8.198e-01
 => minimum loss: 7.128e-01, corresponding pinn/batch index: 0000
 => maximum loss: 1.051e+00, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 170, Mean_loss of pinns: 7.022e-01, loss_BC: 5.361e-06, loss_IC: 2.313e-05, loss_f: 7.022e-01
 => minimum loss: 6.249e-01, corresponding pinn/batch index: 0000
 => maximum loss: 8.928e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 180, Mean_loss of pinns: 6.058e-01, loss_BC: 7.358e-06, loss_IC: 3.357e-05, loss_f: 6.058e-01
 => minimum loss: 5.506e-01, corresponding pinn/batch index: 0100
 => maximum loss: 7.614e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 190, Mean_loss of pinns: 5.265e-01, loss_BC: 7.654e-06, loss_IC: 4.579e-05, loss_f: 5.264e-01
 => minimum loss: 4.744e-01, corresponding pinn/batch index: 0100
 => maximum loss: 6.527e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 200, Mean_loss of pinns: 4.610e-01, loss_BC: 8.105e-06, loss_IC: 5.948e-05, loss_f: 4.609e-01
 => minimum loss: 4.129e-01, corresponding pinn/batch index: 0100
 => maximum loss: 5.631e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 210, Mean_loss of pinns: 4.067e-01, loss_BC: 9.153e-06, loss_IC: 7.415e-05, loss_f: 4.067e-01
 => minimum loss: 3.629e-01, corresponding pinn/batch index: 0100
 => maximum loss: 4.898e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  219

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 1.204e-05, loss_BC: 0.000e+00, loss_IC: 1.439e-06,loss_f: 5.436e-06
pinn: 0300, Iter: 100, total_loss: 2.852e-05, loss_BC: 0.000e+00, loss_IC: 1.977e-06,loss_f: 1.049e-05
pinn: 0100, Iter: 100, total_loss: 1.820e-05, loss_BC: 0.000e+00, loss_IC: 1.112e-06,loss_f: 1.068e-05
pinn: 0200, Iter: 100, total_loss: 5.291e-05, loss_BC: 0.000e+00, loss_IC: 4.988e-06,loss_f: 4.151e-05
pinn: 0200, Iter: 200, total_loss: 9.766e-06, loss_BC: 0.000e+00, loss_IC: 1.169e-06,loss_f: 5.864e-06
pinn: 0100, Iter: 200, total_loss: 7.813e-06, loss_BC: 0.000e+00, loss_IC: 6.199e-07,loss_f: 4.208e-06
pinn: 0000, Iter: 200, total_loss: 4.759e-06, loss_BC: 0.000e+00, loss_IC: 6.583e-07,loss_f: 2.762e-06
pinn: 0300, Iter: 200, total_loss: 4.358e-06, loss_BC: 0.000e+00, loss_IC: 6.174e-07,loss_f: 2.005e-06
pinn: 0200, Iter: 300, total_loss: 4.195e-06, loss_BC: 0.000e+00, loss_IC: 3.215e-07,loss_f: 2.574e-06
pinn: 0000, Iter: 300, total_loss: 3.773e-06, loss_BC: 0.000e+00, loss_IC: 5.498e-07,loss_f: 1.885e-06
pinn: 0100, Iter: 300, total_loss: 4.882e-06, loss_BC: 0.000e+00, loss_IC: 5.121e-07,loss_f: 1.770e-06
pinn: 0300, Iter: 300, total_loss: 2.807e-06, loss_BC: 0.000e+00, loss_IC: 4.143e-07,loss_f: 1.254e-06
pinn: 0200, Iter: 400, total_loss: 3.301e-06, loss_BC: 0.000e+00, loss_IC: 2.837e-07,loss_f: 1.715e-06
pinn: 0000, Iter: 400, total_loss: 3.178e-06, loss_BC: 0.000e+00, loss_IC: 4.427e-07,loss_f: 1.355e-06
pinn: 0100, Iter: 400, total_loss: 4.603e-06, loss_BC: 0.000e+00, loss_IC: 4.180e-07,loss_f: 1.593e-06
pinn: 0300, Iter: 400, total_loss: 2.597e-06, loss_BC: 0.000e+00, loss_IC: 3.557e-07,loss_f: 1.115e-06
pinn: 0200, Iter: 500, total_loss: 2.928e-06, loss_BC: 0.000e+00, loss_IC: 2.424e-07,loss_f: 1.359e-06
pinn: 0300, Iter: 500, total_loss: 2.293e-06, loss_BC: 0.000e+00, loss_IC: 2.510e-07,loss_f: 8.881e-07
pinn: 0100, Iter: 500, total_loss: 4.380e-06, loss_BC: 0.000e+00, loss_IC: 3.284e-07,loss_f: 1.451e-06
pinn: 0000, Iter: 500, total_loss: 2.725e-06, loss_BC: 0.000e+00, loss_IC: 2.559e-07,loss_f: 1.084e-06
pinn: 0200, Iter: 600, total_loss: 2.737e-06, loss_BC: 0.000e+00, loss_IC: 1.986e-07,loss_f: 1.185e-06
pinn: 0000, Iter: 600, total_loss: 2.522e-06, loss_BC: 0.000e+00, loss_IC: 2.318e-07,loss_f: 8.797e-07
pinn: 0300, Iter: 600, total_loss: 2.059e-06, loss_BC: 0.000e+00, loss_IC: 1.381e-07,loss_f: 7.838e-07
pinn: 0100, Iter: 600, total_loss: 4.001e-06, loss_BC: 0.000e+00, loss_IC: 2.781e-07,loss_f: 1.171e-06
pinn: 0000, Iter: 700, total_loss: 2.426e-06, loss_BC: 0.000e+00, loss_IC: 2.196e-07,loss_f: 8.232e-07
pinn: 0200, Iter: 700, total_loss: 2.605e-06, loss_BC: 0.000e+00, loss_IC: 1.702e-07,loss_f: 1.068e-06
pinn: 0300, Iter: 700, total_loss: 1.899e-06, loss_BC: 0.000e+00, loss_IC: 1.020e-07,loss_f: 7.251e-07
pinn: 0100, Iter: 700, total_loss: 3.795e-06, loss_BC: 0.000e+00, loss_IC: 2.076e-07,loss_f: 1.012e-06
pinn: 0200, Iter: 800, total_loss: 2.445e-06, loss_BC: 0.000e+00, loss_IC: 1.480e-07,loss_f: 9.456e-07
pinn: 0000, Iter: 800, total_loss: 2.318e-06, loss_BC: 0.000e+00, loss_IC: 1.820e-07,loss_f: 7.648e-07
pinn: 0300, Iter: 800, total_loss: 1.839e-06, loss_BC: 0.000e+00, loss_IC: 1.059e-07,loss_f: 6.835e-07
pinn: 0100, Iter: 800, total_loss: 3.641e-06, loss_BC: 0.000e+00, loss_IC: 2.190e-07,loss_f: 9.087e-07
pinn: 0200, Iter: 900, total_loss: 2.364e-06, loss_BC: 0.000e+00, loss_IC: 1.263e-07,loss_f: 8.943e-07
pinn: 0000, Iter: 900, total_loss: 2.259e-06, loss_BC: 0.000e+00, loss_IC: 1.768e-07,loss_f: 7.220e-07
pinn: 0100, Iter: 900, total_loss: 3.548e-06, loss_BC: 0.000e+00, loss_IC: 2.443e-07,loss_f: 8.636e-07
pinn: 0300, Iter: 900, total_loss: 1.783e-06, loss_BC: 0.000e+00, loss_IC: 1.131e-07,loss_f: 6.376e-07
pinn: 0200, Iter: 1000, total_loss: 2.270e-06, loss_BC: 0.000e+00, loss_IC: 1.296e-07,loss_f: 8.189e-07
pinn: 0000, Iter: 1000, total_loss: 2.204e-06, loss_BC: 0.000e+00, loss_IC: 1.716e-07,loss_f: 7.061e-07
pinn: 0100, Iter: 1000, total_loss: 3.472e-06, loss_BC: 0.000e+00, loss_IC: 2.296e-07,loss_f: 8.744e-07
pinn: 0300, Iter: 1000, total_loss: 1.727e-06, loss_BC: 0.000e+00, loss_IC: 1.201e-07,loss_f: 5.832e-07
pinn: 0200, Iter: 1100, total_loss: 2.230e-06, loss_BC: 0.000e+00, loss_IC: 1.295e-07,loss_f: 7.953e-07
pinn: 0000, Iter: 1100, total_loss: 2.123e-06, loss_BC: 0.000e+00, loss_IC: 1.476e-07,loss_f: 6.644e-07
pinn: 0100, Iter: 1100, total_loss: 3.299e-06, loss_BC: 0.000e+00, loss_IC: 2.155e-07,loss_f: 8.988e-07
pinn: 0300, Iter: 1100, total_loss: 1.683e-06, loss_BC: 0.000e+00, loss_IC: 1.244e-07,loss_f: 5.663e-07
pinn: 0200, Iter: 1200, total_loss: 2.180e-06, loss_BC: 0.000e+00, loss_IC: 1.435e-07,loss_f: 7.504e-07
pinn: 0100, Iter: 1200, total_loss: 3.092e-06, loss_BC: 0.000e+00, loss_IC: 2.458e-07,loss_f: 8.638e-07
pinn: 0000, Iter: 1200, total_loss: 2.080e-06, loss_BC: 0.000e+00, loss_IC: 1.430e-07,loss_f: 6.417e-07
pinn: 0300, Iter: 1200, total_loss: 1.645e-06, loss_BC: 0.000e+00, loss_IC: 1.343e-07,loss_f: 5.465e-07
pinn: 0200, Iter: 1300, total_loss: 2.133e-06, loss_BC: 0.000e+00, loss_IC: 1.491e-07,loss_f: 7.237e-07
pinn: 0100, Iter: 1300, total_loss: 3.018e-06, loss_BC: 0.000e+00, loss_IC: 2.553e-07,loss_f: 8.738e-07
pinn: 0300, Iter: 1300, total_loss: 1.576e-06, loss_BC: 0.000e+00, loss_IC: 1.174e-07,loss_f: 5.474e-07
pinn: 0000, Iter: 1300, total_loss: 2.025e-06, loss_BC: 0.000e+00, loss_IC: 1.338e-07,loss_f: 6.329e-07
pinn: 0200, Iter: 1400, total_loss: 2.022e-06, loss_BC: 0.000e+00, loss_IC: 1.222e-07,loss_f: 6.848e-07
pinn: 0100, Iter: 1400, total_loss: 2.834e-06, loss_BC: 0.000e+00, loss_IC: 2.872e-07,loss_f: 8.312e-07
pinn: 0000, Iter: 1400, total_loss: 1.979e-06, loss_BC: 0.000e+00, loss_IC: 1.342e-07,loss_f: 5.841e-07
pinn: 0300, Iter: 1400, total_loss: 1.537e-06, loss_BC: 0.000e+00, loss_IC: 1.130e-07,loss_f: 5.382e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 219, Mean_loss of pinns: 2.054e-06, loss_BC: 0.000e+00, loss_IC: 1.673e-07, loss_f: 6.526e-07
 => minimum loss: 1.514e-06, corresponding pinn index: 0300
 => maximum loss: 2.757e-06, corresponding pinn  index: 0100

==> Epoch: 220, Mean_loss of pinns: 7.758e-06, loss_BC: 5.704e-06, loss_IC: 1.673e-07, loss_f: 6.526e-07
 => minimum loss: 5.201e-06, corresponding pinn/batch index: 0100
 => maximum loss: 1.099e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 1.094e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 221, total_loss: 7.753e-06, loss_BC: 5.637e-06, loss_IC: 1.734e-07, loss_f: 7.066e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.03000, t_max: 0.04000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  222 0 1

 -------------------------------------------------------------
  -----  Epoch: 222 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.03000, t_max: 0.04000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  222 !!! 


==> Epoch: 230, Mean_loss of pinns: 2.979e-01, loss_BC: 5.595e-06, loss_IC: 8.087e-07, loss_f: 2.979e-01
 => minimum loss: 2.141e-01, corresponding pinn/batch index: 0000
 => maximum loss: 3.981e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 240, Mean_loss of pinns: 2.435e-01, loss_BC: 6.221e-06, loss_IC: 3.903e-06, loss_f: 2.435e-01
 => minimum loss: 1.853e-01, corresponding pinn/batch index: 0000
 => maximum loss: 3.247e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 250, Mean_loss of pinns: 2.011e-01, loss_BC: 6.852e-06, loss_IC: 8.763e-06, loss_f: 2.011e-01
 => minimum loss: 1.613e-01, corresponding pinn/batch index: 0000
 => maximum loss: 2.670e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 260, Mean_loss of pinns: 1.683e-01, loss_BC: 7.556e-06, loss_IC: 1.482e-05, loss_f: 1.683e-01
 => minimum loss: 1.411e-01, corresponding pinn/batch index: 0000
 => maximum loss: 2.224e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 270, Mean_loss of pinns: 1.427e-01, loss_BC: 8.444e-06, loss_IC: 2.165e-05, loss_f: 1.427e-01
 => minimum loss: 1.216e-01, corresponding pinn/batch index: 0300
 => maximum loss: 1.878e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 280, Mean_loss of pinns: 1.225e-01, loss_BC: 8.528e-06, loss_IC: 2.899e-05, loss_f: 1.225e-01
 => minimum loss: 1.026e-01, corresponding pinn/batch index: 0300
 => maximum loss: 1.608e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 290, Mean_loss of pinns: 1.063e-01, loss_BC: 8.836e-06, loss_IC: 3.669e-05, loss_f: 1.063e-01
 => minimum loss: 8.809e-02, corresponding pinn/batch index: 0300
 => maximum loss: 1.393e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 300, Mean_loss of pinns: 9.316e-02, loss_BC: 9.118e-06, loss_IC: 4.476e-05, loss_f: 9.310e-02
 => minimum loss: 7.678e-02, corresponding pinn/batch index: 0300
 => maximum loss: 1.219e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 310, Mean_loss of pinns: 8.230e-02, loss_BC: 9.223e-06, loss_IC: 5.321e-05, loss_f: 8.224e-02
 => minimum loss: 6.782e-02, corresponding pinn/batch index: 0300
 => maximum loss: 1.076e-01, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 320, Mean_loss of pinns: 7.325e-02, loss_BC: 8.847e-06, loss_IC: 6.205e-05, loss_f: 7.318e-02
 => minimum loss: 6.057e-02, corresponding pinn/batch index: 0300
 => maximum loss: 9.572e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  321

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 5.435e-06, loss_BC: 0.000e+00, loss_IC: 7.271e-07,loss_f: 2.340e-06
pinn: 0100, Iter: 100, total_loss: 5.084e-06, loss_BC: 0.000e+00, loss_IC: 8.416e-07,loss_f: 3.080e-06
pinn: 0200, Iter: 100, total_loss: 1.446e-05, loss_BC: 0.000e+00, loss_IC: 9.743e-07,loss_f: 9.160e-06
pinn: 0000, Iter: 100, total_loss: 4.260e-06, loss_BC: 0.000e+00, loss_IC: 6.026e-07,loss_f: 1.936e-06
pinn: 0300, Iter: 200, total_loss: 2.794e-06, loss_BC: 0.000e+00, loss_IC: 4.036e-07,loss_f: 6.630e-07
pinn: 0200, Iter: 200, total_loss: 3.502e-06, loss_BC: 0.000e+00, loss_IC: 3.821e-07,loss_f: 1.507e-06
pinn: 0000, Iter: 200, total_loss: 2.375e-06, loss_BC: 0.000e+00, loss_IC: 3.200e-07,loss_f: 1.124e-06
pinn: 0100, Iter: 200, total_loss: 2.627e-06, loss_BC: 0.000e+00, loss_IC: 4.341e-07,loss_f: 1.157e-06
pinn: 0300, Iter: 300, total_loss: 2.546e-06, loss_BC: 0.000e+00, loss_IC: 3.327e-07,loss_f: 5.539e-07
pinn: 0200, Iter: 300, total_loss: 2.843e-06, loss_BC: 0.000e+00, loss_IC: 2.707e-07,loss_f: 9.089e-07
pinn: 0000, Iter: 300, total_loss: 1.766e-06, loss_BC: 0.000e+00, loss_IC: 2.808e-07,loss_f: 5.673e-07
pinn: 0100, Iter: 300, total_loss: 2.182e-06, loss_BC: 0.000e+00, loss_IC: 3.463e-07,loss_f: 7.946e-07
pinn: 0200, Iter: 400, total_loss: 2.660e-06, loss_BC: 0.000e+00, loss_IC: 2.276e-07,loss_f: 8.004e-07
pinn: 0300, Iter: 400, total_loss: 2.377e-06, loss_BC: 0.000e+00, loss_IC: 2.335e-07,loss_f: 5.468e-07
pinn: 0000, Iter: 400, total_loss: 1.647e-06, loss_BC: 0.000e+00, loss_IC: 2.271e-07,loss_f: 4.989e-07
pinn: 0100, Iter: 400, total_loss: 1.910e-06, loss_BC: 0.000e+00, loss_IC: 2.674e-07,loss_f: 5.945e-07
pinn: 0200, Iter: 500, total_loss: 2.501e-06, loss_BC: 0.000e+00, loss_IC: 2.029e-07,loss_f: 7.267e-07
pinn: 0300, Iter: 500, total_loss: 2.163e-06, loss_BC: 0.000e+00, loss_IC: 9.436e-08,loss_f: 5.581e-07
pinn: 0000, Iter: 500, total_loss: 1.567e-06, loss_BC: 0.000e+00, loss_IC: 1.804e-07,loss_f: 4.618e-07
pinn: 0100, Iter: 500, total_loss: 1.795e-06, loss_BC: 0.000e+00, loss_IC: 2.180e-07,loss_f: 5.315e-07
pinn: 0200, Iter: 600, total_loss: 2.375e-06, loss_BC: 0.000e+00, loss_IC: 1.940e-07,loss_f: 6.651e-07
pinn: 0300, Iter: 600, total_loss: 2.065e-06, loss_BC: 0.000e+00, loss_IC: 5.340e-08,loss_f: 5.426e-07
pinn: 0000, Iter: 600, total_loss: 1.486e-06, loss_BC: 0.000e+00, loss_IC: 1.552e-07,loss_f: 4.161e-07
pinn: 0100, Iter: 600, total_loss: 1.704e-06, loss_BC: 0.000e+00, loss_IC: 1.846e-07,loss_f: 4.757e-07
pinn: 0200, Iter: 700, total_loss: 2.297e-06, loss_BC: 0.000e+00, loss_IC: 1.688e-07,loss_f: 7.021e-07
pinn: 0300, Iter: 700, total_loss: 1.954e-06, loss_BC: 0.000e+00, loss_IC: 4.944e-08,loss_f: 4.985e-07
pinn: 0000, Iter: 700, total_loss: 1.457e-06, loss_BC: 0.000e+00, loss_IC: 1.450e-07,loss_f: 4.120e-07
pinn: 0100, Iter: 700, total_loss: 1.634e-06, loss_BC: 0.000e+00, loss_IC: 1.806e-07,loss_f: 4.176e-07
pinn: 0200, Iter: 800, total_loss: 2.218e-06, loss_BC: 0.000e+00, loss_IC: 1.816e-07,loss_f: 6.911e-07
pinn: 0300, Iter: 800, total_loss: 1.890e-06, loss_BC: 0.000e+00, loss_IC: 5.263e-08,loss_f: 4.842e-07
pinn: 0000, Iter: 800, total_loss: 1.417e-06, loss_BC: 0.000e+00, loss_IC: 1.377e-07,loss_f: 4.092e-07
pinn: 0100, Iter: 800, total_loss: 1.564e-06, loss_BC: 0.000e+00, loss_IC: 1.600e-07,loss_f: 3.713e-07
pinn: 0200, Iter: 900, total_loss: 2.164e-06, loss_BC: 0.000e+00, loss_IC: 1.669e-07,loss_f: 6.922e-07
pinn: 0300, Iter: 900, total_loss: 1.842e-06, loss_BC: 0.000e+00, loss_IC: 5.962e-08,loss_f: 4.659e-07
pinn: 0000, Iter: 900, total_loss: 1.393e-06, loss_BC: 0.000e+00, loss_IC: 1.356e-07,loss_f: 4.009e-07
pinn: 0100, Iter: 900, total_loss: 1.543e-06, loss_BC: 0.000e+00, loss_IC: 1.513e-07,loss_f: 3.595e-07
pinn: 0200, Iter: 1000, total_loss: 2.118e-06, loss_BC: 0.000e+00, loss_IC: 1.659e-07,loss_f: 7.126e-07
pinn: 0300, Iter: 1000, total_loss: 1.770e-06, loss_BC: 0.000e+00, loss_IC: 7.343e-08,loss_f: 4.627e-07
pinn: 0000, Iter: 1000, total_loss: 1.368e-06, loss_BC: 0.000e+00, loss_IC: 1.289e-07,loss_f: 3.939e-07
pinn: 0100, Iter: 1000, total_loss: 1.516e-06, loss_BC: 0.000e+00, loss_IC: 1.445e-07,loss_f: 3.448e-07
pinn: 0200, Iter: 1100, total_loss: 2.027e-06, loss_BC: 0.000e+00, loss_IC: 1.605e-07,loss_f: 7.096e-07
pinn: 0300, Iter: 1100, total_loss: 1.699e-06, loss_BC: 0.000e+00, loss_IC: 7.398e-08,loss_f: 4.745e-07
pinn: 0000, Iter: 1100, total_loss: 1.336e-06, loss_BC: 0.000e+00, loss_IC: 1.250e-07,loss_f: 3.923e-07
pinn: 0100, Iter: 1100, total_loss: 1.480e-06, loss_BC: 0.000e+00, loss_IC: 1.326e-07,loss_f: 3.370e-07
pinn: 0200, Iter: 1200, total_loss: 1.970e-06, loss_BC: 0.000e+00, loss_IC: 1.511e-07,loss_f: 6.988e-07
pinn: 0300, Iter: 1200, total_loss: 1.641e-06, loss_BC: 0.000e+00, loss_IC: 6.970e-08,loss_f: 4.899e-07
pinn: 0000, Iter: 1200, total_loss: 1.324e-06, loss_BC: 0.000e+00, loss_IC: 1.246e-07,loss_f: 3.954e-07
pinn: 0100, Iter: 1200, total_loss: 1.447e-06, loss_BC: 0.000e+00, loss_IC: 1.372e-07,loss_f: 3.297e-07
pinn: 0200, Iter: 1300, total_loss: 1.895e-06, loss_BC: 0.000e+00, loss_IC: 1.436e-07,loss_f: 7.240e-07
pinn: 0300, Iter: 1300, total_loss: 1.613e-06, loss_BC: 0.000e+00, loss_IC: 7.184e-08,loss_f: 5.079e-07
pinn: 0000, Iter: 1300, total_loss: 1.299e-06, loss_BC: 0.000e+00, loss_IC: 1.219e-07,loss_f: 3.966e-07
pinn: 0100, Iter: 1300, total_loss: 1.420e-06, loss_BC: 0.000e+00, loss_IC: 1.341e-07,loss_f: 3.353e-07
pinn: 0200, Iter: 1400, total_loss: 1.858e-06, loss_BC: 0.000e+00, loss_IC: 1.452e-07,loss_f: 6.920e-07
pinn: 0300, Iter: 1400, total_loss: 1.536e-06, loss_BC: 0.000e+00, loss_IC: 7.591e-08,loss_f: 5.273e-07
pinn: 0000, Iter: 1400, total_loss: 1.276e-06, loss_BC: 0.000e+00, loss_IC: 1.209e-07,loss_f: 3.990e-07
pinn: 0100, Iter: 1400, total_loss: 1.372e-06, loss_BC: 0.000e+00, loss_IC: 1.439e-07,loss_f: 3.349e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 321, Mean_loss of pinns: 1.504e-06, loss_BC: 0.000e+00, loss_IC: 1.192e-07, loss_f: 4.896e-07
 => minimum loss: 1.275e-06, corresponding pinn index: 0000
 => maximum loss: 1.839e-06, corresponding pinn  index: 0200

 max_loss: 1.184e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 323, total_loss: 7.848e-06, loss_BC: 6.247e-06, loss_IC: 1.235e-07, loss_f: 5.821e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.04000, t_max: 0.05000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  324 0 1

 -------------------------------------------------------------
  -----  Epoch: 324 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.04000, t_max: 0.05000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  324 !!! 


==> Epoch: 330, Mean_loss of pinns: 2.889e-01, loss_BC: 6.109e-06, loss_IC: 3.844e-07, loss_f: 2.889e-01
 => minimum loss: 1.138e-01, corresponding pinn/batch index: 0100
 => maximum loss: 5.730e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 340, Mean_loss of pinns: 2.355e-01, loss_BC: 6.478e-06, loss_IC: 2.578e-06, loss_f: 2.355e-01
 => minimum loss: 9.019e-02, corresponding pinn/batch index: 0100
 => maximum loss: 4.607e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 350, Mean_loss of pinns: 1.941e-01, loss_BC: 6.398e-06, loss_IC: 6.278e-06, loss_f: 1.941e-01
 => minimum loss: 7.251e-02, corresponding pinn/batch index: 0100
 => maximum loss: 3.744e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 360, Mean_loss of pinns: 1.620e-01, loss_BC: 7.027e-06, loss_IC: 1.109e-05, loss_f: 1.620e-01
 => minimum loss: 5.919e-02, corresponding pinn/batch index: 0100
 => maximum loss: 3.086e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 370, Mean_loss of pinns: 1.370e-01, loss_BC: 7.727e-06, loss_IC: 1.688e-05, loss_f: 1.370e-01
 => minimum loss: 4.898e-02, corresponding pinn/batch index: 0100
 => maximum loss: 2.581e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 380, Mean_loss of pinns: 1.172e-01, loss_BC: 8.043e-06, loss_IC: 2.371e-05, loss_f: 1.172e-01
 => minimum loss: 4.106e-02, corresponding pinn/batch index: 0100
 => maximum loss: 2.185e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 390, Mean_loss of pinns: 1.012e-01, loss_BC: 8.281e-06, loss_IC: 3.161e-05, loss_f: 1.012e-01
 => minimum loss: 3.486e-02, corresponding pinn/batch index: 0100
 => maximum loss: 1.870e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 400, Mean_loss of pinns: 8.817e-02, loss_BC: 8.992e-06, loss_IC: 4.055e-05, loss_f: 8.812e-02
 => minimum loss: 2.996e-02, corresponding pinn/batch index: 0100
 => maximum loss: 1.615e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 410, Mean_loss of pinns: 7.737e-02, loss_BC: 9.282e-06, loss_IC: 5.044e-05, loss_f: 7.731e-02
 => minimum loss: 2.604e-02, corresponding pinn/batch index: 0100
 => maximum loss: 1.405e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 420, Mean_loss of pinns: 6.832e-02, loss_BC: 1.005e-05, loss_IC: 6.116e-05, loss_f: 6.825e-02
 => minimum loss: 2.286e-02, corresponding pinn/batch index: 0100
 => maximum loss: 1.230e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  423

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 3.854e-06, loss_BC: 0.000e+00, loss_IC: 2.833e-07,loss_f: 1.307e-06
pinn: 0200, Iter: 100, total_loss: 1.207e-05, loss_BC: 0.000e+00, loss_IC: 2.477e-06,loss_f: 7.096e-06
pinn: 0300, Iter: 100, total_loss: 1.801e-05, loss_BC: 0.000e+00, loss_IC: 2.492e-06,loss_f: 4.990e-06
pinn: 0100, Iter: 100, total_loss: 3.947e-06, loss_BC: 0.000e+00, loss_IC: 2.566e-07,loss_f: 1.003e-06
pinn: 0000, Iter: 200, total_loss: 2.296e-06, loss_BC: 0.000e+00, loss_IC: 2.222e-07,loss_f: 7.239e-07
pinn: 0100, Iter: 200, total_loss: 3.355e-06, loss_BC: 0.000e+00, loss_IC: 2.533e-07,loss_f: 8.573e-07
pinn: 0200, Iter: 200, total_loss: 3.564e-06, loss_BC: 0.000e+00, loss_IC: 7.043e-07,loss_f: 1.782e-06
pinn: 0300, Iter: 200, total_loss: 5.036e-06, loss_BC: 0.000e+00, loss_IC: 3.847e-07,loss_f: 2.718e-06
pinn: 0000, Iter: 300, total_loss: 2.014e-06, loss_BC: 0.000e+00, loss_IC: 1.778e-07,loss_f: 5.353e-07
pinn: 0100, Iter: 300, total_loss: 2.965e-06, loss_BC: 0.000e+00, loss_IC: 2.009e-07,loss_f: 8.821e-07
pinn: 0300, Iter: 300, total_loss: 3.498e-06, loss_BC: 0.000e+00, loss_IC: 1.964e-07,loss_f: 1.271e-06
pinn: 0200, Iter: 300, total_loss: 2.245e-06, loss_BC: 0.000e+00, loss_IC: 3.857e-07,loss_f: 8.894e-07
pinn: 0000, Iter: 400, total_loss: 1.893e-06, loss_BC: 0.000e+00, loss_IC: 1.669e-07,loss_f: 5.345e-07
pinn: 0100, Iter: 400, total_loss: 2.782e-06, loss_BC: 0.000e+00, loss_IC: 1.620e-07,loss_f: 8.258e-07
pinn: 0300, Iter: 400, total_loss: 3.317e-06, loss_BC: 0.000e+00, loss_IC: 1.710e-07,loss_f: 1.107e-06
pinn: 0200, Iter: 400, total_loss: 1.780e-06, loss_BC: 0.000e+00, loss_IC: 2.611e-07,loss_f: 5.448e-07
pinn: 0000, Iter: 500, total_loss: 1.789e-06, loss_BC: 0.000e+00, loss_IC: 1.493e-07,loss_f: 5.279e-07
pinn: 0100, Iter: 500, total_loss: 2.697e-06, loss_BC: 0.000e+00, loss_IC: 1.609e-07,loss_f: 7.520e-07
pinn: 0300, Iter: 500, total_loss: 3.149e-06, loss_BC: 0.000e+00, loss_IC: 1.274e-07,loss_f: 9.743e-07
pinn: 0200, Iter: 500, total_loss: 1.687e-06, loss_BC: 0.000e+00, loss_IC: 2.040e-07,loss_f: 5.099e-07
pinn: 0000, Iter: 600, total_loss: 1.743e-06, loss_BC: 0.000e+00, loss_IC: 1.359e-07,loss_f: 5.249e-07
pinn: 0100, Iter: 600, total_loss: 2.592e-06, loss_BC: 0.000e+00, loss_IC: 1.442e-07,loss_f: 7.750e-07
pinn: 0200, Iter: 600, total_loss: 1.602e-06, loss_BC: 0.000e+00, loss_IC: 1.655e-07,loss_f: 4.663e-07
pinn: 0300, Iter: 600, total_loss: 3.046e-06, loss_BC: 0.000e+00, loss_IC: 1.310e-07,loss_f: 9.067e-07
pinn: 0000, Iter: 700, total_loss: 1.703e-06, loss_BC: 0.000e+00, loss_IC: 1.294e-07,loss_f: 5.251e-07
pinn: 0100, Iter: 700, total_loss: 2.492e-06, loss_BC: 0.000e+00, loss_IC: 1.473e-07,loss_f: 7.472e-07
pinn: 0300, Iter: 700, total_loss: 2.932e-06, loss_BC: 0.000e+00, loss_IC: 1.343e-07,loss_f: 8.174e-07
pinn: 0200, Iter: 700, total_loss: 1.545e-06, loss_BC: 0.000e+00, loss_IC: 1.555e-07,loss_f: 4.263e-07
pinn: 0000, Iter: 800, total_loss: 1.659e-06, loss_BC: 0.000e+00, loss_IC: 1.340e-07,loss_f: 4.929e-07
pinn: 0100, Iter: 800, total_loss: 2.373e-06, loss_BC: 0.000e+00, loss_IC: 1.270e-07,loss_f: 7.503e-07
pinn: 0200, Iter: 800, total_loss: 1.492e-06, loss_BC: 0.000e+00, loss_IC: 1.334e-07,loss_f: 4.024e-07
pinn: 0300, Iter: 800, total_loss: 2.855e-06, loss_BC: 0.000e+00, loss_IC: 1.453e-07,loss_f: 7.404e-07
pinn: 0000, Iter: 900, total_loss: 1.574e-06, loss_BC: 0.000e+00, loss_IC: 1.314e-07,loss_f: 4.555e-07
pinn: 0100, Iter: 900, total_loss: 2.288e-06, loss_BC: 0.000e+00, loss_IC: 1.492e-07,loss_f: 7.238e-07
pinn: 0200, Iter: 900, total_loss: 1.474e-06, loss_BC: 0.000e+00, loss_IC: 1.246e-07,loss_f: 3.988e-07
pinn: 0300, Iter: 900, total_loss: 2.805e-06, loss_BC: 0.000e+00, loss_IC: 1.570e-07,loss_f: 7.069e-07
pinn: 0000, Iter: 1000, total_loss: 1.520e-06, loss_BC: 0.000e+00, loss_IC: 1.349e-07,loss_f: 4.404e-07
pinn: 0100, Iter: 1000, total_loss: 2.192e-06, loss_BC: 0.000e+00, loss_IC: 1.623e-07,loss_f: 6.501e-07
pinn: 0200, Iter: 1000, total_loss: 1.417e-06, loss_BC: 0.000e+00, loss_IC: 1.117e-07,loss_f: 3.744e-07
pinn: 0300, Iter: 1000, total_loss: 2.711e-06, loss_BC: 0.000e+00, loss_IC: 1.667e-07,loss_f: 6.671e-07
pinn: 0000, Iter: 1100, total_loss: 1.454e-06, loss_BC: 0.000e+00, loss_IC: 1.385e-07,loss_f: 4.368e-07
pinn: 0100, Iter: 1100, total_loss: 2.140e-06, loss_BC: 0.000e+00, loss_IC: 1.496e-07,loss_f: 6.774e-07
pinn: 0300, Iter: 1100, total_loss: 2.594e-06, loss_BC: 0.000e+00, loss_IC: 1.889e-07,loss_f: 6.798e-07
pinn: 0200, Iter: 1100, total_loss: 1.373e-06, loss_BC: 0.000e+00, loss_IC: 1.086e-07,loss_f: 3.573e-07
pinn: 0000, Iter: 1200, total_loss: 1.389e-06, loss_BC: 0.000e+00, loss_IC: 1.364e-07,loss_f: 4.019e-07
pinn: 0100, Iter: 1200, total_loss: 2.052e-06, loss_BC: 0.000e+00, loss_IC: 1.494e-07,loss_f: 6.811e-07
pinn: 0200, Iter: 1200, total_loss: 1.347e-06, loss_BC: 0.000e+00, loss_IC: 1.098e-07,loss_f: 3.512e-07
pinn: 0300, Iter: 1200, total_loss: 2.528e-06, loss_BC: 0.000e+00, loss_IC: 1.974e-07,loss_f: 6.806e-07
pinn: 0000, Iter: 1300, total_loss: 1.358e-06, loss_BC: 0.000e+00, loss_IC: 1.427e-07,loss_f: 4.052e-07
pinn: 0100, Iter: 1300, total_loss: 1.920e-06, loss_BC: 0.000e+00, loss_IC: 1.391e-07,loss_f: 7.175e-07
pinn: 0300, Iter: 1300, total_loss: 2.423e-06, loss_BC: 0.000e+00, loss_IC: 2.097e-07,loss_f: 6.923e-07
pinn: 0200, Iter: 1300, total_loss: 1.304e-06, loss_BC: 0.000e+00, loss_IC: 1.000e-07,loss_f: 3.575e-07
pinn: 0000, Iter: 1400, total_loss: 1.333e-06, loss_BC: 0.000e+00, loss_IC: 1.320e-07,loss_f: 4.010e-07
pinn: 0100, Iter: 1400, total_loss: 1.731e-06, loss_BC: 0.000e+00, loss_IC: 1.022e-07,loss_f: 6.959e-07
pinn: 0300, Iter: 1400, total_loss: 2.235e-06, loss_BC: 0.000e+00, loss_IC: 2.076e-07,loss_f: 7.071e-07
pinn: 0200, Iter: 1400, total_loss: 1.279e-06, loss_BC: 0.000e+00, loss_IC: 1.049e-07,loss_f: 3.491e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 423, Mean_loss of pinns: 1.617e-06, loss_BC: 0.000e+00, loss_IC: 1.424e-07, loss_f: 5.414e-07
 => minimum loss: 1.248e-06, corresponding pinn index: 0200
 => maximum loss: 2.177e-06, corresponding pinn  index: 0300

 max_loss: 1.132e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 425, total_loss: 6.909e-06, loss_BC: 5.212e-06, loss_IC: 1.474e-07, loss_f: 6.152e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.05000, t_max: 0.06000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  426 0 1

 -------------------------------------------------------------
  -----  Epoch: 426 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.05000, t_max: 0.06000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  426 !!! 


==> Epoch: 430, Mean_loss of pinns: 1.214e-01, loss_BC: 5.225e-06, loss_IC: 2.870e-07, loss_f: 1.214e-01
 => minimum loss: 5.753e-02, corresponding pinn/batch index: 0000
 => maximum loss: 2.361e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 440, Mean_loss of pinns: 9.504e-02, loss_BC: 4.991e-06, loss_IC: 3.385e-06, loss_f: 9.503e-02
 => minimum loss: 4.657e-02, corresponding pinn/batch index: 0000
 => maximum loss: 1.822e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 450, Mean_loss of pinns: 7.541e-02, loss_BC: 4.991e-06, loss_IC: 9.425e-06, loss_f: 7.539e-02
 => minimum loss: 3.834e-02, corresponding pinn/batch index: 0000
 => maximum loss: 1.421e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 460, Mean_loss of pinns: 6.092e-02, loss_BC: 4.322e-06, loss_IC: 1.765e-05, loss_f: 6.090e-02
 => minimum loss: 3.198e-02, corresponding pinn/batch index: 0000
 => maximum loss: 1.129e-01, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 470, Mean_loss of pinns: 5.011e-02, loss_BC: 4.990e-06, loss_IC: 2.744e-05, loss_f: 5.008e-02
 => minimum loss: 2.702e-02, corresponding pinn/batch index: 0000
 => maximum loss: 9.167e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 480, Mean_loss of pinns: 4.190e-02, loss_BC: 4.561e-06, loss_IC: 3.837e-05, loss_f: 4.186e-02
 => minimum loss: 2.314e-02, corresponding pinn/batch index: 0000
 => maximum loss: 7.585e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 490, Mean_loss of pinns: 3.556e-02, loss_BC: 4.514e-06, loss_IC: 5.013e-05, loss_f: 3.551e-02
 => minimum loss: 2.008e-02, corresponding pinn/batch index: 0000
 => maximum loss: 6.381e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 500, Mean_loss of pinns: 3.060e-02, loss_BC: 4.957e-06, loss_IC: 6.248e-05, loss_f: 3.053e-02
 => minimum loss: 1.762e-02, corresponding pinn/batch index: 0000
 => maximum loss: 5.447e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 510, Mean_loss of pinns: 2.664e-02, loss_BC: 4.752e-06, loss_IC: 7.520e-05, loss_f: 2.655e-02
 => minimum loss: 1.560e-02, corresponding pinn/batch index: 0000
 => maximum loss: 4.709e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 520, Mean_loss of pinns: 2.343e-02, loss_BC: 4.803e-06, loss_IC: 8.806e-05, loss_f: 2.334e-02
 => minimum loss: 1.394e-02, corresponding pinn/batch index: 0000
 => maximum loss: 4.118e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  525

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 2.568e-06, loss_BC: 0.000e+00, loss_IC: 3.233e-07,loss_f: 1.342e-06
pinn: 0200, Iter: 100, total_loss: 2.577e-06, loss_BC: 0.000e+00, loss_IC: 4.545e-07,loss_f: 9.197e-07
pinn: 0000, Iter: 100, total_loss: 2.842e-06, loss_BC: 0.000e+00, loss_IC: 5.022e-07,loss_f: 8.156e-07
pinn: 0100, Iter: 100, total_loss: 2.344e-06, loss_BC: 0.000e+00, loss_IC: 5.401e-07,loss_f: 9.005e-07
pinn: 0300, Iter: 200, total_loss: 1.776e-06, loss_BC: 0.000e+00, loss_IC: 2.365e-07,loss_f: 7.228e-07
pinn: 0200, Iter: 200, total_loss: 1.947e-06, loss_BC: 0.000e+00, loss_IC: 1.849e-07,loss_f: 5.210e-07
pinn: 0100, Iter: 200, total_loss: 1.789e-06, loss_BC: 0.000e+00, loss_IC: 2.843e-07,loss_f: 5.937e-07
pinn: 0000, Iter: 200, total_loss: 2.118e-06, loss_BC: 0.000e+00, loss_IC: 1.928e-07,loss_f: 5.726e-07
pinn: 0300, Iter: 300, total_loss: 1.628e-06, loss_BC: 0.000e+00, loss_IC: 2.263e-07,loss_f: 5.923e-07
pinn: 0200, Iter: 300, total_loss: 1.851e-06, loss_BC: 0.000e+00, loss_IC: 1.738e-07,loss_f: 4.376e-07
pinn: 0100, Iter: 300, total_loss: 1.636e-06, loss_BC: 0.000e+00, loss_IC: 2.734e-07,loss_f: 4.771e-07
pinn: 0000, Iter: 300, total_loss: 1.767e-06, loss_BC: 0.000e+00, loss_IC: 1.849e-07,loss_f: 5.379e-07
pinn: 0300, Iter: 400, total_loss: 1.529e-06, loss_BC: 0.000e+00, loss_IC: 1.957e-07,loss_f: 5.206e-07
pinn: 0200, Iter: 400, total_loss: 1.742e-06, loss_BC: 0.000e+00, loss_IC: 1.441e-07,loss_f: 3.497e-07
pinn: 0000, Iter: 400, total_loss: 1.477e-06, loss_BC: 0.000e+00, loss_IC: 1.205e-07,loss_f: 5.073e-07
pinn: 0100, Iter: 400, total_loss: 1.529e-06, loss_BC: 0.000e+00, loss_IC: 2.269e-07,loss_f: 4.389e-07
pinn: 0300, Iter: 500, total_loss: 1.375e-06, loss_BC: 0.000e+00, loss_IC: 1.461e-07,loss_f: 4.051e-07
pinn: 0200, Iter: 500, total_loss: 1.715e-06, loss_BC: 0.000e+00, loss_IC: 1.298e-07,loss_f: 3.470e-07
pinn: 0100, Iter: 500, total_loss: 1.446e-06, loss_BC: 0.000e+00, loss_IC: 1.854e-07,loss_f: 4.003e-07
pinn: 0000, Iter: 500, total_loss: 1.385e-06, loss_BC: 0.000e+00, loss_IC: 9.595e-08,loss_f: 5.023e-07
pinn: 0300, Iter: 600, total_loss: 1.281e-06, loss_BC: 0.000e+00, loss_IC: 9.497e-08,loss_f: 3.557e-07
pinn: 0200, Iter: 600, total_loss: 1.686e-06, loss_BC: 0.000e+00, loss_IC: 1.227e-07,loss_f: 3.279e-07
pinn: 0000, Iter: 600, total_loss: 1.312e-06, loss_BC: 0.000e+00, loss_IC: 8.803e-08,loss_f: 4.647e-07
pinn: 0100, Iter: 600, total_loss: 1.388e-06, loss_BC: 0.000e+00, loss_IC: 1.517e-07,loss_f: 3.729e-07
pinn: 0300, Iter: 700, total_loss: 1.229e-06, loss_BC: 0.000e+00, loss_IC: 7.696e-08,loss_f: 3.190e-07
pinn: 0200, Iter: 700, total_loss: 1.644e-06, loss_BC: 0.000e+00, loss_IC: 1.302e-07,loss_f: 3.207e-07
pinn: 0000, Iter: 700, total_loss: 1.261e-06, loss_BC: 0.000e+00, loss_IC: 7.681e-08,loss_f: 4.272e-07
pinn: 0100, Iter: 700, total_loss: 1.340e-06, loss_BC: 0.000e+00, loss_IC: 1.413e-07,loss_f: 3.435e-07
pinn: 0300, Iter: 800, total_loss: 1.174e-06, loss_BC: 0.000e+00, loss_IC: 7.091e-08,loss_f: 2.996e-07
pinn: 0200, Iter: 800, total_loss: 1.612e-06, loss_BC: 0.000e+00, loss_IC: 1.359e-07,loss_f: 3.198e-07
pinn: 0100, Iter: 800, total_loss: 1.317e-06, loss_BC: 0.000e+00, loss_IC: 1.394e-07,loss_f: 3.322e-07
pinn: 0000, Iter: 800, total_loss: 1.216e-06, loss_BC: 0.000e+00, loss_IC: 5.580e-08,loss_f: 4.183e-07
pinn: 0300, Iter: 900, total_loss: 1.147e-06, loss_BC: 0.000e+00, loss_IC: 7.054e-08,loss_f: 2.921e-07
pinn: 0200, Iter: 900, total_loss: 1.569e-06, loss_BC: 0.000e+00, loss_IC: 1.407e-07,loss_f: 3.383e-07
pinn: 0000, Iter: 900, total_loss: 1.193e-06, loss_BC: 0.000e+00, loss_IC: 5.678e-08,loss_f: 3.933e-07
pinn: 0100, Iter: 900, total_loss: 1.290e-06, loss_BC: 0.000e+00, loss_IC: 1.347e-07,loss_f: 3.136e-07
pinn: 0300, Iter: 1000, total_loss: 1.126e-06, loss_BC: 0.000e+00, loss_IC: 7.292e-08,loss_f: 2.898e-07
pinn: 0200, Iter: 1000, total_loss: 1.525e-06, loss_BC: 0.000e+00, loss_IC: 1.428e-07,loss_f: 3.556e-07
pinn: 0000, Iter: 1000, total_loss: 1.130e-06, loss_BC: 0.000e+00, loss_IC: 6.007e-08,loss_f: 3.703e-07
pinn: 0100, Iter: 1000, total_loss: 1.262e-06, loss_BC: 0.000e+00, loss_IC: 1.333e-07,loss_f: 2.991e-07
pinn: 0300, Iter: 1100, total_loss: 1.109e-06, loss_BC: 0.000e+00, loss_IC: 7.266e-08,loss_f: 2.894e-07
pinn: 0200, Iter: 1100, total_loss: 1.466e-06, loss_BC: 0.000e+00, loss_IC: 1.502e-07,loss_f: 3.861e-07
pinn: 0000, Iter: 1100, total_loss: 1.109e-06, loss_BC: 0.000e+00, loss_IC: 5.810e-08,loss_f: 3.473e-07
pinn: 0100, Iter: 1100, total_loss: 1.247e-06, loss_BC: 0.000e+00, loss_IC: 1.358e-07,loss_f: 2.766e-07
pinn: 0300, Iter: 1200, total_loss: 1.093e-06, loss_BC: 0.000e+00, loss_IC: 7.341e-08,loss_f: 2.891e-07
pinn: 0200, Iter: 1200, total_loss: 1.440e-06, loss_BC: 0.000e+00, loss_IC: 1.540e-07,loss_f: 3.712e-07
pinn: 0000, Iter: 1200, total_loss: 1.093e-06, loss_BC: 0.000e+00, loss_IC: 5.835e-08,loss_f: 3.485e-07
pinn: 0100, Iter: 1200, total_loss: 1.280e-06, loss_BC: 0.000e+00, loss_IC: 1.464e-07,loss_f: 3.285e-07
pinn: 0300, Iter: 1300, total_loss: 1.069e-06, loss_BC: 0.000e+00, loss_IC: 7.088e-08,loss_f: 3.001e-07
pinn: 0200, Iter: 1300, total_loss: 1.387e-06, loss_BC: 0.000e+00, loss_IC: 1.652e-07,loss_f: 4.002e-07
pinn: 0100, Iter: 1300, total_loss: 1.191e-06, loss_BC: 0.000e+00, loss_IC: 1.331e-07,loss_f: 2.593e-07
pinn: 0000, Iter: 1300, total_loss: 1.075e-06, loss_BC: 0.000e+00, loss_IC: 5.906e-08,loss_f: 3.420e-07
pinn: 0300, Iter: 1400, total_loss: 1.057e-06, loss_BC: 0.000e+00, loss_IC: 6.766e-08,loss_f: 3.006e-07
pinn: 0200, Iter: 1400, total_loss: 1.346e-06, loss_BC: 0.000e+00, loss_IC: 1.647e-07,loss_f: 4.136e-07
pinn: 0100, Iter: 1400, total_loss: 1.154e-06, loss_BC: 0.000e+00, loss_IC: 1.385e-07,loss_f: 2.467e-07
pinn: 0000, Iter: 1400, total_loss: 1.040e-06, loss_BC: 0.000e+00, loss_IC: 5.790e-08,loss_f: 3.487e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 525, Mean_loss of pinns: 1.142e-06, loss_BC: 0.000e+00, loss_IC: 1.057e-07, loss_f: 3.326e-07
 => minimum loss: 1.037e-06, corresponding pinn index: 0000
 => maximum loss: 1.332e-06, corresponding pinn  index: 0200

 max_loss: 1.274e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 527, total_loss: 6.572e-06, loss_BC: 5.356e-06, loss_IC: 1.095e-07, loss_f: 4.030e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.06000, t_max: 0.07000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  528 0 1

 -------------------------------------------------------------
  -----  Epoch: 528 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.06000, t_max: 0.07000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  528 !!! 


==> Epoch: 530, Mean_loss of pinns: 8.598e-02, loss_BC: 5.723e-06, loss_IC: 6.731e-08, loss_f: 8.597e-02
 => minimum loss: 6.567e-02, corresponding pinn/batch index: 0100
 => maximum loss: 1.073e-01, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 540, Mean_loss of pinns: 6.785e-02, loss_BC: 5.842e-06, loss_IC: 2.221e-06, loss_f: 6.784e-02
 => minimum loss: 5.018e-02, corresponding pinn/batch index: 0100
 => maximum loss: 8.780e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 550, Mean_loss of pinns: 5.465e-02, loss_BC: 5.968e-06, loss_IC: 6.772e-06, loss_f: 5.463e-02
 => minimum loss: 3.920e-02, corresponding pinn/batch index: 0100
 => maximum loss: 7.264e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 560, Mean_loss of pinns: 4.496e-02, loss_BC: 6.148e-06, loss_IC: 1.298e-05, loss_f: 4.494e-02
 => minimum loss: 3.129e-02, corresponding pinn/batch index: 0100
 => maximum loss: 6.092e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 570, Mean_loss of pinns: 3.758e-02, loss_BC: 6.622e-06, loss_IC: 2.024e-05, loss_f: 3.755e-02
 => minimum loss: 2.540e-02, corresponding pinn/batch index: 0100
 => maximum loss: 5.173e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 580, Mean_loss of pinns: 3.185e-02, loss_BC: 6.826e-06, loss_IC: 2.815e-05, loss_f: 3.181e-02
 => minimum loss: 2.098e-02, corresponding pinn/batch index: 0100
 => maximum loss: 4.440e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 590, Mean_loss of pinns: 2.735e-02, loss_BC: 7.311e-06, loss_IC: 3.649e-05, loss_f: 2.731e-02
 => minimum loss: 1.764e-02, corresponding pinn/batch index: 0100
 => maximum loss: 3.853e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 600, Mean_loss of pinns: 2.379e-02, loss_BC: 7.572e-06, loss_IC: 4.511e-05, loss_f: 2.374e-02
 => minimum loss: 1.509e-02, corresponding pinn/batch index: 0100
 => maximum loss: 3.378e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 610, Mean_loss of pinns: 2.092e-02, loss_BC: 7.704e-06, loss_IC: 5.384e-05, loss_f: 2.086e-02
 => minimum loss: 1.309e-02, corresponding pinn/batch index: 0100
 => maximum loss: 2.988e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 620, Mean_loss of pinns: 1.857e-02, loss_BC: 7.611e-06, loss_IC: 6.247e-05, loss_f: 1.850e-02
 => minimum loss: 1.150e-02, corresponding pinn/batch index: 0100
 => maximum loss: 2.664e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  627

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.879e-06, loss_BC: 0.000e+00, loss_IC: 5.096e-07,loss_f: 6.034e-07
pinn: 0000, Iter: 100, total_loss: 2.498e-06, loss_BC: 0.000e+00, loss_IC: 2.098e-07,loss_f: 8.359e-07
pinn: 0200, Iter: 100, total_loss: 2.214e-06, loss_BC: 0.000e+00, loss_IC: 5.643e-07,loss_f: 9.818e-07
pinn: 0300, Iter: 100, total_loss: 1.989e-06, loss_BC: 0.000e+00, loss_IC: 4.163e-07,loss_f: 6.077e-07
pinn: 0000, Iter: 200, total_loss: 2.177e-06, loss_BC: 0.000e+00, loss_IC: 1.896e-07,loss_f: 5.252e-07
pinn: 0100, Iter: 200, total_loss: 1.377e-06, loss_BC: 0.000e+00, loss_IC: 1.993e-07,loss_f: 4.130e-07
pinn: 0200, Iter: 200, total_loss: 1.606e-06, loss_BC: 0.000e+00, loss_IC: 1.927e-07,loss_f: 7.261e-07
pinn: 0300, Iter: 200, total_loss: 1.526e-06, loss_BC: 0.000e+00, loss_IC: 1.432e-07,loss_f: 3.977e-07
pinn: 0100, Iter: 300, total_loss: 1.313e-06, loss_BC: 0.000e+00, loss_IC: 2.097e-07,loss_f: 3.439e-07
pinn: 0000, Iter: 300, total_loss: 2.069e-06, loss_BC: 0.000e+00, loss_IC: 1.790e-07,loss_f: 4.512e-07
pinn: 0200, Iter: 300, total_loss: 1.480e-06, loss_BC: 0.000e+00, loss_IC: 2.003e-07,loss_f: 5.863e-07
pinn: 0300, Iter: 300, total_loss: 1.485e-06, loss_BC: 0.000e+00, loss_IC: 1.424e-07,loss_f: 3.617e-07
pinn: 0000, Iter: 400, total_loss: 1.957e-06, loss_BC: 0.000e+00, loss_IC: 1.574e-07,loss_f: 3.729e-07
pinn: 0100, Iter: 400, total_loss: 1.262e-06, loss_BC: 0.000e+00, loss_IC: 1.887e-07,loss_f: 3.106e-07
pinn: 0200, Iter: 400, total_loss: 1.388e-06, loss_BC: 0.000e+00, loss_IC: 1.772e-07,loss_f: 5.061e-07
pinn: 0300, Iter: 400, total_loss: 1.441e-06, loss_BC: 0.000e+00, loss_IC: 1.436e-07,loss_f: 3.229e-07
pinn: 0000, Iter: 500, total_loss: 1.911e-06, loss_BC: 0.000e+00, loss_IC: 1.346e-07,loss_f: 3.747e-07
pinn: 0100, Iter: 500, total_loss: 1.208e-06, loss_BC: 0.000e+00, loss_IC: 1.515e-07,loss_f: 2.878e-07
pinn: 0200, Iter: 500, total_loss: 1.271e-06, loss_BC: 0.000e+00, loss_IC: 1.117e-07,loss_f: 4.120e-07
pinn: 0300, Iter: 500, total_loss: 1.392e-06, loss_BC: 0.000e+00, loss_IC: 1.245e-07,loss_f: 3.004e-07
pinn: 0100, Iter: 600, total_loss: 1.166e-06, loss_BC: 0.000e+00, loss_IC: 1.331e-07,loss_f: 2.613e-07
pinn: 0000, Iter: 600, total_loss: 1.814e-06, loss_BC: 0.000e+00, loss_IC: 1.288e-07,loss_f: 3.334e-07
pinn: 0200, Iter: 600, total_loss: 1.228e-06, loss_BC: 0.000e+00, loss_IC: 9.874e-08,loss_f: 3.608e-07
pinn: 0300, Iter: 600, total_loss: 1.363e-06, loss_BC: 0.000e+00, loss_IC: 1.134e-07,loss_f: 2.895e-07
pinn: 0100, Iter: 700, total_loss: 1.137e-06, loss_BC: 0.000e+00, loss_IC: 1.222e-07,loss_f: 2.490e-07
pinn: 0000, Iter: 700, total_loss: 1.706e-06, loss_BC: 0.000e+00, loss_IC: 1.307e-07,loss_f: 3.127e-07
pinn: 0200, Iter: 700, total_loss: 1.190e-06, loss_BC: 0.000e+00, loss_IC: 9.539e-08,loss_f: 3.383e-07
pinn: 0300, Iter: 700, total_loss: 1.306e-06, loss_BC: 0.000e+00, loss_IC: 1.145e-07,loss_f: 2.650e-07
pinn: 0100, Iter: 800, total_loss: 1.118e-06, loss_BC: 0.000e+00, loss_IC: 1.156e-07,loss_f: 2.466e-07
pinn: 0000, Iter: 800, total_loss: 1.605e-06, loss_BC: 0.000e+00, loss_IC: 1.432e-07,loss_f: 3.327e-07
pinn: 0200, Iter: 800, total_loss: 1.176e-06, loss_BC: 0.000e+00, loss_IC: 8.984e-08,loss_f: 3.336e-07
pinn: 0300, Iter: 800, total_loss: 1.276e-06, loss_BC: 0.000e+00, loss_IC: 1.170e-07,loss_f: 2.570e-07
pinn: 0100, Iter: 900, total_loss: 1.093e-06, loss_BC: 0.000e+00, loss_IC: 1.111e-07,loss_f: 2.444e-07
pinn: 0000, Iter: 900, total_loss: 1.516e-06, loss_BC: 0.000e+00, loss_IC: 1.522e-07,loss_f: 3.080e-07
pinn: 0200, Iter: 900, total_loss: 1.165e-06, loss_BC: 0.000e+00, loss_IC: 8.943e-08,loss_f: 3.257e-07
pinn: 0300, Iter: 900, total_loss: 1.262e-06, loss_BC: 0.000e+00, loss_IC: 1.155e-07,loss_f: 2.581e-07
pinn: 0100, Iter: 1000, total_loss: 1.077e-06, loss_BC: 0.000e+00, loss_IC: 1.103e-07,loss_f: 2.491e-07
pinn: 0000, Iter: 1000, total_loss: 1.471e-06, loss_BC: 0.000e+00, loss_IC: 1.589e-07,loss_f: 3.107e-07
pinn: 0200, Iter: 1000, total_loss: 1.145e-06, loss_BC: 0.000e+00, loss_IC: 9.015e-08,loss_f: 3.247e-07
pinn: 0300, Iter: 1000, total_loss: 1.234e-06, loss_BC: 0.000e+00, loss_IC: 1.178e-07,loss_f: 2.536e-07
pinn: 0100, Iter: 1100, total_loss: 1.010e-06, loss_BC: 0.000e+00, loss_IC: 1.208e-07,loss_f: 2.503e-07
pinn: 0000, Iter: 1100, total_loss: 1.422e-06, loss_BC: 0.000e+00, loss_IC: 1.789e-07,loss_f: 3.263e-07
pinn: 0200, Iter: 1100, total_loss: 1.120e-06, loss_BC: 0.000e+00, loss_IC: 8.770e-08,loss_f: 3.183e-07
pinn: 0300, Iter: 1100, total_loss: 1.225e-06, loss_BC: 0.000e+00, loss_IC: 1.185e-07,loss_f: 2.563e-07
pinn: 0000, Iter: 1200, total_loss: 1.392e-06, loss_BC: 0.000e+00, loss_IC: 1.710e-07,loss_f: 3.197e-07
pinn: 0100, Iter: 1200, total_loss: 9.964e-07, loss_BC: 0.000e+00, loss_IC: 1.254e-07,loss_f: 2.566e-07
pinn: 0200, Iter: 1200, total_loss: 1.101e-06, loss_BC: 0.000e+00, loss_IC: 8.787e-08,loss_f: 3.164e-07
pinn: 0300, Iter: 1200, total_loss: 1.207e-06, loss_BC: 0.000e+00, loss_IC: 1.264e-07,loss_f: 2.564e-07
pinn: 0000, Iter: 1300, total_loss: 1.319e-06, loss_BC: 0.000e+00, loss_IC: 1.979e-07,loss_f: 3.120e-07
pinn: 0100, Iter: 1300, total_loss: 9.772e-07, loss_BC: 0.000e+00, loss_IC: 1.205e-07,loss_f: 2.589e-07
pinn: 0200, Iter: 1300, total_loss: 1.089e-06, loss_BC: 0.000e+00, loss_IC: 8.589e-08,loss_f: 3.171e-07
pinn: 0300, Iter: 1300, total_loss: 1.161e-06, loss_BC: 0.000e+00, loss_IC: 1.428e-07,loss_f: 2.850e-07
pinn: 0000, Iter: 1400, total_loss: 1.249e-06, loss_BC: 0.000e+00, loss_IC: 2.090e-07,loss_f: 3.354e-07
pinn: 0100, Iter: 1400, total_loss: 9.600e-07, loss_BC: 0.000e+00, loss_IC: 1.251e-07,loss_f: 2.518e-07
pinn: 0200, Iter: 1400, total_loss: 1.080e-06, loss_BC: 0.000e+00, loss_IC: 8.322e-08,loss_f: 3.202e-07
pinn: 0300, Iter: 1400, total_loss: 1.143e-06, loss_BC: 0.000e+00, loss_IC: 1.358e-07,loss_f: 2.758e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 627, Mean_loss of pinns: 1.102e-06, loss_BC: 0.000e+00, loss_IC: 1.385e-07, loss_f: 2.904e-07
 => minimum loss: 9.569e-07, corresponding pinn index: 0100
 => maximum loss: 1.231e-06, corresponding pinn  index: 0000

 max_loss: 1.379e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 629, total_loss: 6.973e-06, loss_BC: 5.818e-06, loss_IC: 1.407e-07, loss_f: 3.409e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.07000, t_max: 0.08000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  630 0 1

 -------------------------------------------------------------
  -----  Epoch: 630 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.07000, t_max: 0.08000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  630 !!! 


==> Epoch: 630, Mean_loss of pinns: 5.523e-02, loss_BC: 5.969e-06, loss_IC: 0.000e+00, loss_f: 5.523e-02
 => minimum loss: 2.779e-02, corresponding pinn/batch index: 0000
 => maximum loss: 9.286e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 640, Mean_loss of pinns: 4.259e-02, loss_BC: 6.377e-06, loss_IC: 1.660e-06, loss_f: 4.258e-02
 => minimum loss: 2.282e-02, corresponding pinn/batch index: 0000
 => maximum loss: 7.399e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 650, Mean_loss of pinns: 3.369e-02, loss_BC: 6.807e-06, loss_IC: 6.367e-06, loss_f: 3.367e-02
 => minimum loss: 1.830e-02, corresponding pinn/batch index: 0100
 => maximum loss: 5.970e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 660, Mean_loss of pinns: 2.729e-02, loss_BC: 7.061e-06, loss_IC: 1.307e-05, loss_f: 2.727e-02
 => minimum loss: 1.459e-02, corresponding pinn/batch index: 0100
 => maximum loss: 4.898e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 670, Mean_loss of pinns: 2.252e-02, loss_BC: 7.044e-06, loss_IC: 2.084e-05, loss_f: 2.249e-02
 => minimum loss: 1.183e-02, corresponding pinn/batch index: 0100
 => maximum loss: 4.080e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 680, Mean_loss of pinns: 1.887e-02, loss_BC: 7.077e-06, loss_IC: 2.906e-05, loss_f: 1.884e-02
 => minimum loss: 9.818e-03, corresponding pinn/batch index: 0100
 => maximum loss: 3.442e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 690, Mean_loss of pinns: 1.606e-02, loss_BC: 7.086e-06, loss_IC: 3.737e-05, loss_f: 1.602e-02
 => minimum loss: 8.323e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.940e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 700, Mean_loss of pinns: 1.386e-02, loss_BC: 6.680e-06, loss_IC: 4.559e-05, loss_f: 1.381e-02
 => minimum loss: 7.177e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.540e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 710, Mean_loss of pinns: 1.210e-02, loss_BC: 6.326e-06, loss_IC: 5.357e-05, loss_f: 1.204e-02
 => minimum loss: 6.282e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.219e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 720, Mean_loss of pinns: 1.068e-02, loss_BC: 6.277e-06, loss_IC: 6.111e-05, loss_f: 1.061e-02
 => minimum loss: 5.564e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.957e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  729

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 2.671e-06, loss_BC: 0.000e+00, loss_IC: 5.678e-07,loss_f: 8.649e-07
pinn: 0300, Iter: 100, total_loss: 1.316e-06, loss_BC: 0.000e+00, loss_IC: 4.331e-07,loss_f: 5.175e-07
pinn: 0100, Iter: 100, total_loss: 1.596e-06, loss_BC: 0.000e+00, loss_IC: 2.513e-07,loss_f: 5.822e-07
pinn: 0000, Iter: 100, total_loss: 2.066e-06, loss_BC: 0.000e+00, loss_IC: 6.004e-07,loss_f: 8.497e-07
pinn: 0200, Iter: 200, total_loss: 1.841e-06, loss_BC: 0.000e+00, loss_IC: 1.313e-07,loss_f: 4.441e-07
pinn: 0100, Iter: 200, total_loss: 1.275e-06, loss_BC: 0.000e+00, loss_IC: 1.254e-07,loss_f: 3.815e-07
pinn: 0300, Iter: 200, total_loss: 8.483e-07, loss_BC: 0.000e+00, loss_IC: 1.028e-07,loss_f: 3.784e-07
pinn: 0000, Iter: 200, total_loss: 1.307e-06, loss_BC: 0.000e+00, loss_IC: 1.017e-07,loss_f: 5.526e-07
pinn: 0200, Iter: 300, total_loss: 1.720e-06, loss_BC: 0.000e+00, loss_IC: 1.319e-07,loss_f: 3.448e-07
pinn: 0100, Iter: 300, total_loss: 1.211e-06, loss_BC: 0.000e+00, loss_IC: 1.306e-07,loss_f: 3.199e-07
pinn: 0300, Iter: 300, total_loss: 7.509e-07, loss_BC: 0.000e+00, loss_IC: 1.003e-07,loss_f: 2.851e-07
pinn: 0000, Iter: 300, total_loss: 1.197e-06, loss_BC: 0.000e+00, loss_IC: 1.068e-07,loss_f: 4.531e-07
pinn: 0200, Iter: 400, total_loss: 1.674e-06, loss_BC: 0.000e+00, loss_IC: 1.351e-07,loss_f: 3.099e-07
pinn: 0100, Iter: 400, total_loss: 1.182e-06, loss_BC: 0.000e+00, loss_IC: 1.308e-07,loss_f: 2.928e-07
pinn: 0300, Iter: 400, total_loss: 7.177e-07, loss_BC: 0.000e+00, loss_IC: 1.004e-07,loss_f: 2.532e-07
pinn: 0000, Iter: 400, total_loss: 1.133e-06, loss_BC: 0.000e+00, loss_IC: 1.118e-07,loss_f: 3.887e-07
pinn: 0200, Iter: 500, total_loss: 1.612e-06, loss_BC: 0.000e+00, loss_IC: 1.373e-07,loss_f: 2.732e-07
pinn: 0300, Iter: 500, total_loss: 7.061e-07, loss_BC: 0.000e+00, loss_IC: 9.601e-08,loss_f: 2.463e-07
pinn: 0100, Iter: 500, total_loss: 1.160e-06, loss_BC: 0.000e+00, loss_IC: 1.224e-07,loss_f: 2.799e-07
pinn: 0000, Iter: 500, total_loss: 1.076e-06, loss_BC: 0.000e+00, loss_IC: 1.002e-07,loss_f: 3.476e-07
pinn: 0200, Iter: 600, total_loss: 1.560e-06, loss_BC: 0.000e+00, loss_IC: 1.501e-07,loss_f: 2.512e-07
pinn: 0300, Iter: 600, total_loss: 6.812e-07, loss_BC: 0.000e+00, loss_IC: 8.503e-08,loss_f: 2.326e-07
pinn: 0100, Iter: 600, total_loss: 1.127e-06, loss_BC: 0.000e+00, loss_IC: 1.115e-07,loss_f: 2.557e-07
pinn: 0000, Iter: 600, total_loss: 1.015e-06, loss_BC: 0.000e+00, loss_IC: 7.080e-08,loss_f: 3.160e-07
pinn: 0200, Iter: 700, total_loss: 1.514e-06, loss_BC: 0.000e+00, loss_IC: 1.657e-07,loss_f: 2.383e-07
pinn: 0300, Iter: 700, total_loss: 6.575e-07, loss_BC: 0.000e+00, loss_IC: 7.292e-08,loss_f: 2.220e-07
pinn: 0100, Iter: 700, total_loss: 1.094e-06, loss_BC: 0.000e+00, loss_IC: 1.046e-07,loss_f: 2.366e-07
pinn: 0000, Iter: 700, total_loss: 9.493e-07, loss_BC: 0.000e+00, loss_IC: 6.410e-08,loss_f: 2.813e-07
pinn: 0200, Iter: 800, total_loss: 1.477e-06, loss_BC: 0.000e+00, loss_IC: 1.815e-07,loss_f: 2.376e-07
pinn: 0300, Iter: 800, total_loss: 6.444e-07, loss_BC: 0.000e+00, loss_IC: 6.972e-08,loss_f: 2.127e-07
pinn: 0100, Iter: 800, total_loss: 1.071e-06, loss_BC: 0.000e+00, loss_IC: 1.109e-07,loss_f: 2.155e-07
pinn: 0000, Iter: 800, total_loss: 9.244e-07, loss_BC: 0.000e+00, loss_IC: 6.579e-08,loss_f: 2.615e-07
pinn: 0200, Iter: 900, total_loss: 1.452e-06, loss_BC: 0.000e+00, loss_IC: 1.824e-07,loss_f: 2.380e-07
pinn: 0300, Iter: 900, total_loss: 6.341e-07, loss_BC: 0.000e+00, loss_IC: 6.832e-08,loss_f: 2.056e-07
pinn: 0100, Iter: 900, total_loss: 1.045e-06, loss_BC: 0.000e+00, loss_IC: 1.087e-07,loss_f: 2.047e-07
pinn: 0000, Iter: 900, total_loss: 9.047e-07, loss_BC: 0.000e+00, loss_IC: 6.324e-08,loss_f: 2.482e-07
pinn: 0200, Iter: 1000, total_loss: 1.404e-06, loss_BC: 0.000e+00, loss_IC: 1.848e-07,loss_f: 2.553e-07
pinn: 0300, Iter: 1000, total_loss: 6.292e-07, loss_BC: 0.000e+00, loss_IC: 6.886e-08,loss_f: 2.010e-07
pinn: 0100, Iter: 1000, total_loss: 1.021e-06, loss_BC: 0.000e+00, loss_IC: 1.110e-07,loss_f: 1.959e-07
pinn: 0000, Iter: 1000, total_loss: 8.844e-07, loss_BC: 0.000e+00, loss_IC: 6.701e-08,loss_f: 2.271e-07
pinn: 0200, Iter: 1100, total_loss: 1.355e-06, loss_BC: 0.000e+00, loss_IC: 1.986e-07,loss_f: 2.639e-07
pinn: 0300, Iter: 1100, total_loss: 6.230e-07, loss_BC: 0.000e+00, loss_IC: 6.773e-08,loss_f: 1.968e-07
pinn: 0100, Iter: 1100, total_loss: 1.010e-06, loss_BC: 0.000e+00, loss_IC: 1.120e-07,loss_f: 1.912e-07
pinn: 0000, Iter: 1100, total_loss: 8.728e-07, loss_BC: 0.000e+00, loss_IC: 6.624e-08,loss_f: 2.281e-07
pinn: 0200, Iter: 1200, total_loss: 1.319e-06, loss_BC: 0.000e+00, loss_IC: 2.097e-07,loss_f: 2.779e-07
pinn: 0300, Iter: 1200, total_loss: 6.177e-07, loss_BC: 0.000e+00, loss_IC: 6.843e-08,loss_f: 1.924e-07
pinn: 0100, Iter: 1200, total_loss: 9.742e-07, loss_BC: 0.000e+00, loss_IC: 1.142e-07,loss_f: 1.882e-07
pinn: 0000, Iter: 1200, total_loss: 8.510e-07, loss_BC: 0.000e+00, loss_IC: 6.601e-08,loss_f: 2.130e-07
pinn: 0200, Iter: 1300, total_loss: 1.287e-06, loss_BC: 0.000e+00, loss_IC: 2.170e-07,loss_f: 2.904e-07
pinn: 0300, Iter: 1300, total_loss: 6.140e-07, loss_BC: 0.000e+00, loss_IC: 6.769e-08,loss_f: 1.913e-07
pinn: 0100, Iter: 1300, total_loss: 9.427e-07, loss_BC: 0.000e+00, loss_IC: 1.155e-07,loss_f: 1.953e-07
pinn: 0000, Iter: 1300, total_loss: 8.383e-07, loss_BC: 0.000e+00, loss_IC: 6.713e-08,loss_f: 2.045e-07
pinn: 0200, Iter: 1400, total_loss: 1.249e-06, loss_BC: 0.000e+00, loss_IC: 2.465e-07,loss_f: 2.917e-07
pinn: 0300, Iter: 1400, total_loss: 6.119e-07, loss_BC: 0.000e+00, loss_IC: 6.746e-08,loss_f: 1.902e-07
pinn: 0100, Iter: 1400, total_loss: 9.318e-07, loss_BC: 0.000e+00, loss_IC: 1.160e-07,loss_f: 1.913e-07
pinn: 0000, Iter: 1400, total_loss: 8.276e-07, loss_BC: 0.000e+00, loss_IC: 6.434e-08,loss_f: 2.045e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 729, Mean_loss of pinns: 9.012e-07, loss_BC: 0.000e+00, loss_IC: 1.224e-07, loss_f: 2.199e-07
 => minimum loss: 6.116e-07, corresponding pinn index: 0300
 => maximum loss: 1.240e-06, corresponding pinn  index: 0200

==> Epoch: 730, Mean_loss of pinns: 8.120e-06, loss_BC: 7.219e-06, loss_IC: 1.224e-07, loss_f: 2.199e-07
 => minimum loss: 2.819e-06, corresponding pinn/batch index: 0200
 => maximum loss: 1.762e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 1.735e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 731, total_loss: 8.105e-06, loss_BC: 7.163e-06, loss_IC: 1.243e-07, loss_f: 2.589e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.08000, t_max: 0.09000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  732 0 1

 -------------------------------------------------------------
  -----  Epoch: 732 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.08000, t_max: 0.09000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  732 !!! 


==> Epoch: 740, Mean_loss of pinns: 3.544e-02, loss_BC: 8.546e-06, loss_IC: 8.811e-07, loss_f: 3.543e-02
 => minimum loss: 1.703e-02, corresponding pinn/batch index: 0100
 => maximum loss: 5.016e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 750, Mean_loss of pinns: 2.822e-02, loss_BC: 9.612e-06, loss_IC: 4.471e-06, loss_f: 2.820e-02
 => minimum loss: 1.293e-02, corresponding pinn/batch index: 0100
 => maximum loss: 4.075e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 760, Mean_loss of pinns: 2.309e-02, loss_BC: 1.013e-05, loss_IC: 1.013e-05, loss_f: 2.307e-02
 => minimum loss: 1.016e-02, corresponding pinn/batch index: 0100
 => maximum loss: 3.499e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 770, Mean_loss of pinns: 1.920e-02, loss_BC: 1.061e-05, loss_IC: 1.679e-05, loss_f: 1.917e-02
 => minimum loss: 8.108e-03, corresponding pinn/batch index: 0100
 => maximum loss: 3.028e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 780, Mean_loss of pinns: 1.622e-02, loss_BC: 1.091e-05, loss_IC: 2.375e-05, loss_f: 1.618e-02
 => minimum loss: 6.666e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.645e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 790, Mean_loss of pinns: 1.391e-02, loss_BC: 1.112e-05, loss_IC: 3.064e-05, loss_f: 1.387e-02
 => minimum loss: 5.612e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.331e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 800, Mean_loss of pinns: 1.210e-02, loss_BC: 1.117e-05, loss_IC: 3.732e-05, loss_f: 1.205e-02
 => minimum loss: 4.825e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.072e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 810, Mean_loss of pinns: 1.064e-02, loss_BC: 1.099e-05, loss_IC: 4.359e-05, loss_f: 1.059e-02
 => minimum loss: 4.221e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.853e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 820, Mean_loss of pinns: 9.452e-03, loss_BC: 1.055e-05, loss_IC: 4.924e-05, loss_f: 9.391e-03
 => minimum loss: 3.743e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.668e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 830, Mean_loss of pinns: 8.462e-03, loss_BC: 1.019e-05, loss_IC: 5.413e-05, loss_f: 8.397e-03
 => minimum loss: 3.353e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.509e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  831

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.302e-06, loss_BC: 0.000e+00, loss_IC: 1.214e-07,loss_f: 4.049e-07
pinn: 0300, Iter: 100, total_loss: 2.082e-06, loss_BC: 0.000e+00, loss_IC: 3.244e-07,loss_f: 5.931e-07
pinn: 0000, Iter: 100, total_loss: 1.814e-06, loss_BC: 0.000e+00, loss_IC: 6.487e-07,loss_f: 9.522e-07
pinn: 0200, Iter: 100, total_loss: 1.838e-06, loss_BC: 0.000e+00, loss_IC: 3.470e-07,loss_f: 6.669e-07
pinn: 0100, Iter: 200, total_loss: 1.087e-06, loss_BC: 0.000e+00, loss_IC: 1.209e-07,loss_f: 2.136e-07
pinn: 0300, Iter: 200, total_loss: 1.756e-06, loss_BC: 0.000e+00, loss_IC: 1.055e-07,loss_f: 4.999e-07
pinn: 0000, Iter: 200, total_loss: 8.711e-07, loss_BC: 0.000e+00, loss_IC: 1.474e-07,loss_f: 5.033e-07
pinn: 0200, Iter: 200, total_loss: 1.352e-06, loss_BC: 0.000e+00, loss_IC: 1.186e-07,loss_f: 3.809e-07
pinn: 0100, Iter: 300, total_loss: 1.061e-06, loss_BC: 0.000e+00, loss_IC: 1.219e-07,loss_f: 1.898e-07
pinn: 0300, Iter: 300, total_loss: 1.610e-06, loss_BC: 0.000e+00, loss_IC: 1.258e-07,loss_f: 3.491e-07
pinn: 0200, Iter: 300, total_loss: 1.256e-06, loss_BC: 0.000e+00, loss_IC: 1.069e-07,loss_f: 3.172e-07
pinn: 0000, Iter: 300, total_loss: 7.399e-07, loss_BC: 0.000e+00, loss_IC: 1.235e-07,loss_f: 3.944e-07
pinn: 0100, Iter: 400, total_loss: 1.047e-06, loss_BC: 0.000e+00, loss_IC: 1.234e-07,loss_f: 1.788e-07
pinn: 0300, Iter: 400, total_loss: 1.560e-06, loss_BC: 0.000e+00, loss_IC: 1.266e-07,loss_f: 3.279e-07
pinn: 0200, Iter: 400, total_loss: 1.200e-06, loss_BC: 0.000e+00, loss_IC: 9.709e-08,loss_f: 3.036e-07
pinn: 0000, Iter: 400, total_loss: 6.558e-07, loss_BC: 0.000e+00, loss_IC: 1.305e-07,loss_f: 2.988e-07
pinn: 0100, Iter: 500, total_loss: 1.025e-06, loss_BC: 0.000e+00, loss_IC: 1.219e-07,loss_f: 1.646e-07
pinn: 0300, Iter: 500, total_loss: 1.517e-06, loss_BC: 0.000e+00, loss_IC: 1.235e-07,loss_f: 3.258e-07
pinn: 0200, Iter: 500, total_loss: 1.142e-06, loss_BC: 0.000e+00, loss_IC: 8.733e-08,loss_f: 2.760e-07
pinn: 0000, Iter: 500, total_loss: 6.199e-07, loss_BC: 0.000e+00, loss_IC: 1.225e-07,loss_f: 2.653e-07
pinn: 0100, Iter: 600, total_loss: 9.896e-07, loss_BC: 0.000e+00, loss_IC: 1.179e-07,loss_f: 1.495e-07
pinn: 0300, Iter: 600, total_loss: 1.474e-06, loss_BC: 0.000e+00, loss_IC: 1.162e-07,loss_f: 3.245e-07
pinn: 0200, Iter: 600, total_loss: 1.116e-06, loss_BC: 0.000e+00, loss_IC: 8.552e-08,loss_f: 2.705e-07
pinn: 0000, Iter: 600, total_loss: 5.980e-07, loss_BC: 0.000e+00, loss_IC: 1.250e-07,loss_f: 2.365e-07
pinn: 0100, Iter: 700, total_loss: 9.809e-07, loss_BC: 0.000e+00, loss_IC: 1.161e-07,loss_f: 1.477e-07
pinn: 0300, Iter: 700, total_loss: 1.433e-06, loss_BC: 0.000e+00, loss_IC: 1.122e-07,loss_f: 3.280e-07
pinn: 0200, Iter: 700, total_loss: 1.084e-06, loss_BC: 0.000e+00, loss_IC: 9.011e-08,loss_f: 2.645e-07
pinn: 0000, Iter: 700, total_loss: 5.783e-07, loss_BC: 0.000e+00, loss_IC: 1.196e-07,loss_f: 2.213e-07
pinn: 0100, Iter: 800, total_loss: 9.566e-07, loss_BC: 0.000e+00, loss_IC: 1.132e-07,loss_f: 1.517e-07
pinn: 0300, Iter: 800, total_loss: 1.396e-06, loss_BC: 0.000e+00, loss_IC: 1.118e-07,loss_f: 3.273e-07
pinn: 0200, Iter: 800, total_loss: 1.068e-06, loss_BC: 0.000e+00, loss_IC: 8.734e-08,loss_f: 2.697e-07
pinn: 0000, Iter: 800, total_loss: 5.703e-07, loss_BC: 0.000e+00, loss_IC: 1.167e-07,loss_f: 2.148e-07
pinn: 0100, Iter: 900, total_loss: 9.365e-07, loss_BC: 0.000e+00, loss_IC: 1.112e-07,loss_f: 1.586e-07
pinn: 0300, Iter: 900, total_loss: 1.367e-06, loss_BC: 0.000e+00, loss_IC: 1.111e-07,loss_f: 3.307e-07
pinn: 0200, Iter: 900, total_loss: 1.052e-06, loss_BC: 0.000e+00, loss_IC: 8.572e-08,loss_f: 2.685e-07
pinn: 0000, Iter: 900, total_loss: 5.658e-07, loss_BC: 0.000e+00, loss_IC: 1.137e-07,loss_f: 2.148e-07
pinn: 0100, Iter: 1000, total_loss: 9.211e-07, loss_BC: 0.000e+00, loss_IC: 1.071e-07,loss_f: 1.644e-07
pinn: 0300, Iter: 1000, total_loss: 1.339e-06, loss_BC: 0.000e+00, loss_IC: 1.107e-07,loss_f: 3.387e-07
pinn: 0200, Iter: 1000, total_loss: 1.035e-06, loss_BC: 0.000e+00, loss_IC: 8.566e-08,loss_f: 2.680e-07
pinn: 0000, Iter: 1000, total_loss: 5.556e-07, loss_BC: 0.000e+00, loss_IC: 1.095e-07,loss_f: 2.084e-07
pinn: 0100, Iter: 1100, total_loss: 9.147e-07, loss_BC: 0.000e+00, loss_IC: 1.083e-07,loss_f: 1.676e-07
pinn: 0300, Iter: 1100, total_loss: 1.304e-06, loss_BC: 0.000e+00, loss_IC: 1.171e-07,loss_f: 3.423e-07
pinn: 0200, Iter: 1100, total_loss: 1.018e-06, loss_BC: 0.000e+00, loss_IC: 8.613e-08,loss_f: 2.775e-07
pinn: 0000, Iter: 1100, total_loss: 5.429e-07, loss_BC: 0.000e+00, loss_IC: 1.002e-07,loss_f: 2.046e-07
pinn: 0100, Iter: 1200, total_loss: 9.010e-07, loss_BC: 0.000e+00, loss_IC: 1.123e-07,loss_f: 1.703e-07
pinn: 0300, Iter: 1200, total_loss: 1.271e-06, loss_BC: 0.000e+00, loss_IC: 1.220e-07,loss_f: 3.404e-07
pinn: 0200, Iter: 1200, total_loss: 1.001e-06, loss_BC: 0.000e+00, loss_IC: 8.684e-08,loss_f: 2.765e-07
pinn: 0000, Iter: 1200, total_loss: 5.390e-07, loss_BC: 0.000e+00, loss_IC: 9.831e-08,loss_f: 2.038e-07
pinn: 0100, Iter: 1300, total_loss: 8.801e-07, loss_BC: 0.000e+00, loss_IC: 1.214e-07,loss_f: 1.805e-07
pinn: 0300, Iter: 1300, total_loss: 1.244e-06, loss_BC: 0.000e+00, loss_IC: 1.199e-07,loss_f: 3.642e-07
pinn: 0200, Iter: 1300, total_loss: 9.501e-07, loss_BC: 0.000e+00, loss_IC: 9.044e-08,loss_f: 2.853e-07
pinn: 0000, Iter: 1300, total_loss: 5.258e-07, loss_BC: 0.000e+00, loss_IC: 8.759e-08,loss_f: 2.009e-07
pinn: 0100, Iter: 1400, total_loss: 8.635e-07, loss_BC: 0.000e+00, loss_IC: 1.268e-07,loss_f: 1.905e-07
pinn: 0300, Iter: 1400, total_loss: 1.223e-06, loss_BC: 0.000e+00, loss_IC: 1.282e-07,loss_f: 3.728e-07
pinn: 0200, Iter: 1400, total_loss: 9.392e-07, loss_BC: 0.000e+00, loss_IC: 9.156e-08,loss_f: 2.819e-07
pinn: 0000, Iter: 1400, total_loss: 5.155e-07, loss_BC: 0.000e+00, loss_IC: 7.739e-08,loss_f: 1.993e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 831, Mean_loss of pinns: 8.791e-07, loss_BC: 0.000e+00, loss_IC: 1.080e-07, loss_f: 2.575e-07
 => minimum loss: 5.152e-07, corresponding pinn index: 0000
 => maximum loss: 1.222e-06, corresponding pinn  index: 0300

 max_loss: 2.005e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 833, total_loss: 9.970e-06, loss_BC: 9.056e-06, loss_IC: 1.093e-07, loss_f: 2.905e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.09000, t_max: 0.10000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  834 0 1

 -------------------------------------------------------------
  -----  Epoch: 834 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.09000, t_max: 0.10000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  834 !!! 


==> Epoch: 840, Mean_loss of pinns: 3.603e-02, loss_BC: 1.002e-05, loss_IC: 3.768e-07, loss_f: 3.602e-02
 => minimum loss: 1.076e-02, corresponding pinn/batch index: 0000
 => maximum loss: 7.929e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 850, Mean_loss of pinns: 2.833e-02, loss_BC: 1.034e-05, loss_IC: 2.876e-06, loss_f: 2.832e-02
 => minimum loss: 8.914e-03, corresponding pinn/batch index: 0000
 => maximum loss: 6.095e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 860, Mean_loss of pinns: 2.278e-02, loss_BC: 9.972e-06, loss_IC: 7.462e-06, loss_f: 2.276e-02
 => minimum loss: 7.443e-03, corresponding pinn/batch index: 0000
 => maximum loss: 4.801e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 870, Mean_loss of pinns: 1.862e-02, loss_BC: 9.440e-06, loss_IC: 1.365e-05, loss_f: 1.860e-02
 => minimum loss: 6.302e-03, corresponding pinn/batch index: 0000
 => maximum loss: 3.870e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 880, Mean_loss of pinns: 1.547e-02, loss_BC: 9.506e-06, loss_IC: 2.101e-05, loss_f: 1.544e-02
 => minimum loss: 5.401e-03, corresponding pinn/batch index: 0000
 => maximum loss: 3.174e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 890, Mean_loss of pinns: 1.304e-02, loss_BC: 8.780e-06, loss_IC: 2.921e-05, loss_f: 1.301e-02
 => minimum loss: 4.675e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.644e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 900, Mean_loss of pinns: 1.115e-02, loss_BC: 8.713e-06, loss_IC: 3.796e-05, loss_f: 1.110e-02
 => minimum loss: 4.087e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.236e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 910, Mean_loss of pinns: 9.655e-03, loss_BC: 8.017e-06, loss_IC: 4.692e-05, loss_f: 9.600e-03
 => minimum loss: 3.603e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.918e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 920, Mean_loss of pinns: 8.454e-03, loss_BC: 8.147e-06, loss_IC: 5.567e-05, loss_f: 8.389e-03
 => minimum loss: 3.205e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.665e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 930, Mean_loss of pinns: 7.473e-03, loss_BC: 7.762e-06, loss_IC: 6.390e-05, loss_f: 7.401e-03
 => minimum loss: 2.872e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.462e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  933

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 2.160e-06, loss_BC: 0.000e+00, loss_IC: 3.895e-07,loss_f: 6.137e-07
pinn: 0100, Iter: 100, total_loss: 1.383e-06, loss_BC: 0.000e+00, loss_IC: 3.790e-07,loss_f: 6.006e-07
pinn: 0000, Iter: 100, total_loss: 1.748e-06, loss_BC: 0.000e+00, loss_IC: 3.813e-07,loss_f: 5.935e-07
pinn: 0200, Iter: 100, total_loss: 2.306e-06, loss_BC: 0.000e+00, loss_IC: 4.610e-07,loss_f: 1.015e-06
pinn: 0300, Iter: 200, total_loss: 1.725e-06, loss_BC: 0.000e+00, loss_IC: 1.227e-07,loss_f: 4.219e-07
pinn: 0000, Iter: 200, total_loss: 1.241e-06, loss_BC: 0.000e+00, loss_IC: 9.412e-08,loss_f: 3.566e-07
pinn: 0100, Iter: 200, total_loss: 8.853e-07, loss_BC: 0.000e+00, loss_IC: 1.308e-07,loss_f: 3.228e-07
pinn: 0200, Iter: 200, total_loss: 1.572e-06, loss_BC: 0.000e+00, loss_IC: 8.542e-08,loss_f: 6.158e-07
pinn: 0300, Iter: 300, total_loss: 1.639e-06, loss_BC: 0.000e+00, loss_IC: 1.364e-07,loss_f: 3.510e-07
pinn: 0000, Iter: 300, total_loss: 1.120e-06, loss_BC: 0.000e+00, loss_IC: 1.154e-07,loss_f: 2.537e-07
pinn: 0100, Iter: 300, total_loss: 7.867e-07, loss_BC: 0.000e+00, loss_IC: 1.262e-07,loss_f: 2.848e-07
pinn: 0200, Iter: 300, total_loss: 1.359e-06, loss_BC: 0.000e+00, loss_IC: 9.625e-08,loss_f: 4.540e-07
pinn: 0300, Iter: 400, total_loss: 1.593e-06, loss_BC: 0.000e+00, loss_IC: 1.483e-07,loss_f: 3.221e-07
pinn: 0000, Iter: 400, total_loss: 1.040e-06, loss_BC: 0.000e+00, loss_IC: 1.096e-07,loss_f: 2.210e-07
pinn: 0100, Iter: 400, total_loss: 7.263e-07, loss_BC: 0.000e+00, loss_IC: 1.256e-07,loss_f: 2.505e-07
pinn: 0200, Iter: 400, total_loss: 1.255e-06, loss_BC: 0.000e+00, loss_IC: 1.035e-07,loss_f: 3.955e-07
pinn: 0300, Iter: 500, total_loss: 1.550e-06, loss_BC: 0.000e+00, loss_IC: 1.580e-07,loss_f: 2.958e-07
pinn: 0000, Iter: 500, total_loss: 9.964e-07, loss_BC: 0.000e+00, loss_IC: 1.116e-07,loss_f: 2.058e-07
pinn: 0100, Iter: 500, total_loss: 6.673e-07, loss_BC: 0.000e+00, loss_IC: 1.078e-07,loss_f: 2.342e-07
pinn: 0200, Iter: 500, total_loss: 1.206e-06, loss_BC: 0.000e+00, loss_IC: 8.817e-08,loss_f: 3.813e-07
pinn: 0300, Iter: 600, total_loss: 1.526e-06, loss_BC: 0.000e+00, loss_IC: 1.677e-07,loss_f: 2.829e-07
pinn: 0000, Iter: 600, total_loss: 9.735e-07, loss_BC: 0.000e+00, loss_IC: 1.105e-07,loss_f: 2.017e-07
pinn: 0100, Iter: 600, total_loss: 6.310e-07, loss_BC: 0.000e+00, loss_IC: 1.061e-07,loss_f: 2.115e-07
pinn: 0200, Iter: 600, total_loss: 1.196e-06, loss_BC: 0.000e+00, loss_IC: 9.037e-08,loss_f: 3.770e-07
pinn: 0000, Iter: 700, total_loss: 9.639e-07, loss_BC: 0.000e+00, loss_IC: 1.083e-07,loss_f: 2.063e-07
pinn: 0300, Iter: 700, total_loss: 1.505e-06, loss_BC: 0.000e+00, loss_IC: 1.772e-07,loss_f: 2.762e-07
pinn: 0100, Iter: 700, total_loss: 6.073e-07, loss_BC: 0.000e+00, loss_IC: 1.025e-07,loss_f: 2.039e-07
pinn: 0200, Iter: 700, total_loss: 1.173e-06, loss_BC: 0.000e+00, loss_IC: 9.109e-08,loss_f: 3.685e-07
pinn: 0000, Iter: 800, total_loss: 9.580e-07, loss_BC: 0.000e+00, loss_IC: 1.054e-07,loss_f: 2.082e-07
pinn: 0300, Iter: 800, total_loss: 1.484e-06, loss_BC: 0.000e+00, loss_IC: 1.800e-07,loss_f: 2.742e-07
pinn: 0100, Iter: 800, total_loss: 6.114e-07, loss_BC: 0.000e+00, loss_IC: 1.096e-07,loss_f: 2.074e-07
pinn: 0200, Iter: 800, total_loss: 1.157e-06, loss_BC: 0.000e+00, loss_IC: 9.439e-08,loss_f: 3.535e-07
pinn: 0300, Iter: 900, total_loss: 1.432e-06, loss_BC: 0.000e+00, loss_IC: 1.899e-07,loss_f: 2.799e-07
pinn: 0000, Iter: 900, total_loss: 9.479e-07, loss_BC: 0.000e+00, loss_IC: 1.061e-07,loss_f: 2.096e-07
pinn: 0200, Iter: 900, total_loss: 1.144e-06, loss_BC: 0.000e+00, loss_IC: 9.360e-08,loss_f: 3.454e-07
pinn: 0100, Iter: 900, total_loss: 5.704e-07, loss_BC: 0.000e+00, loss_IC: 9.823e-08,loss_f: 1.884e-07
pinn: 0000, Iter: 1000, total_loss: 9.425e-07, loss_BC: 0.000e+00, loss_IC: 1.058e-07,loss_f: 2.066e-07
pinn: 0300, Iter: 1000, total_loss: 1.371e-06, loss_BC: 0.000e+00, loss_IC: 1.981e-07,loss_f: 2.830e-07
pinn: 0100, Iter: 1000, total_loss: 5.592e-07, loss_BC: 0.000e+00, loss_IC: 9.626e-08,loss_f: 1.805e-07
pinn: 0200, Iter: 1000, total_loss: 1.128e-06, loss_BC: 0.000e+00, loss_IC: 9.304e-08,loss_f: 3.345e-07
pinn: 0000, Iter: 1100, total_loss: 9.308e-07, loss_BC: 0.000e+00, loss_IC: 1.066e-07,loss_f: 2.161e-07
pinn: 0300, Iter: 1100, total_loss: 1.352e-06, loss_BC: 0.000e+00, loss_IC: 2.037e-07,loss_f: 2.814e-07
pinn: 0100, Iter: 1100, total_loss: 5.480e-07, loss_BC: 0.000e+00, loss_IC: 9.440e-08,loss_f: 1.752e-07
pinn: 0200, Iter: 1100, total_loss: 1.120e-06, loss_BC: 0.000e+00, loss_IC: 9.333e-08,loss_f: 3.343e-07
pinn: 0300, Iter: 1200, total_loss: 1.329e-06, loss_BC: 0.000e+00, loss_IC: 1.983e-07,loss_f: 2.916e-07
pinn: 0000, Iter: 1200, total_loss: 9.153e-07, loss_BC: 0.000e+00, loss_IC: 1.120e-07,loss_f: 2.022e-07
pinn: 0100, Iter: 1200, total_loss: 5.373e-07, loss_BC: 0.000e+00, loss_IC: 9.208e-08,loss_f: 1.724e-07
pinn: 0200, Iter: 1200, total_loss: 1.193e-06, loss_BC: 0.000e+00, loss_IC: 1.127e-07,loss_f: 3.931e-07
pinn: 0000, Iter: 1300, total_loss: 9.100e-07, loss_BC: 0.000e+00, loss_IC: 1.112e-07,loss_f: 2.065e-07
pinn: 0300, Iter: 1300, total_loss: 1.305e-06, loss_BC: 0.000e+00, loss_IC: 2.009e-07,loss_f: 2.970e-07
pinn: 0100, Iter: 1300, total_loss: 5.297e-07, loss_BC: 0.000e+00, loss_IC: 8.870e-08,loss_f: 1.715e-07
pinn: 0200, Iter: 1300, total_loss: 1.093e-06, loss_BC: 0.000e+00, loss_IC: 1.012e-07,loss_f: 3.230e-07
pinn: 0000, Iter: 1400, total_loss: 8.872e-07, loss_BC: 0.000e+00, loss_IC: 1.059e-07,loss_f: 2.076e-07
pinn: 0300, Iter: 1400, total_loss: 1.275e-06, loss_BC: 0.000e+00, loss_IC: 1.986e-07,loss_f: 2.950e-07
pinn: 0100, Iter: 1400, total_loss: 5.266e-07, loss_BC: 0.000e+00, loss_IC: 8.669e-08,loss_f: 1.725e-07
pinn: 0200, Iter: 1400, total_loss: 1.072e-06, loss_BC: 0.000e+00, loss_IC: 1.043e-07,loss_f: 3.124e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 933, Mean_loss of pinns: 9.378e-07, loss_BC: 0.000e+00, loss_IC: 1.233e-07, loss_f: 2.456e-07
 => minimum loss: 5.253e-07, corresponding pinn index: 0100
 => maximum loss: 1.273e-06, corresponding pinn  index: 0300

 max_loss: 2.364e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 935, total_loss: 1.139e-05, loss_BC: 1.043e-05, loss_IC: 1.259e-07, loss_f: 2.694e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.10000, t_max: 0.11000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  936 0 1

 -------------------------------------------------------------
  -----  Epoch: 936 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.10000, t_max: 0.11000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  936 !!! 


==> Epoch: 940, Mean_loss of pinns: 3.296e-02, loss_BC: 1.202e-05, loss_IC: 1.988e-07, loss_f: 3.294e-02
 => minimum loss: 2.146e-02, corresponding pinn/batch index: 0100
 => maximum loss: 4.504e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 950, Mean_loss of pinns: 2.587e-02, loss_BC: 1.262e-05, loss_IC: 2.453e-06, loss_f: 2.586e-02
 => minimum loss: 1.620e-02, corresponding pinn/batch index: 0100
 => maximum loss: 3.594e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 960, Mean_loss of pinns: 2.110e-02, loss_BC: 1.324e-05, loss_IC: 6.719e-06, loss_f: 2.108e-02
 => minimum loss: 1.272e-02, corresponding pinn/batch index: 0100
 => maximum loss: 2.964e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 970, Mean_loss of pinns: 1.751e-02, loss_BC: 1.318e-05, loss_IC: 1.218e-05, loss_f: 1.749e-02
 => minimum loss: 1.012e-02, corresponding pinn/batch index: 0100
 => maximum loss: 2.492e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 980, Mean_loss of pinns: 1.473e-02, loss_BC: 1.364e-05, loss_IC: 1.828e-05, loss_f: 1.469e-02
 => minimum loss: 8.234e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.119e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 990, Mean_loss of pinns: 1.257e-02, loss_BC: 1.303e-05, loss_IC: 2.474e-05, loss_f: 1.253e-02
 => minimum loss: 6.861e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.825e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1000, Mean_loss of pinns: 1.087e-02, loss_BC: 1.290e-05, loss_IC: 3.134e-05, loss_f: 1.083e-02
 => minimum loss: 5.835e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.590e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1010, Mean_loss of pinns: 9.513e-03, loss_BC: 1.241e-05, loss_IC: 3.782e-05, loss_f: 9.462e-03
 => minimum loss: 5.054e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.400e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1020, Mean_loss of pinns: 8.406e-03, loss_BC: 1.173e-05, loss_IC: 4.389e-05, loss_f: 8.349e-03
 => minimum loss: 4.442e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.242e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1030, Mean_loss of pinns: 7.490e-03, loss_BC: 1.124e-05, loss_IC: 4.935e-05, loss_f: 7.429e-03
 => minimum loss: 3.950e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.110e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1035

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.630e-06, loss_BC: 0.000e+00, loss_IC: 2.466e-07,loss_f: 4.155e-07
pinn: 0000, Iter: 100, total_loss: 2.096e-06, loss_BC: 0.000e+00, loss_IC: 7.897e-07,loss_f: 6.271e-07
pinn: 0300, Iter: 100, total_loss: 1.662e-06, loss_BC: 0.000e+00, loss_IC: 2.886e-07,loss_f: 5.638e-07
pinn: 0200, Iter: 100, total_loss: 1.103e-06, loss_BC: 0.000e+00, loss_IC: 2.521e-07,loss_f: 5.644e-07
pinn: 0100, Iter: 200, total_loss: 1.370e-06, loss_BC: 0.000e+00, loss_IC: 1.974e-07,loss_f: 2.209e-07
pinn: 0300, Iter: 200, total_loss: 1.245e-06, loss_BC: 0.000e+00, loss_IC: 1.139e-07,loss_f: 3.039e-07
pinn: 0000, Iter: 200, total_loss: 1.273e-06, loss_BC: 0.000e+00, loss_IC: 1.660e-07,loss_f: 3.916e-07
pinn: 0200, Iter: 200, total_loss: 6.886e-07, loss_BC: 0.000e+00, loss_IC: 8.588e-08,loss_f: 3.107e-07
pinn: 0100, Iter: 300, total_loss: 1.290e-06, loss_BC: 0.000e+00, loss_IC: 1.830e-07,loss_f: 1.898e-07
pinn: 0300, Iter: 300, total_loss: 1.181e-06, loss_BC: 0.000e+00, loss_IC: 1.114e-07,loss_f: 2.578e-07
pinn: 0000, Iter: 300, total_loss: 1.177e-06, loss_BC: 0.000e+00, loss_IC: 1.404e-07,loss_f: 3.344e-07
pinn: 0200, Iter: 300, total_loss: 6.237e-07, loss_BC: 0.000e+00, loss_IC: 8.718e-08,loss_f: 2.445e-07
pinn: 0100, Iter: 400, total_loss: 1.248e-06, loss_BC: 0.000e+00, loss_IC: 1.884e-07,loss_f: 1.750e-07
pinn: 0300, Iter: 400, total_loss: 1.115e-06, loss_BC: 0.000e+00, loss_IC: 1.028e-07,loss_f: 2.201e-07
pinn: 0200, Iter: 400, total_loss: 5.928e-07, loss_BC: 0.000e+00, loss_IC: 8.588e-08,loss_f: 2.167e-07
pinn: 0000, Iter: 400, total_loss: 1.109e-06, loss_BC: 0.000e+00, loss_IC: 1.245e-07,loss_f: 3.033e-07
pinn: 0100, Iter: 500, total_loss: 1.219e-06, loss_BC: 0.000e+00, loss_IC: 2.126e-07,loss_f: 1.606e-07
pinn: 0300, Iter: 500, total_loss: 1.076e-06, loss_BC: 0.000e+00, loss_IC: 1.109e-07,loss_f: 2.012e-07
pinn: 0000, Iter: 500, total_loss: 1.059e-06, loss_BC: 0.000e+00, loss_IC: 1.304e-07,loss_f: 2.623e-07
pinn: 0200, Iter: 500, total_loss: 5.680e-07, loss_BC: 0.000e+00, loss_IC: 8.715e-08,loss_f: 1.892e-07
pinn: 0100, Iter: 600, total_loss: 1.191e-06, loss_BC: 0.000e+00, loss_IC: 2.154e-07,loss_f: 1.565e-07
pinn: 0300, Iter: 600, total_loss: 1.050e-06, loss_BC: 0.000e+00, loss_IC: 1.114e-07,loss_f: 1.909e-07
pinn: 0000, Iter: 600, total_loss: 1.041e-06, loss_BC: 0.000e+00, loss_IC: 1.338e-07,loss_f: 2.500e-07
pinn: 0200, Iter: 600, total_loss: 5.523e-07, loss_BC: 0.000e+00, loss_IC: 8.616e-08,loss_f: 1.750e-07
pinn: 0100, Iter: 700, total_loss: 1.176e-06, loss_BC: 0.000e+00, loss_IC: 2.257e-07,loss_f: 1.537e-07
pinn: 0300, Iter: 700, total_loss: 1.027e-06, loss_BC: 0.000e+00, loss_IC: 1.168e-07,loss_f: 1.916e-07
pinn: 0000, Iter: 700, total_loss: 1.001e-06, loss_BC: 0.000e+00, loss_IC: 1.410e-07,loss_f: 2.279e-07
pinn: 0200, Iter: 700, total_loss: 5.334e-07, loss_BC: 0.000e+00, loss_IC: 8.618e-08,loss_f: 1.590e-07
pinn: 0100, Iter: 800, total_loss: 1.150e-06, loss_BC: 0.000e+00, loss_IC: 2.242e-07,loss_f: 1.600e-07
pinn: 0300, Iter: 800, total_loss: 1.014e-06, loss_BC: 0.000e+00, loss_IC: 1.259e-07,loss_f: 1.861e-07
pinn: 0000, Iter: 800, total_loss: 9.890e-07, loss_BC: 0.000e+00, loss_IC: 1.501e-07,loss_f: 2.174e-07
pinn: 0200, Iter: 800, total_loss: 5.254e-07, loss_BC: 0.000e+00, loss_IC: 8.768e-08,loss_f: 1.511e-07
pinn: 0100, Iter: 900, total_loss: 1.117e-06, loss_BC: 0.000e+00, loss_IC: 2.469e-07,loss_f: 1.669e-07
pinn: 0000, Iter: 900, total_loss: 9.787e-07, loss_BC: 0.000e+00, loss_IC: 1.508e-07,loss_f: 2.072e-07
pinn: 0300, Iter: 900, total_loss: 9.992e-07, loss_BC: 0.000e+00, loss_IC: 1.381e-07,loss_f: 1.859e-07
pinn: 0200, Iter: 900, total_loss: 5.109e-07, loss_BC: 0.000e+00, loss_IC: 8.566e-08,loss_f: 1.427e-07
pinn: 0100, Iter: 1000, total_loss: 1.098e-06, loss_BC: 0.000e+00, loss_IC: 2.617e-07,loss_f: 1.638e-07
pinn: 0300, Iter: 1000, total_loss: 9.920e-07, loss_BC: 0.000e+00, loss_IC: 1.411e-07,loss_f: 1.855e-07
pinn: 0000, Iter: 1000, total_loss: 9.684e-07, loss_BC: 0.000e+00, loss_IC: 1.556e-07,loss_f: 1.981e-07
pinn: 0200, Iter: 1000, total_loss: 5.038e-07, loss_BC: 0.000e+00, loss_IC: 8.281e-08,loss_f: 1.405e-07
pinn: 0100, Iter: 1100, total_loss: 1.103e-06, loss_BC: 0.000e+00, loss_IC: 2.621e-07,loss_f: 1.761e-07
pinn: 0300, Iter: 1100, total_loss: 9.738e-07, loss_BC: 0.000e+00, loss_IC: 1.494e-07,loss_f: 1.847e-07
pinn: 0000, Iter: 1100, total_loss: 9.532e-07, loss_BC: 0.000e+00, loss_IC: 1.583e-07,loss_f: 1.876e-07
pinn: 0200, Iter: 1100, total_loss: 4.978e-07, loss_BC: 0.000e+00, loss_IC: 7.811e-08,loss_f: 1.407e-07
pinn: 0100, Iter: 1200, total_loss: 1.052e-06, loss_BC: 0.000e+00, loss_IC: 2.586e-07,loss_f: 1.812e-07
pinn: 0300, Iter: 1200, total_loss: 9.678e-07, loss_BC: 0.000e+00, loss_IC: 1.589e-07,loss_f: 1.875e-07
pinn: 0000, Iter: 1200, total_loss: 9.474e-07, loss_BC: 0.000e+00, loss_IC: 1.605e-07,loss_f: 1.850e-07
pinn: 0200, Iter: 1200, total_loss: 4.946e-07, loss_BC: 0.000e+00, loss_IC: 7.555e-08,loss_f: 1.403e-07
pinn: 0100, Iter: 1300, total_loss: 1.030e-06, loss_BC: 0.000e+00, loss_IC: 2.601e-07,loss_f: 1.858e-07
pinn: 0300, Iter: 1300, total_loss: 9.523e-07, loss_BC: 0.000e+00, loss_IC: 1.639e-07,loss_f: 1.816e-07
pinn: 0000, Iter: 1300, total_loss: 9.367e-07, loss_BC: 0.000e+00, loss_IC: 1.535e-07,loss_f: 1.861e-07
pinn: 0200, Iter: 1300, total_loss: 4.907e-07, loss_BC: 0.000e+00, loss_IC: 7.200e-08,loss_f: 1.426e-07
pinn: 0100, Iter: 1400, total_loss: 1.020e-06, loss_BC: 0.000e+00, loss_IC: 2.590e-07,loss_f: 1.942e-07
pinn: 0300, Iter: 1400, total_loss: 9.398e-07, loss_BC: 0.000e+00, loss_IC: 1.632e-07,loss_f: 1.840e-07
pinn: 0200, Iter: 1400, total_loss: 4.829e-07, loss_BC: 0.000e+00, loss_IC: 7.087e-08,loss_f: 1.392e-07
pinn: 0000, Iter: 1400, total_loss: 9.207e-07, loss_BC: 0.000e+00, loss_IC: 1.562e-07,loss_f: 1.853e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1035, Mean_loss of pinns: 8.371e-07, loss_BC: 0.000e+00, loss_IC: 1.638e-07, loss_f: 1.743e-07
 => minimum loss: 4.819e-07, corresponding pinn index: 0200
 => maximum loss: 1.015e-06, corresponding pinn  index: 0100

 max_loss: 2.782e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1037, total_loss: 1.173e-05, loss_BC: 1.085e-05, loss_IC: 1.653e-07, loss_f: 2.081e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.11000, t_max: 0.12000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1038 0 1

 -------------------------------------------------------------
  -----  Epoch: 1038 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.11000, t_max: 0.12000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1038 !!! 


==> Epoch: 1040, Mean_loss of pinns: 1.842e-02, loss_BC: 1.266e-05, loss_IC: 6.189e-08, loss_f: 1.841e-02
 => minimum loss: 6.022e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.788e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1050, Mean_loss of pinns: 1.375e-02, loss_BC: 1.343e-05, loss_IC: 2.331e-06, loss_f: 1.374e-02
 => minimum loss: 4.892e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.018e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1060, Mean_loss of pinns: 1.089e-02, loss_BC: 1.352e-05, loss_IC: 7.690e-06, loss_f: 1.087e-02
 => minimum loss: 4.034e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.561e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1070, Mean_loss of pinns: 8.803e-03, loss_BC: 1.355e-05, loss_IC: 1.491e-05, loss_f: 8.774e-03
 => minimum loss: 3.378e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.245e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1080, Mean_loss of pinns: 7.225e-03, loss_BC: 1.293e-05, loss_IC: 2.299e-05, loss_f: 7.189e-03
 => minimum loss: 2.865e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.010e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1090, Mean_loss of pinns: 6.056e-03, loss_BC: 1.238e-05, loss_IC: 3.131e-05, loss_f: 6.011e-03
 => minimum loss: 2.462e-03, corresponding pinn/batch index: 0000
 => maximum loss: 8.528e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1100, Mean_loss of pinns: 5.165e-03, loss_BC: 1.175e-05, loss_IC: 3.927e-05, loss_f: 5.113e-03
 => minimum loss: 2.143e-03, corresponding pinn/batch index: 0000
 => maximum loss: 7.312e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1110, Mean_loss of pinns: 4.472e-03, loss_BC: 1.158e-05, loss_IC: 4.630e-05, loss_f: 4.414e-03
 => minimum loss: 1.888e-03, corresponding pinn/batch index: 0000
 => maximum loss: 6.353e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1120, Mean_loss of pinns: 3.923e-03, loss_BC: 1.150e-05, loss_IC: 5.206e-05, loss_f: 3.859e-03
 => minimum loss: 1.678e-03, corresponding pinn/batch index: 0000
 => maximum loss: 5.585e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1130, Mean_loss of pinns: 3.478e-03, loss_BC: 1.129e-05, loss_IC: 5.646e-05, loss_f: 3.410e-03
 => minimum loss: 1.505e-03, corresponding pinn/batch index: 0000
 => maximum loss: 4.957e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1137

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 1.678e-06, loss_BC: 0.000e+00, loss_IC: 3.187e-07,loss_f: 6.486e-07
pinn: 0100, Iter: 100, total_loss: 1.994e-06, loss_BC: 0.000e+00, loss_IC: 4.090e-07,loss_f: 7.868e-07
pinn: 0000, Iter: 100, total_loss: 1.209e-06, loss_BC: 0.000e+00, loss_IC: 2.598e-07,loss_f: 5.183e-07
pinn: 0300, Iter: 100, total_loss: 2.131e-06, loss_BC: 0.000e+00, loss_IC: 1.974e-07,loss_f: 6.710e-07
pinn: 0200, Iter: 200, total_loss: 1.161e-06, loss_BC: 0.000e+00, loss_IC: 7.666e-08,loss_f: 3.243e-07
pinn: 0100, Iter: 200, total_loss: 1.336e-06, loss_BC: 0.000e+00, loss_IC: 1.095e-07,loss_f: 4.088e-07
pinn: 0300, Iter: 200, total_loss: 1.766e-06, loss_BC: 0.000e+00, loss_IC: 6.518e-08,loss_f: 4.582e-07
pinn: 0000, Iter: 200, total_loss: 7.520e-07, loss_BC: 0.000e+00, loss_IC: 5.405e-08,loss_f: 2.416e-07
pinn: 0200, Iter: 300, total_loss: 1.111e-06, loss_BC: 0.000e+00, loss_IC: 8.323e-08,loss_f: 2.812e-07
pinn: 0100, Iter: 300, total_loss: 1.193e-06, loss_BC: 0.000e+00, loss_IC: 1.079e-07,loss_f: 3.119e-07
pinn: 0000, Iter: 300, total_loss: 6.785e-07, loss_BC: 0.000e+00, loss_IC: 5.225e-08,loss_f: 1.733e-07
pinn: 0300, Iter: 300, total_loss: 1.653e-06, loss_BC: 0.000e+00, loss_IC: 8.546e-08,loss_f: 3.921e-07
pinn: 0200, Iter: 400, total_loss: 1.014e-06, loss_BC: 0.000e+00, loss_IC: 9.271e-08,loss_f: 2.219e-07
pinn: 0100, Iter: 400, total_loss: 1.112e-06, loss_BC: 0.000e+00, loss_IC: 1.150e-07,loss_f: 2.726e-07
pinn: 0300, Iter: 400, total_loss: 1.587e-06, loss_BC: 0.000e+00, loss_IC: 8.981e-08,loss_f: 3.893e-07
pinn: 0000, Iter: 400, total_loss: 6.613e-07, loss_BC: 0.000e+00, loss_IC: 5.351e-08,loss_f: 1.622e-07
pinn: 0200, Iter: 500, total_loss: 9.863e-07, loss_BC: 0.000e+00, loss_IC: 8.795e-08,loss_f: 2.129e-07
pinn: 0100, Iter: 500, total_loss: 1.054e-06, loss_BC: 0.000e+00, loss_IC: 1.060e-07,loss_f: 2.779e-07
pinn: 0300, Iter: 500, total_loss: 1.527e-06, loss_BC: 0.000e+00, loss_IC: 8.440e-08,loss_f: 3.942e-07
pinn: 0000, Iter: 500, total_loss: 6.408e-07, loss_BC: 0.000e+00, loss_IC: 5.432e-08,loss_f: 1.421e-07
pinn: 0200, Iter: 600, total_loss: 9.537e-07, loss_BC: 0.000e+00, loss_IC: 7.390e-08,loss_f: 2.053e-07
pinn: 0100, Iter: 600, total_loss: 1.001e-06, loss_BC: 0.000e+00, loss_IC: 1.132e-07,loss_f: 2.346e-07
pinn: 0300, Iter: 600, total_loss: 1.512e-06, loss_BC: 0.000e+00, loss_IC: 8.408e-08,loss_f: 3.923e-07
pinn: 0000, Iter: 600, total_loss: 6.293e-07, loss_BC: 0.000e+00, loss_IC: 5.449e-08,loss_f: 1.322e-07
pinn: 0200, Iter: 700, total_loss: 9.373e-07, loss_BC: 0.000e+00, loss_IC: 7.074e-08,loss_f: 2.036e-07
pinn: 0100, Iter: 700, total_loss: 9.446e-07, loss_BC: 0.000e+00, loss_IC: 1.037e-07,loss_f: 2.093e-07
pinn: 0300, Iter: 700, total_loss: 1.466e-06, loss_BC: 0.000e+00, loss_IC: 8.737e-08,loss_f: 3.769e-07
pinn: 0000, Iter: 700, total_loss: 6.214e-07, loss_BC: 0.000e+00, loss_IC: 5.490e-08,loss_f: 1.259e-07
pinn: 0200, Iter: 800, total_loss: 9.205e-07, loss_BC: 0.000e+00, loss_IC: 7.273e-08,loss_f: 2.029e-07
pinn: 0100, Iter: 800, total_loss: 9.257e-07, loss_BC: 0.000e+00, loss_IC: 1.001e-07,loss_f: 2.020e-07
pinn: 0000, Iter: 800, total_loss: 6.152e-07, loss_BC: 0.000e+00, loss_IC: 5.584e-08,loss_f: 1.225e-07
pinn: 0300, Iter: 800, total_loss: 1.448e-06, loss_BC: 0.000e+00, loss_IC: 8.699e-08,loss_f: 3.663e-07
pinn: 0200, Iter: 900, total_loss: 9.107e-07, loss_BC: 0.000e+00, loss_IC: 7.297e-08,loss_f: 2.015e-07
pinn: 0100, Iter: 900, total_loss: 9.097e-07, loss_BC: 0.000e+00, loss_IC: 1.017e-07,loss_f: 1.918e-07
pinn: 0300, Iter: 900, total_loss: 1.421e-06, loss_BC: 0.000e+00, loss_IC: 8.611e-08,loss_f: 3.676e-07
pinn: 0000, Iter: 900, total_loss: 6.092e-07, loss_BC: 0.000e+00, loss_IC: 5.610e-08,loss_f: 1.215e-07
pinn: 0200, Iter: 1000, total_loss: 8.983e-07, loss_BC: 0.000e+00, loss_IC: 7.568e-08,loss_f: 2.041e-07
pinn: 0100, Iter: 1000, total_loss: 8.992e-07, loss_BC: 0.000e+00, loss_IC: 1.001e-07,loss_f: 1.882e-07
pinn: 0300, Iter: 1000, total_loss: 1.391e-06, loss_BC: 0.000e+00, loss_IC: 8.947e-08,loss_f: 3.534e-07
pinn: 0000, Iter: 1000, total_loss: 5.992e-07, loss_BC: 0.000e+00, loss_IC: 5.786e-08,loss_f: 1.184e-07
pinn: 0200, Iter: 1100, total_loss: 8.718e-07, loss_BC: 0.000e+00, loss_IC: 7.539e-08,loss_f: 2.080e-07
pinn: 0100, Iter: 1100, total_loss: 8.774e-07, loss_BC: 0.000e+00, loss_IC: 9.617e-08,loss_f: 1.867e-07
pinn: 0300, Iter: 1100, total_loss: 1.373e-06, loss_BC: 0.000e+00, loss_IC: 8.670e-08,loss_f: 3.522e-07
pinn: 0000, Iter: 1100, total_loss: 5.957e-07, loss_BC: 0.000e+00, loss_IC: 5.792e-08,loss_f: 1.180e-07
pinn: 0200, Iter: 1200, total_loss: 8.601e-07, loss_BC: 0.000e+00, loss_IC: 7.524e-08,loss_f: 2.126e-07
pinn: 0100, Iter: 1200, total_loss: 8.701e-07, loss_BC: 0.000e+00, loss_IC: 9.871e-08,loss_f: 1.762e-07
pinn: 0300, Iter: 1200, total_loss: 1.356e-06, loss_BC: 0.000e+00, loss_IC: 9.015e-08,loss_f: 3.517e-07
pinn: 0000, Iter: 1200, total_loss: 5.861e-07, loss_BC: 0.000e+00, loss_IC: 5.519e-08,loss_f: 1.173e-07
pinn: 0200, Iter: 1300, total_loss: 8.495e-07, loss_BC: 0.000e+00, loss_IC: 7.688e-08,loss_f: 2.144e-07
pinn: 0100, Iter: 1300, total_loss: 8.586e-07, loss_BC: 0.000e+00, loss_IC: 9.945e-08,loss_f: 1.720e-07
pinn: 0300, Iter: 1300, total_loss: 1.319e-06, loss_BC: 0.000e+00, loss_IC: 9.408e-08,loss_f: 3.422e-07
pinn: 0000, Iter: 1300, total_loss: 5.799e-07, loss_BC: 0.000e+00, loss_IC: 5.442e-08,loss_f: 1.176e-07
pinn: 0100, Iter: 1400, total_loss: 8.552e-07, loss_BC: 0.000e+00, loss_IC: 9.968e-08,loss_f: 1.743e-07
pinn: 0200, Iter: 1400, total_loss: 8.343e-07, loss_BC: 0.000e+00, loss_IC: 8.329e-08,loss_f: 2.103e-07
pinn: 0300, Iter: 1400, total_loss: 1.308e-06, loss_BC: 0.000e+00, loss_IC: 9.248e-08,loss_f: 3.594e-07
pinn: 0000, Iter: 1400, total_loss: 5.710e-07, loss_BC: 0.000e+00, loss_IC: 5.421e-08,loss_f: 1.147e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1137, Mean_loss of pinns: 8.904e-07, loss_BC: 0.000e+00, loss_IC: 8.256e-08, loss_f: 2.140e-07
 => minimum loss: 5.701e-07, corresponding pinn index: 0000
 => maximum loss: 1.305e-06, corresponding pinn  index: 0300

 max_loss: 2.977e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1139, total_loss: 1.292e-05, loss_BC: 1.201e-05, loss_IC: 8.325e-08, loss_f: 2.365e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.12000, t_max: 0.13000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1140 0 1

 -------------------------------------------------------------
  -----  Epoch: 1140 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.12000, t_max: 0.13000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1140 !!! 


==> Epoch: 1140, Mean_loss of pinns: 4.148e-02, loss_BC: 1.401e-05, loss_IC: 0.000e+00, loss_f: 4.147e-02
 => minimum loss: 1.979e-02, corresponding pinn/batch index: 0000
 => maximum loss: 7.072e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1150, Mean_loss of pinns: 3.267e-02, loss_BC: 1.644e-05, loss_IC: 1.670e-06, loss_f: 3.265e-02
 => minimum loss: 1.516e-02, corresponding pinn/batch index: 0100
 => maximum loss: 5.649e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1160, Mean_loss of pinns: 2.638e-02, loss_BC: 1.790e-05, loss_IC: 6.235e-06, loss_f: 2.636e-02
 => minimum loss: 1.173e-02, corresponding pinn/batch index: 0100
 => maximum loss: 4.578e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1170, Mean_loss of pinns: 2.164e-02, loss_BC: 1.805e-05, loss_IC: 1.285e-05, loss_f: 2.161e-02
 => minimum loss: 9.232e-03, corresponding pinn/batch index: 0100
 => maximum loss: 3.770e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1180, Mean_loss of pinns: 1.799e-02, loss_BC: 1.844e-05, loss_IC: 2.088e-05, loss_f: 1.795e-02
 => minimum loss: 7.437e-03, corresponding pinn/batch index: 0100
 => maximum loss: 3.142e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1190, Mean_loss of pinns: 1.514e-02, loss_BC: 1.828e-05, loss_IC: 2.988e-05, loss_f: 1.509e-02
 => minimum loss: 6.155e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.650e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1200, Mean_loss of pinns: 1.292e-02, loss_BC: 1.763e-05, loss_IC: 3.954e-05, loss_f: 1.286e-02
 => minimum loss: 5.208e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.262e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1210, Mean_loss of pinns: 1.116e-02, loss_BC: 1.699e-05, loss_IC: 4.957e-05, loss_f: 1.109e-02
 => minimum loss: 4.496e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.954e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1220, Mean_loss of pinns: 9.741e-03, loss_BC: 1.608e-05, loss_IC: 5.961e-05, loss_f: 9.665e-03
 => minimum loss: 3.942e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.705e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1230, Mean_loss of pinns: 8.586e-03, loss_BC: 1.450e-05, loss_IC: 6.928e-05, loss_f: 8.502e-03
 => minimum loss: 3.499e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.502e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1239

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 9.679e-07, loss_BC: 0.000e+00, loss_IC: 2.249e-07,loss_f: 4.872e-07
pinn: 0200, Iter: 100, total_loss: 1.592e-06, loss_BC: 0.000e+00, loss_IC: 3.036e-07,loss_f: 7.113e-07
pinn: 0100, Iter: 100, total_loss: 7.753e-07, loss_BC: 0.000e+00, loss_IC: 1.499e-07,loss_f: 4.808e-07
pinn: 0000, Iter: 100, total_loss: 1.285e-06, loss_BC: 0.000e+00, loss_IC: 3.881e-07,loss_f: 6.203e-07
pinn: 0300, Iter: 200, total_loss: 7.300e-07, loss_BC: 0.000e+00, loss_IC: 8.714e-08,loss_f: 3.812e-07
pinn: 0100, Iter: 200, total_loss: 4.809e-07, loss_BC: 0.000e+00, loss_IC: 7.897e-08,loss_f: 2.553e-07
pinn: 0200, Iter: 200, total_loss: 1.210e-06, loss_BC: 0.000e+00, loss_IC: 1.301e-07,loss_f: 4.796e-07
pinn: 0000, Iter: 200, total_loss: 6.635e-07, loss_BC: 0.000e+00, loss_IC: 9.933e-08,loss_f: 2.477e-07
pinn: 0300, Iter: 300, total_loss: 6.771e-07, loss_BC: 0.000e+00, loss_IC: 8.743e-08,loss_f: 3.292e-07
pinn: 0200, Iter: 300, total_loss: 1.119e-06, loss_BC: 0.000e+00, loss_IC: 1.280e-07,loss_f: 3.967e-07
pinn: 0100, Iter: 300, total_loss: 4.121e-07, loss_BC: 0.000e+00, loss_IC: 8.396e-08,loss_f: 1.802e-07
pinn: 0000, Iter: 300, total_loss: 6.058e-07, loss_BC: 0.000e+00, loss_IC: 9.867e-08,loss_f: 1.919e-07
pinn: 0300, Iter: 400, total_loss: 6.433e-07, loss_BC: 0.000e+00, loss_IC: 8.044e-08,loss_f: 2.998e-07
pinn: 0100, Iter: 400, total_loss: 3.968e-07, loss_BC: 0.000e+00, loss_IC: 8.664e-08,loss_f: 1.610e-07
pinn: 0200, Iter: 400, total_loss: 9.900e-07, loss_BC: 0.000e+00, loss_IC: 1.260e-07,loss_f: 2.989e-07
pinn: 0000, Iter: 400, total_loss: 5.734e-07, loss_BC: 0.000e+00, loss_IC: 9.288e-08,loss_f: 1.661e-07
pinn: 0300, Iter: 500, total_loss: 5.806e-07, loss_BC: 0.000e+00, loss_IC: 6.676e-08,loss_f: 2.398e-07
pinn: 0200, Iter: 500, total_loss: 9.266e-07, loss_BC: 0.000e+00, loss_IC: 1.363e-07,loss_f: 2.354e-07
pinn: 0100, Iter: 500, total_loss: 3.868e-07, loss_BC: 0.000e+00, loss_IC: 8.938e-08,loss_f: 1.472e-07
pinn: 0000, Iter: 500, total_loss: 5.575e-07, loss_BC: 0.000e+00, loss_IC: 8.508e-08,loss_f: 1.572e-07
pinn: 0300, Iter: 600, total_loss: 5.696e-07, loss_BC: 0.000e+00, loss_IC: 6.591e-08,loss_f: 2.262e-07
pinn: 0200, Iter: 600, total_loss: 8.772e-07, loss_BC: 0.000e+00, loss_IC: 1.350e-07,loss_f: 2.013e-07
pinn: 0100, Iter: 600, total_loss: 3.705e-07, loss_BC: 0.000e+00, loss_IC: 9.208e-08,loss_f: 1.255e-07
pinn: 0000, Iter: 600, total_loss: 5.469e-07, loss_BC: 0.000e+00, loss_IC: 7.830e-08,loss_f: 1.573e-07
pinn: 0300, Iter: 700, total_loss: 5.619e-07, loss_BC: 0.000e+00, loss_IC: 6.554e-08,loss_f: 2.190e-07
pinn: 0200, Iter: 700, total_loss: 8.557e-07, loss_BC: 0.000e+00, loss_IC: 1.396e-07,loss_f: 1.862e-07
pinn: 0100, Iter: 700, total_loss: 3.572e-07, loss_BC: 0.000e+00, loss_IC: 9.027e-08,loss_f: 1.117e-07
pinn: 0000, Iter: 700, total_loss: 5.311e-07, loss_BC: 0.000e+00, loss_IC: 7.175e-08,loss_f: 1.494e-07
pinn: 0300, Iter: 800, total_loss: 5.512e-07, loss_BC: 0.000e+00, loss_IC: 6.316e-08,loss_f: 2.090e-07
pinn: 0200, Iter: 800, total_loss: 8.427e-07, loss_BC: 0.000e+00, loss_IC: 1.370e-07,loss_f: 1.821e-07
pinn: 0100, Iter: 800, total_loss: 3.506e-07, loss_BC: 0.000e+00, loss_IC: 8.745e-08,loss_f: 1.079e-07
pinn: 0000, Iter: 800, total_loss: 5.216e-07, loss_BC: 0.000e+00, loss_IC: 6.711e-08,loss_f: 1.505e-07
pinn: 0300, Iter: 900, total_loss: 5.414e-07, loss_BC: 0.000e+00, loss_IC: 5.867e-08,loss_f: 2.048e-07
pinn: 0200, Iter: 900, total_loss: 8.354e-07, loss_BC: 0.000e+00, loss_IC: 1.402e-07,loss_f: 1.787e-07
pinn: 0100, Iter: 900, total_loss: 3.471e-07, loss_BC: 0.000e+00, loss_IC: 8.632e-08,loss_f: 1.056e-07
pinn: 0000, Iter: 900, total_loss: 5.117e-07, loss_BC: 0.000e+00, loss_IC: 6.444e-08,loss_f: 1.460e-07
pinn: 0300, Iter: 1000, total_loss: 5.287e-07, loss_BC: 0.000e+00, loss_IC: 5.493e-08,loss_f: 1.963e-07
pinn: 0200, Iter: 1000, total_loss: 8.239e-07, loss_BC: 0.000e+00, loss_IC: 1.456e-07,loss_f: 1.734e-07
pinn: 0000, Iter: 1000, total_loss: 5.053e-07, loss_BC: 0.000e+00, loss_IC: 6.198e-08,loss_f: 1.432e-07
pinn: 0100, Iter: 1000, total_loss: 3.405e-07, loss_BC: 0.000e+00, loss_IC: 8.279e-08,loss_f: 1.018e-07
pinn: 0300, Iter: 1100, total_loss: 5.172e-07, loss_BC: 0.000e+00, loss_IC: 5.074e-08,loss_f: 1.884e-07
pinn: 0200, Iter: 1100, total_loss: 8.183e-07, loss_BC: 0.000e+00, loss_IC: 1.433e-07,loss_f: 1.712e-07
pinn: 0000, Iter: 1100, total_loss: 4.931e-07, loss_BC: 0.000e+00, loss_IC: 5.648e-08,loss_f: 1.426e-07
pinn: 0100, Iter: 1100, total_loss: 3.341e-07, loss_BC: 0.000e+00, loss_IC: 7.826e-08,loss_f: 1.001e-07
pinn: 0300, Iter: 1200, total_loss: 5.070e-07, loss_BC: 0.000e+00, loss_IC: 4.964e-08,loss_f: 1.825e-07
pinn: 0200, Iter: 1200, total_loss: 8.030e-07, loss_BC: 0.000e+00, loss_IC: 1.368e-07,loss_f: 1.707e-07
pinn: 0000, Iter: 1200, total_loss: 4.738e-07, loss_BC: 0.000e+00, loss_IC: 5.092e-08,loss_f: 1.305e-07
pinn: 0100, Iter: 1200, total_loss: 3.288e-07, loss_BC: 0.000e+00, loss_IC: 7.553e-08,loss_f: 9.861e-08
pinn: 0300, Iter: 1300, total_loss: 4.986e-07, loss_BC: 0.000e+00, loss_IC: 4.596e-08,loss_f: 1.806e-07
pinn: 0200, Iter: 1300, total_loss: 7.941e-07, loss_BC: 0.000e+00, loss_IC: 1.399e-07,loss_f: 1.655e-07
pinn: 0000, Iter: 1300, total_loss: 4.677e-07, loss_BC: 0.000e+00, loss_IC: 4.869e-08,loss_f: 1.268e-07
pinn: 0100, Iter: 1300, total_loss: 3.262e-07, loss_BC: 0.000e+00, loss_IC: 7.491e-08,loss_f: 9.738e-08
pinn: 0300, Iter: 1400, total_loss: 4.948e-07, loss_BC: 0.000e+00, loss_IC: 4.656e-08,loss_f: 1.783e-07
pinn: 0200, Iter: 1400, total_loss: 7.836e-07, loss_BC: 0.000e+00, loss_IC: 1.315e-07,loss_f: 1.678e-07
pinn: 0100, Iter: 1400, total_loss: 3.233e-07, loss_BC: 0.000e+00, loss_IC: 7.323e-08,loss_f: 9.656e-08
pinn: 0000, Iter: 1400, total_loss: 4.528e-07, loss_BC: 0.000e+00, loss_IC: 4.227e-08,loss_f: 1.200e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1239, Mean_loss of pinns: 5.123e-07, loss_BC: 0.000e+00, loss_IC: 7.271e-08, loss_f: 1.405e-07
 => minimum loss: 3.224e-07, corresponding pinn index: 0100
 => maximum loss: 7.829e-07, corresponding pinn  index: 0200

==> Epoch: 1240, Mean_loss of pinns: 1.486e-05, loss_BC: 1.435e-05, loss_IC: 7.271e-08, loss_f: 1.405e-07
 => minimum loss: 2.274e-06, corresponding pinn/batch index: 0200
 => maximum loss: 3.512e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 3.527e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1241, total_loss: 1.506e-05, loss_BC: 1.453e-05, loss_IC: 7.546e-08, loss_f: 1.625e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.13000, t_max: 0.14000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1242 0 1

 -------------------------------------------------------------
  -----  Epoch: 1242 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.13000, t_max: 0.14000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1242 !!! 


==> Epoch: 1250, Mean_loss of pinns: 1.581e-02, loss_BC: 1.668e-05, loss_IC: 9.714e-07, loss_f: 1.579e-02
 => minimum loss: 1.221e-02, corresponding pinn/batch index: 0000
 => maximum loss: 2.458e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1260, Mean_loss of pinns: 1.257e-02, loss_BC: 1.731e-05, loss_IC: 4.622e-06, loss_f: 1.255e-02
 => minimum loss: 9.895e-03, corresponding pinn/batch index: 0200
 => maximum loss: 1.991e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1270, Mean_loss of pinns: 1.023e-02, loss_BC: 1.699e-05, loss_IC: 1.014e-05, loss_f: 1.020e-02
 => minimum loss: 8.011e-03, corresponding pinn/batch index: 0200
 => maximum loss: 1.635e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1280, Mean_loss of pinns: 8.421e-03, loss_BC: 1.746e-05, loss_IC: 1.682e-05, loss_f: 8.386e-03
 => minimum loss: 6.577e-03, corresponding pinn/batch index: 0200
 => maximum loss: 1.354e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1290, Mean_loss of pinns: 7.056e-03, loss_BC: 1.748e-05, loss_IC: 2.451e-05, loss_f: 7.014e-03
 => minimum loss: 5.449e-03, corresponding pinn/batch index: 0300
 => maximum loss: 1.138e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1300, Mean_loss of pinns: 6.010e-03, loss_BC: 1.775e-05, loss_IC: 3.294e-05, loss_f: 5.958e-03
 => minimum loss: 4.570e-03, corresponding pinn/batch index: 0300
 => maximum loss: 9.690e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1310, Mean_loss of pinns: 5.190e-03, loss_BC: 1.842e-05, loss_IC: 4.153e-05, loss_f: 5.130e-03
 => minimum loss: 3.900e-03, corresponding pinn/batch index: 0300
 => maximum loss: 8.358e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1320, Mean_loss of pinns: 4.538e-03, loss_BC: 1.778e-05, loss_IC: 4.964e-05, loss_f: 4.470e-03
 => minimum loss: 3.385e-03, corresponding pinn/batch index: 0300
 => maximum loss: 7.295e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1330, Mean_loss of pinns: 4.010e-03, loss_BC: 1.799e-05, loss_IC: 5.687e-05, loss_f: 3.935e-03
 => minimum loss: 2.977e-03, corresponding pinn/batch index: 0300
 => maximum loss: 6.435e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1340, Mean_loss of pinns: 3.575e-03, loss_BC: 1.742e-05, loss_IC: 6.299e-05, loss_f: 3.494e-03
 => minimum loss: 2.646e-03, corresponding pinn/batch index: 0300
 => maximum loss: 5.729e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1341

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 1.521e-06, loss_BC: 0.000e+00, loss_IC: 4.330e-07,loss_f: 6.230e-07
pinn: 0200, Iter: 100, total_loss: 1.465e-06, loss_BC: 0.000e+00, loss_IC: 2.777e-07,loss_f: 6.157e-07
pinn: 0300, Iter: 100, total_loss: 8.115e-07, loss_BC: 0.000e+00, loss_IC: 1.683e-07,loss_f: 4.265e-07
pinn: 0100, Iter: 100, total_loss: 1.758e-06, loss_BC: 0.000e+00, loss_IC: 2.977e-07,loss_f: 9.796e-07
pinn: 0200, Iter: 200, total_loss: 1.123e-06, loss_BC: 0.000e+00, loss_IC: 1.065e-07,loss_f: 3.989e-07
pinn: 0100, Iter: 200, total_loss: 1.063e-06, loss_BC: 0.000e+00, loss_IC: 1.116e-07,loss_f: 3.755e-07
pinn: 0000, Iter: 200, total_loss: 9.263e-07, loss_BC: 0.000e+00, loss_IC: 1.318e-07,loss_f: 3.123e-07
pinn: 0300, Iter: 200, total_loss: 5.838e-07, loss_BC: 0.000e+00, loss_IC: 9.957e-08,loss_f: 2.635e-07
pinn: 0200, Iter: 300, total_loss: 1.015e-06, loss_BC: 0.000e+00, loss_IC: 1.043e-07,loss_f: 3.155e-07
pinn: 0100, Iter: 300, total_loss: 8.229e-07, loss_BC: 0.000e+00, loss_IC: 1.013e-07,loss_f: 3.481e-07
pinn: 0300, Iter: 300, total_loss: 5.256e-07, loss_BC: 0.000e+00, loss_IC: 9.881e-08,loss_f: 2.112e-07
pinn: 0000, Iter: 300, total_loss: 8.499e-07, loss_BC: 0.000e+00, loss_IC: 1.250e-07,loss_f: 2.475e-07
pinn: 0200, Iter: 400, total_loss: 9.798e-07, loss_BC: 0.000e+00, loss_IC: 1.029e-07,loss_f: 2.972e-07
pinn: 0300, Iter: 400, total_loss: 4.950e-07, loss_BC: 0.000e+00, loss_IC: 9.227e-08,loss_f: 2.075e-07
pinn: 0100, Iter: 400, total_loss: 6.685e-07, loss_BC: 0.000e+00, loss_IC: 9.519e-08,loss_f: 2.661e-07
pinn: 0000, Iter: 400, total_loss: 8.132e-07, loss_BC: 0.000e+00, loss_IC: 1.344e-07,loss_f: 2.053e-07
pinn: 0200, Iter: 500, total_loss: 9.548e-07, loss_BC: 0.000e+00, loss_IC: 9.877e-08,loss_f: 2.909e-07
pinn: 0100, Iter: 500, total_loss: 6.224e-07, loss_BC: 0.000e+00, loss_IC: 9.330e-08,loss_f: 2.243e-07
pinn: 0300, Iter: 500, total_loss: 4.714e-07, loss_BC: 0.000e+00, loss_IC: 9.057e-08,loss_f: 1.954e-07
pinn: 0000, Iter: 500, total_loss: 7.889e-07, loss_BC: 0.000e+00, loss_IC: 1.297e-07,loss_f: 1.885e-07
pinn: 0200, Iter: 600, total_loss: 9.379e-07, loss_BC: 0.000e+00, loss_IC: 9.883e-08,loss_f: 2.778e-07
pinn: 0300, Iter: 600, total_loss: 4.593e-07, loss_BC: 0.000e+00, loss_IC: 9.024e-08,loss_f: 1.877e-07
pinn: 0100, Iter: 600, total_loss: 5.912e-07, loss_BC: 0.000e+00, loss_IC: 8.894e-08,loss_f: 2.104e-07
pinn: 0000, Iter: 600, total_loss: 7.763e-07, loss_BC: 0.000e+00, loss_IC: 1.306e-07,loss_f: 1.780e-07
pinn: 0300, Iter: 700, total_loss: 4.403e-07, loss_BC: 0.000e+00, loss_IC: 8.641e-08,loss_f: 1.762e-07
pinn: 0200, Iter: 700, total_loss: 9.150e-07, loss_BC: 0.000e+00, loss_IC: 9.825e-08,loss_f: 2.677e-07
pinn: 0100, Iter: 700, total_loss: 5.449e-07, loss_BC: 0.000e+00, loss_IC: 8.388e-08,loss_f: 1.993e-07
pinn: 0000, Iter: 700, total_loss: 7.543e-07, loss_BC: 0.000e+00, loss_IC: 1.360e-07,loss_f: 1.637e-07
pinn: 0300, Iter: 800, total_loss: 4.318e-07, loss_BC: 0.000e+00, loss_IC: 8.355e-08,loss_f: 1.760e-07
pinn: 0200, Iter: 800, total_loss: 9.077e-07, loss_BC: 0.000e+00, loss_IC: 9.928e-08,loss_f: 2.645e-07
pinn: 0100, Iter: 800, total_loss: 5.159e-07, loss_BC: 0.000e+00, loss_IC: 8.249e-08,loss_f: 1.956e-07
pinn: 0000, Iter: 800, total_loss: 7.406e-07, loss_BC: 0.000e+00, loss_IC: 1.353e-07,loss_f: 1.581e-07
pinn: 0300, Iter: 900, total_loss: 4.161e-07, loss_BC: 0.000e+00, loss_IC: 7.969e-08,loss_f: 1.721e-07
pinn: 0200, Iter: 900, total_loss: 9.030e-07, loss_BC: 0.000e+00, loss_IC: 9.770e-08,loss_f: 2.676e-07
pinn: 0100, Iter: 900, total_loss: 5.007e-07, loss_BC: 0.000e+00, loss_IC: 7.763e-08,loss_f: 2.012e-07
pinn: 0000, Iter: 900, total_loss: 7.360e-07, loss_BC: 0.000e+00, loss_IC: 1.372e-07,loss_f: 1.556e-07
pinn: 0300, Iter: 1000, total_loss: 4.009e-07, loss_BC: 0.000e+00, loss_IC: 7.559e-08,loss_f: 1.668e-07
pinn: 0200, Iter: 1000, total_loss: 8.833e-07, loss_BC: 0.000e+00, loss_IC: 9.704e-08,loss_f: 2.647e-07
pinn: 0100, Iter: 1000, total_loss: 4.638e-07, loss_BC: 0.000e+00, loss_IC: 6.881e-08,loss_f: 2.003e-07
pinn: 0000, Iter: 1000, total_loss: 7.266e-07, loss_BC: 0.000e+00, loss_IC: 1.347e-07,loss_f: 1.563e-07
pinn: 0300, Iter: 1100, total_loss: 3.965e-07, loss_BC: 0.000e+00, loss_IC: 7.453e-08,loss_f: 1.646e-07
pinn: 0200, Iter: 1100, total_loss: 8.779e-07, loss_BC: 0.000e+00, loss_IC: 9.865e-08,loss_f: 2.654e-07
pinn: 0100, Iter: 1100, total_loss: 4.464e-07, loss_BC: 0.000e+00, loss_IC: 6.666e-08,loss_f: 1.978e-07
pinn: 0000, Iter: 1100, total_loss: 7.221e-07, loss_BC: 0.000e+00, loss_IC: 1.358e-07,loss_f: 1.541e-07
pinn: 0300, Iter: 1200, total_loss: 3.827e-07, loss_BC: 0.000e+00, loss_IC: 6.792e-08,loss_f: 1.657e-07
pinn: 0200, Iter: 1200, total_loss: 8.660e-07, loss_BC: 0.000e+00, loss_IC: 9.990e-08,loss_f: 2.574e-07
pinn: 0100, Iter: 1200, total_loss: 4.381e-07, loss_BC: 0.000e+00, loss_IC: 6.448e-08,loss_f: 1.937e-07
pinn: 0000, Iter: 1200, total_loss: 7.149e-07, loss_BC: 0.000e+00, loss_IC: 1.332e-07,loss_f: 1.558e-07
pinn: 0300, Iter: 1300, total_loss: 3.753e-07, loss_BC: 0.000e+00, loss_IC: 6.735e-08,loss_f: 1.610e-07
pinn: 0200, Iter: 1300, total_loss: 8.556e-07, loss_BC: 0.000e+00, loss_IC: 9.961e-08,loss_f: 2.574e-07
pinn: 0100, Iter: 1300, total_loss: 4.232e-07, loss_BC: 0.000e+00, loss_IC: 6.457e-08,loss_f: 1.888e-07
pinn: 0000, Iter: 1300, total_loss: 7.036e-07, loss_BC: 0.000e+00, loss_IC: 1.302e-07,loss_f: 1.584e-07
pinn: 0300, Iter: 1400, total_loss: 3.666e-07, loss_BC: 0.000e+00, loss_IC: 6.227e-08,loss_f: 1.620e-07
pinn: 0200, Iter: 1400, total_loss: 8.493e-07, loss_BC: 0.000e+00, loss_IC: 9.982e-08,loss_f: 2.570e-07
pinn: 0100, Iter: 1400, total_loss: 4.102e-07, loss_BC: 0.000e+00, loss_IC: 6.417e-08,loss_f: 1.824e-07
pinn: 0000, Iter: 1400, total_loss: 6.963e-07, loss_BC: 0.000e+00, loss_IC: 1.280e-07,loss_f: 1.558e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1341, Mean_loss of pinns: 5.777e-07, loss_BC: 0.000e+00, loss_IC: 8.741e-08, loss_f: 1.888e-07
 => minimum loss: 3.657e-07, corresponding pinn index: 0300
 => maximum loss: 8.472e-07, corresponding pinn  index: 0200

 max_loss: 4.425e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1343, total_loss: 1.824e-05, loss_BC: 1.765e-05, loss_IC: 8.845e-08, loss_f: 2.066e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.14000, t_max: 0.15000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1344 0 1

 -------------------------------------------------------------
  -----  Epoch: 1344 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.14000, t_max: 0.15000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1344 !!! 


==> Epoch: 1350, Mean_loss of pinns: 2.499e-02, loss_BC: 2.007e-05, loss_IC: 7.787e-07, loss_f: 2.497e-02
 => minimum loss: 4.659e-03, corresponding pinn/batch index: 0000
 => maximum loss: 3.644e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1360, Mean_loss of pinns: 1.938e-02, loss_BC: 2.097e-05, loss_IC: 5.258e-06, loss_f: 1.935e-02
 => minimum loss: 3.758e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.835e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1370, Mean_loss of pinns: 1.542e-02, loss_BC: 2.004e-05, loss_IC: 1.278e-05, loss_f: 1.539e-02
 => minimum loss: 3.085e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.256e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1380, Mean_loss of pinns: 1.247e-02, loss_BC: 2.019e-05, loss_IC: 2.238e-05, loss_f: 1.243e-02
 => minimum loss: 2.582e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.825e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1390, Mean_loss of pinns: 1.026e-02, loss_BC: 1.984e-05, loss_IC: 3.344e-05, loss_f: 1.021e-02
 => minimum loss: 2.197e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.504e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1400, Mean_loss of pinns: 8.607e-03, loss_BC: 1.902e-05, loss_IC: 4.548e-05, loss_f: 8.542e-03
 => minimum loss: 1.893e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.264e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1410, Mean_loss of pinns: 7.341e-03, loss_BC: 1.879e-05, loss_IC: 5.781e-05, loss_f: 7.264e-03
 => minimum loss: 1.653e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.080e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1420, Mean_loss of pinns: 6.354e-03, loss_BC: 1.898e-05, loss_IC: 6.966e-05, loss_f: 6.265e-03
 => minimum loss: 1.464e-03, corresponding pinn/batch index: 0000
 => maximum loss: 9.371e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1430, Mean_loss of pinns: 5.570e-03, loss_BC: 1.863e-05, loss_IC: 8.046e-05, loss_f: 5.471e-03
 => minimum loss: 1.307e-03, corresponding pinn/batch index: 0000
 => maximum loss: 8.234e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1440, Mean_loss of pinns: 4.938e-03, loss_BC: 1.906e-05, loss_IC: 8.993e-05, loss_f: 4.828e-03
 => minimum loss: 1.179e-03, corresponding pinn/batch index: 0000
 => maximum loss: 7.314e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1443

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 9.256e-07, loss_BC: 0.000e+00, loss_IC: 2.251e-07,loss_f: 5.005e-07
pinn: 0300, Iter: 100, total_loss: 6.204e-07, loss_BC: 0.000e+00, loss_IC: 1.339e-07,loss_f: 2.614e-07
pinn: 0000, Iter: 100, total_loss: 1.700e-06, loss_BC: 0.000e+00, loss_IC: 2.355e-07,loss_f: 9.296e-07
pinn: 0200, Iter: 100, total_loss: 9.984e-07, loss_BC: 0.000e+00, loss_IC: 1.744e-07,loss_f: 6.437e-07
pinn: 0100, Iter: 200, total_loss: 5.868e-07, loss_BC: 0.000e+00, loss_IC: 9.774e-08,loss_f: 2.861e-07
pinn: 0000, Iter: 200, total_loss: 8.248e-07, loss_BC: 0.000e+00, loss_IC: 7.216e-08,loss_f: 2.169e-07
pinn: 0300, Iter: 200, total_loss: 4.687e-07, loss_BC: 0.000e+00, loss_IC: 4.923e-08,loss_f: 2.008e-07
pinn: 0200, Iter: 200, total_loss: 4.992e-07, loss_BC: 0.000e+00, loss_IC: 6.192e-08,loss_f: 2.597e-07
pinn: 0000, Iter: 300, total_loss: 7.712e-07, loss_BC: 0.000e+00, loss_IC: 7.268e-08,loss_f: 1.686e-07
pinn: 0100, Iter: 300, total_loss: 5.343e-07, loss_BC: 0.000e+00, loss_IC: 9.438e-08,loss_f: 2.391e-07
pinn: 0300, Iter: 300, total_loss: 4.377e-07, loss_BC: 0.000e+00, loss_IC: 4.899e-08,loss_f: 1.692e-07
pinn: 0200, Iter: 300, total_loss: 4.519e-07, loss_BC: 0.000e+00, loss_IC: 6.026e-08,loss_f: 2.149e-07
pinn: 0100, Iter: 400, total_loss: 4.925e-07, loss_BC: 0.000e+00, loss_IC: 9.172e-08,loss_f: 2.019e-07
pinn: 0000, Iter: 400, total_loss: 7.489e-07, loss_BC: 0.000e+00, loss_IC: 6.882e-08,loss_f: 1.537e-07
pinn: 0300, Iter: 400, total_loss: 4.211e-07, loss_BC: 0.000e+00, loss_IC: 4.580e-08,loss_f: 1.593e-07
pinn: 0200, Iter: 400, total_loss: 4.205e-07, loss_BC: 0.000e+00, loss_IC: 5.925e-08,loss_f: 1.847e-07
pinn: 0100, Iter: 500, total_loss: 4.633e-07, loss_BC: 0.000e+00, loss_IC: 9.150e-08,loss_f: 1.746e-07
pinn: 0000, Iter: 500, total_loss: 7.295e-07, loss_BC: 0.000e+00, loss_IC: 7.005e-08,loss_f: 1.431e-07
pinn: 0200, Iter: 500, total_loss: 3.967e-07, loss_BC: 0.000e+00, loss_IC: 5.664e-08,loss_f: 1.639e-07
pinn: 0300, Iter: 500, total_loss: 4.029e-07, loss_BC: 0.000e+00, loss_IC: 4.460e-08,loss_f: 1.453e-07
pinn: 0100, Iter: 600, total_loss: 4.528e-07, loss_BC: 0.000e+00, loss_IC: 9.070e-08,loss_f: 1.660e-07
pinn: 0000, Iter: 600, total_loss: 7.144e-07, loss_BC: 0.000e+00, loss_IC: 7.316e-08,loss_f: 1.363e-07
pinn: 0300, Iter: 600, total_loss: 3.930e-07, loss_BC: 0.000e+00, loss_IC: 4.421e-08,loss_f: 1.374e-07
pinn: 0200, Iter: 600, total_loss: 3.828e-07, loss_BC: 0.000e+00, loss_IC: 5.609e-08,loss_f: 1.510e-07
pinn: 0100, Iter: 700, total_loss: 4.395e-07, loss_BC: 0.000e+00, loss_IC: 9.145e-08,loss_f: 1.543e-07
pinn: 0000, Iter: 700, total_loss: 6.994e-07, loss_BC: 0.000e+00, loss_IC: 8.238e-08,loss_f: 1.284e-07
pinn: 0300, Iter: 700, total_loss: 3.789e-07, loss_BC: 0.000e+00, loss_IC: 4.048e-08,loss_f: 1.278e-07
pinn: 0200, Iter: 700, total_loss: 3.664e-07, loss_BC: 0.000e+00, loss_IC: 5.277e-08,loss_f: 1.387e-07
pinn: 0100, Iter: 800, total_loss: 4.316e-07, loss_BC: 0.000e+00, loss_IC: 9.033e-08,loss_f: 1.488e-07
pinn: 0000, Iter: 800, total_loss: 6.745e-07, loss_BC: 0.000e+00, loss_IC: 8.526e-08,loss_f: 1.231e-07
pinn: 0300, Iter: 800, total_loss: 3.745e-07, loss_BC: 0.000e+00, loss_IC: 3.628e-08,loss_f: 1.277e-07
pinn: 0200, Iter: 800, total_loss: 3.540e-07, loss_BC: 0.000e+00, loss_IC: 5.228e-08,loss_f: 1.275e-07
pinn: 0100, Iter: 900, total_loss: 4.237e-07, loss_BC: 0.000e+00, loss_IC: 9.041e-08,loss_f: 1.425e-07
pinn: 0000, Iter: 900, total_loss: 6.655e-07, loss_BC: 0.000e+00, loss_IC: 8.572e-08,loss_f: 1.219e-07
pinn: 0200, Iter: 900, total_loss: 3.474e-07, loss_BC: 0.000e+00, loss_IC: 5.203e-08,loss_f: 1.212e-07
pinn: 0300, Iter: 900, total_loss: 3.701e-07, loss_BC: 0.000e+00, loss_IC: 3.583e-08,loss_f: 1.237e-07
pinn: 0100, Iter: 1000, total_loss: 4.213e-07, loss_BC: 0.000e+00, loss_IC: 8.981e-08,loss_f: 1.413e-07
pinn: 0000, Iter: 1000, total_loss: 6.573e-07, loss_BC: 0.000e+00, loss_IC: 8.802e-08,loss_f: 1.228e-07
pinn: 0200, Iter: 1000, total_loss: 3.399e-07, loss_BC: 0.000e+00, loss_IC: 5.123e-08,loss_f: 1.148e-07
pinn: 0300, Iter: 1000, total_loss: 3.688e-07, loss_BC: 0.000e+00, loss_IC: 3.643e-08,loss_f: 1.217e-07
pinn: 0100, Iter: 1100, total_loss: 4.177e-07, loss_BC: 0.000e+00, loss_IC: 8.883e-08,loss_f: 1.392e-07
pinn: 0000, Iter: 1100, total_loss: 6.509e-07, loss_BC: 0.000e+00, loss_IC: 9.241e-08,loss_f: 1.204e-07
pinn: 0200, Iter: 1100, total_loss: 3.365e-07, loss_BC: 0.000e+00, loss_IC: 5.220e-08,loss_f: 1.106e-07
pinn: 0300, Iter: 1100, total_loss: 3.641e-07, loss_BC: 0.000e+00, loss_IC: 3.613e-08,loss_f: 1.191e-07
pinn: 0100, Iter: 1200, total_loss: 4.145e-07, loss_BC: 0.000e+00, loss_IC: 8.893e-08,loss_f: 1.367e-07
pinn: 0000, Iter: 1200, total_loss: 6.336e-07, loss_BC: 0.000e+00, loss_IC: 1.040e-07,loss_f: 1.183e-07
pinn: 0200, Iter: 1200, total_loss: 3.350e-07, loss_BC: 0.000e+00, loss_IC: 5.083e-08,loss_f: 1.103e-07
pinn: 0300, Iter: 1200, total_loss: 3.635e-07, loss_BC: 0.000e+00, loss_IC: 3.639e-08,loss_f: 1.175e-07
pinn: 0100, Iter: 1300, total_loss: 4.109e-07, loss_BC: 0.000e+00, loss_IC: 8.791e-08,loss_f: 1.348e-07
pinn: 0000, Iter: 1300, total_loss: 6.246e-07, loss_BC: 0.000e+00, loss_IC: 1.019e-07,loss_f: 1.172e-07
pinn: 0300, Iter: 1300, total_loss: 4.056e-07, loss_BC: 0.000e+00, loss_IC: 4.843e-08,loss_f: 1.560e-07
pinn: 0200, Iter: 1300, total_loss: 3.302e-07, loss_BC: 0.000e+00, loss_IC: 4.923e-08,loss_f: 1.069e-07
pinn: 0100, Iter: 1400, total_loss: 4.096e-07, loss_BC: 0.000e+00, loss_IC: 8.715e-08,loss_f: 1.347e-07
pinn: 0000, Iter: 1400, total_loss: 6.118e-07, loss_BC: 0.000e+00, loss_IC: 1.025e-07,loss_f: 1.197e-07
pinn: 0200, Iter: 1400, total_loss: 3.271e-07, loss_BC: 0.000e+00, loss_IC: 4.840e-08,loss_f: 1.047e-07
pinn: 0300, Iter: 1400, total_loss: 3.592e-07, loss_BC: 0.000e+00, loss_IC: 3.751e-08,loss_f: 1.160e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1443, Mean_loss of pinns: 4.255e-07, loss_BC: 0.000e+00, loss_IC: 6.782e-08, loss_f: 1.175e-07
 => minimum loss: 3.269e-07, corresponding pinn index: 0200
 => maximum loss: 6.106e-07, corresponding pinn  index: 0000

 max_loss: 5.102e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1445, total_loss: 2.193e-05, loss_BC: 2.149e-05, loss_IC: 6.971e-08, loss_f: 1.353e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.15000, t_max: 0.16000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1446 0 1

 -------------------------------------------------------------
  -----  Epoch: 1446 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.15000, t_max: 0.16000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1446 !!! 


==> Epoch: 1450, Mean_loss of pinns: 1.757e-02, loss_BC: 2.407e-05, loss_IC: 2.068e-07, loss_f: 1.755e-02
 => minimum loss: 3.662e-03, corresponding pinn/batch index: 0000
 => maximum loss: 4.734e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1460, Mean_loss of pinns: 1.363e-02, loss_BC: 2.335e-05, loss_IC: 2.607e-06, loss_f: 1.361e-02
 => minimum loss: 2.957e-03, corresponding pinn/batch index: 0000
 => maximum loss: 3.681e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1470, Mean_loss of pinns: 1.100e-02, loss_BC: 2.353e-05, loss_IC: 7.285e-06, loss_f: 1.097e-02
 => minimum loss: 2.431e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.967e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1480, Mean_loss of pinns: 9.016e-03, loss_BC: 2.226e-05, loss_IC: 1.334e-05, loss_f: 8.980e-03
 => minimum loss: 2.035e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.439e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1490, Mean_loss of pinns: 7.501e-03, loss_BC: 2.059e-05, loss_IC: 2.018e-05, loss_f: 7.459e-03
 => minimum loss: 1.726e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.025e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1500, Mean_loss of pinns: 6.324e-03, loss_BC: 1.950e-05, loss_IC: 2.734e-05, loss_f: 6.277e-03
 => minimum loss: 1.488e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.701e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1510, Mean_loss of pinns: 5.406e-03, loss_BC: 1.798e-05, loss_IC: 3.437e-05, loss_f: 5.353e-03
 => minimum loss: 1.299e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.446e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1520, Mean_loss of pinns: 4.675e-03, loss_BC: 1.697e-05, loss_IC: 4.095e-05, loss_f: 4.616e-03
 => minimum loss: 1.148e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.243e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1530, Mean_loss of pinns: 4.085e-03, loss_BC: 1.664e-05, loss_IC: 4.693e-05, loss_f: 4.021e-03
 => minimum loss: 1.025e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.080e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1540, Mean_loss of pinns: 3.602e-03, loss_BC: 1.560e-05, loss_IC: 5.225e-05, loss_f: 3.534e-03
 => minimum loss: 9.227e-04, corresponding pinn/batch index: 0000
 => maximum loss: 9.469e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1545

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 1.191e-06, loss_BC: 0.000e+00, loss_IC: 2.487e-07,loss_f: 5.828e-07
pinn: 0000, Iter: 100, total_loss: 9.530e-07, loss_BC: 0.000e+00, loss_IC: 1.583e-07,loss_f: 4.755e-07
pinn: 0200, Iter: 100, total_loss: 9.151e-07, loss_BC: 0.000e+00, loss_IC: 2.169e-07,loss_f: 4.462e-07
pinn: 0100, Iter: 100, total_loss: 1.532e-06, loss_BC: 0.000e+00, loss_IC: 1.454e-07,loss_f: 5.221e-07
pinn: 0300, Iter: 200, total_loss: 8.015e-07, loss_BC: 0.000e+00, loss_IC: 1.146e-07,loss_f: 3.223e-07
pinn: 0200, Iter: 200, total_loss: 5.998e-07, loss_BC: 0.000e+00, loss_IC: 9.922e-08,loss_f: 2.259e-07
pinn: 0100, Iter: 200, total_loss: 1.186e-06, loss_BC: 0.000e+00, loss_IC: 7.893e-08,loss_f: 2.181e-07
pinn: 0000, Iter: 200, total_loss: 6.939e-07, loss_BC: 0.000e+00, loss_IC: 7.033e-08,loss_f: 2.781e-07
pinn: 0300, Iter: 300, total_loss: 7.348e-07, loss_BC: 0.000e+00, loss_IC: 1.139e-07,loss_f: 2.622e-07
pinn: 0200, Iter: 300, total_loss: 5.707e-07, loss_BC: 0.000e+00, loss_IC: 8.983e-08,loss_f: 2.139e-07
pinn: 0100, Iter: 300, total_loss: 1.130e-06, loss_BC: 0.000e+00, loss_IC: 7.920e-08,loss_f: 2.011e-07
pinn: 0000, Iter: 300, total_loss: 6.003e-07, loss_BC: 0.000e+00, loss_IC: 7.119e-08,loss_f: 2.397e-07
pinn: 0300, Iter: 400, total_loss: 7.143e-07, loss_BC: 0.000e+00, loss_IC: 1.092e-07,loss_f: 2.475e-07
pinn: 0000, Iter: 400, total_loss: 5.305e-07, loss_BC: 0.000e+00, loss_IC: 7.322e-08,loss_f: 2.195e-07
pinn: 0100, Iter: 400, total_loss: 1.076e-06, loss_BC: 0.000e+00, loss_IC: 9.781e-08,loss_f: 1.745e-07
pinn: 0200, Iter: 400, total_loss: 5.520e-07, loss_BC: 0.000e+00, loss_IC: 7.973e-08,loss_f: 2.097e-07
pinn: 0300, Iter: 500, total_loss: 6.796e-07, loss_BC: 0.000e+00, loss_IC: 1.094e-07,loss_f: 2.155e-07
pinn: 0100, Iter: 500, total_loss: 1.040e-06, loss_BC: 0.000e+00, loss_IC: 1.064e-07,loss_f: 1.649e-07
pinn: 0000, Iter: 500, total_loss: 4.699e-07, loss_BC: 0.000e+00, loss_IC: 7.517e-08,loss_f: 1.992e-07
pinn: 0200, Iter: 500, total_loss: 5.327e-07, loss_BC: 0.000e+00, loss_IC: 7.440e-08,loss_f: 1.963e-07
pinn: 0300, Iter: 600, total_loss: 6.640e-07, loss_BC: 0.000e+00, loss_IC: 1.131e-07,loss_f: 1.984e-07
pinn: 0000, Iter: 600, total_loss: 4.359e-07, loss_BC: 0.000e+00, loss_IC: 7.377e-08,loss_f: 1.989e-07
pinn: 0200, Iter: 600, total_loss: 5.157e-07, loss_BC: 0.000e+00, loss_IC: 6.731e-08,loss_f: 2.001e-07
pinn: 0100, Iter: 600, total_loss: 1.018e-06, loss_BC: 0.000e+00, loss_IC: 1.117e-07,loss_f: 1.572e-07
pinn: 0300, Iter: 700, total_loss: 6.539e-07, loss_BC: 0.000e+00, loss_IC: 1.151e-07,loss_f: 1.899e-07
pinn: 0000, Iter: 700, total_loss: 4.945e-07, loss_BC: 0.000e+00, loss_IC: 8.102e-08,loss_f: 2.675e-07
pinn: 0100, Iter: 700, total_loss: 9.842e-07, loss_BC: 0.000e+00, loss_IC: 1.180e-07,loss_f: 1.455e-07
pinn: 0200, Iter: 700, total_loss: 5.017e-07, loss_BC: 0.000e+00, loss_IC: 6.135e-08,loss_f: 1.966e-07
pinn: 0300, Iter: 800, total_loss: 6.434e-07, loss_BC: 0.000e+00, loss_IC: 1.187e-07,loss_f: 1.801e-07
pinn: 0100, Iter: 800, total_loss: 9.600e-07, loss_BC: 0.000e+00, loss_IC: 1.226e-07,loss_f: 1.387e-07
pinn: 0000, Iter: 800, total_loss: 3.909e-07, loss_BC: 0.000e+00, loss_IC: 7.410e-08,loss_f: 1.791e-07
pinn: 0200, Iter: 800, total_loss: 4.897e-07, loss_BC: 0.000e+00, loss_IC: 5.937e-08,loss_f: 1.911e-07
pinn: 0300, Iter: 900, total_loss: 6.311e-07, loss_BC: 0.000e+00, loss_IC: 1.176e-07,loss_f: 1.730e-07
pinn: 0100, Iter: 900, total_loss: 9.398e-07, loss_BC: 0.000e+00, loss_IC: 1.247e-07,loss_f: 1.394e-07
pinn: 0000, Iter: 900, total_loss: 3.864e-07, loss_BC: 0.000e+00, loss_IC: 7.279e-08,loss_f: 1.717e-07
pinn: 0200, Iter: 900, total_loss: 4.741e-07, loss_BC: 0.000e+00, loss_IC: 5.750e-08,loss_f: 1.831e-07
pinn: 0300, Iter: 1000, total_loss: 6.274e-07, loss_BC: 0.000e+00, loss_IC: 1.179e-07,loss_f: 1.702e-07
pinn: 0100, Iter: 1000, total_loss: 9.283e-07, loss_BC: 0.000e+00, loss_IC: 1.241e-07,loss_f: 1.411e-07
pinn: 0000, Iter: 1000, total_loss: 3.812e-07, loss_BC: 0.000e+00, loss_IC: 7.302e-08,loss_f: 1.670e-07
pinn: 0200, Iter: 1000, total_loss: 4.696e-07, loss_BC: 0.000e+00, loss_IC: 5.676e-08,loss_f: 1.847e-07
pinn: 0300, Iter: 1100, total_loss: 6.099e-07, loss_BC: 0.000e+00, loss_IC: 1.092e-07,loss_f: 1.666e-07
pinn: 0100, Iter: 1100, total_loss: 9.221e-07, loss_BC: 0.000e+00, loss_IC: 1.254e-07,loss_f: 1.415e-07
pinn: 0000, Iter: 1100, total_loss: 3.697e-07, loss_BC: 0.000e+00, loss_IC: 7.251e-08,loss_f: 1.640e-07
pinn: 0200, Iter: 1100, total_loss: 4.611e-07, loss_BC: 0.000e+00, loss_IC: 5.627e-08,loss_f: 1.829e-07
pinn: 0300, Iter: 1200, total_loss: 6.016e-07, loss_BC: 0.000e+00, loss_IC: 1.085e-07,loss_f: 1.618e-07
pinn: 0100, Iter: 1200, total_loss: 9.131e-07, loss_BC: 0.000e+00, loss_IC: 1.242e-07,loss_f: 1.479e-07
pinn: 0000, Iter: 1200, total_loss: 3.558e-07, loss_BC: 0.000e+00, loss_IC: 6.669e-08,loss_f: 1.588e-07
pinn: 0200, Iter: 1200, total_loss: 4.506e-07, loss_BC: 0.000e+00, loss_IC: 5.330e-08,loss_f: 1.864e-07
pinn: 0300, Iter: 1300, total_loss: 5.962e-07, loss_BC: 0.000e+00, loss_IC: 1.058e-07,loss_f: 1.591e-07
pinn: 0100, Iter: 1300, total_loss: 8.868e-07, loss_BC: 0.000e+00, loss_IC: 1.279e-07,loss_f: 1.557e-07
pinn: 0000, Iter: 1300, total_loss: 3.507e-07, loss_BC: 0.000e+00, loss_IC: 6.341e-08,loss_f: 1.570e-07
pinn: 0200, Iter: 1300, total_loss: 4.416e-07, loss_BC: 0.000e+00, loss_IC: 5.492e-08,loss_f: 1.797e-07
pinn: 0300, Iter: 1400, total_loss: 5.754e-07, loss_BC: 0.000e+00, loss_IC: 1.036e-07,loss_f: 1.505e-07
pinn: 0000, Iter: 1400, total_loss: 3.429e-07, loss_BC: 0.000e+00, loss_IC: 6.161e-08,loss_f: 1.531e-07
pinn: 0200, Iter: 1400, total_loss: 4.371e-07, loss_BC: 0.000e+00, loss_IC: 5.431e-08,loss_f: 1.819e-07
pinn: 0100, Iter: 1400, total_loss: 8.805e-07, loss_BC: 0.000e+00, loss_IC: 1.256e-07,loss_f: 1.616e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1545, Mean_loss of pinns: 5.575e-07, loss_BC: 0.000e+00, loss_IC: 8.725e-08, loss_f: 1.615e-07
 => minimum loss: 3.420e-07, corresponding pinn index: 0000
 => maximum loss: 8.772e-07, corresponding pinn  index: 0100

 max_loss: 6.063e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1547, total_loss: 2.555e-05, loss_BC: 2.497e-05, loss_IC: 8.896e-08, loss_f: 1.831e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.16000, t_max: 0.17000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1548 0 1

 -------------------------------------------------------------
  -----  Epoch: 1548 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.16000, t_max: 0.17000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1548 !!! 


==> Epoch: 1550, Mean_loss of pinns: 2.142e-02, loss_BC: 2.937e-05, loss_IC: 6.035e-08, loss_f: 2.139e-02
 => minimum loss: 1.162e-02, corresponding pinn/batch index: 0300
 => maximum loss: 3.549e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1560, Mean_loss of pinns: 1.649e-02, loss_BC: 3.075e-05, loss_IC: 2.026e-06, loss_f: 1.646e-02
 => minimum loss: 8.100e-03, corresponding pinn/batch index: 0300
 => maximum loss: 2.694e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1570, Mean_loss of pinns: 1.322e-02, loss_BC: 3.163e-05, loss_IC: 6.292e-06, loss_f: 1.318e-02
 => minimum loss: 6.502e-03, corresponding pinn/batch index: 0300
 => maximum loss: 2.100e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1580, Mean_loss of pinns: 1.075e-02, loss_BC: 3.180e-05, loss_IC: 1.192e-05, loss_f: 1.070e-02
 => minimum loss: 5.231e-03, corresponding pinn/batch index: 0300
 => maximum loss: 1.672e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1590, Mean_loss of pinns: 8.887e-03, loss_BC: 3.298e-05, loss_IC: 1.850e-05, loss_f: 8.835e-03
 => minimum loss: 4.272e-03, corresponding pinn/batch index: 0300
 => maximum loss: 1.360e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1600, Mean_loss of pinns: 7.489e-03, loss_BC: 3.234e-05, loss_IC: 2.592e-05, loss_f: 7.430e-03
 => minimum loss: 3.574e-03, corresponding pinn/batch index: 0300
 => maximum loss: 1.133e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1610, Mean_loss of pinns: 6.409e-03, loss_BC: 3.135e-05, loss_IC: 3.380e-05, loss_f: 6.343e-03
 => minimum loss: 3.032e-03, corresponding pinn/batch index: 0300
 => maximum loss: 9.631e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1620, Mean_loss of pinns: 5.564e-03, loss_BC: 3.173e-05, loss_IC: 4.149e-05, loss_f: 5.490e-03
 => minimum loss: 2.616e-03, corresponding pinn/batch index: 0300
 => maximum loss: 8.335e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1630, Mean_loss of pinns: 4.885e-03, loss_BC: 3.015e-05, loss_IC: 4.856e-05, loss_f: 4.806e-03
 => minimum loss: 2.284e-03, corresponding pinn/batch index: 0300
 => maximum loss: 7.317e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1640, Mean_loss of pinns: 4.335e-03, loss_BC: 3.071e-05, loss_IC: 5.480e-05, loss_f: 4.248e-03
 => minimum loss: 2.019e-03, corresponding pinn/batch index: 0300
 => maximum loss: 6.497e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1647

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 1.351e-06, loss_BC: 0.000e+00, loss_IC: 2.547e-07,loss_f: 5.520e-07
pinn: 0200, Iter: 100, total_loss: 1.475e-06, loss_BC: 0.000e+00, loss_IC: 3.127e-07,loss_f: 6.225e-07
pinn: 0300, Iter: 100, total_loss: 1.697e-06, loss_BC: 0.000e+00, loss_IC: 2.910e-07,loss_f: 8.122e-07
pinn: 0100, Iter: 100, total_loss: 1.388e-06, loss_BC: 0.000e+00, loss_IC: 2.640e-07,loss_f: 7.346e-07
pinn: 0000, Iter: 200, total_loss: 9.703e-07, loss_BC: 0.000e+00, loss_IC: 1.364e-07,loss_f: 2.745e-07
pinn: 0100, Iter: 200, total_loss: 8.579e-07, loss_BC: 0.000e+00, loss_IC: 1.945e-07,loss_f: 2.705e-07
pinn: 0200, Iter: 200, total_loss: 1.060e-06, loss_BC: 0.000e+00, loss_IC: 1.733e-07,loss_f: 3.144e-07
pinn: 0300, Iter: 200, total_loss: 9.281e-07, loss_BC: 0.000e+00, loss_IC: 1.568e-07,loss_f: 1.780e-07
pinn: 0100, Iter: 300, total_loss: 8.091e-07, loss_BC: 0.000e+00, loss_IC: 1.984e-07,loss_f: 2.222e-07
pinn: 0000, Iter: 300, total_loss: 8.857e-07, loss_BC: 0.000e+00, loss_IC: 1.305e-07,loss_f: 2.090e-07
pinn: 0200, Iter: 300, total_loss: 9.792e-07, loss_BC: 0.000e+00, loss_IC: 1.447e-07,loss_f: 2.717e-07
pinn: 0300, Iter: 300, total_loss: 8.653e-07, loss_BC: 0.000e+00, loss_IC: 1.369e-07,loss_f: 1.425e-07
pinn: 0000, Iter: 400, total_loss: 8.530e-07, loss_BC: 0.000e+00, loss_IC: 1.249e-07,loss_f: 1.954e-07
pinn: 0200, Iter: 400, total_loss: 9.330e-07, loss_BC: 0.000e+00, loss_IC: 1.287e-07,loss_f: 2.400e-07
pinn: 0100, Iter: 400, total_loss: 7.282e-07, loss_BC: 0.000e+00, loss_IC: 1.871e-07,loss_f: 1.730e-07
pinn: 0300, Iter: 400, total_loss: 8.362e-07, loss_BC: 0.000e+00, loss_IC: 1.189e-07,loss_f: 1.426e-07
pinn: 0000, Iter: 500, total_loss: 8.228e-07, loss_BC: 0.000e+00, loss_IC: 1.247e-07,loss_f: 1.764e-07
pinn: 0200, Iter: 500, total_loss: 8.848e-07, loss_BC: 0.000e+00, loss_IC: 1.166e-07,loss_f: 2.074e-07
pinn: 0300, Iter: 500, total_loss: 8.066e-07, loss_BC: 0.000e+00, loss_IC: 1.070e-07,loss_f: 1.413e-07
pinn: 0100, Iter: 500, total_loss: 6.915e-07, loss_BC: 0.000e+00, loss_IC: 1.774e-07,loss_f: 1.567e-07
pinn: 0000, Iter: 600, total_loss: 8.063e-07, loss_BC: 0.000e+00, loss_IC: 1.256e-07,loss_f: 1.685e-07
pinn: 0100, Iter: 600, total_loss: 6.714e-07, loss_BC: 0.000e+00, loss_IC: 1.705e-07,loss_f: 1.487e-07
pinn: 0200, Iter: 600, total_loss: 8.718e-07, loss_BC: 0.000e+00, loss_IC: 1.168e-07,loss_f: 1.961e-07
pinn: 0300, Iter: 600, total_loss: 7.672e-07, loss_BC: 0.000e+00, loss_IC: 9.817e-08,loss_f: 1.394e-07
pinn: 0000, Iter: 700, total_loss: 7.832e-07, loss_BC: 0.000e+00, loss_IC: 1.270e-07,loss_f: 1.563e-07
pinn: 0100, Iter: 700, total_loss: 6.594e-07, loss_BC: 0.000e+00, loss_IC: 1.633e-07,loss_f: 1.456e-07
pinn: 0200, Iter: 700, total_loss: 8.583e-07, loss_BC: 0.000e+00, loss_IC: 1.129e-07,loss_f: 1.918e-07
pinn: 0300, Iter: 700, total_loss: 7.471e-07, loss_BC: 0.000e+00, loss_IC: 1.030e-07,loss_f: 1.320e-07
pinn: 0000, Iter: 800, total_loss: 7.682e-07, loss_BC: 0.000e+00, loss_IC: 1.245e-07,loss_f: 1.518e-07
pinn: 0200, Iter: 800, total_loss: 8.491e-07, loss_BC: 0.000e+00, loss_IC: 1.117e-07,loss_f: 1.896e-07
pinn: 0100, Iter: 800, total_loss: 6.493e-07, loss_BC: 0.000e+00, loss_IC: 1.583e-07,loss_f: 1.448e-07
pinn: 0300, Iter: 800, total_loss: 7.211e-07, loss_BC: 0.000e+00, loss_IC: 1.078e-07,loss_f: 1.203e-07
pinn: 0000, Iter: 900, total_loss: 7.607e-07, loss_BC: 0.000e+00, loss_IC: 1.277e-07,loss_f: 1.462e-07
pinn: 0200, Iter: 900, total_loss: 8.380e-07, loss_BC: 0.000e+00, loss_IC: 1.108e-07,loss_f: 1.915e-07
pinn: 0300, Iter: 900, total_loss: 7.074e-07, loss_BC: 0.000e+00, loss_IC: 1.129e-07,loss_f: 1.143e-07
pinn: 0100, Iter: 900, total_loss: 6.448e-07, loss_BC: 0.000e+00, loss_IC: 1.517e-07,loss_f: 1.457e-07
pinn: 0000, Iter: 1000, total_loss: 7.413e-07, loss_BC: 0.000e+00, loss_IC: 1.294e-07,loss_f: 1.407e-07
pinn: 0200, Iter: 1000, total_loss: 8.256e-07, loss_BC: 0.000e+00, loss_IC: 1.120e-07,loss_f: 1.923e-07
pinn: 0100, Iter: 1000, total_loss: 6.337e-07, loss_BC: 0.000e+00, loss_IC: 1.519e-07,loss_f: 1.400e-07
pinn: 0300, Iter: 1000, total_loss: 7.021e-07, loss_BC: 0.000e+00, loss_IC: 1.151e-07,loss_f: 1.120e-07
pinn: 0000, Iter: 1100, total_loss: 7.323e-07, loss_BC: 0.000e+00, loss_IC: 1.286e-07,loss_f: 1.376e-07
pinn: 0200, Iter: 1100, total_loss: 8.199e-07, loss_BC: 0.000e+00, loss_IC: 1.137e-07,loss_f: 1.978e-07
pinn: 0100, Iter: 1100, total_loss: 6.289e-07, loss_BC: 0.000e+00, loss_IC: 1.484e-07,loss_f: 1.405e-07
pinn: 0300, Iter: 1100, total_loss: 6.969e-07, loss_BC: 0.000e+00, loss_IC: 1.155e-07,loss_f: 1.113e-07
pinn: 0000, Iter: 1200, total_loss: 7.185e-07, loss_BC: 0.000e+00, loss_IC: 1.317e-07,loss_f: 1.342e-07
pinn: 0100, Iter: 1200, total_loss: 6.228e-07, loss_BC: 0.000e+00, loss_IC: 1.471e-07,loss_f: 1.379e-07
pinn: 0200, Iter: 1200, total_loss: 8.155e-07, loss_BC: 0.000e+00, loss_IC: 1.169e-07,loss_f: 1.909e-07
pinn: 0300, Iter: 1200, total_loss: 6.950e-07, loss_BC: 0.000e+00, loss_IC: 1.150e-07,loss_f: 1.101e-07
pinn: 0000, Iter: 1300, total_loss: 7.117e-07, loss_BC: 0.000e+00, loss_IC: 1.341e-07,loss_f: 1.315e-07
pinn: 0200, Iter: 1300, total_loss: 8.068e-07, loss_BC: 0.000e+00, loss_IC: 1.190e-07,loss_f: 1.909e-07
pinn: 0100, Iter: 1300, total_loss: 6.178e-07, loss_BC: 0.000e+00, loss_IC: 1.480e-07,loss_f: 1.344e-07
pinn: 0300, Iter: 1300, total_loss: 6.856e-07, loss_BC: 0.000e+00, loss_IC: 1.156e-07,loss_f: 1.081e-07
pinn: 0000, Iter: 1400, total_loss: 7.079e-07, loss_BC: 0.000e+00, loss_IC: 1.355e-07,loss_f: 1.315e-07
pinn: 0100, Iter: 1400, total_loss: 6.139e-07, loss_BC: 0.000e+00, loss_IC: 1.424e-07,loss_f: 1.360e-07
pinn: 0200, Iter: 1400, total_loss: 7.934e-07, loss_BC: 0.000e+00, loss_IC: 1.177e-07,loss_f: 1.904e-07
pinn: 0300, Iter: 1400, total_loss: 6.809e-07, loss_BC: 0.000e+00, loss_IC: 1.210e-07,loss_f: 1.090e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1647, Mean_loss of pinns: 6.979e-07, loss_BC: 0.000e+00, loss_IC: 1.293e-07, loss_f: 1.416e-07
 => minimum loss: 6.136e-07, corresponding pinn index: 0100
 => maximum loss: 7.896e-07, corresponding pinn  index: 0200

 max_loss: 6.767e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1649, total_loss: 2.893e-05, loss_BC: 2.822e-05, loss_IC: 1.307e-07, loss_f: 1.559e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.17000, t_max: 0.18000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1650 0 1

 -------------------------------------------------------------
  -----  Epoch: 1650 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.17000, t_max: 0.18000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1650 !!! 


==> Epoch: 1650, Mean_loss of pinns: 9.358e-03, loss_BC: 3.275e-05, loss_IC: 0.000e+00, loss_f: 9.324e-03
 => minimum loss: 3.446e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.303e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1660, Mean_loss of pinns: 6.737e-03, loss_BC: 3.372e-05, loss_IC: 1.479e-06, loss_f: 6.702e-03
 => minimum loss: 2.772e-03, corresponding pinn/batch index: 0000
 => maximum loss: 9.932e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1670, Mean_loss of pinns: 5.407e-03, loss_BC: 3.366e-05, loss_IC: 5.576e-06, loss_f: 5.367e-03
 => minimum loss: 2.294e-03, corresponding pinn/batch index: 0000
 => maximum loss: 8.051e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1680, Mean_loss of pinns: 4.377e-03, loss_BC: 3.362e-05, loss_IC: 1.089e-05, loss_f: 4.332e-03
 => minimum loss: 1.931e-03, corresponding pinn/batch index: 0000
 => maximum loss: 6.589e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1690, Mean_loss of pinns: 3.622e-03, loss_BC: 3.244e-05, loss_IC: 1.673e-05, loss_f: 3.572e-03
 => minimum loss: 1.643e-03, corresponding pinn/batch index: 0000
 => maximum loss: 5.506e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1700, Mean_loss of pinns: 3.061e-03, loss_BC: 3.238e-05, loss_IC: 2.287e-05, loss_f: 3.005e-03
 => minimum loss: 1.419e-03, corresponding pinn/batch index: 0000
 => maximum loss: 4.682e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1710, Mean_loss of pinns: 2.627e-03, loss_BC: 3.121e-05, loss_IC: 2.861e-05, loss_f: 2.567e-03
 => minimum loss: 1.239e-03, corresponding pinn/batch index: 0000
 => maximum loss: 4.039e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1720, Mean_loss of pinns: 2.289e-03, loss_BC: 3.098e-05, loss_IC: 3.323e-05, loss_f: 2.224e-03
 => minimum loss: 1.094e-03, corresponding pinn/batch index: 0000
 => maximum loss: 3.526e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1730, Mean_loss of pinns: 2.015e-03, loss_BC: 2.974e-05, loss_IC: 3.656e-05, loss_f: 1.949e-03
 => minimum loss: 9.772e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.108e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1740, Mean_loss of pinns: 1.792e-03, loss_BC: 2.997e-05, loss_IC: 3.867e-05, loss_f: 1.723e-03
 => minimum loss: 8.811e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.762e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1749

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 1.037e-06, loss_BC: 0.000e+00, loss_IC: 1.014e-07,loss_f: 6.076e-07
pinn: 0100, Iter: 100, total_loss: 1.391e-06, loss_BC: 0.000e+00, loss_IC: 1.637e-07,loss_f: 5.955e-07
pinn: 0200, Iter: 100, total_loss: 1.896e-06, loss_BC: 0.000e+00, loss_IC: 8.490e-08,loss_f: 5.545e-07
pinn: 0000, Iter: 100, total_loss: 7.951e-07, loss_BC: 0.000e+00, loss_IC: 9.901e-08,loss_f: 4.064e-07
pinn: 0200, Iter: 200, total_loss: 1.598e-06, loss_BC: 0.000e+00, loss_IC: 4.727e-08,loss_f: 3.566e-07
pinn: 0300, Iter: 200, total_loss: 6.621e-07, loss_BC: 0.000e+00, loss_IC: 3.963e-08,loss_f: 2.244e-07
pinn: 0100, Iter: 200, total_loss: 9.323e-07, loss_BC: 0.000e+00, loss_IC: 1.132e-07,loss_f: 1.777e-07
pinn: 0000, Iter: 200, total_loss: 5.535e-07, loss_BC: 0.000e+00, loss_IC: 6.119e-08,loss_f: 1.791e-07
pinn: 0200, Iter: 300, total_loss: 1.307e-06, loss_BC: 0.000e+00, loss_IC: 6.355e-08,loss_f: 3.448e-07
pinn: 0300, Iter: 300, total_loss: 5.470e-07, loss_BC: 0.000e+00, loss_IC: 4.355e-08,loss_f: 1.803e-07
pinn: 0000, Iter: 300, total_loss: 5.066e-07, loss_BC: 0.000e+00, loss_IC: 5.334e-08,loss_f: 1.373e-07
pinn: 0100, Iter: 300, total_loss: 9.008e-07, loss_BC: 0.000e+00, loss_IC: 1.126e-07,loss_f: 1.533e-07
pinn: 0200, Iter: 400, total_loss: 1.107e-06, loss_BC: 0.000e+00, loss_IC: 6.498e-08,loss_f: 3.498e-07
pinn: 0300, Iter: 400, total_loss: 5.082e-07, loss_BC: 0.000e+00, loss_IC: 3.730e-08,loss_f: 1.691e-07
pinn: 0000, Iter: 400, total_loss: 4.905e-07, loss_BC: 0.000e+00, loss_IC: 5.251e-08,loss_f: 1.249e-07
pinn: 0100, Iter: 400, total_loss: 8.816e-07, loss_BC: 0.000e+00, loss_IC: 1.118e-07,loss_f: 1.565e-07
pinn: 0200, Iter: 500, total_loss: 1.046e-06, loss_BC: 0.000e+00, loss_IC: 5.786e-08,loss_f: 3.379e-07
pinn: 0000, Iter: 500, total_loss: 4.788e-07, loss_BC: 0.000e+00, loss_IC: 5.089e-08,loss_f: 1.176e-07
pinn: 0100, Iter: 500, total_loss: 8.661e-07, loss_BC: 0.000e+00, loss_IC: 1.146e-07,loss_f: 1.530e-07
pinn: 0300, Iter: 500, total_loss: 4.672e-07, loss_BC: 0.000e+00, loss_IC: 3.493e-08,loss_f: 1.612e-07
pinn: 0200, Iter: 600, total_loss: 1.030e-06, loss_BC: 0.000e+00, loss_IC: 5.903e-08,loss_f: 3.280e-07
pinn: 0100, Iter: 600, total_loss: 8.493e-07, loss_BC: 0.000e+00, loss_IC: 1.225e-07,loss_f: 1.545e-07
pinn: 0000, Iter: 600, total_loss: 4.710e-07, loss_BC: 0.000e+00, loss_IC: 5.061e-08,loss_f: 1.138e-07
pinn: 0300, Iter: 600, total_loss: 4.387e-07, loss_BC: 0.000e+00, loss_IC: 2.992e-08,loss_f: 1.585e-07
pinn: 0200, Iter: 700, total_loss: 9.887e-07, loss_BC: 0.000e+00, loss_IC: 6.107e-08,loss_f: 2.960e-07
pinn: 0100, Iter: 700, total_loss: 8.305e-07, loss_BC: 0.000e+00, loss_IC: 1.225e-07,loss_f: 1.621e-07
pinn: 0000, Iter: 700, total_loss: 4.672e-07, loss_BC: 0.000e+00, loss_IC: 5.037e-08,loss_f: 1.140e-07
pinn: 0300, Iter: 700, total_loss: 4.196e-07, loss_BC: 0.000e+00, loss_IC: 2.936e-08,loss_f: 1.468e-07
pinn: 0200, Iter: 800, total_loss: 9.639e-07, loss_BC: 0.000e+00, loss_IC: 6.816e-08,loss_f: 2.700e-07
pinn: 0000, Iter: 800, total_loss: 4.605e-07, loss_BC: 0.000e+00, loss_IC: 4.912e-08,loss_f: 1.151e-07
pinn: 0300, Iter: 800, total_loss: 4.050e-07, loss_BC: 0.000e+00, loss_IC: 2.742e-08,loss_f: 1.469e-07
pinn: 0100, Iter: 800, total_loss: 8.152e-07, loss_BC: 0.000e+00, loss_IC: 1.265e-07,loss_f: 1.552e-07
pinn: 0200, Iter: 900, total_loss: 9.420e-07, loss_BC: 0.000e+00, loss_IC: 7.432e-08,loss_f: 2.673e-07
pinn: 0000, Iter: 900, total_loss: 4.537e-07, loss_BC: 0.000e+00, loss_IC: 5.021e-08,loss_f: 1.136e-07
pinn: 0100, Iter: 900, total_loss: 8.026e-07, loss_BC: 0.000e+00, loss_IC: 1.305e-07,loss_f: 1.559e-07
pinn: 0300, Iter: 900, total_loss: 3.855e-07, loss_BC: 0.000e+00, loss_IC: 2.797e-08,loss_f: 1.422e-07
pinn: 0200, Iter: 1000, total_loss: 9.220e-07, loss_BC: 0.000e+00, loss_IC: 7.440e-08,loss_f: 2.559e-07
pinn: 0000, Iter: 1000, total_loss: 4.467e-07, loss_BC: 0.000e+00, loss_IC: 4.995e-08,loss_f: 1.126e-07
pinn: 0300, Iter: 1000, total_loss: 3.806e-07, loss_BC: 0.000e+00, loss_IC: 2.844e-08,loss_f: 1.371e-07
pinn: 0100, Iter: 1000, total_loss: 7.891e-07, loss_BC: 0.000e+00, loss_IC: 1.395e-07,loss_f: 1.544e-07
pinn: 0000, Iter: 1100, total_loss: 4.414e-07, loss_BC: 0.000e+00, loss_IC: 4.935e-08,loss_f: 1.110e-07
pinn: 0200, Iter: 1100, total_loss: 9.022e-07, loss_BC: 0.000e+00, loss_IC: 7.776e-08,loss_f: 2.481e-07
pinn: 0300, Iter: 1100, total_loss: 3.730e-07, loss_BC: 0.000e+00, loss_IC: 2.825e-08,loss_f: 1.347e-07
pinn: 0100, Iter: 1100, total_loss: 7.635e-07, loss_BC: 0.000e+00, loss_IC: 1.286e-07,loss_f: 1.541e-07
pinn: 0000, Iter: 1200, total_loss: 4.332e-07, loss_BC: 0.000e+00, loss_IC: 5.260e-08,loss_f: 1.066e-07
pinn: 0200, Iter: 1200, total_loss: 8.858e-07, loss_BC: 0.000e+00, loss_IC: 8.105e-08,loss_f: 2.430e-07
pinn: 0300, Iter: 1200, total_loss: 3.635e-07, loss_BC: 0.000e+00, loss_IC: 2.823e-08,loss_f: 1.284e-07
pinn: 0100, Iter: 1200, total_loss: 7.580e-07, loss_BC: 0.000e+00, loss_IC: 1.300e-07,loss_f: 1.568e-07
pinn: 0200, Iter: 1300, total_loss: 8.561e-07, loss_BC: 0.000e+00, loss_IC: 8.590e-08,loss_f: 2.386e-07
pinn: 0000, Iter: 1300, total_loss: 4.262e-07, loss_BC: 0.000e+00, loss_IC: 5.450e-08,loss_f: 1.022e-07
pinn: 0100, Iter: 1300, total_loss: 7.467e-07, loss_BC: 0.000e+00, loss_IC: 1.274e-07,loss_f: 1.585e-07
pinn: 0300, Iter: 1300, total_loss: 3.582e-07, loss_BC: 0.000e+00, loss_IC: 2.918e-08,loss_f: 1.292e-07
pinn: 0000, Iter: 1400, total_loss: 4.234e-07, loss_BC: 0.000e+00, loss_IC: 5.399e-08,loss_f: 1.049e-07
pinn: 0200, Iter: 1400, total_loss: 8.416e-07, loss_BC: 0.000e+00, loss_IC: 8.921e-08,loss_f: 2.373e-07
pinn: 0100, Iter: 1400, total_loss: 7.391e-07, loss_BC: 0.000e+00, loss_IC: 1.260e-07,loss_f: 1.581e-07
pinn: 0300, Iter: 1400, total_loss: 3.538e-07, loss_BC: 0.000e+00, loss_IC: 2.804e-08,loss_f: 1.278e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1749, Mean_loss of pinns: 5.855e-07, loss_BC: 0.000e+00, loss_IC: 7.333e-08, loss_f: 1.547e-07
 => minimum loss: 3.532e-07, corresponding pinn index: 0300
 => maximum loss: 8.389e-07, corresponding pinn  index: 0200

==> Epoch: 1750, Mean_loss of pinns: 3.498e-05, loss_BC: 3.440e-05, loss_IC: 7.333e-08, loss_f: 1.547e-07
 => minimum loss: 3.813e-06, corresponding pinn/batch index: 0200
 => maximum loss: 8.040e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 1760, Mean_loss of pinns: 3.284e-05, loss_BC: 3.186e-05, loss_IC: 1.516e-07, loss_f: 4.742e-07
 => minimum loss: 4.114e-06, corresponding pinn/batch index: 0200
 => maximum loss: 7.336e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 1770, Mean_loss of pinns: 3.115e-05, loss_BC: 2.975e-05, loss_IC: 5.795e-07, loss_f: 4.621e-07
 => minimum loss: 4.155e-06, corresponding pinn/batch index: 0200
 => maximum loss: 6.877e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

==> Epoch: 1780, Mean_loss of pinns: 2.845e-05, loss_BC: 2.638e-05, loss_IC: 1.271e-06, loss_f: 4.449e-07
 => minimum loss: 3.917e-06, corresponding pinn/batch index: 0200
 => maximum loss: 6.280e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.420e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1785, total_loss: 2.876e-05, loss_BC: 2.639e-05, loss_IC: 1.620e-06, loss_f: 3.886e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.18000, t_max: 0.19000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1786 0 1

 -------------------------------------------------------------
  -----  Epoch: 1786 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.18000, t_max: 0.19000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1786 !!! 


==> Epoch: 1790, Mean_loss of pinns: 1.946e-02, loss_BC: 3.027e-05, loss_IC: 4.040e-07, loss_f: 1.943e-02
 => minimum loss: 8.634e-03, corresponding pinn/batch index: 0000
 => maximum loss: 3.312e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1800, Mean_loss of pinns: 1.506e-02, loss_BC: 3.099e-05, loss_IC: 4.424e-06, loss_f: 1.502e-02
 => minimum loss: 7.034e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.610e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1810, Mean_loss of pinns: 1.199e-02, loss_BC: 3.055e-05, loss_IC: 1.127e-05, loss_f: 1.194e-02
 => minimum loss: 5.786e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.095e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1820, Mean_loss of pinns: 9.689e-03, loss_BC: 3.004e-05, loss_IC: 1.975e-05, loss_f: 9.639e-03
 => minimum loss: 4.834e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.702e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1830, Mean_loss of pinns: 7.974e-03, loss_BC: 2.965e-05, loss_IC: 2.928e-05, loss_f: 7.914e-03
 => minimum loss: 4.096e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.402e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1840, Mean_loss of pinns: 6.690e-03, loss_BC: 2.887e-05, loss_IC: 3.941e-05, loss_f: 6.621e-03
 => minimum loss: 3.516e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.175e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1850, Mean_loss of pinns: 5.708e-03, loss_BC: 2.771e-05, loss_IC: 4.962e-05, loss_f: 5.630e-03
 => minimum loss: 3.053e-03, corresponding pinn/batch index: 0000
 => maximum loss: 9.994e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1860, Mean_loss of pinns: 4.942e-03, loss_BC: 2.644e-05, loss_IC: 5.927e-05, loss_f: 4.856e-03
 => minimum loss: 2.681e-03, corresponding pinn/batch index: 0000
 => maximum loss: 8.620e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1870, Mean_loss of pinns: 4.335e-03, loss_BC: 2.565e-05, loss_IC: 6.782e-05, loss_f: 4.241e-03
 => minimum loss: 2.376e-03, corresponding pinn/batch index: 0000
 => maximum loss: 7.527e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1880, Mean_loss of pinns: 3.844e-03, loss_BC: 2.543e-05, loss_IC: 7.502e-05, loss_f: 3.743e-03
 => minimum loss: 2.130e-03, corresponding pinn/batch index: 0000
 => maximum loss: 6.643e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  1885

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 1.904e-06, loss_BC: 0.000e+00, loss_IC: 2.020e-07,loss_f: 5.402e-07
pinn: 0100, Iter: 100, total_loss: 8.696e-07, loss_BC: 0.000e+00, loss_IC: 1.259e-07,loss_f: 6.167e-07
pinn: 0000, Iter: 100, total_loss: 7.554e-07, loss_BC: 0.000e+00, loss_IC: 1.321e-07,loss_f: 3.337e-07
pinn: 0200, Iter: 100, total_loss: 1.143e-06, loss_BC: 0.000e+00, loss_IC: 1.526e-07,loss_f: 4.364e-07
pinn: 0300, Iter: 200, total_loss: 1.471e-06, loss_BC: 0.000e+00, loss_IC: 9.956e-08,loss_f: 2.073e-07
pinn: 0100, Iter: 200, total_loss: 5.325e-07, loss_BC: 0.000e+00, loss_IC: 1.125e-07,loss_f: 2.935e-07
pinn: 0000, Iter: 200, total_loss: 6.109e-07, loss_BC: 0.000e+00, loss_IC: 9.864e-08,loss_f: 2.107e-07
pinn: 0200, Iter: 200, total_loss: 9.040e-07, loss_BC: 0.000e+00, loss_IC: 1.150e-07,loss_f: 2.347e-07
pinn: 0100, Iter: 300, total_loss: 4.920e-07, loss_BC: 0.000e+00, loss_IC: 1.087e-07,loss_f: 2.562e-07
pinn: 0300, Iter: 300, total_loss: 1.404e-06, loss_BC: 0.000e+00, loss_IC: 1.048e-07,loss_f: 1.675e-07
pinn: 0000, Iter: 300, total_loss: 5.715e-07, loss_BC: 0.000e+00, loss_IC: 9.280e-08,loss_f: 1.752e-07
pinn: 0200, Iter: 300, total_loss: 8.659e-07, loss_BC: 0.000e+00, loss_IC: 1.082e-07,loss_f: 2.064e-07
pinn: 0300, Iter: 400, total_loss: 1.328e-06, loss_BC: 0.000e+00, loss_IC: 1.161e-07,loss_f: 1.565e-07
pinn: 0100, Iter: 400, total_loss: 4.423e-07, loss_BC: 0.000e+00, loss_IC: 1.124e-07,loss_f: 2.026e-07
pinn: 0200, Iter: 400, total_loss: 8.415e-07, loss_BC: 0.000e+00, loss_IC: 1.066e-07,loss_f: 1.891e-07
pinn: 0000, Iter: 400, total_loss: 5.514e-07, loss_BC: 0.000e+00, loss_IC: 9.420e-08,loss_f: 1.559e-07
pinn: 0300, Iter: 500, total_loss: 1.284e-06, loss_BC: 0.000e+00, loss_IC: 1.472e-07,loss_f: 1.489e-07
pinn: 0100, Iter: 500, total_loss: 3.918e-07, loss_BC: 0.000e+00, loss_IC: 1.151e-07,loss_f: 1.492e-07
pinn: 0200, Iter: 500, total_loss: 7.987e-07, loss_BC: 0.000e+00, loss_IC: 9.397e-08,loss_f: 1.704e-07
pinn: 0000, Iter: 500, total_loss: 5.452e-07, loss_BC: 0.000e+00, loss_IC: 9.536e-08,loss_f: 1.488e-07
pinn: 0300, Iter: 600, total_loss: 1.238e-06, loss_BC: 0.000e+00, loss_IC: 1.626e-07,loss_f: 1.355e-07
pinn: 0200, Iter: 600, total_loss: 7.722e-07, loss_BC: 0.000e+00, loss_IC: 9.652e-08,loss_f: 1.558e-07
pinn: 0100, Iter: 600, total_loss: 3.600e-07, loss_BC: 0.000e+00, loss_IC: 9.911e-08,loss_f: 1.323e-07
pinn: 0000, Iter: 600, total_loss: 5.424e-07, loss_BC: 0.000e+00, loss_IC: 9.627e-08,loss_f: 1.459e-07
pinn: 0200, Iter: 700, total_loss: 7.423e-07, loss_BC: 0.000e+00, loss_IC: 9.354e-08,loss_f: 1.430e-07
pinn: 0300, Iter: 700, total_loss: 1.215e-06, loss_BC: 0.000e+00, loss_IC: 1.712e-07,loss_f: 1.312e-07
pinn: 0100, Iter: 700, total_loss: 3.432e-07, loss_BC: 0.000e+00, loss_IC: 8.959e-08,loss_f: 1.240e-07
pinn: 0000, Iter: 700, total_loss: 5.368e-07, loss_BC: 0.000e+00, loss_IC: 9.746e-08,loss_f: 1.391e-07
pinn: 0300, Iter: 800, total_loss: 1.172e-06, loss_BC: 0.000e+00, loss_IC: 1.771e-07,loss_f: 1.299e-07
pinn: 0200, Iter: 800, total_loss: 7.234e-07, loss_BC: 0.000e+00, loss_IC: 9.702e-08,loss_f: 1.367e-07
pinn: 0100, Iter: 800, total_loss: 3.314e-07, loss_BC: 0.000e+00, loss_IC: 8.473e-08,loss_f: 1.161e-07
pinn: 0000, Iter: 800, total_loss: 5.246e-07, loss_BC: 0.000e+00, loss_IC: 9.401e-08,loss_f: 1.301e-07
pinn: 0300, Iter: 900, total_loss: 1.141e-06, loss_BC: 0.000e+00, loss_IC: 1.928e-07,loss_f: 1.321e-07
pinn: 0100, Iter: 900, total_loss: 3.205e-07, loss_BC: 0.000e+00, loss_IC: 7.899e-08,loss_f: 1.101e-07
pinn: 0200, Iter: 900, total_loss: 7.167e-07, loss_BC: 0.000e+00, loss_IC: 9.571e-08,loss_f: 1.335e-07
pinn: 0000, Iter: 900, total_loss: 5.191e-07, loss_BC: 0.000e+00, loss_IC: 9.283e-08,loss_f: 1.255e-07
pinn: 0300, Iter: 1000, total_loss: 1.109e-06, loss_BC: 0.000e+00, loss_IC: 2.163e-07,loss_f: 1.404e-07
pinn: 0100, Iter: 1000, total_loss: 3.156e-07, loss_BC: 0.000e+00, loss_IC: 7.809e-08,loss_f: 1.059e-07
pinn: 0200, Iter: 1000, total_loss: 7.092e-07, loss_BC: 0.000e+00, loss_IC: 9.877e-08,loss_f: 1.341e-07
pinn: 0000, Iter: 1000, total_loss: 5.134e-07, loss_BC: 0.000e+00, loss_IC: 9.082e-08,loss_f: 1.224e-07
pinn: 0100, Iter: 1100, total_loss: 3.061e-07, loss_BC: 0.000e+00, loss_IC: 7.326e-08,loss_f: 1.006e-07
pinn: 0300, Iter: 1100, total_loss: 1.082e-06, loss_BC: 0.000e+00, loss_IC: 2.169e-07,loss_f: 1.459e-07
pinn: 0200, Iter: 1100, total_loss: 6.988e-07, loss_BC: 0.000e+00, loss_IC: 1.003e-07,loss_f: 1.336e-07
pinn: 0000, Iter: 1100, total_loss: 5.069e-07, loss_BC: 0.000e+00, loss_IC: 8.784e-08,loss_f: 1.201e-07
pinn: 0200, Iter: 1200, total_loss: 6.960e-07, loss_BC: 0.000e+00, loss_IC: 9.711e-08,loss_f: 1.308e-07
pinn: 0300, Iter: 1200, total_loss: 1.055e-06, loss_BC: 0.000e+00, loss_IC: 2.301e-07,loss_f: 1.431e-07
pinn: 0100, Iter: 1200, total_loss: 3.045e-07, loss_BC: 0.000e+00, loss_IC: 7.362e-08,loss_f: 9.855e-08
pinn: 0000, Iter: 1200, total_loss: 5.003e-07, loss_BC: 0.000e+00, loss_IC: 8.386e-08,loss_f: 1.207e-07
pinn: 0100, Iter: 1300, total_loss: 3.016e-07, loss_BC: 0.000e+00, loss_IC: 7.192e-08,loss_f: 9.697e-08
pinn: 0300, Iter: 1300, total_loss: 1.042e-06, loss_BC: 0.000e+00, loss_IC: 2.416e-07,loss_f: 1.491e-07
pinn: 0200, Iter: 1300, total_loss: 6.876e-07, loss_BC: 0.000e+00, loss_IC: 1.018e-07,loss_f: 1.332e-07
pinn: 0000, Iter: 1300, total_loss: 4.973e-07, loss_BC: 0.000e+00, loss_IC: 8.327e-08,loss_f: 1.196e-07
pinn: 0300, Iter: 1400, total_loss: 1.037e-06, loss_BC: 0.000e+00, loss_IC: 2.587e-07,loss_f: 1.958e-07
pinn: 0100, Iter: 1400, total_loss: 2.988e-07, loss_BC: 0.000e+00, loss_IC: 7.138e-08,loss_f: 9.466e-08
pinn: 0200, Iter: 1400, total_loss: 6.836e-07, loss_BC: 0.000e+00, loss_IC: 1.023e-07,loss_f: 1.343e-07
pinn: 0000, Iter: 1400, total_loss: 4.904e-07, loss_BC: 0.000e+00, loss_IC: 8.060e-08,loss_f: 1.181e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 1885, Mean_loss of pinns: 6.156e-07, loss_BC: 0.000e+00, loss_IC: 1.225e-07, loss_f: 1.280e-07
 => minimum loss: 2.958e-07, corresponding pinn index: 0100
 => maximum loss: 9.950e-07, corresponding pinn  index: 0300

==> Epoch: 1890, Mean_loss of pinns: 3.148e-05, loss_BC: 3.071e-05, loss_IC: 1.412e-07, loss_f: 2.667e-07
 => minimum loss: 4.959e-06, corresponding pinn/batch index: 0200
 => maximum loss: 7.269e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 1900, Mean_loss of pinns: 3.052e-05, loss_BC: 2.942e-05, loss_IC: 2.708e-07, loss_f: 4.586e-07
 => minimum loss: 5.250e-06, corresponding pinn/batch index: 0200
 => maximum loss: 6.998e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.666e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 1904, total_loss: 2.917e-05, loss_BC: 2.805e-05, loss_IC: 3.448e-07, loss_f: 4.078e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.19000, t_max: 0.20000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  1905 0 1

 -------------------------------------------------------------
  -----  Epoch: 1905 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.19000, t_max: 0.20000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  1905 !!! 


==> Epoch: 1910, Mean_loss of pinns: 5.139e-03, loss_BC: 3.301e-05, loss_IC: 2.961e-07, loss_f: 5.106e-03
 => minimum loss: 2.803e-03, corresponding pinn/batch index: 0000
 => maximum loss: 7.677e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1920, Mean_loss of pinns: 3.984e-03, loss_BC: 3.276e-05, loss_IC: 2.767e-06, loss_f: 3.948e-03
 => minimum loss: 2.300e-03, corresponding pinn/batch index: 0000
 => maximum loss: 5.563e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1930, Mean_loss of pinns: 3.214e-03, loss_BC: 3.170e-05, loss_IC: 6.842e-06, loss_f: 3.175e-03
 => minimum loss: 1.922e-03, corresponding pinn/batch index: 0000
 => maximum loss: 4.436e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1940, Mean_loss of pinns: 2.628e-03, loss_BC: 3.104e-05, loss_IC: 1.179e-05, loss_f: 2.584e-03
 => minimum loss: 1.629e-03, corresponding pinn/batch index: 0000
 => maximum loss: 3.657e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1950, Mean_loss of pinns: 2.198e-03, loss_BC: 2.948e-05, loss_IC: 1.739e-05, loss_f: 2.150e-03
 => minimum loss: 1.397e-03, corresponding pinn/batch index: 0000
 => maximum loss: 3.077e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1960, Mean_loss of pinns: 1.872e-03, loss_BC: 2.906e-05, loss_IC: 2.295e-05, loss_f: 1.819e-03
 => minimum loss: 1.214e-03, corresponding pinn/batch index: 0000
 => maximum loss: 2.629e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1970, Mean_loss of pinns: 1.618e-03, loss_BC: 2.734e-05, loss_IC: 2.759e-05, loss_f: 1.562e-03
 => minimum loss: 1.060e-03, corresponding pinn/batch index: 0100
 => maximum loss: 2.274e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1980, Mean_loss of pinns: 1.417e-03, loss_BC: 2.667e-05, loss_IC: 3.082e-05, loss_f: 1.359e-03
 => minimum loss: 9.269e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.990e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 1990, Mean_loss of pinns: 1.254e-03, loss_BC: 2.581e-05, loss_IC: 3.257e-05, loss_f: 1.195e-03
 => minimum loss: 8.186e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.759e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2000, Mean_loss of pinns: 1.120e-03, loss_BC: 2.547e-05, loss_IC: 3.302e-05, loss_f: 1.061e-03
 => minimum loss: 7.288e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.568e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2004

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.042e-06, loss_BC: 0.000e+00, loss_IC: 1.359e-07,loss_f: 3.828e-07
pinn: 0300, Iter: 100, total_loss: 5.565e-07, loss_BC: 0.000e+00, loss_IC: 5.253e-08,loss_f: 2.173e-07
pinn: 0000, Iter: 100, total_loss: 1.024e-06, loss_BC: 0.000e+00, loss_IC: 6.051e-08,loss_f: 2.870e-07
pinn: 0200, Iter: 100, total_loss: 1.119e-06, loss_BC: 0.000e+00, loss_IC: 1.007e-07,loss_f: 5.662e-07
pinn: 0000, Iter: 200, total_loss: 8.717e-07, loss_BC: 0.000e+00, loss_IC: 4.411e-08,loss_f: 1.360e-07
pinn: 0300, Iter: 200, total_loss: 4.885e-07, loss_BC: 0.000e+00, loss_IC: 3.858e-08,loss_f: 1.638e-07
pinn: 0100, Iter: 200, total_loss: 8.117e-07, loss_BC: 0.000e+00, loss_IC: 1.274e-07,loss_f: 1.643e-07
pinn: 0200, Iter: 200, total_loss: 7.902e-07, loss_BC: 0.000e+00, loss_IC: 4.487e-08,loss_f: 3.017e-07
pinn: 0300, Iter: 300, total_loss: 4.635e-07, loss_BC: 0.000e+00, loss_IC: 2.911e-08,loss_f: 1.470e-07
pinn: 0100, Iter: 300, total_loss: 7.808e-07, loss_BC: 0.000e+00, loss_IC: 1.267e-07,loss_f: 1.409e-07
pinn: 0000, Iter: 300, total_loss: 8.347e-07, loss_BC: 0.000e+00, loss_IC: 4.355e-08,loss_f: 1.109e-07
pinn: 0200, Iter: 300, total_loss: 5.401e-07, loss_BC: 0.000e+00, loss_IC: 5.068e-08,loss_f: 2.315e-07
pinn: 0000, Iter: 400, total_loss: 8.150e-07, loss_BC: 0.000e+00, loss_IC: 4.640e-08,loss_f: 1.001e-07
pinn: 0100, Iter: 400, total_loss: 7.601e-07, loss_BC: 0.000e+00, loss_IC: 1.349e-07,loss_f: 1.247e-07
pinn: 0300, Iter: 400, total_loss: 4.547e-07, loss_BC: 0.000e+00, loss_IC: 2.614e-08,loss_f: 1.427e-07
pinn: 0200, Iter: 400, total_loss: 4.847e-07, loss_BC: 0.000e+00, loss_IC: 4.215e-08,loss_f: 2.109e-07
pinn: 0000, Iter: 500, total_loss: 8.003e-07, loss_BC: 0.000e+00, loss_IC: 4.921e-08,loss_f: 9.294e-08
pinn: 0100, Iter: 500, total_loss: 7.336e-07, loss_BC: 0.000e+00, loss_IC: 1.323e-07,loss_f: 1.131e-07
pinn: 0300, Iter: 500, total_loss: 4.416e-07, loss_BC: 0.000e+00, loss_IC: 2.645e-08,loss_f: 1.322e-07
pinn: 0200, Iter: 500, total_loss: 4.569e-07, loss_BC: 0.000e+00, loss_IC: 3.238e-08,loss_f: 2.034e-07
pinn: 0300, Iter: 600, total_loss: 4.300e-07, loss_BC: 0.000e+00, loss_IC: 3.131e-08,loss_f: 1.202e-07
pinn: 0100, Iter: 600, total_loss: 7.239e-07, loss_BC: 0.000e+00, loss_IC: 1.303e-07,loss_f: 1.082e-07
pinn: 0000, Iter: 600, total_loss: 7.765e-07, loss_BC: 0.000e+00, loss_IC: 5.415e-08,loss_f: 8.992e-08
pinn: 0200, Iter: 600, total_loss: 4.345e-07, loss_BC: 0.000e+00, loss_IC: 3.176e-08,loss_f: 1.825e-07
pinn: 0300, Iter: 700, total_loss: 4.252e-07, loss_BC: 0.000e+00, loss_IC: 3.209e-08,loss_f: 1.158e-07
pinn: 0000, Iter: 700, total_loss: 7.431e-07, loss_BC: 0.000e+00, loss_IC: 6.875e-08,loss_f: 8.697e-08
pinn: 0100, Iter: 700, total_loss: 7.085e-07, loss_BC: 0.000e+00, loss_IC: 1.316e-07,loss_f: 1.031e-07
pinn: 0200, Iter: 700, total_loss: 4.201e-07, loss_BC: 0.000e+00, loss_IC: 3.098e-08,loss_f: 1.762e-07
pinn: 0000, Iter: 800, total_loss: 7.117e-07, loss_BC: 0.000e+00, loss_IC: 7.772e-08,loss_f: 8.644e-08
pinn: 0100, Iter: 800, total_loss: 6.926e-07, loss_BC: 0.000e+00, loss_IC: 1.267e-07,loss_f: 9.673e-08
pinn: 0300, Iter: 800, total_loss: 4.184e-07, loss_BC: 0.000e+00, loss_IC: 3.443e-08,loss_f: 1.092e-07
pinn: 0200, Iter: 800, total_loss: 4.119e-07, loss_BC: 0.000e+00, loss_IC: 3.054e-08,loss_f: 1.705e-07
pinn: 0100, Iter: 900, total_loss: 6.806e-07, loss_BC: 0.000e+00, loss_IC: 1.219e-07,loss_f: 9.599e-08
pinn: 0200, Iter: 900, total_loss: 4.078e-07, loss_BC: 0.000e+00, loss_IC: 3.082e-08,loss_f: 1.666e-07
pinn: 0300, Iter: 900, total_loss: 4.126e-07, loss_BC: 0.000e+00, loss_IC: 3.590e-08,loss_f: 1.044e-07
pinn: 0000, Iter: 900, total_loss: 6.967e-07, loss_BC: 0.000e+00, loss_IC: 7.910e-08,loss_f: 8.980e-08
pinn: 0100, Iter: 1000, total_loss: 6.736e-07, loss_BC: 0.000e+00, loss_IC: 1.228e-07,loss_f: 9.341e-08
pinn: 0300, Iter: 1000, total_loss: 4.084e-07, loss_BC: 0.000e+00, loss_IC: 3.786e-08,loss_f: 1.019e-07
pinn: 0000, Iter: 1000, total_loss: 6.755e-07, loss_BC: 0.000e+00, loss_IC: 7.723e-08,loss_f: 9.397e-08
pinn: 0200, Iter: 1000, total_loss: 4.052e-07, loss_BC: 0.000e+00, loss_IC: 3.105e-08,loss_f: 1.621e-07
pinn: 0100, Iter: 1100, total_loss: 6.637e-07, loss_BC: 0.000e+00, loss_IC: 1.210e-07,loss_f: 9.066e-08
pinn: 0300, Iter: 1100, total_loss: 4.042e-07, loss_BC: 0.000e+00, loss_IC: 3.816e-08,loss_f: 9.874e-08
pinn: 0000, Iter: 1100, total_loss: 6.653e-07, loss_BC: 0.000e+00, loss_IC: 7.421e-08,loss_f: 9.464e-08
pinn: 0200, Iter: 1100, total_loss: 4.031e-07, loss_BC: 0.000e+00, loss_IC: 3.105e-08,loss_f: 1.622e-07
pinn: 0100, Iter: 1200, total_loss: 6.483e-07, loss_BC: 0.000e+00, loss_IC: 1.127e-07,loss_f: 9.115e-08
pinn: 0300, Iter: 1200, total_loss: 4.027e-07, loss_BC: 0.000e+00, loss_IC: 3.926e-08,loss_f: 9.754e-08
pinn: 0200, Iter: 1200, total_loss: 3.983e-07, loss_BC: 0.000e+00, loss_IC: 3.096e-08,loss_f: 1.595e-07
pinn: 0000, Iter: 1200, total_loss: 6.576e-07, loss_BC: 0.000e+00, loss_IC: 7.479e-08,loss_f: 9.883e-08
pinn: 0100, Iter: 1300, total_loss: 6.418e-07, loss_BC: 0.000e+00, loss_IC: 1.120e-07,loss_f: 9.019e-08
pinn: 0200, Iter: 1300, total_loss: 3.918e-07, loss_BC: 0.000e+00, loss_IC: 3.081e-08,loss_f: 1.566e-07
pinn: 0000, Iter: 1300, total_loss: 6.445e-07, loss_BC: 0.000e+00, loss_IC: 7.565e-08,loss_f: 1.007e-07
pinn: 0300, Iter: 1300, total_loss: 3.970e-07, loss_BC: 0.000e+00, loss_IC: 3.942e-08,loss_f: 9.516e-08
pinn: 0100, Iter: 1400, total_loss: 6.271e-07, loss_BC: 0.000e+00, loss_IC: 1.036e-07,loss_f: 8.967e-08
pinn: 0300, Iter: 1400, total_loss: 3.930e-07, loss_BC: 0.000e+00, loss_IC: 3.798e-08,loss_f: 9.383e-08
pinn: 0000, Iter: 1400, total_loss: 6.401e-07, loss_BC: 0.000e+00, loss_IC: 7.479e-08,loss_f: 9.960e-08
pinn: 0200, Iter: 1400, total_loss: 3.853e-07, loss_BC: 0.000e+00, loss_IC: 2.978e-08,loss_f: 1.580e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2004, Mean_loss of pinns: 5.108e-07, loss_BC: 0.000e+00, loss_IC: 6.174e-08, loss_f: 1.097e-07
 => minimum loss: 3.842e-07, corresponding pinn index: 0200
 => maximum loss: 6.398e-07, corresponding pinn  index: 0000

==> Epoch: 2010, Mean_loss of pinns: 3.210e-05, loss_BC: 3.142e-05, loss_IC: 7.629e-08, loss_f: 2.624e-07
 => minimum loss: 5.762e-06, corresponding pinn/batch index: 0200
 => maximum loss: 7.109e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 2020, Mean_loss of pinns: 2.928e-05, loss_BC: 2.826e-05, loss_IC: 3.352e-07, loss_f: 3.469e-07
 => minimum loss: 5.597e-06, corresponding pinn/batch index: 0200
 => maximum loss: 6.393e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.276e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2023, total_loss: 2.872e-05, loss_BC: 2.754e-05, loss_IC: 4.873e-07, loss_f: 3.535e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.20000, t_max: 0.21000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2024 0 1

 -------------------------------------------------------------
  -----  Epoch: 2024 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.20000, t_max: 0.21000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2024 !!! 


==> Epoch: 2030, Mean_loss of pinns: 1.063e-02, loss_BC: 3.190e-05, loss_IC: 4.032e-07, loss_f: 1.060e-02
 => minimum loss: 2.637e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.844e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2040, Mean_loss of pinns: 8.539e-03, loss_BC: 3.193e-05, loss_IC: 2.922e-06, loss_f: 8.504e-03
 => minimum loss: 2.082e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.479e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2050, Mean_loss of pinns: 6.946e-03, loss_BC: 3.038e-05, loss_IC: 6.865e-06, loss_f: 6.908e-03
 => minimum loss: 1.617e-03, corresponding pinn/batch index: 0100
 => maximum loss: 1.202e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2060, Mean_loss of pinns: 5.722e-03, loss_BC: 3.034e-05, loss_IC: 1.165e-05, loss_f: 5.679e-03
 => minimum loss: 1.318e-03, corresponding pinn/batch index: 0100
 => maximum loss: 9.861e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2070, Mean_loss of pinns: 4.789e-03, loss_BC: 2.868e-05, loss_IC: 1.709e-05, loss_f: 4.742e-03
 => minimum loss: 1.097e-03, corresponding pinn/batch index: 0100
 => maximum loss: 8.206e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2080, Mean_loss of pinns: 4.063e-03, loss_BC: 2.804e-05, loss_IC: 2.273e-05, loss_f: 4.012e-03
 => minimum loss: 9.296e-04, corresponding pinn/batch index: 0100
 => maximum loss: 6.923e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2090, Mean_loss of pinns: 3.492e-03, loss_BC: 2.620e-05, loss_IC: 2.804e-05, loss_f: 3.438e-03
 => minimum loss: 7.993e-04, corresponding pinn/batch index: 0100
 => maximum loss: 5.916e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2100, Mean_loss of pinns: 3.037e-03, loss_BC: 2.504e-05, loss_IC: 3.269e-05, loss_f: 2.979e-03
 => minimum loss: 6.945e-04, corresponding pinn/batch index: 0100
 => maximum loss: 5.117e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2110, Mean_loss of pinns: 2.670e-03, loss_BC: 2.511e-05, loss_IC: 3.659e-05, loss_f: 2.607e-03
 => minimum loss: 6.115e-04, corresponding pinn/batch index: 0100
 => maximum loss: 4.474e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2120, Mean_loss of pinns: 2.367e-03, loss_BC: 2.411e-05, loss_IC: 3.962e-05, loss_f: 2.303e-03
 => minimum loss: 5.430e-04, corresponding pinn/batch index: 0100
 => maximum loss: 3.950e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2123

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 1.668e-06, loss_BC: 0.000e+00, loss_IC: 1.305e-07,loss_f: 3.701e-07
pinn: 0100, Iter: 100, total_loss: 9.984e-07, loss_BC: 0.000e+00, loss_IC: 1.268e-07,loss_f: 6.164e-07
pinn: 0200, Iter: 100, total_loss: 1.323e-06, loss_BC: 0.000e+00, loss_IC: 1.017e-07,loss_f: 3.884e-07
pinn: 0000, Iter: 100, total_loss: 5.948e-07, loss_BC: 0.000e+00, loss_IC: 9.083e-08,loss_f: 4.097e-07
pinn: 0300, Iter: 200, total_loss: 1.556e-06, loss_BC: 0.000e+00, loss_IC: 1.642e-07,loss_f: 2.653e-07
pinn: 0100, Iter: 200, total_loss: 6.188e-07, loss_BC: 0.000e+00, loss_IC: 9.699e-08,loss_f: 2.338e-07
pinn: 0200, Iter: 200, total_loss: 1.079e-06, loss_BC: 0.000e+00, loss_IC: 7.826e-08,loss_f: 1.755e-07
pinn: 0000, Iter: 200, total_loss: 3.731e-07, loss_BC: 0.000e+00, loss_IC: 7.264e-08,loss_f: 2.065e-07
pinn: 0300, Iter: 300, total_loss: 1.408e-06, loss_BC: 0.000e+00, loss_IC: 1.012e-07,loss_f: 2.167e-07
pinn: 0200, Iter: 300, total_loss: 1.058e-06, loss_BC: 0.000e+00, loss_IC: 8.011e-08,loss_f: 1.651e-07
pinn: 0100, Iter: 300, total_loss: 5.346e-07, loss_BC: 0.000e+00, loss_IC: 9.529e-08,loss_f: 1.576e-07
pinn: 0000, Iter: 300, total_loss: 3.242e-07, loss_BC: 0.000e+00, loss_IC: 6.785e-08,loss_f: 1.625e-07
pinn: 0300, Iter: 400, total_loss: 1.311e-06, loss_BC: 0.000e+00, loss_IC: 1.019e-07,loss_f: 2.214e-07
pinn: 0100, Iter: 400, total_loss: 4.977e-07, loss_BC: 0.000e+00, loss_IC: 8.716e-08,loss_f: 1.425e-07
pinn: 0200, Iter: 400, total_loss: 1.030e-06, loss_BC: 0.000e+00, loss_IC: 8.986e-08,loss_f: 1.589e-07
pinn: 0000, Iter: 400, total_loss: 2.906e-07, loss_BC: 0.000e+00, loss_IC: 7.050e-08,loss_f: 1.270e-07
pinn: 0300, Iter: 500, total_loss: 1.259e-06, loss_BC: 0.000e+00, loss_IC: 1.155e-07,loss_f: 2.014e-07
pinn: 0200, Iter: 500, total_loss: 1.004e-06, loss_BC: 0.000e+00, loss_IC: 1.008e-07,loss_f: 1.537e-07
pinn: 0100, Iter: 500, total_loss: 4.737e-07, loss_BC: 0.000e+00, loss_IC: 8.686e-08,loss_f: 1.279e-07
pinn: 0000, Iter: 500, total_loss: 2.787e-07, loss_BC: 0.000e+00, loss_IC: 7.061e-08,loss_f: 1.149e-07
pinn: 0300, Iter: 600, total_loss: 1.215e-06, loss_BC: 0.000e+00, loss_IC: 1.321e-07,loss_f: 1.870e-07
pinn: 0100, Iter: 600, total_loss: 4.521e-07, loss_BC: 0.000e+00, loss_IC: 8.537e-08,loss_f: 1.186e-07
pinn: 0200, Iter: 600, total_loss: 9.790e-07, loss_BC: 0.000e+00, loss_IC: 1.242e-07,loss_f: 1.512e-07
pinn: 0000, Iter: 600, total_loss: 2.656e-07, loss_BC: 0.000e+00, loss_IC: 6.802e-08,loss_f: 1.043e-07
pinn: 0300, Iter: 700, total_loss: 1.191e-06, loss_BC: 0.000e+00, loss_IC: 1.332e-07,loss_f: 1.816e-07
pinn: 0100, Iter: 700, total_loss: 4.405e-07, loss_BC: 0.000e+00, loss_IC: 8.631e-08,loss_f: 1.085e-07
pinn: 0200, Iter: 700, total_loss: 9.563e-07, loss_BC: 0.000e+00, loss_IC: 1.371e-07,loss_f: 1.543e-07
pinn: 0000, Iter: 700, total_loss: 2.575e-07, loss_BC: 0.000e+00, loss_IC: 6.750e-08,loss_f: 9.644e-08
pinn: 0300, Iter: 800, total_loss: 1.158e-06, loss_BC: 0.000e+00, loss_IC: 1.552e-07,loss_f: 1.766e-07
pinn: 0200, Iter: 800, total_loss: 9.234e-07, loss_BC: 0.000e+00, loss_IC: 1.427e-07,loss_f: 1.528e-07
pinn: 0100, Iter: 800, total_loss: 4.346e-07, loss_BC: 0.000e+00, loss_IC: 8.284e-08,loss_f: 1.084e-07
pinn: 0000, Iter: 800, total_loss: 2.529e-07, loss_BC: 0.000e+00, loss_IC: 6.707e-08,loss_f: 9.214e-08
pinn: 0300, Iter: 900, total_loss: 1.124e-06, loss_BC: 0.000e+00, loss_IC: 1.760e-07,loss_f: 1.820e-07
pinn: 0200, Iter: 900, total_loss: 9.049e-07, loss_BC: 0.000e+00, loss_IC: 1.532e-07,loss_f: 1.558e-07
pinn: 0100, Iter: 900, total_loss: 4.292e-07, loss_BC: 0.000e+00, loss_IC: 7.895e-08,loss_f: 1.090e-07
pinn: 0000, Iter: 900, total_loss: 2.496e-07, loss_BC: 0.000e+00, loss_IC: 6.686e-08,loss_f: 8.881e-08
pinn: 0300, Iter: 1000, total_loss: 1.100e-06, loss_BC: 0.000e+00, loss_IC: 1.724e-07,loss_f: 1.866e-07
pinn: 0200, Iter: 1000, total_loss: 8.722e-07, loss_BC: 0.000e+00, loss_IC: 1.649e-07,loss_f: 1.626e-07
pinn: 0100, Iter: 1000, total_loss: 4.226e-07, loss_BC: 0.000e+00, loss_IC: 7.633e-08,loss_f: 1.072e-07
pinn: 0000, Iter: 1000, total_loss: 2.468e-07, loss_BC: 0.000e+00, loss_IC: 6.452e-08,loss_f: 8.808e-08
pinn: 0300, Iter: 1100, total_loss: 1.091e-06, loss_BC: 0.000e+00, loss_IC: 1.848e-07,loss_f: 1.901e-07
pinn: 0200, Iter: 1100, total_loss: 8.508e-07, loss_BC: 0.000e+00, loss_IC: 1.596e-07,loss_f: 1.657e-07
pinn: 0100, Iter: 1100, total_loss: 4.190e-07, loss_BC: 0.000e+00, loss_IC: 7.373e-08,loss_f: 1.084e-07
pinn: 0000, Iter: 1100, total_loss: 2.426e-07, loss_BC: 0.000e+00, loss_IC: 6.228e-08,loss_f: 8.561e-08
pinn: 0300, Iter: 1200, total_loss: 1.034e-06, loss_BC: 0.000e+00, loss_IC: 1.988e-07,loss_f: 1.917e-07
pinn: 0200, Iter: 1200, total_loss: 8.359e-07, loss_BC: 0.000e+00, loss_IC: 1.547e-07,loss_f: 1.662e-07
pinn: 0100, Iter: 1200, total_loss: 4.127e-07, loss_BC: 0.000e+00, loss_IC: 7.221e-08,loss_f: 1.082e-07
pinn: 0000, Iter: 1200, total_loss: 2.415e-07, loss_BC: 0.000e+00, loss_IC: 6.157e-08,loss_f: 8.514e-08
pinn: 0300, Iter: 1300, total_loss: 9.955e-07, loss_BC: 0.000e+00, loss_IC: 1.975e-07,loss_f: 2.252e-07
pinn: 0200, Iter: 1300, total_loss: 8.255e-07, loss_BC: 0.000e+00, loss_IC: 1.629e-07,loss_f: 1.696e-07
pinn: 0100, Iter: 1300, total_loss: 4.070e-07, loss_BC: 0.000e+00, loss_IC: 7.106e-08,loss_f: 1.076e-07
pinn: 0000, Iter: 1300, total_loss: 2.383e-07, loss_BC: 0.000e+00, loss_IC: 6.013e-08,loss_f: 8.283e-08
pinn: 0300, Iter: 1400, total_loss: 9.819e-07, loss_BC: 0.000e+00, loss_IC: 1.904e-07,loss_f: 2.200e-07
pinn: 0200, Iter: 1400, total_loss: 8.059e-07, loss_BC: 0.000e+00, loss_IC: 1.642e-07,loss_f: 1.725e-07
pinn: 0100, Iter: 1400, total_loss: 4.048e-07, loss_BC: 0.000e+00, loss_IC: 7.013e-08,loss_f: 1.084e-07
pinn: 0000, Iter: 1400, total_loss: 2.370e-07, loss_BC: 0.000e+00, loss_IC: 5.868e-08,loss_f: 8.292e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2123, Mean_loss of pinns: 6.040e-07, loss_BC: 0.000e+00, loss_IC: 1.192e-07, loss_f: 1.423e-07
 => minimum loss: 2.362e-07, corresponding pinn index: 0000
 => maximum loss: 9.738e-07, corresponding pinn  index: 0300

==> Epoch: 2130, Mean_loss of pinns: 3.042e-05, loss_BC: 2.962e-05, loss_IC: 1.557e-07, loss_f: 3.064e-07
 => minimum loss: 5.351e-06, corresponding pinn/batch index: 0200
 => maximum loss: 7.148e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 2140, Mean_loss of pinns: 2.900e-05, loss_BC: 2.793e-05, loss_IC: 3.327e-07, loss_f: 3.896e-07
 => minimum loss: 5.627e-06, corresponding pinn/batch index: 0200
 => maximum loss: 6.852e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.998e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2142, total_loss: 2.922e-05, loss_BC: 2.810e-05, loss_IC: 3.789e-07, loss_f: 3.998e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.21000, t_max: 0.22000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2143 0 1

 -------------------------------------------------------------
  -----  Epoch: 2143 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.21000, t_max: 0.22000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2143 !!! 


==> Epoch: 2150, Mean_loss of pinns: 5.163e-03, loss_BC: 3.246e-05, loss_IC: 9.560e-07, loss_f: 5.129e-03
 => minimum loss: 2.267e-03, corresponding pinn/batch index: 0000
 => maximum loss: 1.102e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2160, Mean_loss of pinns: 3.994e-03, loss_BC: 3.261e-05, loss_IC: 5.301e-06, loss_f: 3.955e-03
 => minimum loss: 1.875e-03, corresponding pinn/batch index: 0000
 => maximum loss: 8.230e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2170, Mean_loss of pinns: 3.149e-03, loss_BC: 3.109e-05, loss_IC: 1.180e-05, loss_f: 3.106e-03
 => minimum loss: 1.571e-03, corresponding pinn/batch index: 0000
 => maximum loss: 6.376e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2180, Mean_loss of pinns: 2.543e-03, loss_BC: 3.028e-05, loss_IC: 1.952e-05, loss_f: 2.493e-03
 => minimum loss: 1.334e-03, corresponding pinn/batch index: 0000
 => maximum loss: 5.017e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2190, Mean_loss of pinns: 2.106e-03, loss_BC: 2.871e-05, loss_IC: 2.737e-05, loss_f: 2.049e-03
 => minimum loss: 1.145e-03, corresponding pinn/batch index: 0000
 => maximum loss: 4.081e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2200, Mean_loss of pinns: 1.781e-03, loss_BC: 2.772e-05, loss_IC: 3.411e-05, loss_f: 1.719e-03
 => minimum loss: 9.990e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.404e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2210, Mean_loss of pinns: 1.534e-03, loss_BC: 2.624e-05, loss_IC: 3.904e-05, loss_f: 1.468e-03
 => minimum loss: 8.774e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.905e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2220, Mean_loss of pinns: 1.342e-03, loss_BC: 2.584e-05, loss_IC: 4.200e-05, loss_f: 1.273e-03
 => minimum loss: 7.819e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.525e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2230, Mean_loss of pinns: 1.187e-03, loss_BC: 2.548e-05, loss_IC: 4.321e-05, loss_f: 1.118e-03
 => minimum loss: 7.031e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.228e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2240, Mean_loss of pinns: 1.060e-03, loss_BC: 2.429e-05, loss_IC: 4.306e-05, loss_f: 9.925e-04
 => minimum loss: 6.334e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.987e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2242

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 9.186e-07, loss_BC: 0.000e+00, loss_IC: 9.082e-08,loss_f: 4.163e-07
pinn: 0100, Iter: 100, total_loss: 1.406e-06, loss_BC: 0.000e+00, loss_IC: 1.402e-07,loss_f: 2.456e-07
pinn: 0300, Iter: 100, total_loss: 9.362e-07, loss_BC: 0.000e+00, loss_IC: 1.845e-07,loss_f: 3.646e-07
pinn: 0200, Iter: 100, total_loss: 9.947e-07, loss_BC: 0.000e+00, loss_IC: 1.028e-07,loss_f: 4.548e-07
pinn: 0000, Iter: 200, total_loss: 6.585e-07, loss_BC: 0.000e+00, loss_IC: 7.750e-08,loss_f: 1.704e-07
pinn: 0200, Iter: 200, total_loss: 7.305e-07, loss_BC: 0.000e+00, loss_IC: 7.580e-08,loss_f: 2.067e-07
pinn: 0300, Iter: 200, total_loss: 7.640e-07, loss_BC: 0.000e+00, loss_IC: 1.405e-07,loss_f: 2.442e-07
pinn: 0100, Iter: 200, total_loss: 1.195e-06, loss_BC: 0.000e+00, loss_IC: 9.699e-08,loss_f: 1.024e-07
pinn: 0000, Iter: 300, total_loss: 6.031e-07, loss_BC: 0.000e+00, loss_IC: 6.852e-08,loss_f: 1.282e-07
pinn: 0200, Iter: 300, total_loss: 6.969e-07, loss_BC: 0.000e+00, loss_IC: 7.649e-08,loss_f: 1.776e-07
pinn: 0100, Iter: 300, total_loss: 1.144e-06, loss_BC: 0.000e+00, loss_IC: 9.551e-08,loss_f: 8.593e-08
pinn: 0300, Iter: 300, total_loss: 6.908e-07, loss_BC: 0.000e+00, loss_IC: 1.045e-07,loss_f: 2.199e-07
pinn: 0000, Iter: 400, total_loss: 5.795e-07, loss_BC: 0.000e+00, loss_IC: 7.379e-08,loss_f: 1.077e-07
pinn: 0200, Iter: 400, total_loss: 6.727e-07, loss_BC: 0.000e+00, loss_IC: 7.459e-08,loss_f: 1.644e-07
pinn: 0100, Iter: 400, total_loss: 1.098e-06, loss_BC: 0.000e+00, loss_IC: 1.244e-07,loss_f: 8.700e-08
pinn: 0300, Iter: 400, total_loss: 6.287e-07, loss_BC: 0.000e+00, loss_IC: 9.536e-08,loss_f: 1.805e-07
pinn: 0000, Iter: 500, total_loss: 5.717e-07, loss_BC: 0.000e+00, loss_IC: 7.674e-08,loss_f: 1.021e-07
pinn: 0200, Iter: 500, total_loss: 6.583e-07, loss_BC: 0.000e+00, loss_IC: 7.687e-08,loss_f: 1.549e-07
pinn: 0300, Iter: 500, total_loss: 6.125e-07, loss_BC: 0.000e+00, loss_IC: 9.210e-08,loss_f: 1.718e-07
pinn: 0100, Iter: 500, total_loss: 1.075e-06, loss_BC: 0.000e+00, loss_IC: 1.362e-07,loss_f: 8.399e-08
pinn: 0000, Iter: 600, total_loss: 5.670e-07, loss_BC: 0.000e+00, loss_IC: 7.803e-08,loss_f: 9.883e-08
pinn: 0200, Iter: 600, total_loss: 6.436e-07, loss_BC: 0.000e+00, loss_IC: 8.208e-08,loss_f: 1.457e-07
pinn: 0300, Iter: 600, total_loss: 5.936e-07, loss_BC: 0.000e+00, loss_IC: 9.038e-08,loss_f: 1.579e-07
pinn: 0100, Iter: 600, total_loss: 1.044e-06, loss_BC: 0.000e+00, loss_IC: 1.640e-07,loss_f: 8.084e-08
pinn: 0000, Iter: 700, total_loss: 5.639e-07, loss_BC: 0.000e+00, loss_IC: 8.060e-08,loss_f: 9.719e-08
pinn: 0200, Iter: 700, total_loss: 6.364e-07, loss_BC: 0.000e+00, loss_IC: 8.618e-08,loss_f: 1.408e-07
pinn: 0300, Iter: 700, total_loss: 5.847e-07, loss_BC: 0.000e+00, loss_IC: 9.146e-08,loss_f: 1.506e-07
pinn: 0100, Iter: 700, total_loss: 1.009e-06, loss_BC: 0.000e+00, loss_IC: 1.784e-07,loss_f: 8.111e-08
pinn: 0000, Iter: 800, total_loss: 5.591e-07, loss_BC: 0.000e+00, loss_IC: 7.732e-08,loss_f: 9.741e-08
pinn: 0200, Iter: 800, total_loss: 6.276e-07, loss_BC: 0.000e+00, loss_IC: 8.823e-08,loss_f: 1.360e-07
pinn: 0100, Iter: 800, total_loss: 9.822e-07, loss_BC: 0.000e+00, loss_IC: 1.938e-07,loss_f: 9.320e-08
pinn: 0300, Iter: 800, total_loss: 5.733e-07, loss_BC: 0.000e+00, loss_IC: 9.293e-08,loss_f: 1.406e-07
pinn: 0000, Iter: 900, total_loss: 5.512e-07, loss_BC: 0.000e+00, loss_IC: 8.081e-08,loss_f: 9.439e-08
pinn: 0200, Iter: 900, total_loss: 6.229e-07, loss_BC: 0.000e+00, loss_IC: 8.426e-08,loss_f: 1.354e-07
pinn: 0100, Iter: 900, total_loss: 9.323e-07, loss_BC: 0.000e+00, loss_IC: 2.040e-07,loss_f: 1.001e-07
pinn: 0300, Iter: 900, total_loss: 5.665e-07, loss_BC: 0.000e+00, loss_IC: 9.193e-08,loss_f: 1.349e-07
pinn: 0000, Iter: 1000, total_loss: 5.407e-07, loss_BC: 0.000e+00, loss_IC: 8.282e-08,loss_f: 9.221e-08
pinn: 0100, Iter: 1000, total_loss: 9.110e-07, loss_BC: 0.000e+00, loss_IC: 2.580e-07,loss_f: 1.061e-07
pinn: 0200, Iter: 1000, total_loss: 6.104e-07, loss_BC: 0.000e+00, loss_IC: 7.733e-08,loss_f: 1.377e-07
pinn: 0300, Iter: 1000, total_loss: 5.631e-07, loss_BC: 0.000e+00, loss_IC: 9.635e-08,loss_f: 1.304e-07
pinn: 0000, Iter: 1100, total_loss: 5.347e-07, loss_BC: 0.000e+00, loss_IC: 8.168e-08,loss_f: 9.299e-08
pinn: 0100, Iter: 1100, total_loss: 8.691e-07, loss_BC: 0.000e+00, loss_IC: 2.589e-07,loss_f: 1.221e-07
pinn: 0200, Iter: 1100, total_loss: 6.033e-07, loss_BC: 0.000e+00, loss_IC: 7.579e-08,loss_f: 1.368e-07
pinn: 0300, Iter: 1100, total_loss: 5.585e-07, loss_BC: 0.000e+00, loss_IC: 9.494e-08,loss_f: 1.279e-07
pinn: 0100, Iter: 1200, total_loss: 8.502e-07, loss_BC: 0.000e+00, loss_IC: 2.391e-07,loss_f: 1.148e-07
pinn: 0000, Iter: 1200, total_loss: 5.302e-07, loss_BC: 0.000e+00, loss_IC: 8.234e-08,loss_f: 9.264e-08
pinn: 0200, Iter: 1200, total_loss: 6.008e-07, loss_BC: 0.000e+00, loss_IC: 7.417e-08,loss_f: 1.361e-07
pinn: 0300, Iter: 1200, total_loss: 5.530e-07, loss_BC: 0.000e+00, loss_IC: 9.384e-08,loss_f: 1.258e-07
pinn: 0100, Iter: 1300, total_loss: 8.079e-07, loss_BC: 0.000e+00, loss_IC: 2.548e-07,loss_f: 1.258e-07
pinn: 0000, Iter: 1300, total_loss: 5.231e-07, loss_BC: 0.000e+00, loss_IC: 8.413e-08,loss_f: 9.099e-08
pinn: 0200, Iter: 1300, total_loss: 5.936e-07, loss_BC: 0.000e+00, loss_IC: 7.258e-08,loss_f: 1.356e-07
pinn: 0300, Iter: 1300, total_loss: 5.473e-07, loss_BC: 0.000e+00, loss_IC: 9.158e-08,loss_f: 1.225e-07
pinn: 0100, Iter: 1400, total_loss: 7.934e-07, loss_BC: 0.000e+00, loss_IC: 2.592e-07,loss_f: 1.357e-07
pinn: 0000, Iter: 1400, total_loss: 5.130e-07, loss_BC: 0.000e+00, loss_IC: 8.280e-08,loss_f: 9.086e-08
pinn: 0200, Iter: 1400, total_loss: 5.887e-07, loss_BC: 0.000e+00, loss_IC: 7.318e-08,loss_f: 1.364e-07
pinn: 0300, Iter: 1400, total_loss: 5.429e-07, loss_BC: 0.000e+00, loss_IC: 8.962e-08,loss_f: 1.223e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2242, Mean_loss of pinns: 6.085e-07, loss_BC: 0.000e+00, loss_IC: 1.270e-07, loss_f: 1.238e-07
 => minimum loss: 5.126e-07, corresponding pinn index: 0000
 => maximum loss: 7.914e-07, corresponding pinn  index: 0100

==> Epoch: 2250, Mean_loss of pinns: 3.686e-05, loss_BC: 3.606e-05, loss_IC: 1.696e-07, loss_f: 2.664e-07
 => minimum loss: 7.239e-06, corresponding pinn/batch index: 0200
 => maximum loss: 8.358e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 2260, Mean_loss of pinns: 3.361e-05, loss_BC: 3.231e-05, loss_IC: 6.190e-07, loss_f: 3.193e-07
 => minimum loss: 7.075e-06, corresponding pinn/batch index: 0200
 => maximum loss: 7.408e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 2270, Mean_loss of pinns: 3.278e-05, loss_BC: 3.070e-05, loss_IC: 1.417e-06, loss_f: 3.049e-07
 => minimum loss: 7.301e-06, corresponding pinn/batch index: 0200
 => maximum loss: 7.273e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 2280, Mean_loss of pinns: 3.129e-05, loss_BC: 2.860e-05, loss_IC: 2.080e-06, loss_f: 2.549e-07
 => minimum loss: 7.452e-06, corresponding pinn/batch index: 0200
 => maximum loss: 6.860e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

==> Epoch: 2290, Mean_loss of pinns: 3.118e-05, loss_BC: 2.816e-05, loss_IC: 2.427e-06, loss_f: 2.393e-07
 => minimum loss: 7.201e-06, corresponding pinn/batch index: 0200
 => maximum loss: 6.941e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.794e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2295, total_loss: 3.062e-05, loss_BC: 2.753e-05, loss_IC: 2.500e-06, loss_f: 2.328e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.22000, t_max: 0.23000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2296 0 1

 -------------------------------------------------------------
  -----  Epoch: 2296 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.22000, t_max: 0.23000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2296 !!! 


==> Epoch: 2300, Mean_loss of pinns: 5.534e-03, loss_BC: 3.256e-05, loss_IC: 3.679e-07, loss_f: 5.501e-03
 => minimum loss: 1.361e-03, corresponding pinn/batch index: 0000
 => maximum loss: 9.133e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2310, Mean_loss of pinns: 4.214e-03, loss_BC: 3.290e-05, loss_IC: 4.167e-06, loss_f: 4.176e-03
 => minimum loss: 1.101e-03, corresponding pinn/batch index: 0000
 => maximum loss: 6.797e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2320, Mean_loss of pinns: 3.315e-03, loss_BC: 3.132e-05, loss_IC: 1.095e-05, loss_f: 3.272e-03
 => minimum loss: 9.067e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.307e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2330, Mean_loss of pinns: 2.657e-03, loss_BC: 2.997e-05, loss_IC: 1.950e-05, loss_f: 2.608e-03
 => minimum loss: 7.621e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.184e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2340, Mean_loss of pinns: 2.190e-03, loss_BC: 2.975e-05, loss_IC: 2.847e-05, loss_f: 2.132e-03
 => minimum loss: 6.564e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.409e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2350, Mean_loss of pinns: 1.845e-03, loss_BC: 2.901e-05, loss_IC: 3.629e-05, loss_f: 1.779e-03
 => minimum loss: 5.721e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.840e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2360, Mean_loss of pinns: 1.585e-03, loss_BC: 2.893e-05, loss_IC: 4.209e-05, loss_f: 1.514e-03
 => minimum loss: 5.097e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.421e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2370, Mean_loss of pinns: 1.382e-03, loss_BC: 2.801e-05, loss_IC: 4.575e-05, loss_f: 1.308e-03
 => minimum loss: 4.554e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.100e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2380, Mean_loss of pinns: 1.220e-03, loss_BC: 2.752e-05, loss_IC: 4.742e-05, loss_f: 1.145e-03
 => minimum loss: 4.117e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.847e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2390, Mean_loss of pinns: 1.089e-03, loss_BC: 2.811e-05, loss_IC: 4.735e-05, loss_f: 1.013e-03
 => minimum loss: 3.778e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.644e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2395

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 1.155e-06, loss_BC: 0.000e+00, loss_IC: 1.007e-07,loss_f: 3.243e-07
pinn: 0200, Iter: 100, total_loss: 6.526e-07, loss_BC: 0.000e+00, loss_IC: 1.096e-07,loss_f: 3.422e-07
pinn: 0300, Iter: 100, total_loss: 9.309e-07, loss_BC: 0.000e+00, loss_IC: 1.673e-07,loss_f: 6.122e-07
pinn: 0100, Iter: 100, total_loss: 1.162e-06, loss_BC: 0.000e+00, loss_IC: 1.057e-07,loss_f: 5.376e-07
pinn: 0000, Iter: 200, total_loss: 9.822e-07, loss_BC: 0.000e+00, loss_IC: 1.091e-07,loss_f: 1.498e-07
pinn: 0200, Iter: 200, total_loss: 4.452e-07, loss_BC: 0.000e+00, loss_IC: 8.058e-08,loss_f: 1.649e-07
pinn: 0100, Iter: 200, total_loss: 9.545e-07, loss_BC: 0.000e+00, loss_IC: 8.091e-08,loss_f: 3.090e-07
pinn: 0300, Iter: 200, total_loss: 5.259e-07, loss_BC: 0.000e+00, loss_IC: 1.456e-07,loss_f: 2.337e-07
pinn: 0000, Iter: 300, total_loss: 9.115e-07, loss_BC: 0.000e+00, loss_IC: 9.222e-08,loss_f: 1.041e-07
pinn: 0200, Iter: 300, total_loss: 4.130e-07, loss_BC: 0.000e+00, loss_IC: 7.775e-08,loss_f: 1.370e-07
pinn: 0100, Iter: 300, total_loss: 8.742e-07, loss_BC: 0.000e+00, loss_IC: 6.301e-08,loss_f: 3.147e-07
pinn: 0300, Iter: 300, total_loss: 4.677e-07, loss_BC: 0.000e+00, loss_IC: 1.427e-07,loss_f: 1.769e-07
pinn: 0000, Iter: 400, total_loss: 8.733e-07, loss_BC: 0.000e+00, loss_IC: 8.883e-08,loss_f: 8.829e-08
pinn: 0200, Iter: 400, total_loss: 3.899e-07, loss_BC: 0.000e+00, loss_IC: 7.294e-08,loss_f: 1.202e-07
pinn: 0100, Iter: 400, total_loss: 7.878e-07, loss_BC: 0.000e+00, loss_IC: 6.278e-08,loss_f: 2.883e-07
pinn: 0300, Iter: 400, total_loss: 4.357e-07, loss_BC: 0.000e+00, loss_IC: 1.127e-07,loss_f: 1.780e-07
pinn: 0000, Iter: 500, total_loss: 8.517e-07, loss_BC: 0.000e+00, loss_IC: 9.654e-08,loss_f: 8.485e-08
pinn: 0100, Iter: 500, total_loss: 7.096e-07, loss_BC: 0.000e+00, loss_IC: 4.708e-08,loss_f: 2.772e-07
pinn: 0200, Iter: 500, total_loss: 3.821e-07, loss_BC: 0.000e+00, loss_IC: 7.186e-08,loss_f: 1.142e-07
pinn: 0300, Iter: 500, total_loss: 4.189e-07, loss_BC: 0.000e+00, loss_IC: 1.051e-07,loss_f: 1.705e-07
pinn: 0000, Iter: 600, total_loss: 8.368e-07, loss_BC: 0.000e+00, loss_IC: 9.698e-08,loss_f: 8.116e-08
pinn: 0200, Iter: 600, total_loss: 3.700e-07, loss_BC: 0.000e+00, loss_IC: 7.297e-08,loss_f: 1.039e-07
pinn: 0100, Iter: 600, total_loss: 6.479e-07, loss_BC: 0.000e+00, loss_IC: 5.017e-08,loss_f: 2.506e-07
pinn: 0300, Iter: 600, total_loss: 4.126e-07, loss_BC: 0.000e+00, loss_IC: 1.014e-07,loss_f: 1.679e-07
pinn: 0000, Iter: 700, total_loss: 8.227e-07, loss_BC: 0.000e+00, loss_IC: 1.080e-07,loss_f: 8.243e-08
pinn: 0100, Iter: 700, total_loss: 5.534e-07, loss_BC: 0.000e+00, loss_IC: 3.546e-08,loss_f: 2.210e-07
pinn: 0200, Iter: 700, total_loss: 3.665e-07, loss_BC: 0.000e+00, loss_IC: 7.168e-08,loss_f: 1.017e-07
pinn: 0300, Iter: 700, total_loss: 4.038e-07, loss_BC: 0.000e+00, loss_IC: 9.902e-08,loss_f: 1.619e-07
pinn: 0000, Iter: 800, total_loss: 7.988e-07, loss_BC: 0.000e+00, loss_IC: 1.319e-07,loss_f: 7.859e-08
pinn: 0200, Iter: 800, total_loss: 3.597e-07, loss_BC: 0.000e+00, loss_IC: 6.977e-08,loss_f: 9.827e-08
pinn: 0100, Iter: 800, total_loss: 5.311e-07, loss_BC: 0.000e+00, loss_IC: 3.003e-08,loss_f: 2.136e-07
pinn: 0300, Iter: 800, total_loss: 3.964e-07, loss_BC: 0.000e+00, loss_IC: 9.593e-08,loss_f: 1.588e-07
pinn: 0000, Iter: 900, total_loss: 7.905e-07, loss_BC: 0.000e+00, loss_IC: 1.373e-07,loss_f: 7.817e-08
pinn: 0100, Iter: 900, total_loss: 5.173e-07, loss_BC: 0.000e+00, loss_IC: 3.249e-08,loss_f: 2.054e-07
pinn: 0200, Iter: 900, total_loss: 3.566e-07, loss_BC: 0.000e+00, loss_IC: 6.951e-08,loss_f: 9.637e-08
pinn: 0300, Iter: 900, total_loss: 3.868e-07, loss_BC: 0.000e+00, loss_IC: 9.184e-08,loss_f: 1.521e-07
pinn: 0000, Iter: 1000, total_loss: 7.729e-07, loss_BC: 0.000e+00, loss_IC: 1.382e-07,loss_f: 8.303e-08
pinn: 0200, Iter: 1000, total_loss: 3.506e-07, loss_BC: 0.000e+00, loss_IC: 6.961e-08,loss_f: 9.216e-08
pinn: 0100, Iter: 1000, total_loss: 4.923e-07, loss_BC: 0.000e+00, loss_IC: 2.980e-08,loss_f: 2.072e-07
pinn: 0300, Iter: 1000, total_loss: 3.784e-07, loss_BC: 0.000e+00, loss_IC: 8.862e-08,loss_f: 1.462e-07
pinn: 0000, Iter: 1100, total_loss: 7.660e-07, loss_BC: 0.000e+00, loss_IC: 1.459e-07,loss_f: 8.549e-08
pinn: 0100, Iter: 1100, total_loss: 4.560e-07, loss_BC: 0.000e+00, loss_IC: 2.818e-08,loss_f: 2.070e-07
pinn: 0200, Iter: 1100, total_loss: 3.483e-07, loss_BC: 0.000e+00, loss_IC: 6.947e-08,loss_f: 9.035e-08
pinn: 0300, Iter: 1100, total_loss: 3.706e-07, loss_BC: 0.000e+00, loss_IC: 8.430e-08,loss_f: 1.417e-07
pinn: 0000, Iter: 1200, total_loss: 7.542e-07, loss_BC: 0.000e+00, loss_IC: 1.345e-07,loss_f: 9.251e-08
pinn: 0200, Iter: 1200, total_loss: 3.472e-07, loss_BC: 0.000e+00, loss_IC: 6.897e-08,loss_f: 8.989e-08
pinn: 0100, Iter: 1200, total_loss: 4.320e-07, loss_BC: 0.000e+00, loss_IC: 2.558e-08,loss_f: 1.991e-07
pinn: 0300, Iter: 1200, total_loss: 3.555e-07, loss_BC: 0.000e+00, loss_IC: 7.356e-08,loss_f: 1.342e-07
pinn: 0000, Iter: 1300, total_loss: 7.413e-07, loss_BC: 0.000e+00, loss_IC: 1.497e-07,loss_f: 9.427e-08
pinn: 0200, Iter: 1300, total_loss: 3.444e-07, loss_BC: 0.000e+00, loss_IC: 6.722e-08,loss_f: 8.923e-08
pinn: 0100, Iter: 1300, total_loss: 4.217e-07, loss_BC: 0.000e+00, loss_IC: 2.430e-08,loss_f: 1.979e-07
pinn: 0300, Iter: 1300, total_loss: 3.402e-07, loss_BC: 0.000e+00, loss_IC: 5.951e-08,loss_f: 1.289e-07
pinn: 0000, Iter: 1400, total_loss: 7.256e-07, loss_BC: 0.000e+00, loss_IC: 1.332e-07,loss_f: 1.037e-07
pinn: 0200, Iter: 1400, total_loss: 3.436e-07, loss_BC: 0.000e+00, loss_IC: 6.661e-08,loss_f: 8.926e-08
pinn: 0100, Iter: 1400, total_loss: 4.131e-07, loss_BC: 0.000e+00, loss_IC: 2.267e-08,loss_f: 1.946e-07
pinn: 0300, Iter: 1400, total_loss: 3.333e-07, loss_BC: 0.000e+00, loss_IC: 5.335e-08,loss_f: 1.262e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2395, Mean_loss of pinns: 4.530e-07, loss_BC: 0.000e+00, loss_IC: 6.871e-08, loss_f: 1.293e-07
 => minimum loss: 3.331e-07, corresponding pinn index: 0300
 => maximum loss: 7.232e-07, corresponding pinn  index: 0000

 max_loss: 6.369e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2397, total_loss: 3.136e-05, loss_BC: 3.090e-05, loss_IC: 6.921e-08, loss_f: 1.373e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.23000, t_max: 0.24000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2398 0 1

 -------------------------------------------------------------
  -----  Epoch: 2398 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.23000, t_max: 0.24000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2398 !!! 


==> Epoch: 2400, Mean_loss of pinns: 3.062e-03, loss_BC: 3.600e-05, loss_IC: 8.314e-08, loss_f: 3.025e-03
 => minimum loss: 1.897e-03, corresponding pinn/batch index: 0200
 => maximum loss: 4.714e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2410, Mean_loss of pinns: 2.276e-03, loss_BC: 3.709e-05, loss_IC: 2.940e-06, loss_f: 2.236e-03
 => minimum loss: 1.497e-03, corresponding pinn/batch index: 0200
 => maximum loss: 3.266e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2420, Mean_loss of pinns: 1.798e-03, loss_BC: 3.671e-05, loss_IC: 8.350e-06, loss_f: 1.753e-03
 => minimum loss: 1.199e-03, corresponding pinn/batch index: 0200
 => maximum loss: 2.564e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2430, Mean_loss of pinns: 1.449e-03, loss_BC: 3.630e-05, loss_IC: 1.491e-05, loss_f: 1.397e-03
 => minimum loss: 9.843e-04, corresponding pinn/batch index: 0200
 => maximum loss: 2.007e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2440, Mean_loss of pinns: 1.203e-03, loss_BC: 3.394e-05, loss_IC: 2.122e-05, loss_f: 1.147e-03
 => minimum loss: 8.255e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.638e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2450, Mean_loss of pinns: 1.019e-03, loss_BC: 3.289e-05, loss_IC: 2.598e-05, loss_f: 9.601e-04
 => minimum loss: 7.038e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.368e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2460, Mean_loss of pinns: 8.786e-04, loss_BC: 3.127e-05, loss_IC: 2.828e-05, loss_f: 8.187e-04
 => minimum loss: 6.088e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.165e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2470, Mean_loss of pinns: 7.684e-04, loss_BC: 3.045e-05, loss_IC: 2.818e-05, loss_f: 7.094e-04
 => minimum loss: 5.332e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.011e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2480, Mean_loss of pinns: 6.780e-04, loss_BC: 2.854e-05, loss_IC: 2.643e-05, loss_f: 6.227e-04
 => minimum loss: 4.720e-04, corresponding pinn/batch index: 0200
 => maximum loss: 8.854e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2490, Mean_loss of pinns: 6.045e-04, loss_BC: 2.781e-05, loss_IC: 2.375e-05, loss_f: 5.525e-04
 => minimum loss: 4.226e-04, corresponding pinn/batch index: 0200
 => maximum loss: 7.846e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2497

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 7.168e-07, loss_BC: 0.000e+00, loss_IC: 7.879e-08,loss_f: 3.072e-07
pinn: 0100, Iter: 100, total_loss: 6.929e-07, loss_BC: 0.000e+00, loss_IC: 8.440e-08,loss_f: 4.679e-07
pinn: 0000, Iter: 100, total_loss: 9.427e-07, loss_BC: 0.000e+00, loss_IC: 7.185e-08,loss_f: 2.838e-07
pinn: 0300, Iter: 100, total_loss: 8.728e-07, loss_BC: 0.000e+00, loss_IC: 1.057e-07,loss_f: 4.619e-07
pinn: 0200, Iter: 200, total_loss: 5.086e-07, loss_BC: 0.000e+00, loss_IC: 7.537e-08,loss_f: 1.106e-07
pinn: 0100, Iter: 200, total_loss: 3.350e-07, loss_BC: 0.000e+00, loss_IC: 4.038e-08,loss_f: 1.578e-07
pinn: 0300, Iter: 200, total_loss: 5.053e-07, loss_BC: 0.000e+00, loss_IC: 7.331e-08,loss_f: 1.453e-07
pinn: 0000, Iter: 200, total_loss: 7.525e-07, loss_BC: 0.000e+00, loss_IC: 4.691e-08,loss_f: 1.111e-07
pinn: 0200, Iter: 300, total_loss: 4.869e-07, loss_BC: 0.000e+00, loss_IC: 6.749e-08,loss_f: 9.751e-08
pinn: 0100, Iter: 300, total_loss: 3.095e-07, loss_BC: 0.000e+00, loss_IC: 3.560e-08,loss_f: 1.359e-07
pinn: 0000, Iter: 300, total_loss: 7.239e-07, loss_BC: 0.000e+00, loss_IC: 3.896e-08,loss_f: 9.080e-08
pinn: 0300, Iter: 300, total_loss: 4.671e-07, loss_BC: 0.000e+00, loss_IC: 6.451e-08,loss_f: 1.141e-07
pinn: 0200, Iter: 400, total_loss: 4.758e-07, loss_BC: 0.000e+00, loss_IC: 6.692e-08,loss_f: 8.843e-08
pinn: 0100, Iter: 400, total_loss: 2.911e-07, loss_BC: 0.000e+00, loss_IC: 3.185e-08,loss_f: 1.202e-07
pinn: 0000, Iter: 400, total_loss: 7.103e-07, loss_BC: 0.000e+00, loss_IC: 4.063e-08,loss_f: 8.173e-08
pinn: 0300, Iter: 400, total_loss: 4.515e-07, loss_BC: 0.000e+00, loss_IC: 6.513e-08,loss_f: 1.016e-07
pinn: 0200, Iter: 500, total_loss: 4.658e-07, loss_BC: 0.000e+00, loss_IC: 6.700e-08,loss_f: 8.107e-08
pinn: 0100, Iter: 500, total_loss: 2.780e-07, loss_BC: 0.000e+00, loss_IC: 2.909e-08,loss_f: 1.091e-07
pinn: 0300, Iter: 500, total_loss: 4.451e-07, loss_BC: 0.000e+00, loss_IC: 6.672e-08,loss_f: 9.520e-08
pinn: 0000, Iter: 500, total_loss: 6.963e-07, loss_BC: 0.000e+00, loss_IC: 4.490e-08,loss_f: 7.901e-08
pinn: 0200, Iter: 600, total_loss: 4.605e-07, loss_BC: 0.000e+00, loss_IC: 6.412e-08,loss_f: 8.016e-08
pinn: 0100, Iter: 600, total_loss: 2.530e-07, loss_BC: 0.000e+00, loss_IC: 2.457e-08,loss_f: 8.607e-08
pinn: 0300, Iter: 600, total_loss: 4.353e-07, loss_BC: 0.000e+00, loss_IC: 6.707e-08,loss_f: 8.895e-08
pinn: 0000, Iter: 600, total_loss: 6.828e-07, loss_BC: 0.000e+00, loss_IC: 5.853e-08,loss_f: 7.738e-08
pinn: 0200, Iter: 700, total_loss: 4.581e-07, loss_BC: 0.000e+00, loss_IC: 6.359e-08,loss_f: 7.937e-08
pinn: 0100, Iter: 700, total_loss: 2.425e-07, loss_BC: 0.000e+00, loss_IC: 2.257e-08,loss_f: 7.633e-08
pinn: 0000, Iter: 700, total_loss: 6.692e-07, loss_BC: 0.000e+00, loss_IC: 6.079e-08,loss_f: 8.133e-08
pinn: 0300, Iter: 700, total_loss: 4.248e-07, loss_BC: 0.000e+00, loss_IC: 6.543e-08,loss_f: 8.204e-08
pinn: 0200, Iter: 800, total_loss: 4.536e-07, loss_BC: 0.000e+00, loss_IC: 6.201e-08,loss_f: 7.847e-08
pinn: 0100, Iter: 800, total_loss: 2.359e-07, loss_BC: 0.000e+00, loss_IC: 2.216e-08,loss_f: 7.061e-08
pinn: 0300, Iter: 800, total_loss: 4.196e-07, loss_BC: 0.000e+00, loss_IC: 6.728e-08,loss_f: 7.875e-08
pinn: 0000, Iter: 800, total_loss: 6.551e-07, loss_BC: 0.000e+00, loss_IC: 6.314e-08,loss_f: 8.355e-08
pinn: 0200, Iter: 900, total_loss: 4.429e-07, loss_BC: 0.000e+00, loss_IC: 6.407e-08,loss_f: 7.568e-08
pinn: 0100, Iter: 900, total_loss: 2.369e-07, loss_BC: 0.000e+00, loss_IC: 2.271e-08,loss_f: 7.043e-08
pinn: 0000, Iter: 900, total_loss: 6.401e-07, loss_BC: 0.000e+00, loss_IC: 7.790e-08,loss_f: 9.426e-08
pinn: 0300, Iter: 900, total_loss: 4.155e-07, loss_BC: 0.000e+00, loss_IC: 6.623e-08,loss_f: 7.765e-08
pinn: 0200, Iter: 1000, total_loss: 4.371e-07, loss_BC: 0.000e+00, loss_IC: 6.404e-08,loss_f: 7.668e-08
pinn: 0100, Iter: 1000, total_loss: 2.261e-07, loss_BC: 0.000e+00, loss_IC: 2.362e-08,loss_f: 6.037e-08
pinn: 0000, Iter: 1000, total_loss: 6.121e-07, loss_BC: 0.000e+00, loss_IC: 8.621e-08,loss_f: 9.196e-08
pinn: 0300, Iter: 1000, total_loss: 4.105e-07, loss_BC: 0.000e+00, loss_IC: 6.745e-08,loss_f: 7.456e-08
pinn: 0200, Iter: 1100, total_loss: 4.339e-07, loss_BC: 0.000e+00, loss_IC: 6.399e-08,loss_f: 7.689e-08
pinn: 0100, Iter: 1100, total_loss: 2.200e-07, loss_BC: 0.000e+00, loss_IC: 2.273e-08,loss_f: 5.581e-08
pinn: 0000, Iter: 1100, total_loss: 5.901e-07, loss_BC: 0.000e+00, loss_IC: 9.242e-08,loss_f: 9.106e-08
pinn: 0300, Iter: 1100, total_loss: 4.076e-07, loss_BC: 0.000e+00, loss_IC: 6.696e-08,loss_f: 7.323e-08
pinn: 0200, Iter: 1200, total_loss: 4.268e-07, loss_BC: 0.000e+00, loss_IC: 6.342e-08,loss_f: 7.946e-08
pinn: 0100, Iter: 1200, total_loss: 2.169e-07, loss_BC: 0.000e+00, loss_IC: 2.320e-08,loss_f: 5.341e-08
pinn: 0000, Iter: 1200, total_loss: 5.679e-07, loss_BC: 0.000e+00, loss_IC: 1.010e-07,loss_f: 9.794e-08
pinn: 0300, Iter: 1200, total_loss: 4.051e-07, loss_BC: 0.000e+00, loss_IC: 6.645e-08,loss_f: 7.206e-08
pinn: 0200, Iter: 1300, total_loss: 4.189e-07, loss_BC: 0.000e+00, loss_IC: 6.049e-08,loss_f: 8.250e-08
pinn: 0100, Iter: 1300, total_loss: 2.134e-07, loss_BC: 0.000e+00, loss_IC: 2.376e-08,loss_f: 5.065e-08
pinn: 0000, Iter: 1300, total_loss: 5.402e-07, loss_BC: 0.000e+00, loss_IC: 1.140e-07,loss_f: 9.879e-08
pinn: 0300, Iter: 1300, total_loss: 4.026e-07, loss_BC: 0.000e+00, loss_IC: 6.723e-08,loss_f: 7.075e-08
pinn: 0200, Iter: 1400, total_loss: 4.157e-07, loss_BC: 0.000e+00, loss_IC: 6.048e-08,loss_f: 8.427e-08
pinn: 0100, Iter: 1400, total_loss: 2.105e-07, loss_BC: 0.000e+00, loss_IC: 2.508e-08,loss_f: 4.776e-08
pinn: 0000, Iter: 1400, total_loss: 5.315e-07, loss_BC: 0.000e+00, loss_IC: 1.140e-07,loss_f: 1.011e-07
pinn: 0300, Iter: 1400, total_loss: 3.990e-07, loss_BC: 0.000e+00, loss_IC: 6.549e-08,loss_f: 7.043e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2497, Mean_loss of pinns: 3.869e-07, loss_BC: 0.000e+00, loss_IC: 6.598e-08, loss_f: 7.662e-08
 => minimum loss: 2.098e-07, corresponding pinn index: 0100
 => maximum loss: 5.266e-07, corresponding pinn  index: 0000

==> Epoch: 2500, Mean_loss of pinns: 3.666e-05, loss_BC: 3.624e-05, loss_IC: 7.020e-08, loss_f: 9.732e-08
 => minimum loss: 1.087e-05, corresponding pinn/batch index: 0200
 => maximum loss: 7.249e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 2510, Mean_loss of pinns: 3.451e-05, loss_BC: 3.386e-05, loss_IC: 2.150e-07, loss_f: 1.953e-07
 => minimum loss: 1.023e-05, corresponding pinn/batch index: 0200
 => maximum loss: 6.819e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.783e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2516, total_loss: 3.402e-05, loss_BC: 3.311e-05, loss_IC: 4.400e-07, loss_f: 2.267e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.24000, t_max: 0.25000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2517 0 1

 -------------------------------------------------------------
  -----  Epoch: 2517 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.24000, t_max: 0.25000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2517 !!! 


==> Epoch: 2520, Mean_loss of pinns: 4.034e-03, loss_BC: 3.606e-05, loss_IC: 1.495e-07, loss_f: 3.997e-03
 => minimum loss: 1.282e-03, corresponding pinn/batch index: 0000
 => maximum loss: 6.105e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2530, Mean_loss of pinns: 3.130e-03, loss_BC: 3.687e-05, loss_IC: 2.680e-06, loss_f: 3.090e-03
 => minimum loss: 1.031e-03, corresponding pinn/batch index: 0000
 => maximum loss: 4.585e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2540, Mean_loss of pinns: 2.511e-03, loss_BC: 3.639e-05, loss_IC: 7.480e-06, loss_f: 2.467e-03
 => minimum loss: 8.500e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.697e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2550, Mean_loss of pinns: 2.048e-03, loss_BC: 3.411e-05, loss_IC: 1.352e-05, loss_f: 2.000e-03
 => minimum loss: 7.097e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.997e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2560, Mean_loss of pinns: 1.709e-03, loss_BC: 3.312e-05, loss_IC: 1.952e-05, loss_f: 1.656e-03
 => minimum loss: 6.087e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.499e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2570, Mean_loss of pinns: 1.450e-03, loss_BC: 3.268e-05, loss_IC: 2.418e-05, loss_f: 1.393e-03
 => minimum loss: 5.314e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.118e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2580, Mean_loss of pinns: 1.250e-03, loss_BC: 3.205e-05, loss_IC: 2.718e-05, loss_f: 1.190e-03
 => minimum loss: 4.691e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.826e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2590, Mean_loss of pinns: 1.089e-03, loss_BC: 3.050e-05, loss_IC: 2.867e-05, loss_f: 1.030e-03
 => minimum loss: 4.176e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.593e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2600, Mean_loss of pinns: 9.604e-04, loss_BC: 2.944e-05, loss_IC: 2.888e-05, loss_f: 9.018e-04
 => minimum loss: 3.750e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.404e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2610, Mean_loss of pinns: 8.540e-04, loss_BC: 2.836e-05, loss_IC: 2.804e-05, loss_f: 7.974e-04
 => minimum loss: 3.408e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.247e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2616

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 6.056e-07, loss_BC: 0.000e+00, loss_IC: 7.548e-08,loss_f: 3.725e-07
pinn: 0000, Iter: 100, total_loss: 9.247e-07, loss_BC: 0.000e+00, loss_IC: 6.422e-08,loss_f: 4.043e-07
pinn: 0300, Iter: 100, total_loss: 6.383e-07, loss_BC: 0.000e+00, loss_IC: 1.544e-07,loss_f: 2.357e-07
pinn: 0200, Iter: 100, total_loss: 3.669e-07, loss_BC: 0.000e+00, loss_IC: 8.513e-08,loss_f: 1.974e-07
pinn: 0100, Iter: 200, total_loss: 3.132e-07, loss_BC: 0.000e+00, loss_IC: 4.969e-08,loss_f: 1.087e-07
pinn: 0300, Iter: 200, total_loss: 5.081e-07, loss_BC: 0.000e+00, loss_IC: 1.079e-07,loss_f: 1.606e-07
pinn: 0200, Iter: 200, total_loss: 3.033e-07, loss_BC: 0.000e+00, loss_IC: 8.656e-08,loss_f: 1.329e-07
pinn: 0000, Iter: 200, total_loss: 7.778e-07, loss_BC: 0.000e+00, loss_IC: 7.692e-08,loss_f: 2.405e-07
pinn: 0100, Iter: 300, total_loss: 2.842e-07, loss_BC: 0.000e+00, loss_IC: 5.040e-08,loss_f: 7.889e-08
pinn: 0000, Iter: 300, total_loss: 6.853e-07, loss_BC: 0.000e+00, loss_IC: 6.000e-08,loss_f: 1.713e-07
pinn: 0300, Iter: 300, total_loss: 4.885e-07, loss_BC: 0.000e+00, loss_IC: 9.990e-08,loss_f: 1.485e-07
pinn: 0200, Iter: 300, total_loss: 2.899e-07, loss_BC: 0.000e+00, loss_IC: 8.580e-08,loss_f: 1.203e-07
pinn: 0100, Iter: 400, total_loss: 2.772e-07, loss_BC: 0.000e+00, loss_IC: 4.985e-08,loss_f: 7.265e-08
pinn: 0200, Iter: 400, total_loss: 2.791e-07, loss_BC: 0.000e+00, loss_IC: 8.303e-08,loss_f: 1.122e-07
pinn: 0300, Iter: 400, total_loss: 4.694e-07, loss_BC: 0.000e+00, loss_IC: 9.108e-08,loss_f: 1.406e-07
pinn: 0000, Iter: 400, total_loss: 6.460e-07, loss_BC: 0.000e+00, loss_IC: 6.005e-08,loss_f: 1.378e-07
pinn: 0100, Iter: 500, total_loss: 2.724e-07, loss_BC: 0.000e+00, loss_IC: 5.203e-08,loss_f: 6.626e-08
pinn: 0300, Iter: 500, total_loss: 4.532e-07, loss_BC: 0.000e+00, loss_IC: 8.441e-08,loss_f: 1.339e-07
pinn: 0000, Iter: 500, total_loss: 6.104e-07, loss_BC: 0.000e+00, loss_IC: 6.236e-08,loss_f: 1.156e-07
pinn: 0200, Iter: 500, total_loss: 2.681e-07, loss_BC: 0.000e+00, loss_IC: 7.652e-08,loss_f: 1.077e-07
pinn: 0100, Iter: 600, total_loss: 2.648e-07, loss_BC: 0.000e+00, loss_IC: 5.001e-08,loss_f: 6.047e-08
pinn: 0300, Iter: 600, total_loss: 4.422e-07, loss_BC: 0.000e+00, loss_IC: 8.011e-08,loss_f: 1.295e-07
pinn: 0000, Iter: 600, total_loss: 5.939e-07, loss_BC: 0.000e+00, loss_IC: 6.335e-08,loss_f: 1.043e-07
pinn: 0200, Iter: 600, total_loss: 2.608e-07, loss_BC: 0.000e+00, loss_IC: 7.135e-08,loss_f: 1.055e-07
pinn: 0100, Iter: 700, total_loss: 2.601e-07, loss_BC: 0.000e+00, loss_IC: 4.778e-08,loss_f: 5.775e-08
pinn: 0000, Iter: 700, total_loss: 5.823e-07, loss_BC: 0.000e+00, loss_IC: 6.662e-08,loss_f: 9.730e-08
pinn: 0300, Iter: 700, total_loss: 4.328e-07, loss_BC: 0.000e+00, loss_IC: 7.836e-08,loss_f: 1.236e-07
pinn: 0200, Iter: 700, total_loss: 2.541e-07, loss_BC: 0.000e+00, loss_IC: 6.700e-08,loss_f: 1.027e-07
pinn: 0100, Iter: 800, total_loss: 2.571e-07, loss_BC: 0.000e+00, loss_IC: 4.578e-08,loss_f: 5.678e-08
pinn: 0000, Iter: 800, total_loss: 5.732e-07, loss_BC: 0.000e+00, loss_IC: 6.493e-08,loss_f: 9.156e-08
pinn: 0300, Iter: 800, total_loss: 4.242e-07, loss_BC: 0.000e+00, loss_IC: 7.828e-08,loss_f: 1.179e-07
pinn: 0200, Iter: 800, total_loss: 2.470e-07, loss_BC: 0.000e+00, loss_IC: 5.955e-08,loss_f: 1.022e-07
pinn: 0100, Iter: 900, total_loss: 2.529e-07, loss_BC: 0.000e+00, loss_IC: 4.485e-08,loss_f: 5.381e-08
pinn: 0000, Iter: 900, total_loss: 5.614e-07, loss_BC: 0.000e+00, loss_IC: 6.745e-08,loss_f: 8.576e-08
pinn: 0300, Iter: 900, total_loss: 4.186e-07, loss_BC: 0.000e+00, loss_IC: 7.710e-08,loss_f: 1.142e-07
pinn: 0200, Iter: 900, total_loss: 2.447e-07, loss_BC: 0.000e+00, loss_IC: 5.701e-08,loss_f: 1.021e-07
pinn: 0100, Iter: 1000, total_loss: 2.470e-07, loss_BC: 0.000e+00, loss_IC: 4.160e-08,loss_f: 5.132e-08
pinn: 0000, Iter: 1000, total_loss: 5.540e-07, loss_BC: 0.000e+00, loss_IC: 6.619e-08,loss_f: 8.160e-08
pinn: 0300, Iter: 1000, total_loss: 4.155e-07, loss_BC: 0.000e+00, loss_IC: 7.541e-08,loss_f: 1.132e-07
pinn: 0200, Iter: 1000, total_loss: 2.397e-07, loss_BC: 0.000e+00, loss_IC: 5.412e-08,loss_f: 9.924e-08
pinn: 0100, Iter: 1100, total_loss: 2.452e-07, loss_BC: 0.000e+00, loss_IC: 4.071e-08,loss_f: 5.048e-08
pinn: 0000, Iter: 1100, total_loss: 5.509e-07, loss_BC: 0.000e+00, loss_IC: 6.487e-08,loss_f: 8.044e-08
pinn: 0300, Iter: 1100, total_loss: 4.115e-07, loss_BC: 0.000e+00, loss_IC: 7.255e-08,loss_f: 1.123e-07
pinn: 0200, Iter: 1100, total_loss: 2.354e-07, loss_BC: 0.000e+00, loss_IC: 4.942e-08,loss_f: 9.858e-08
pinn: 0100, Iter: 1200, total_loss: 2.426e-07, loss_BC: 0.000e+00, loss_IC: 4.035e-08,loss_f: 4.878e-08
pinn: 0000, Iter: 1200, total_loss: 5.396e-07, loss_BC: 0.000e+00, loss_IC: 5.732e-08,loss_f: 8.036e-08
pinn: 0200, Iter: 1200, total_loss: 2.320e-07, loss_BC: 0.000e+00, loss_IC: 4.802e-08,loss_f: 9.607e-08
pinn: 0300, Iter: 1200, total_loss: 4.099e-07, loss_BC: 0.000e+00, loss_IC: 6.943e-08,loss_f: 1.130e-07
pinn: 0100, Iter: 1300, total_loss: 2.394e-07, loss_BC: 0.000e+00, loss_IC: 3.967e-08,loss_f: 4.739e-08
pinn: 0000, Iter: 1300, total_loss: 5.333e-07, loss_BC: 0.000e+00, loss_IC: 5.665e-08,loss_f: 7.877e-08
pinn: 0200, Iter: 1300, total_loss: 2.309e-07, loss_BC: 0.000e+00, loss_IC: 4.648e-08,loss_f: 9.608e-08
pinn: 0300, Iter: 1300, total_loss: 4.043e-07, loss_BC: 0.000e+00, loss_IC: 6.557e-08,loss_f: 1.120e-07
pinn: 0100, Iter: 1400, total_loss: 2.365e-07, loss_BC: 0.000e+00, loss_IC: 4.020e-08,loss_f: 4.516e-08
pinn: 0000, Iter: 1400, total_loss: 5.309e-07, loss_BC: 0.000e+00, loss_IC: 5.745e-08,loss_f: 8.038e-08
pinn: 0200, Iter: 1400, total_loss: 2.293e-07, loss_BC: 0.000e+00, loss_IC: 4.640e-08,loss_f: 9.457e-08
pinn: 0300, Iter: 1400, total_loss: 4.012e-07, loss_BC: 0.000e+00, loss_IC: 6.289e-08,loss_f: 1.120e-07

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2616, Mean_loss of pinns: 3.483e-07, loss_BC: 0.000e+00, loss_IC: 5.152e-08, loss_f: 8.233e-08
 => minimum loss: 2.287e-07, corresponding pinn index: 0200
 => maximum loss: 5.305e-07, corresponding pinn  index: 0000

==> Epoch: 2620, Mean_loss of pinns: 3.600e-05, loss_BC: 3.560e-05, loss_IC: 5.941e-08, loss_f: 1.304e-07
 => minimum loss: 1.177e-05, corresponding pinn/batch index: 0200
 => maximum loss: 6.639e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

==> Epoch: 2630, Mean_loss of pinns: 3.444e-05, loss_BC: 3.355e-05, loss_IC: 4.208e-07, loss_f: 2.593e-07
 => minimum loss: 1.190e-05, corresponding pinn/batch index: 0200
 => maximum loss: 6.243e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 5.999e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2635, total_loss: 3.308e-05, loss_BC: 3.176e-05, loss_IC: 8.326e-07, loss_f: 2.801e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.25000, t_max: 0.26000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2636 0 1

 -------------------------------------------------------------
  -----  Epoch: 2636 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.25000, t_max: 0.26000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2636 !!! 


==> Epoch: 2640, Mean_loss of pinns: 4.955e-03, loss_BC: 3.616e-05, loss_IC: 3.192e-07, loss_f: 4.919e-03
 => minimum loss: 1.993e-03, corresponding pinn/batch index: 0200
 => maximum loss: 8.985e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2650, Mean_loss of pinns: 3.875e-03, loss_BC: 3.551e-05, loss_IC: 3.591e-06, loss_f: 3.836e-03
 => minimum loss: 1.604e-03, corresponding pinn/batch index: 0200
 => maximum loss: 7.359e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2660, Mean_loss of pinns: 3.113e-03, loss_BC: 3.427e-05, loss_IC: 8.856e-06, loss_f: 3.069e-03
 => minimum loss: 1.293e-03, corresponding pinn/batch index: 0200
 => maximum loss: 6.078e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2670, Mean_loss of pinns: 2.543e-03, loss_BC: 3.402e-05, loss_IC: 1.507e-05, loss_f: 2.494e-03
 => minimum loss: 1.067e-03, corresponding pinn/batch index: 0200
 => maximum loss: 5.087e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2680, Mean_loss of pinns: 2.126e-03, loss_BC: 3.256e-05, loss_IC: 2.100e-05, loss_f: 2.073e-03
 => minimum loss: 8.982e-04, corresponding pinn/batch index: 0200
 => maximum loss: 4.308e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2690, Mean_loss of pinns: 1.807e-03, loss_BC: 3.136e-05, loss_IC: 2.580e-05, loss_f: 1.750e-03
 => minimum loss: 7.688e-04, corresponding pinn/batch index: 0200
 => maximum loss: 3.691e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2700, Mean_loss of pinns: 1.559e-03, loss_BC: 2.997e-05, loss_IC: 2.889e-05, loss_f: 1.500e-03
 => minimum loss: 6.668e-04, corresponding pinn/batch index: 0200
 => maximum loss: 3.195e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2710, Mean_loss of pinns: 1.363e-03, loss_BC: 2.930e-05, loss_IC: 3.018e-05, loss_f: 1.303e-03
 => minimum loss: 5.863e-04, corresponding pinn/batch index: 0200
 => maximum loss: 2.796e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2720, Mean_loss of pinns: 1.203e-03, loss_BC: 2.819e-05, loss_IC: 3.013e-05, loss_f: 1.145e-03
 => minimum loss: 5.211e-04, corresponding pinn/batch index: 0200
 => maximum loss: 2.468e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2730, Mean_loss of pinns: 1.071e-03, loss_BC: 2.647e-05, loss_IC: 2.912e-05, loss_f: 1.015e-03
 => minimum loss: 4.675e-04, corresponding pinn/batch index: 0200
 => maximum loss: 2.198e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2735

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 7.949e-07, loss_BC: 0.000e+00, loss_IC: 1.665e-07,loss_f: 3.874e-07
pinn: 0000, Iter: 100, total_loss: 6.113e-07, loss_BC: 0.000e+00, loss_IC: 8.704e-08,loss_f: 4.161e-07
pinn: 0300, Iter: 100, total_loss: 5.048e-07, loss_BC: 0.000e+00, loss_IC: 8.861e-08,loss_f: 2.910e-07
pinn: 0200, Iter: 100, total_loss: 7.521e-07, loss_BC: 0.000e+00, loss_IC: 7.050e-08,loss_f: 5.616e-07
pinn: 0100, Iter: 200, total_loss: 4.915e-07, loss_BC: 0.000e+00, loss_IC: 1.024e-07,loss_f: 1.374e-07
pinn: 0000, Iter: 200, total_loss: 3.645e-07, loss_BC: 0.000e+00, loss_IC: 5.136e-08,loss_f: 2.049e-07
pinn: 0300, Iter: 200, total_loss: 3.775e-07, loss_BC: 0.000e+00, loss_IC: 6.625e-08,loss_f: 1.822e-07
pinn: 0200, Iter: 200, total_loss: 3.522e-07, loss_BC: 0.000e+00, loss_IC: 5.500e-08,loss_f: 1.615e-07
pinn: 0100, Iter: 300, total_loss: 4.580e-07, loss_BC: 0.000e+00, loss_IC: 9.486e-08,loss_f: 1.137e-07
pinn: 0000, Iter: 300, total_loss: 3.180e-07, loss_BC: 0.000e+00, loss_IC: 4.972e-08,loss_f: 1.596e-07
pinn: 0300, Iter: 300, total_loss: 3.450e-07, loss_BC: 0.000e+00, loss_IC: 6.475e-08,loss_f: 1.504e-07
pinn: 0200, Iter: 300, total_loss: 3.240e-07, loss_BC: 0.000e+00, loss_IC: 5.242e-08,loss_f: 1.340e-07
pinn: 0100, Iter: 400, total_loss: 4.237e-07, loss_BC: 0.000e+00, loss_IC: 8.401e-08,loss_f: 1.025e-07
pinn: 0000, Iter: 400, total_loss: 2.937e-07, loss_BC: 0.000e+00, loss_IC: 5.533e-08,loss_f: 1.309e-07
pinn: 0200, Iter: 400, total_loss: 3.047e-07, loss_BC: 0.000e+00, loss_IC: 5.278e-08,loss_f: 1.158e-07
pinn: 0300, Iter: 400, total_loss: 3.258e-07, loss_BC: 0.000e+00, loss_IC: 6.519e-08,loss_f: 1.320e-07
pinn: 0100, Iter: 500, total_loss: 3.904e-07, loss_BC: 0.000e+00, loss_IC: 7.820e-08,loss_f: 9.037e-08
pinn: 0000, Iter: 500, total_loss: 2.734e-07, loss_BC: 0.000e+00, loss_IC: 5.798e-08,loss_f: 1.087e-07
pinn: 0200, Iter: 500, total_loss: 2.883e-07, loss_BC: 0.000e+00, loss_IC: 5.318e-08,loss_f: 1.010e-07
pinn: 0300, Iter: 500, total_loss: 3.207e-07, loss_BC: 0.000e+00, loss_IC: 6.563e-08,loss_f: 1.266e-07
pinn: 0100, Iter: 600, total_loss: 3.748e-07, loss_BC: 0.000e+00, loss_IC: 7.735e-08,loss_f: 8.084e-08
pinn: 0000, Iter: 600, total_loss: 2.504e-07, loss_BC: 0.000e+00, loss_IC: 5.964e-08,loss_f: 8.519e-08
pinn: 0200, Iter: 600, total_loss: 2.741e-07, loss_BC: 0.000e+00, loss_IC: 4.894e-08,loss_f: 9.459e-08
pinn: 0300, Iter: 600, total_loss: 3.152e-07, loss_BC: 0.000e+00, loss_IC: 6.364e-08,loss_f: 1.231e-07
pinn: 0100, Iter: 700, total_loss: 3.705e-07, loss_BC: 0.000e+00, loss_IC: 7.751e-08,loss_f: 7.790e-08
pinn: 0000, Iter: 700, total_loss: 2.415e-07, loss_BC: 0.000e+00, loss_IC: 5.899e-08,loss_f: 7.696e-08
pinn: 0200, Iter: 700, total_loss: 2.634e-07, loss_BC: 0.000e+00, loss_IC: 4.688e-08,loss_f: 8.802e-08
pinn: 0300, Iter: 700, total_loss: 3.073e-07, loss_BC: 0.000e+00, loss_IC: 6.157e-08,loss_f: 1.174e-07
pinn: 0100, Iter: 800, total_loss: 3.659e-07, loss_BC: 0.000e+00, loss_IC: 7.423e-08,loss_f: 7.721e-08
pinn: 0000, Iter: 800, total_loss: 2.391e-07, loss_BC: 0.000e+00, loss_IC: 5.989e-08,loss_f: 7.383e-08
pinn: 0200, Iter: 800, total_loss: 2.558e-07, loss_BC: 0.000e+00, loss_IC: 4.434e-08,loss_f: 8.295e-08
pinn: 0300, Iter: 800, total_loss: 2.952e-07, loss_BC: 0.000e+00, loss_IC: 5.724e-08,loss_f: 1.112e-07
pinn: 0100, Iter: 900, total_loss: 3.639e-07, loss_BC: 0.000e+00, loss_IC: 7.241e-08,loss_f: 7.811e-08
pinn: 0000, Iter: 900, total_loss: 2.365e-07, loss_BC: 0.000e+00, loss_IC: 6.025e-08,loss_f: 7.102e-08
pinn: 0300, Iter: 900, total_loss: 2.838e-07, loss_BC: 0.000e+00, loss_IC: 5.169e-08,loss_f: 1.058e-07
pinn: 0200, Iter: 900, total_loss: 2.525e-07, loss_BC: 0.000e+00, loss_IC: 4.281e-08,loss_f: 8.181e-08
pinn: 0100, Iter: 1000, total_loss: 3.625e-07, loss_BC: 0.000e+00, loss_IC: 7.068e-08,loss_f: 7.724e-08
pinn: 0000, Iter: 1000, total_loss: 2.330e-07, loss_BC: 0.000e+00, loss_IC: 5.962e-08,loss_f: 6.794e-08
pinn: 0200, Iter: 1000, total_loss: 2.445e-07, loss_BC: 0.000e+00, loss_IC: 3.997e-08,loss_f: 7.956e-08
pinn: 0300, Iter: 1000, total_loss: 2.760e-07, loss_BC: 0.000e+00, loss_IC: 4.782e-08,loss_f: 1.021e-07
pinn: 0100, Iter: 1100, total_loss: 3.600e-07, loss_BC: 0.000e+00, loss_IC: 6.681e-08,loss_f: 7.819e-08
pinn: 0000, Iter: 1100, total_loss: 2.291e-07, loss_BC: 0.000e+00, loss_IC: 5.958e-08,loss_f: 6.380e-08
pinn: 0300, Iter: 1100, total_loss: 2.697e-07, loss_BC: 0.000e+00, loss_IC: 4.528e-08,loss_f: 9.838e-08
pinn: 0200, Iter: 1100, total_loss: 2.385e-07, loss_BC: 0.000e+00, loss_IC: 3.836e-08,loss_f: 7.849e-08
pinn: 0100, Iter: 1200, total_loss: 3.541e-07, loss_BC: 0.000e+00, loss_IC: 6.225e-08,loss_f: 7.815e-08
pinn: 0000, Iter: 1200, total_loss: 2.272e-07, loss_BC: 0.000e+00, loss_IC: 5.890e-08,loss_f: 6.264e-08
pinn: 0300, Iter: 1200, total_loss: 2.643e-07, loss_BC: 0.000e+00, loss_IC: 4.315e-08,loss_f: 9.486e-08
pinn: 0200, Iter: 1200, total_loss: 2.340e-07, loss_BC: 0.000e+00, loss_IC: 3.689e-08,loss_f: 7.809e-08
pinn: 0100, Iter: 1300, total_loss: 3.526e-07, loss_BC: 0.000e+00, loss_IC: 6.274e-08,loss_f: 7.557e-08
pinn: 0000, Iter: 1300, total_loss: 2.247e-07, loss_BC: 0.000e+00, loss_IC: 5.790e-08,loss_f: 6.089e-08
pinn: 0300, Iter: 1300, total_loss: 2.627e-07, loss_BC: 0.000e+00, loss_IC: 4.240e-08,loss_f: 9.418e-08
pinn: 0200, Iter: 1300, total_loss: 2.303e-07, loss_BC: 0.000e+00, loss_IC: 3.623e-08,loss_f: 7.727e-08
pinn: 0100, Iter: 1400, total_loss: 3.443e-07, loss_BC: 0.000e+00, loss_IC: 5.571e-08,loss_f: 7.528e-08
pinn: 0000, Iter: 1400, total_loss: 2.237e-07, loss_BC: 0.000e+00, loss_IC: 5.697e-08,loss_f: 6.064e-08
pinn: 0300, Iter: 1400, total_loss: 2.551e-07, loss_BC: 0.000e+00, loss_IC: 3.937e-08,loss_f: 8.916e-08
pinn: 0200, Iter: 1400, total_loss: 2.282e-07, loss_BC: 0.000e+00, loss_IC: 3.631e-08,loss_f: 7.602e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2735, Mean_loss of pinns: 2.619e-07, loss_BC: 0.000e+00, loss_IC: 4.689e-08, loss_f: 7.514e-08
 => minimum loss: 2.233e-07, corresponding pinn index: 0000
 => maximum loss: 3.442e-07, corresponding pinn  index: 0100

 max_loss: 6.739e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2737, total_loss: 3.722e-05, loss_BC: 3.695e-05, loss_IC: 4.771e-08, loss_f: 8.091e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.26000, t_max: 0.27000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2738 0 1

 -------------------------------------------------------------
  -----  Epoch: 2738 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.26000, t_max: 0.27000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2738 !!! 


==> Epoch: 2740, Mean_loss of pinns: 4.989e-03, loss_BC: 4.123e-05, loss_IC: 8.414e-08, loss_f: 4.948e-03
 => minimum loss: 8.044e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.255e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2750, Mean_loss of pinns: 3.744e-03, loss_BC: 3.972e-05, loss_IC: 3.016e-06, loss_f: 3.701e-03
 => minimum loss: 6.385e-04, corresponding pinn/batch index: 0000
 => maximum loss: 9.194e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2760, Mean_loss of pinns: 2.937e-03, loss_BC: 3.836e-05, loss_IC: 9.114e-06, loss_f: 2.889e-03
 => minimum loss: 5.203e-04, corresponding pinn/batch index: 0000
 => maximum loss: 7.144e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2770, Mean_loss of pinns: 2.345e-03, loss_BC: 3.740e-05, loss_IC: 1.655e-05, loss_f: 2.291e-03
 => minimum loss: 4.350e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.605e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2780, Mean_loss of pinns: 1.919e-03, loss_BC: 3.632e-05, loss_IC: 2.377e-05, loss_f: 1.859e-03
 => minimum loss: 3.727e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.520e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2790, Mean_loss of pinns: 1.605e-03, loss_BC: 3.510e-05, loss_IC: 3.007e-05, loss_f: 1.540e-03
 => minimum loss: 3.255e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.739e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2800, Mean_loss of pinns: 1.370e-03, loss_BC: 3.498e-05, loss_IC: 3.508e-05, loss_f: 1.300e-03
 => minimum loss: 2.885e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.168e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2810, Mean_loss of pinns: 1.189e-03, loss_BC: 3.410e-05, loss_IC: 3.839e-05, loss_f: 1.116e-03
 => minimum loss: 2.581e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.737e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2820, Mean_loss of pinns: 1.046e-03, loss_BC: 3.365e-05, loss_IC: 4.012e-05, loss_f: 9.720e-04
 => minimum loss: 2.344e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.400e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2830, Mean_loss of pinns: 9.300e-04, loss_BC: 3.285e-05, loss_IC: 4.055e-05, loss_f: 8.564e-04
 => minimum loss: 2.118e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.132e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2837

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 5.176e-07, loss_BC: 0.000e+00, loss_IC: 5.030e-08,loss_f: 3.847e-07
pinn: 0200, Iter: 100, total_loss: 6.635e-07, loss_BC: 0.000e+00, loss_IC: 9.817e-08,loss_f: 4.154e-07
pinn: 0100, Iter: 100, total_loss: 6.165e-07, loss_BC: 0.000e+00, loss_IC: 1.410e-07,loss_f: 4.374e-07
pinn: 0300, Iter: 100, total_loss: 1.508e-06, loss_BC: 0.000e+00, loss_IC: 1.115e-07,loss_f: 4.057e-07
pinn: 0200, Iter: 200, total_loss: 4.350e-07, loss_BC: 0.000e+00, loss_IC: 7.546e-08,loss_f: 1.967e-07
pinn: 0000, Iter: 200, total_loss: 2.994e-07, loss_BC: 0.000e+00, loss_IC: 7.380e-08,loss_f: 1.461e-07
pinn: 0100, Iter: 200, total_loss: 3.124e-07, loss_BC: 0.000e+00, loss_IC: 1.340e-07,loss_f: 1.410e-07
pinn: 0300, Iter: 200, total_loss: 1.355e-06, loss_BC: 0.000e+00, loss_IC: 6.068e-08,loss_f: 2.847e-07
pinn: 0000, Iter: 300, total_loss: 2.376e-07, loss_BC: 0.000e+00, loss_IC: 6.014e-08,loss_f: 9.747e-08
pinn: 0200, Iter: 300, total_loss: 4.032e-07, loss_BC: 0.000e+00, loss_IC: 7.701e-08,loss_f: 1.674e-07
pinn: 0100, Iter: 300, total_loss: 2.918e-07, loss_BC: 0.000e+00, loss_IC: 1.284e-07,loss_f: 1.257e-07
pinn: 0300, Iter: 300, total_loss: 1.158e-06, loss_BC: 0.000e+00, loss_IC: 5.158e-08,loss_f: 2.364e-07
pinn: 0000, Iter: 400, total_loss: 2.160e-07, loss_BC: 0.000e+00, loss_IC: 5.629e-08,loss_f: 8.031e-08
pinn: 0200, Iter: 400, total_loss: 3.757e-07, loss_BC: 0.000e+00, loss_IC: 7.680e-08,loss_f: 1.486e-07
pinn: 0100, Iter: 400, total_loss: 2.824e-07, loss_BC: 0.000e+00, loss_IC: 1.256e-07,loss_f: 1.191e-07
pinn: 0300, Iter: 400, total_loss: 1.030e-06, loss_BC: 0.000e+00, loss_IC: 4.237e-08,loss_f: 2.313e-07
pinn: 0200, Iter: 500, total_loss: 3.586e-07, loss_BC: 0.000e+00, loss_IC: 7.424e-08,loss_f: 1.373e-07
pinn: 0000, Iter: 500, total_loss: 2.050e-07, loss_BC: 0.000e+00, loss_IC: 4.974e-08,loss_f: 7.617e-08
pinn: 0300, Iter: 500, total_loss: 9.472e-07, loss_BC: 0.000e+00, loss_IC: 4.966e-08,loss_f: 2.659e-07
pinn: 0100, Iter: 500, total_loss: 2.670e-07, loss_BC: 0.000e+00, loss_IC: 1.193e-07,loss_f: 1.100e-07
pinn: 0200, Iter: 600, total_loss: 3.432e-07, loss_BC: 0.000e+00, loss_IC: 6.817e-08,loss_f: 1.315e-07
pinn: 0000, Iter: 600, total_loss: 1.980e-07, loss_BC: 0.000e+00, loss_IC: 4.588e-08,loss_f: 7.332e-08
pinn: 0300, Iter: 600, total_loss: 8.344e-07, loss_BC: 0.000e+00, loss_IC: 4.367e-08,loss_f: 2.807e-07
pinn: 0100, Iter: 600, total_loss: 2.544e-07, loss_BC: 0.000e+00, loss_IC: 1.106e-07,loss_f: 1.060e-07
pinn: 0200, Iter: 700, total_loss: 3.323e-07, loss_BC: 0.000e+00, loss_IC: 6.326e-08,loss_f: 1.269e-07
pinn: 0000, Iter: 700, total_loss: 1.938e-07, loss_BC: 0.000e+00, loss_IC: 4.270e-08,loss_f: 7.208e-08
pinn: 0300, Iter: 700, total_loss: 7.554e-07, loss_BC: 0.000e+00, loss_IC: 3.668e-08,loss_f: 2.614e-07
pinn: 0100, Iter: 700, total_loss: 2.391e-07, loss_BC: 0.000e+00, loss_IC: 9.660e-08,loss_f: 1.044e-07
pinn: 0000, Iter: 800, total_loss: 1.911e-07, loss_BC: 0.000e+00, loss_IC: 4.232e-08,loss_f: 6.957e-08
pinn: 0200, Iter: 800, total_loss: 3.257e-07, loss_BC: 0.000e+00, loss_IC: 5.857e-08,loss_f: 1.262e-07
pinn: 0300, Iter: 800, total_loss: 7.080e-07, loss_BC: 0.000e+00, loss_IC: 3.113e-08,loss_f: 2.432e-07
pinn: 0100, Iter: 800, total_loss: 2.258e-07, loss_BC: 0.000e+00, loss_IC: 8.469e-08,loss_f: 1.021e-07
pinn: 0000, Iter: 900, total_loss: 1.891e-07, loss_BC: 0.000e+00, loss_IC: 4.135e-08,loss_f: 6.837e-08
pinn: 0200, Iter: 900, total_loss: 3.145e-07, loss_BC: 0.000e+00, loss_IC: 5.130e-08,loss_f: 1.222e-07
pinn: 0300, Iter: 900, total_loss: 6.718e-07, loss_BC: 0.000e+00, loss_IC: 2.994e-08,loss_f: 2.308e-07
pinn: 0100, Iter: 900, total_loss: 2.088e-07, loss_BC: 0.000e+00, loss_IC: 6.560e-08,loss_f: 1.027e-07
pinn: 0000, Iter: 1000, total_loss: 1.858e-07, loss_BC: 0.000e+00, loss_IC: 3.808e-08,loss_f: 6.787e-08
pinn: 0200, Iter: 1000, total_loss: 3.076e-07, loss_BC: 0.000e+00, loss_IC: 4.495e-08,loss_f: 1.232e-07
pinn: 0300, Iter: 1000, total_loss: 6.475e-07, loss_BC: 0.000e+00, loss_IC: 3.719e-08,loss_f: 2.165e-07
pinn: 0100, Iter: 1000, total_loss: 1.983e-07, loss_BC: 0.000e+00, loss_IC: 5.556e-08,loss_f: 1.012e-07
pinn: 0200, Iter: 1100, total_loss: 2.998e-07, loss_BC: 0.000e+00, loss_IC: 4.110e-08,loss_f: 1.181e-07
pinn: 0000, Iter: 1100, total_loss: 1.838e-07, loss_BC: 0.000e+00, loss_IC: 3.630e-08,loss_f: 6.733e-08
pinn: 0300, Iter: 1100, total_loss: 6.210e-07, loss_BC: 0.000e+00, loss_IC: 3.840e-08,loss_f: 2.049e-07
pinn: 0100, Iter: 1100, total_loss: 1.903e-07, loss_BC: 0.000e+00, loss_IC: 4.760e-08,loss_f: 1.003e-07
pinn: 0200, Iter: 1200, total_loss: 2.970e-07, loss_BC: 0.000e+00, loss_IC: 3.950e-08,loss_f: 1.156e-07
pinn: 0000, Iter: 1200, total_loss: 1.806e-07, loss_BC: 0.000e+00, loss_IC: 3.339e-08,loss_f: 6.641e-08
pinn: 0300, Iter: 1200, total_loss: 5.973e-07, loss_BC: 0.000e+00, loss_IC: 3.880e-08,loss_f: 1.923e-07
pinn: 0100, Iter: 1200, total_loss: 1.845e-07, loss_BC: 0.000e+00, loss_IC: 4.284e-08,loss_f: 9.860e-08
pinn: 0000, Iter: 1300, total_loss: 1.797e-07, loss_BC: 0.000e+00, loss_IC: 3.289e-08,loss_f: 6.577e-08
pinn: 0200, Iter: 1300, total_loss: 2.893e-07, loss_BC: 0.000e+00, loss_IC: 3.633e-08,loss_f: 1.095e-07
pinn: 0300, Iter: 1300, total_loss: 2.426e-06, loss_BC: 0.000e+00, loss_IC: 6.968e-08,loss_f: 2.055e-06
pinn: 0100, Iter: 1300, total_loss: 1.781e-07, loss_BC: 0.000e+00, loss_IC: 3.582e-08,loss_f: 9.840e-08
pinn: 0200, Iter: 1400, total_loss: 2.878e-07, loss_BC: 0.000e+00, loss_IC: 3.476e-08,loss_f: 1.102e-07
pinn: 0000, Iter: 1400, total_loss: 1.787e-07, loss_BC: 0.000e+00, loss_IC: 3.202e-08,loss_f: 6.541e-08
pinn: 0300, Iter: 1400, total_loss: 5.474e-07, loss_BC: 0.000e+00, loss_IC: 4.419e-08,loss_f: 1.725e-07
pinn: 0100, Iter: 1400, total_loss: 1.752e-07, loss_BC: 0.000e+00, loss_IC: 3.299e-08,loss_f: 9.782e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2837, Mean_loss of pinns: 2.968e-07, loss_BC: 0.000e+00, loss_IC: 3.616e-08, loss_f: 1.108e-07
 => minimum loss: 1.750e-07, corresponding pinn index: 0100
 => maximum loss: 5.462e-07, corresponding pinn  index: 0300

==> Epoch: 2840, Mean_loss of pinns: 4.162e-05, loss_BC: 4.130e-05, loss_IC: 4.043e-08, loss_f: 1.277e-07
 => minimum loss: 1.994e-05, corresponding pinn/batch index: 0200
 => maximum loss: 7.064e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 2850, Mean_loss of pinns: 3.816e-05, loss_BC: 3.706e-05, loss_IC: 6.714e-07, loss_f: 2.798e-07
 => minimum loss: 1.955e-05, corresponding pinn/batch index: 0200
 => maximum loss: 6.148e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 5.915e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2856, total_loss: 3.791e-05, loss_BC: 3.608e-05, loss_IC: 1.427e-06, loss_f: 2.524e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.27000, t_max: 0.28000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2857 0 1

 -------------------------------------------------------------
  -----  Epoch: 2857 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.27000, t_max: 0.28000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2857 !!! 


==> Epoch: 2860, Mean_loss of pinns: 4.103e-03, loss_BC: 3.940e-05, loss_IC: 2.251e-07, loss_f: 4.063e-03
 => minimum loss: 5.553e-04, corresponding pinn/batch index: 0000
 => maximum loss: 8.988e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2870, Mean_loss of pinns: 3.136e-03, loss_BC: 3.875e-05, loss_IC: 3.903e-06, loss_f: 3.093e-03
 => minimum loss: 4.485e-04, corresponding pinn/batch index: 0000
 => maximum loss: 6.618e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2880, Mean_loss of pinns: 2.465e-03, loss_BC: 3.715e-05, loss_IC: 1.077e-05, loss_f: 2.416e-03
 => minimum loss: 3.727e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.088e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2890, Mean_loss of pinns: 1.978e-03, loss_BC: 3.614e-05, loss_IC: 1.906e-05, loss_f: 1.922e-03
 => minimum loss: 3.163e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.976e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2900, Mean_loss of pinns: 1.630e-03, loss_BC: 3.434e-05, loss_IC: 2.669e-05, loss_f: 1.569e-03
 => minimum loss: 2.739e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.217e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2910, Mean_loss of pinns: 1.375e-03, loss_BC: 3.494e-05, loss_IC: 3.268e-05, loss_f: 1.307e-03
 => minimum loss: 2.440e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.678e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2920, Mean_loss of pinns: 1.182e-03, loss_BC: 3.361e-05, loss_IC: 3.685e-05, loss_f: 1.111e-03
 => minimum loss: 2.191e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.287e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2930, Mean_loss of pinns: 1.034e-03, loss_BC: 3.359e-05, loss_IC: 3.899e-05, loss_f: 9.607e-04
 => minimum loss: 1.983e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.995e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2940, Mean_loss of pinns: 9.144e-04, loss_BC: 3.266e-05, loss_IC: 3.934e-05, loss_f: 8.420e-04
 => minimum loss: 1.813e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.763e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2950, Mean_loss of pinns: 8.165e-04, loss_BC: 3.160e-05, loss_IC: 3.840e-05, loss_f: 7.461e-04
 => minimum loss: 1.649e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.575e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  2956

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 1.047e-06, loss_BC: 0.000e+00, loss_IC: 1.154e-07,loss_f: 4.591e-07
pinn: 0000, Iter: 100, total_loss: 4.178e-07, loss_BC: 0.000e+00, loss_IC: 5.343e-08,loss_f: 2.939e-07
pinn: 0100, Iter: 100, total_loss: 9.726e-07, loss_BC: 0.000e+00, loss_IC: 1.354e-07,loss_f: 4.522e-07
pinn: 0200, Iter: 100, total_loss: 1.082e-06, loss_BC: 0.000e+00, loss_IC: 9.371e-08,loss_f: 2.966e-07
pinn: 0300, Iter: 200, total_loss: 7.600e-07, loss_BC: 0.000e+00, loss_IC: 4.726e-08,loss_f: 2.633e-07
pinn: 0000, Iter: 200, total_loss: 2.255e-07, loss_BC: 0.000e+00, loss_IC: 4.793e-08,loss_f: 1.086e-07
pinn: 0100, Iter: 200, total_loss: 6.145e-07, loss_BC: 0.000e+00, loss_IC: 8.289e-08,loss_f: 1.592e-07
pinn: 0200, Iter: 200, total_loss: 9.224e-07, loss_BC: 0.000e+00, loss_IC: 7.534e-08,loss_f: 1.471e-07
pinn: 0300, Iter: 300, total_loss: 6.913e-07, loss_BC: 0.000e+00, loss_IC: 4.522e-08,loss_f: 1.977e-07
pinn: 0000, Iter: 300, total_loss: 1.967e-07, loss_BC: 0.000e+00, loss_IC: 4.724e-08,loss_f: 8.056e-08
pinn: 0200, Iter: 300, total_loss: 8.890e-07, loss_BC: 0.000e+00, loss_IC: 7.057e-08,loss_f: 1.222e-07
pinn: 0100, Iter: 300, total_loss: 5.785e-07, loss_BC: 0.000e+00, loss_IC: 8.306e-08,loss_f: 1.224e-07
pinn: 0300, Iter: 400, total_loss: 6.391e-07, loss_BC: 0.000e+00, loss_IC: 4.572e-08,loss_f: 1.599e-07
pinn: 0000, Iter: 400, total_loss: 1.785e-07, loss_BC: 0.000e+00, loss_IC: 4.549e-08,loss_f: 6.394e-08
pinn: 0200, Iter: 400, total_loss: 8.744e-07, loss_BC: 0.000e+00, loss_IC: 7.520e-08,loss_f: 1.152e-07
pinn: 0100, Iter: 400, total_loss: 5.615e-07, loss_BC: 0.000e+00, loss_IC: 8.561e-08,loss_f: 1.080e-07
pinn: 0300, Iter: 500, total_loss: 6.126e-07, loss_BC: 0.000e+00, loss_IC: 5.077e-08,loss_f: 1.407e-07
pinn: 0000, Iter: 500, total_loss: 1.699e-07, loss_BC: 0.000e+00, loss_IC: 4.389e-08,loss_f: 5.713e-08
pinn: 0200, Iter: 500, total_loss: 8.457e-07, loss_BC: 0.000e+00, loss_IC: 7.531e-08,loss_f: 1.070e-07
pinn: 0100, Iter: 500, total_loss: 5.422e-07, loss_BC: 0.000e+00, loss_IC: 9.506e-08,loss_f: 9.076e-08
pinn: 0300, Iter: 600, total_loss: 5.847e-07, loss_BC: 0.000e+00, loss_IC: 6.026e-08,loss_f: 1.164e-07
pinn: 0000, Iter: 600, total_loss: 1.669e-07, loss_BC: 0.000e+00, loss_IC: 4.183e-08,loss_f: 5.605e-08
pinn: 0200, Iter: 600, total_loss: 8.193e-07, loss_BC: 0.000e+00, loss_IC: 7.462e-08,loss_f: 1.034e-07
pinn: 0100, Iter: 600, total_loss: 5.317e-07, loss_BC: 0.000e+00, loss_IC: 9.701e-08,loss_f: 8.174e-08
pinn: 0300, Iter: 700, total_loss: 5.616e-07, loss_BC: 0.000e+00, loss_IC: 6.560e-08,loss_f: 1.006e-07
pinn: 0000, Iter: 700, total_loss: 1.646e-07, loss_BC: 0.000e+00, loss_IC: 3.987e-08,loss_f: 5.547e-08
pinn: 0200, Iter: 700, total_loss: 8.035e-07, loss_BC: 0.000e+00, loss_IC: 7.866e-08,loss_f: 1.060e-07
pinn: 0100, Iter: 700, total_loss: 5.246e-07, loss_BC: 0.000e+00, loss_IC: 9.922e-08,loss_f: 7.681e-08
pinn: 0300, Iter: 800, total_loss: 5.506e-07, loss_BC: 0.000e+00, loss_IC: 6.998e-08,loss_f: 9.081e-08
pinn: 0000, Iter: 800, total_loss: 1.611e-07, loss_BC: 0.000e+00, loss_IC: 3.671e-08,loss_f: 5.467e-08
pinn: 0200, Iter: 800, total_loss: 7.886e-07, loss_BC: 0.000e+00, loss_IC: 8.205e-08,loss_f: 1.030e-07
pinn: 0100, Iter: 800, total_loss: 5.167e-07, loss_BC: 0.000e+00, loss_IC: 9.727e-08,loss_f: 7.017e-08
pinn: 0300, Iter: 900, total_loss: 5.378e-07, loss_BC: 0.000e+00, loss_IC: 7.592e-08,loss_f: 8.050e-08
pinn: 0000, Iter: 900, total_loss: 1.583e-07, loss_BC: 0.000e+00, loss_IC: 3.375e-08,loss_f: 5.447e-08
pinn: 0200, Iter: 900, total_loss: 7.740e-07, loss_BC: 0.000e+00, loss_IC: 9.284e-08,loss_f: 1.067e-07
pinn: 0100, Iter: 900, total_loss: 5.120e-07, loss_BC: 0.000e+00, loss_IC: 9.646e-08,loss_f: 6.735e-08
pinn: 0300, Iter: 1000, total_loss: 5.234e-07, loss_BC: 0.000e+00, loss_IC: 8.156e-08,loss_f: 7.143e-08
pinn: 0000, Iter: 1000, total_loss: 1.556e-07, loss_BC: 0.000e+00, loss_IC: 3.113e-08,loss_f: 5.406e-08
pinn: 0200, Iter: 1000, total_loss: 7.619e-07, loss_BC: 0.000e+00, loss_IC: 9.845e-08,loss_f: 1.062e-07
pinn: 0100, Iter: 1000, total_loss: 5.070e-07, loss_BC: 0.000e+00, loss_IC: 9.394e-08,loss_f: 6.540e-08
pinn: 0300, Iter: 1100, total_loss: 5.119e-07, loss_BC: 0.000e+00, loss_IC: 7.856e-08,loss_f: 6.975e-08
pinn: 0000, Iter: 1100, total_loss: 1.543e-07, loss_BC: 0.000e+00, loss_IC: 2.968e-08,loss_f: 5.403e-08
pinn: 0200, Iter: 1100, total_loss: 7.229e-07, loss_BC: 0.000e+00, loss_IC: 1.168e-07,loss_f: 1.061e-07
pinn: 0100, Iter: 1100, total_loss: 5.041e-07, loss_BC: 0.000e+00, loss_IC: 9.203e-08,loss_f: 6.514e-08
pinn: 0300, Iter: 1200, total_loss: 5.072e-07, loss_BC: 0.000e+00, loss_IC: 7.542e-08,loss_f: 6.854e-08
pinn: 0000, Iter: 1200, total_loss: 1.523e-07, loss_BC: 0.000e+00, loss_IC: 2.775e-08,loss_f: 5.396e-08
pinn: 0200, Iter: 1200, total_loss: 7.164e-07, loss_BC: 0.000e+00, loss_IC: 1.243e-07,loss_f: 1.105e-07
pinn: 0100, Iter: 1200, total_loss: 5.014e-07, loss_BC: 0.000e+00, loss_IC: 8.922e-08,loss_f: 6.512e-08
pinn: 0300, Iter: 1300, total_loss: 4.918e-07, loss_BC: 0.000e+00, loss_IC: 7.497e-08,loss_f: 6.551e-08
pinn: 0000, Iter: 1300, total_loss: 1.509e-07, loss_BC: 0.000e+00, loss_IC: 2.535e-08,loss_f: 5.488e-08
pinn: 0200, Iter: 1300, total_loss: 6.998e-07, loss_BC: 0.000e+00, loss_IC: 1.308e-07,loss_f: 1.113e-07
pinn: 0100, Iter: 1300, total_loss: 4.978e-07, loss_BC: 0.000e+00, loss_IC: 8.832e-08,loss_f: 6.490e-08
pinn: 0300, Iter: 1400, total_loss: 4.901e-07, loss_BC: 0.000e+00, loss_IC: 7.275e-08,loss_f: 6.478e-08
pinn: 0000, Iter: 1400, total_loss: 1.486e-07, loss_BC: 0.000e+00, loss_IC: 2.337e-08,loss_f: 5.472e-08
pinn: 0200, Iter: 1400, total_loss: 6.758e-07, loss_BC: 0.000e+00, loss_IC: 1.366e-07,loss_f: 1.157e-07
pinn: 0100, Iter: 1400, total_loss: 4.923e-07, loss_BC: 0.000e+00, loss_IC: 8.684e-08,loss_f: 6.713e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 2956, Mean_loss of pinns: 4.497e-07, loss_BC: 0.000e+00, loss_IC: 8.423e-08, loss_f: 7.711e-08
 => minimum loss: 1.484e-07, corresponding pinn index: 0000
 => maximum loss: 6.686e-07, corresponding pinn  index: 0200

 max_loss: 6.235e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 2958, total_loss: 4.206e-05, loss_BC: 4.160e-05, loss_IC: 8.482e-08, loss_f: 8.146e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.28000, t_max: 0.29000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  2959 0 1

 -------------------------------------------------------------
  -----  Epoch: 2959 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.28000, t_max: 0.29000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  2959 !!! 


==> Epoch: 2960, Mean_loss of pinns: 2.503e-03, loss_BC: 4.678e-05, loss_IC: 1.869e-08, loss_f: 2.456e-03
 => minimum loss: 1.019e-03, corresponding pinn/batch index: 0000
 => maximum loss: 5.870e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2970, Mean_loss of pinns: 1.819e-03, loss_BC: 4.527e-05, loss_IC: 2.143e-06, loss_f: 1.772e-03
 => minimum loss: 8.183e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.153e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2980, Mean_loss of pinns: 1.421e-03, loss_BC: 4.216e-05, loss_IC: 6.756e-06, loss_f: 1.372e-03
 => minimum loss: 6.722e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.217e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 2990, Mean_loss of pinns: 1.135e-03, loss_BC: 4.089e-05, loss_IC: 1.289e-05, loss_f: 1.081e-03
 => minimum loss: 5.595e-04, corresponding pinn/batch index: 0100
 => maximum loss: 2.515e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3000, Mean_loss of pinns: 9.365e-04, loss_BC: 3.859e-05, loss_IC: 1.895e-05, loss_f: 8.786e-04
 => minimum loss: 4.662e-04, corresponding pinn/batch index: 0100
 => maximum loss: 2.048e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3010, Mean_loss of pinns: 7.905e-04, loss_BC: 3.761e-05, loss_IC: 2.338e-05, loss_f: 7.292e-04
 => minimum loss: 3.940e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.709e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3020, Mean_loss of pinns: 6.813e-04, loss_BC: 3.682e-05, loss_IC: 2.584e-05, loss_f: 6.183e-04
 => minimum loss: 3.365e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.466e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3030, Mean_loss of pinns: 5.958e-04, loss_BC: 3.593e-05, loss_IC: 2.651e-05, loss_f: 5.331e-04
 => minimum loss: 2.920e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.277e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3040, Mean_loss of pinns: 5.271e-04, loss_BC: 3.503e-05, loss_IC: 2.593e-05, loss_f: 4.659e-04
 => minimum loss: 2.560e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.127e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3050, Mean_loss of pinns: 4.714e-04, loss_BC: 3.497e-05, loss_IC: 2.449e-05, loss_f: 4.116e-04
 => minimum loss: 2.268e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.003e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3058

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 1.045e-06, loss_BC: 0.000e+00, loss_IC: 1.106e-07,loss_f: 2.672e-07
pinn: 0000, Iter: 100, total_loss: 6.019e-07, loss_BC: 0.000e+00, loss_IC: 7.480e-08,loss_f: 2.685e-07
pinn: 0100, Iter: 100, total_loss: 5.467e-07, loss_BC: 0.000e+00, loss_IC: 9.351e-08,loss_f: 2.708e-07
pinn: 0200, Iter: 100, total_loss: 4.213e-07, loss_BC: 0.000e+00, loss_IC: 3.723e-08,loss_f: 3.482e-07
pinn: 0000, Iter: 200, total_loss: 4.460e-07, loss_BC: 0.000e+00, loss_IC: 8.457e-08,loss_f: 1.114e-07
pinn: 0300, Iter: 200, total_loss: 8.801e-07, loss_BC: 0.000e+00, loss_IC: 1.179e-07,loss_f: 1.227e-07
pinn: 0200, Iter: 200, total_loss: 2.139e-07, loss_BC: 0.000e+00, loss_IC: 3.901e-08,loss_f: 1.394e-07
pinn: 0100, Iter: 200, total_loss: 3.807e-07, loss_BC: 0.000e+00, loss_IC: 8.277e-08,loss_f: 1.119e-07
pinn: 0300, Iter: 300, total_loss: 8.389e-07, loss_BC: 0.000e+00, loss_IC: 1.181e-07,loss_f: 9.428e-08
pinn: 0000, Iter: 300, total_loss: 4.066e-07, loss_BC: 0.000e+00, loss_IC: 8.396e-08,loss_f: 7.442e-08
pinn: 0200, Iter: 300, total_loss: 1.947e-07, loss_BC: 0.000e+00, loss_IC: 3.798e-08,loss_f: 1.213e-07
pinn: 0100, Iter: 300, total_loss: 3.548e-07, loss_BC: 0.000e+00, loss_IC: 7.880e-08,loss_f: 9.060e-08
pinn: 0300, Iter: 400, total_loss: 8.162e-07, loss_BC: 0.000e+00, loss_IC: 1.159e-07,loss_f: 8.879e-08
pinn: 0000, Iter: 400, total_loss: 3.948e-07, loss_BC: 0.000e+00, loss_IC: 8.079e-08,loss_f: 6.830e-08
pinn: 0200, Iter: 400, total_loss: 1.861e-07, loss_BC: 0.000e+00, loss_IC: 3.805e-08,loss_f: 1.127e-07
pinn: 0100, Iter: 400, total_loss: 3.460e-07, loss_BC: 0.000e+00, loss_IC: 7.736e-08,loss_f: 8.429e-08
pinn: 0300, Iter: 500, total_loss: 8.028e-07, loss_BC: 0.000e+00, loss_IC: 1.155e-07,loss_f: 8.411e-08
pinn: 0000, Iter: 500, total_loss: 3.895e-07, loss_BC: 0.000e+00, loss_IC: 7.973e-08,loss_f: 6.698e-08
pinn: 0200, Iter: 500, total_loss: 1.677e-07, loss_BC: 0.000e+00, loss_IC: 3.636e-08,loss_f: 9.583e-08
pinn: 0100, Iter: 500, total_loss: 3.393e-07, loss_BC: 0.000e+00, loss_IC: 7.198e-08,loss_f: 8.439e-08
pinn: 0300, Iter: 600, total_loss: 7.910e-07, loss_BC: 0.000e+00, loss_IC: 1.169e-07,loss_f: 8.330e-08
pinn: 0000, Iter: 600, total_loss: 3.831e-07, loss_BC: 0.000e+00, loss_IC: 7.643e-08,loss_f: 6.707e-08
pinn: 0100, Iter: 600, total_loss: 3.285e-07, loss_BC: 0.000e+00, loss_IC: 6.474e-08,loss_f: 8.205e-08
pinn: 0200, Iter: 600, total_loss: 1.525e-07, loss_BC: 0.000e+00, loss_IC: 3.227e-08,loss_f: 8.440e-08
pinn: 0300, Iter: 700, total_loss: 7.778e-07, loss_BC: 0.000e+00, loss_IC: 1.240e-07,loss_f: 8.336e-08
pinn: 0000, Iter: 700, total_loss: 3.787e-07, loss_BC: 0.000e+00, loss_IC: 7.547e-08,loss_f: 6.623e-08
pinn: 0200, Iter: 700, total_loss: 1.458e-07, loss_BC: 0.000e+00, loss_IC: 2.955e-08,loss_f: 8.021e-08
pinn: 0100, Iter: 700, total_loss: 3.249e-07, loss_BC: 0.000e+00, loss_IC: 6.259e-08,loss_f: 8.110e-08
pinn: 0300, Iter: 800, total_loss: 7.670e-07, loss_BC: 0.000e+00, loss_IC: 1.284e-07,loss_f: 8.721e-08
pinn: 0000, Iter: 800, total_loss: 3.743e-07, loss_BC: 0.000e+00, loss_IC: 7.232e-08,loss_f: 6.662e-08
pinn: 0100, Iter: 800, total_loss: 3.203e-07, loss_BC: 0.000e+00, loss_IC: 5.984e-08,loss_f: 7.974e-08
pinn: 0200, Iter: 800, total_loss: 1.401e-07, loss_BC: 0.000e+00, loss_IC: 2.785e-08,loss_f: 7.600e-08
pinn: 0300, Iter: 900, total_loss: 7.606e-07, loss_BC: 0.000e+00, loss_IC: 1.309e-07,loss_f: 8.858e-08
pinn: 0000, Iter: 900, total_loss: 3.677e-07, loss_BC: 0.000e+00, loss_IC: 7.200e-08,loss_f: 6.434e-08
pinn: 0100, Iter: 900, total_loss: 3.125e-07, loss_BC: 0.000e+00, loss_IC: 5.318e-08,loss_f: 8.029e-08
pinn: 0200, Iter: 900, total_loss: 1.351e-07, loss_BC: 0.000e+00, loss_IC: 2.673e-08,loss_f: 7.188e-08
pinn: 0300, Iter: 1000, total_loss: 7.434e-07, loss_BC: 0.000e+00, loss_IC: 1.239e-07,loss_f: 1.013e-07
pinn: 0000, Iter: 1000, total_loss: 3.609e-07, loss_BC: 0.000e+00, loss_IC: 6.945e-08,loss_f: 6.255e-08
pinn: 0100, Iter: 1000, total_loss: 3.092e-07, loss_BC: 0.000e+00, loss_IC: 5.076e-08,loss_f: 8.091e-08
pinn: 0200, Iter: 1000, total_loss: 1.310e-07, loss_BC: 0.000e+00, loss_IC: 2.677e-08,loss_f: 6.757e-08
pinn: 0300, Iter: 1100, total_loss: 7.309e-07, loss_BC: 0.000e+00, loss_IC: 1.202e-07,loss_f: 1.107e-07
pinn: 0000, Iter: 1100, total_loss: 3.557e-07, loss_BC: 0.000e+00, loss_IC: 6.520e-08,loss_f: 6.229e-08
pinn: 0100, Iter: 1100, total_loss: 3.039e-07, loss_BC: 0.000e+00, loss_IC: 4.875e-08,loss_f: 7.964e-08
pinn: 0200, Iter: 1100, total_loss: 1.251e-07, loss_BC: 0.000e+00, loss_IC: 2.589e-08,loss_f: 6.226e-08
pinn: 0300, Iter: 1200, total_loss: 7.229e-07, loss_BC: 0.000e+00, loss_IC: 1.179e-07,loss_f: 1.063e-07
pinn: 0000, Iter: 1200, total_loss: 3.527e-07, loss_BC: 0.000e+00, loss_IC: 6.373e-08,loss_f: 6.159e-08
pinn: 0100, Iter: 1200, total_loss: 3.023e-07, loss_BC: 0.000e+00, loss_IC: 4.728e-08,loss_f: 8.014e-08
pinn: 0200, Iter: 1200, total_loss: 1.201e-07, loss_BC: 0.000e+00, loss_IC: 2.360e-08,loss_f: 5.919e-08
pinn: 0300, Iter: 1300, total_loss: 7.007e-07, loss_BC: 0.000e+00, loss_IC: 1.029e-07,loss_f: 1.244e-07
pinn: 0000, Iter: 1300, total_loss: 3.497e-07, loss_BC: 0.000e+00, loss_IC: 6.113e-08,loss_f: 6.226e-08
pinn: 0100, Iter: 1300, total_loss: 2.997e-07, loss_BC: 0.000e+00, loss_IC: 4.510e-08,loss_f: 8.093e-08
pinn: 0200, Iter: 1300, total_loss: 1.176e-07, loss_BC: 0.000e+00, loss_IC: 2.305e-08,loss_f: 5.711e-08
pinn: 0300, Iter: 1400, total_loss: 6.796e-07, loss_BC: 0.000e+00, loss_IC: 9.530e-08,loss_f: 1.275e-07
pinn: 0000, Iter: 1400, total_loss: 3.462e-07, loss_BC: 0.000e+00, loss_IC: 5.681e-08,loss_f: 6.274e-08
pinn: 0100, Iter: 1400, total_loss: 2.968e-07, loss_BC: 0.000e+00, loss_IC: 4.252e-08,loss_f: 8.124e-08
pinn: 0200, Iter: 1400, total_loss: 1.159e-07, loss_BC: 0.000e+00, loss_IC: 2.240e-08,loss_f: 5.595e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3058, Mean_loss of pinns: 3.577e-07, loss_BC: 0.000e+00, loss_IC: 5.212e-08, loss_f: 8.389e-08
 => minimum loss: 1.158e-07, corresponding pinn index: 0200
 => maximum loss: 6.753e-07, corresponding pinn  index: 0300

==> Epoch: 3060, Mean_loss of pinns: 4.762e-05, loss_BC: 4.725e-05, loss_IC: 5.286e-08, loss_f: 8.932e-08
 => minimum loss: 3.057e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.704e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.704e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3060, total_loss: 4.762e-05, loss_BC: 4.725e-05, loss_IC: 5.286e-08, loss_f: 8.932e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.29000, t_max: 0.30000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3061 0 1

 -------------------------------------------------------------
  -----  Epoch: 3061 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.29000, t_max: 0.30000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3061 !!! 


==> Epoch: 3070, Mean_loss of pinns: 3.614e-03, loss_BC: 5.440e-05, loss_IC: 1.208e-06, loss_f: 3.558e-03
 => minimum loss: 1.588e-03, corresponding pinn/batch index: 0100
 => maximum loss: 5.399e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3080, Mean_loss of pinns: 2.917e-03, loss_BC: 5.222e-05, loss_IC: 4.677e-06, loss_f: 2.859e-03
 => minimum loss: 1.250e-03, corresponding pinn/batch index: 0100
 => maximum loss: 4.418e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3090, Mean_loss of pinns: 2.378e-03, loss_BC: 4.937e-05, loss_IC: 9.639e-06, loss_f: 2.319e-03
 => minimum loss: 1.022e-03, corresponding pinn/batch index: 0100
 => maximum loss: 3.643e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3100, Mean_loss of pinns: 1.974e-03, loss_BC: 4.737e-05, loss_IC: 1.565e-05, loss_f: 1.910e-03
 => minimum loss: 8.481e-04, corresponding pinn/batch index: 0100
 => maximum loss: 3.030e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3110, Mean_loss of pinns: 1.662e-03, loss_BC: 4.537e-05, loss_IC: 2.179e-05, loss_f: 1.595e-03
 => minimum loss: 7.146e-04, corresponding pinn/batch index: 0100
 => maximum loss: 2.552e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3120, Mean_loss of pinns: 1.421e-03, loss_BC: 4.264e-05, loss_IC: 2.705e-05, loss_f: 1.351e-03
 => minimum loss: 6.102e-04, corresponding pinn/batch index: 0100
 => maximum loss: 2.172e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3130, Mean_loss of pinns: 1.232e-03, loss_BC: 4.129e-05, loss_IC: 3.064e-05, loss_f: 1.159e-03
 => minimum loss: 5.280e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.876e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3140, Mean_loss of pinns: 1.080e-03, loss_BC: 3.975e-05, loss_IC: 3.250e-05, loss_f: 1.007e-03
 => minimum loss: 4.613e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.635e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3150, Mean_loss of pinns: 9.565e-04, loss_BC: 3.928e-05, loss_IC: 3.288e-05, loss_f: 8.838e-04
 => minimum loss: 4.067e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.443e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3160, Mean_loss of pinns: 8.547e-04, loss_BC: 3.878e-05, loss_IC: 3.209e-05, loss_f: 7.833e-04
 => minimum loss: 3.630e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.283e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3160

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 9.800e-07, loss_BC: 0.000e+00, loss_IC: 9.211e-08,loss_f: 3.254e-07
pinn: 0200, Iter: 100, total_loss: 8.698e-07, loss_BC: 0.000e+00, loss_IC: 8.522e-08,loss_f: 2.778e-07
pinn: 0300, Iter: 100, total_loss: 7.843e-07, loss_BC: 0.000e+00, loss_IC: 1.191e-07,loss_f: 2.616e-07
pinn: 0100, Iter: 100, total_loss: 9.369e-07, loss_BC: 0.000e+00, loss_IC: 1.051e-07,loss_f: 2.740e-07
pinn: 0200, Iter: 200, total_loss: 7.530e-07, loss_BC: 0.000e+00, loss_IC: 9.090e-08,loss_f: 1.583e-07
pinn: 0000, Iter: 200, total_loss: 7.610e-07, loss_BC: 0.000e+00, loss_IC: 5.904e-08,loss_f: 1.501e-07
pinn: 0100, Iter: 200, total_loss: 7.306e-07, loss_BC: 0.000e+00, loss_IC: 8.461e-08,loss_f: 9.910e-08
pinn: 0300, Iter: 200, total_loss: 6.485e-07, loss_BC: 0.000e+00, loss_IC: 8.744e-08,loss_f: 1.631e-07
pinn: 0300, Iter: 300, total_loss: 6.174e-07, loss_BC: 0.000e+00, loss_IC: 9.271e-08,loss_f: 1.375e-07
pinn: 0000, Iter: 300, total_loss: 6.862e-07, loss_BC: 0.000e+00, loss_IC: 5.085e-08,loss_f: 8.514e-08
pinn: 0200, Iter: 300, total_loss: 7.093e-07, loss_BC: 0.000e+00, loss_IC: 8.584e-08,loss_f: 1.362e-07
pinn: 0100, Iter: 300, total_loss: 7.040e-07, loss_BC: 0.000e+00, loss_IC: 8.746e-08,loss_f: 8.094e-08
pinn: 0300, Iter: 400, total_loss: 5.876e-07, loss_BC: 0.000e+00, loss_IC: 9.317e-08,loss_f: 1.187e-07
pinn: 0200, Iter: 400, total_loss: 6.799e-07, loss_BC: 0.000e+00, loss_IC: 9.087e-08,loss_f: 1.242e-07
pinn: 0000, Iter: 400, total_loss: 6.640e-07, loss_BC: 0.000e+00, loss_IC: 5.370e-08,loss_f: 6.953e-08
pinn: 0100, Iter: 400, total_loss: 6.928e-07, loss_BC: 0.000e+00, loss_IC: 9.402e-08,loss_f: 7.705e-08
pinn: 0200, Iter: 500, total_loss: 6.655e-07, loss_BC: 0.000e+00, loss_IC: 9.242e-08,loss_f: 1.170e-07
pinn: 0300, Iter: 500, total_loss: 5.681e-07, loss_BC: 0.000e+00, loss_IC: 9.783e-08,loss_f: 1.036e-07
pinn: 0100, Iter: 500, total_loss: 6.842e-07, loss_BC: 0.000e+00, loss_IC: 9.859e-08,loss_f: 7.468e-08
pinn: 0000, Iter: 500, total_loss: 6.486e-07, loss_BC: 0.000e+00, loss_IC: 6.422e-08,loss_f: 6.403e-08
pinn: 0200, Iter: 600, total_loss: 6.536e-07, loss_BC: 0.000e+00, loss_IC: 9.869e-08,loss_f: 1.117e-07
pinn: 0300, Iter: 600, total_loss: 5.565e-07, loss_BC: 0.000e+00, loss_IC: 9.827e-08,loss_f: 9.515e-08
pinn: 0100, Iter: 600, total_loss: 6.727e-07, loss_BC: 0.000e+00, loss_IC: 1.115e-07,loss_f: 7.317e-08
pinn: 0000, Iter: 600, total_loss: 6.393e-07, loss_BC: 0.000e+00, loss_IC: 7.059e-08,loss_f: 6.223e-08
pinn: 0200, Iter: 700, total_loss: 6.470e-07, loss_BC: 0.000e+00, loss_IC: 9.864e-08,loss_f: 1.123e-07
pinn: 0300, Iter: 700, total_loss: 5.499e-07, loss_BC: 0.000e+00, loss_IC: 9.645e-08,loss_f: 9.177e-08
pinn: 0100, Iter: 700, total_loss: 6.617e-07, loss_BC: 0.000e+00, loss_IC: 1.181e-07,loss_f: 7.346e-08
pinn: 0000, Iter: 700, total_loss: 6.301e-07, loss_BC: 0.000e+00, loss_IC: 7.170e-08,loss_f: 6.043e-08
pinn: 0200, Iter: 800, total_loss: 6.289e-07, loss_BC: 0.000e+00, loss_IC: 9.984e-08,loss_f: 1.164e-07
pinn: 0300, Iter: 800, total_loss: 5.436e-07, loss_BC: 0.000e+00, loss_IC: 9.392e-08,loss_f: 8.871e-08
pinn: 0000, Iter: 800, total_loss: 6.233e-07, loss_BC: 0.000e+00, loss_IC: 7.277e-08,loss_f: 5.996e-08
pinn: 0100, Iter: 800, total_loss: 6.398e-07, loss_BC: 0.000e+00, loss_IC: 1.323e-07,loss_f: 7.945e-08
pinn: 0200, Iter: 900, total_loss: 6.206e-07, loss_BC: 0.000e+00, loss_IC: 9.874e-08,loss_f: 1.149e-07
pinn: 0100, Iter: 900, total_loss: 6.163e-07, loss_BC: 0.000e+00, loss_IC: 1.262e-07,loss_f: 8.747e-08
pinn: 0000, Iter: 900, total_loss: 6.102e-07, loss_BC: 0.000e+00, loss_IC: 7.620e-08,loss_f: 6.364e-08
pinn: 0300, Iter: 900, total_loss: 5.380e-07, loss_BC: 0.000e+00, loss_IC: 9.269e-08,loss_f: 8.582e-08
pinn: 0200, Iter: 1000, total_loss: 6.062e-07, loss_BC: 0.000e+00, loss_IC: 1.043e-07,loss_f: 1.146e-07
pinn: 0100, Iter: 1000, total_loss: 6.084e-07, loss_BC: 0.000e+00, loss_IC: 1.419e-07,loss_f: 9.288e-08
pinn: 0000, Iter: 1000, total_loss: 5.976e-07, loss_BC: 0.000e+00, loss_IC: 8.391e-08,loss_f: 6.434e-08
pinn: 0300, Iter: 1000, total_loss: 5.344e-07, loss_BC: 0.000e+00, loss_IC: 9.301e-08,loss_f: 8.437e-08
pinn: 0200, Iter: 1100, total_loss: 6.014e-07, loss_BC: 0.000e+00, loss_IC: 1.041e-07,loss_f: 1.143e-07
pinn: 0100, Iter: 1100, total_loss: 5.889e-07, loss_BC: 0.000e+00, loss_IC: 1.423e-07,loss_f: 9.433e-08
pinn: 0300, Iter: 1100, total_loss: 5.316e-07, loss_BC: 0.000e+00, loss_IC: 9.191e-08,loss_f: 8.362e-08
pinn: 0000, Iter: 1100, total_loss: 5.892e-07, loss_BC: 0.000e+00, loss_IC: 8.840e-08,loss_f: 6.399e-08
pinn: 0200, Iter: 1200, total_loss: 5.911e-07, loss_BC: 0.000e+00, loss_IC: 1.040e-07,loss_f: 1.155e-07
pinn: 0100, Iter: 1200, total_loss: 5.833e-07, loss_BC: 0.000e+00, loss_IC: 1.409e-07,loss_f: 9.812e-08
pinn: 0300, Iter: 1200, total_loss: 5.275e-07, loss_BC: 0.000e+00, loss_IC: 9.107e-08,loss_f: 8.343e-08
pinn: 0000, Iter: 1200, total_loss: 5.683e-07, loss_BC: 0.000e+00, loss_IC: 9.777e-08,loss_f: 6.980e-08
pinn: 0100, Iter: 1300, total_loss: 5.622e-07, loss_BC: 0.000e+00, loss_IC: 1.487e-07,loss_f: 1.028e-07
pinn: 0200, Iter: 1300, total_loss: 5.772e-07, loss_BC: 0.000e+00, loss_IC: 1.051e-07,loss_f: 1.190e-07
pinn: 0300, Iter: 1300, total_loss: 5.259e-07, loss_BC: 0.000e+00, loss_IC: 8.796e-08,loss_f: 8.413e-08
pinn: 0000, Iter: 1300, total_loss: 5.626e-07, loss_BC: 0.000e+00, loss_IC: 9.721e-08,loss_f: 6.829e-08
pinn: 0100, Iter: 1400, total_loss: 5.566e-07, loss_BC: 0.000e+00, loss_IC: 1.425e-07,loss_f: 9.469e-08
pinn: 0200, Iter: 1400, total_loss: 5.709e-07, loss_BC: 0.000e+00, loss_IC: 1.045e-07,loss_f: 1.183e-07
pinn: 0300, Iter: 1400, total_loss: 5.210e-07, loss_BC: 0.000e+00, loss_IC: 8.652e-08,loss_f: 8.493e-08
pinn: 0000, Iter: 1400, total_loss: 5.537e-07, loss_BC: 0.000e+00, loss_IC: 1.111e-07,loss_f: 7.231e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3160, Mean_loss of pinns: 5.482e-07, loss_BC: 0.000e+00, loss_IC: 1.107e-07, loss_f: 9.252e-08
 => minimum loss: 5.201e-07, corresponding pinn index: 0300
 => maximum loss: 5.702e-07, corresponding pinn  index: 0200

==> Epoch: 3170, Mean_loss of pinns: 5.312e-05, loss_BC: 5.238e-05, loss_IC: 2.009e-07, loss_f: 1.960e-07
 => minimum loss: 3.045e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.678e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 3180, Mean_loss of pinns: 5.013e-05, loss_BC: 4.880e-05, loss_IC: 7.209e-07, loss_f: 2.712e-07
 => minimum loss: 2.925e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.162e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 3190, Mean_loss of pinns: 4.868e-05, loss_BC: 4.658e-05, loss_IC: 1.490e-06, loss_f: 2.711e-07
 => minimum loss: 2.813e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.112e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 max_loss: 6.892e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3196, total_loss: 4.716e-05, loss_BC: 4.469e-05, loss_IC: 1.892e-06, loss_f: 2.434e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.30000, t_max: 0.31000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3197 0 1

 -------------------------------------------------------------
  -----  Epoch: 3197 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.30000, t_max: 0.31000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3197 !!! 


==> Epoch: 3200, Mean_loss of pinns: 3.031e-03, loss_BC: 5.067e-05, loss_IC: 1.972e-07, loss_f: 2.979e-03
 => minimum loss: 5.505e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.165e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3210, Mean_loss of pinns: 2.371e-03, loss_BC: 4.751e-05, loss_IC: 3.525e-06, loss_f: 2.319e-03
 => minimum loss: 4.402e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.182e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3220, Mean_loss of pinns: 1.894e-03, loss_BC: 4.671e-05, loss_IC: 9.513e-06, loss_f: 1.837e-03
 => minimum loss: 3.646e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.398e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3230, Mean_loss of pinns: 1.544e-03, loss_BC: 4.496e-05, loss_IC: 1.587e-05, loss_f: 1.483e-03
 => minimum loss: 3.105e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.788e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3240, Mean_loss of pinns: 1.285e-03, loss_BC: 4.429e-05, loss_IC: 2.137e-05, loss_f: 1.219e-03
 => minimum loss: 2.699e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.323e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3250, Mean_loss of pinns: 1.091e-03, loss_BC: 4.380e-05, loss_IC: 2.555e-05, loss_f: 1.021e-03
 => minimum loss: 2.398e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.963e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3260, Mean_loss of pinns: 9.379e-04, loss_BC: 4.131e-05, loss_IC: 2.798e-05, loss_f: 8.683e-04
 => minimum loss: 2.128e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.681e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3270, Mean_loss of pinns: 8.189e-04, loss_BC: 4.104e-05, loss_IC: 2.859e-05, loss_f: 7.489e-04
 => minimum loss: 1.914e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.462e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3280, Mean_loss of pinns: 7.212e-04, loss_BC: 3.930e-05, loss_IC: 2.774e-05, loss_f: 6.538e-04
 => minimum loss: 1.748e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.280e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3290, Mean_loss of pinns: 6.409e-04, loss_BC: 3.776e-05, loss_IC: 2.585e-05, loss_f: 5.769e-04
 => minimum loss: 1.587e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.137e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3296

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 4.018e-07, loss_BC: 0.000e+00, loss_IC: 3.747e-08,loss_f: 2.471e-07
pinn: 0200, Iter: 100, total_loss: 5.932e-07, loss_BC: 0.000e+00, loss_IC: 6.627e-08,loss_f: 2.197e-07
pinn: 0300, Iter: 100, total_loss: 8.177e-07, loss_BC: 0.000e+00, loss_IC: 6.931e-08,loss_f: 2.268e-07
pinn: 0100, Iter: 100, total_loss: 8.963e-07, loss_BC: 0.000e+00, loss_IC: 8.930e-08,loss_f: 3.600e-07
pinn: 0000, Iter: 200, total_loss: 2.636e-07, loss_BC: 0.000e+00, loss_IC: 3.988e-08,loss_f: 1.095e-07
pinn: 0100, Iter: 200, total_loss: 6.669e-07, loss_BC: 0.000e+00, loss_IC: 6.491e-08,loss_f: 1.727e-07
pinn: 0300, Iter: 200, total_loss: 7.053e-07, loss_BC: 0.000e+00, loss_IC: 6.723e-08,loss_f: 1.293e-07
pinn: 0200, Iter: 200, total_loss: 5.102e-07, loss_BC: 0.000e+00, loss_IC: 6.511e-08,loss_f: 1.391e-07
pinn: 0000, Iter: 300, total_loss: 2.308e-07, loss_BC: 0.000e+00, loss_IC: 4.024e-08,loss_f: 7.631e-08
pinn: 0200, Iter: 300, total_loss: 4.816e-07, loss_BC: 0.000e+00, loss_IC: 6.580e-08,loss_f: 1.141e-07
pinn: 0100, Iter: 300, total_loss: 6.332e-07, loss_BC: 0.000e+00, loss_IC: 7.455e-08,loss_f: 1.359e-07
pinn: 0300, Iter: 300, total_loss: 6.780e-07, loss_BC: 0.000e+00, loss_IC: 6.439e-08,loss_f: 1.054e-07
pinn: 0300, Iter: 400, total_loss: 6.639e-07, loss_BC: 0.000e+00, loss_IC: 6.415e-08,loss_f: 9.932e-08
pinn: 0100, Iter: 400, total_loss: 5.950e-07, loss_BC: 0.000e+00, loss_IC: 6.671e-08,loss_f: 1.086e-07
pinn: 0000, Iter: 400, total_loss: 2.151e-07, loss_BC: 0.000e+00, loss_IC: 3.851e-08,loss_f: 6.245e-08
pinn: 0200, Iter: 400, total_loss: 4.723e-07, loss_BC: 0.000e+00, loss_IC: 6.869e-08,loss_f: 1.075e-07
pinn: 0300, Iter: 500, total_loss: 6.440e-07, loss_BC: 0.000e+00, loss_IC: 7.243e-08,loss_f: 9.308e-08
pinn: 0100, Iter: 500, total_loss: 5.930e-07, loss_BC: 0.000e+00, loss_IC: 6.892e-08,loss_f: 1.057e-07
pinn: 0000, Iter: 500, total_loss: 2.084e-07, loss_BC: 0.000e+00, loss_IC: 3.682e-08,loss_f: 5.737e-08
pinn: 0200, Iter: 500, total_loss: 4.617e-07, loss_BC: 0.000e+00, loss_IC: 7.186e-08,loss_f: 9.933e-08
pinn: 0300, Iter: 600, total_loss: 6.382e-07, loss_BC: 0.000e+00, loss_IC: 6.926e-08,loss_f: 9.363e-08
pinn: 0000, Iter: 600, total_loss: 2.061e-07, loss_BC: 0.000e+00, loss_IC: 3.582e-08,loss_f: 5.609e-08
pinn: 0100, Iter: 600, total_loss: 5.754e-07, loss_BC: 0.000e+00, loss_IC: 7.843e-08,loss_f: 9.076e-08
pinn: 0200, Iter: 600, total_loss: 4.558e-07, loss_BC: 0.000e+00, loss_IC: 7.374e-08,loss_f: 9.606e-08
pinn: 0300, Iter: 700, total_loss: 6.282e-07, loss_BC: 0.000e+00, loss_IC: 7.476e-08,loss_f: 9.337e-08
pinn: 0000, Iter: 700, total_loss: 1.986e-07, loss_BC: 0.000e+00, loss_IC: 3.319e-08,loss_f: 5.139e-08
pinn: 0100, Iter: 700, total_loss: 5.454e-07, loss_BC: 0.000e+00, loss_IC: 7.914e-08,loss_f: 6.929e-08
pinn: 0200, Iter: 700, total_loss: 4.515e-07, loss_BC: 0.000e+00, loss_IC: 7.098e-08,loss_f: 9.524e-08
pinn: 0300, Iter: 800, total_loss: 6.192e-07, loss_BC: 0.000e+00, loss_IC: 7.680e-08,loss_f: 9.515e-08
pinn: 0000, Iter: 800, total_loss: 1.966e-07, loss_BC: 0.000e+00, loss_IC: 3.087e-08,loss_f: 5.135e-08
pinn: 0100, Iter: 800, total_loss: 5.396e-07, loss_BC: 0.000e+00, loss_IC: 7.739e-08,loss_f: 6.778e-08
pinn: 0200, Iter: 800, total_loss: 4.487e-07, loss_BC: 0.000e+00, loss_IC: 7.114e-08,loss_f: 9.497e-08
pinn: 0300, Iter: 900, total_loss: 5.963e-07, loss_BC: 0.000e+00, loss_IC: 7.485e-08,loss_f: 1.031e-07
pinn: 0100, Iter: 900, total_loss: 5.318e-07, loss_BC: 0.000e+00, loss_IC: 7.813e-08,loss_f: 6.792e-08
pinn: 0000, Iter: 900, total_loss: 1.943e-07, loss_BC: 0.000e+00, loss_IC: 2.898e-08,loss_f: 5.046e-08
pinn: 0200, Iter: 900, total_loss: 4.458e-07, loss_BC: 0.000e+00, loss_IC: 6.866e-08,loss_f: 9.403e-08
pinn: 0300, Iter: 1000, total_loss: 5.919e-07, loss_BC: 0.000e+00, loss_IC: 7.438e-08,loss_f: 1.049e-07
pinn: 0100, Iter: 1000, total_loss: 5.243e-07, loss_BC: 0.000e+00, loss_IC: 7.624e-08,loss_f: 6.772e-08
pinn: 0000, Iter: 1000, total_loss: 1.912e-07, loss_BC: 0.000e+00, loss_IC: 2.619e-08,loss_f: 4.955e-08
pinn: 0200, Iter: 1000, total_loss: 4.421e-07, loss_BC: 0.000e+00, loss_IC: 6.845e-08,loss_f: 9.365e-08
pinn: 0300, Iter: 1100, total_loss: 5.791e-07, loss_BC: 0.000e+00, loss_IC: 7.316e-08,loss_f: 1.089e-07
pinn: 0100, Iter: 1100, total_loss: 5.051e-07, loss_BC: 0.000e+00, loss_IC: 8.098e-08,loss_f: 6.458e-08
pinn: 0200, Iter: 1100, total_loss: 4.370e-07, loss_BC: 0.000e+00, loss_IC: 6.576e-08,loss_f: 9.435e-08
pinn: 0000, Iter: 1100, total_loss: 1.905e-07, loss_BC: 0.000e+00, loss_IC: 2.606e-08,loss_f: 4.885e-08
pinn: 0100, Iter: 1200, total_loss: 4.932e-07, loss_BC: 0.000e+00, loss_IC: 8.056e-08,loss_f: 6.503e-08
pinn: 0300, Iter: 1200, total_loss: 5.707e-07, loss_BC: 0.000e+00, loss_IC: 7.009e-08,loss_f: 1.088e-07
pinn: 0200, Iter: 1200, total_loss: 4.297e-07, loss_BC: 0.000e+00, loss_IC: 6.195e-08,loss_f: 9.214e-08
pinn: 0000, Iter: 1200, total_loss: 1.884e-07, loss_BC: 0.000e+00, loss_IC: 2.474e-08,loss_f: 4.780e-08
pinn: 0100, Iter: 1300, total_loss: 4.897e-07, loss_BC: 0.000e+00, loss_IC: 8.082e-08,loss_f: 6.658e-08
pinn: 0300, Iter: 1300, total_loss: 5.625e-07, loss_BC: 0.000e+00, loss_IC: 7.149e-08,loss_f: 1.102e-07
pinn: 0000, Iter: 1300, total_loss: 1.876e-07, loss_BC: 0.000e+00, loss_IC: 2.410e-08,loss_f: 4.757e-08
pinn: 0200, Iter: 1300, total_loss: 4.250e-07, loss_BC: 0.000e+00, loss_IC: 6.256e-08,loss_f: 9.179e-08
pinn: 0300, Iter: 1400, total_loss: 5.531e-07, loss_BC: 0.000e+00, loss_IC: 6.819e-08,loss_f: 1.140e-07
pinn: 0100, Iter: 1400, total_loss: 5.075e-07, loss_BC: 0.000e+00, loss_IC: 8.944e-08,loss_f: 8.258e-08
pinn: 0200, Iter: 1400, total_loss: 4.228e-07, loss_BC: 0.000e+00, loss_IC: 6.248e-08,loss_f: 9.120e-08
pinn: 0000, Iter: 1400, total_loss: 1.870e-07, loss_BC: 0.000e+00, loss_IC: 2.410e-08,loss_f: 4.702e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3296, Mean_loss of pinns: 4.099e-07, loss_BC: 0.000e+00, loss_IC: 5.808e-08, loss_f: 8.029e-08
 => minimum loss: 1.869e-07, corresponding pinn index: 0000
 => maximum loss: 5.513e-07, corresponding pinn  index: 0300

==> Epoch: 3300, Mean_loss of pinns: 5.082e-05, loss_BC: 5.037e-05, loss_IC: 7.541e-08, loss_f: 1.074e-07
 => minimum loss: 2.877e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.798e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

==> Epoch: 3310, Mean_loss of pinns: 4.736e-05, loss_BC: 4.595e-05, loss_IC: 9.040e-07, loss_f: 2.270e-07
 => minimum loss: 2.739e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.529e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.488e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3315, total_loss: 4.730e-05, loss_BC: 4.534e-05, loss_IC: 1.477e-06, loss_f: 2.129e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.31000, t_max: 0.32000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3316 0 1

 -------------------------------------------------------------
  -----  Epoch: 3316 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.31000, t_max: 0.32000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3316 !!! 


==> Epoch: 3320, Mean_loss of pinns: 3.393e-03, loss_BC: 4.947e-05, loss_IC: 3.460e-07, loss_f: 3.343e-03
 => minimum loss: 9.252e-04, corresponding pinn/batch index: 0000
 => maximum loss: 8.975e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3330, Mean_loss of pinns: 2.683e-03, loss_BC: 4.814e-05, loss_IC: 3.699e-06, loss_f: 2.631e-03
 => minimum loss: 7.506e-04, corresponding pinn/batch index: 0000
 => maximum loss: 7.057e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3340, Mean_loss of pinns: 2.170e-03, loss_BC: 4.704e-05, loss_IC: 9.409e-06, loss_f: 2.114e-03
 => minimum loss: 6.195e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.701e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3350, Mean_loss of pinns: 1.786e-03, loss_BC: 4.484e-05, loss_IC: 1.570e-05, loss_f: 1.725e-03
 => minimum loss: 5.220e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.683e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3360, Mean_loss of pinns: 1.501e-03, loss_BC: 4.436e-05, loss_IC: 2.085e-05, loss_f: 1.435e-03
 => minimum loss: 4.463e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.931e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3370, Mean_loss of pinns: 1.281e-03, loss_BC: 4.407e-05, loss_IC: 2.446e-05, loss_f: 1.212e-03
 => minimum loss: 3.876e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.346e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3380, Mean_loss of pinns: 1.107e-03, loss_BC: 4.301e-05, loss_IC: 2.652e-05, loss_f: 1.037e-03
 => minimum loss: 3.399e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.886e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3390, Mean_loss of pinns: 9.669e-04, loss_BC: 4.145e-05, loss_IC: 2.748e-05, loss_f: 8.976e-04
 => minimum loss: 3.018e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.515e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3400, Mean_loss of pinns: 8.542e-04, loss_BC: 4.167e-05, loss_IC: 2.776e-05, loss_f: 7.844e-04
 => minimum loss: 2.688e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.216e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3410, Mean_loss of pinns: 7.617e-04, loss_BC: 4.228e-05, loss_IC: 2.755e-05, loss_f: 6.915e-04
 => minimum loss: 2.442e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.968e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3415

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.009e-06, loss_BC: 0.000e+00, loss_IC: 1.072e-07,loss_f: 3.776e-07
pinn: 0000, Iter: 100, total_loss: 5.420e-07, loss_BC: 0.000e+00, loss_IC: 6.522e-08,loss_f: 2.166e-07
pinn: 0200, Iter: 100, total_loss: 7.593e-07, loss_BC: 0.000e+00, loss_IC: 9.284e-08,loss_f: 2.009e-07
pinn: 0300, Iter: 100, total_loss: 5.464e-07, loss_BC: 0.000e+00, loss_IC: 1.453e-07,loss_f: 2.417e-07
pinn: 0100, Iter: 200, total_loss: 6.823e-07, loss_BC: 0.000e+00, loss_IC: 7.005e-08,loss_f: 1.132e-07
pinn: 0000, Iter: 200, total_loss: 4.162e-07, loss_BC: 0.000e+00, loss_IC: 5.731e-08,loss_f: 1.002e-07
pinn: 0200, Iter: 200, total_loss: 6.543e-07, loss_BC: 0.000e+00, loss_IC: 7.303e-08,loss_f: 1.126e-07
pinn: 0300, Iter: 200, total_loss: 3.986e-07, loss_BC: 0.000e+00, loss_IC: 7.096e-08,loss_f: 1.738e-07
pinn: 0100, Iter: 300, total_loss: 6.473e-07, loss_BC: 0.000e+00, loss_IC: 6.732e-08,loss_f: 8.492e-08
pinn: 0000, Iter: 300, total_loss: 3.841e-07, loss_BC: 0.000e+00, loss_IC: 5.352e-08,loss_f: 7.293e-08
pinn: 0200, Iter: 300, total_loss: 6.340e-07, loss_BC: 0.000e+00, loss_IC: 7.899e-08,loss_f: 1.014e-07
pinn: 0300, Iter: 300, total_loss: 3.628e-07, loss_BC: 0.000e+00, loss_IC: 7.367e-08,loss_f: 1.360e-07
pinn: 0100, Iter: 400, total_loss: 6.375e-07, loss_BC: 0.000e+00, loss_IC: 7.076e-08,loss_f: 8.237e-08
pinn: 0200, Iter: 400, total_loss: 6.128e-07, loss_BC: 0.000e+00, loss_IC: 7.811e-08,loss_f: 9.244e-08
pinn: 0000, Iter: 400, total_loss: 3.731e-07, loss_BC: 0.000e+00, loss_IC: 5.766e-08,loss_f: 6.215e-08
pinn: 0300, Iter: 400, total_loss: 3.456e-07, loss_BC: 0.000e+00, loss_IC: 7.152e-08,loss_f: 1.245e-07
pinn: 0100, Iter: 500, total_loss: 6.331e-07, loss_BC: 0.000e+00, loss_IC: 7.213e-08,loss_f: 8.238e-08
pinn: 0200, Iter: 500, total_loss: 5.952e-07, loss_BC: 0.000e+00, loss_IC: 8.563e-08,loss_f: 8.155e-08
pinn: 0000, Iter: 500, total_loss: 3.689e-07, loss_BC: 0.000e+00, loss_IC: 5.812e-08,loss_f: 5.976e-08
pinn: 0300, Iter: 500, total_loss: 3.279e-07, loss_BC: 0.000e+00, loss_IC: 7.227e-08,loss_f: 1.075e-07
pinn: 0100, Iter: 600, total_loss: 6.235e-07, loss_BC: 0.000e+00, loss_IC: 7.984e-08,loss_f: 8.275e-08
pinn: 0200, Iter: 600, total_loss: 5.845e-07, loss_BC: 0.000e+00, loss_IC: 8.765e-08,loss_f: 7.869e-08
pinn: 0000, Iter: 600, total_loss: 3.634e-07, loss_BC: 0.000e+00, loss_IC: 5.938e-08,loss_f: 5.688e-08
pinn: 0300, Iter: 600, total_loss: 3.181e-07, loss_BC: 0.000e+00, loss_IC: 7.231e-08,loss_f: 9.819e-08
pinn: 0100, Iter: 700, total_loss: 6.096e-07, loss_BC: 0.000e+00, loss_IC: 8.597e-08,loss_f: 8.076e-08
pinn: 0200, Iter: 700, total_loss: 5.780e-07, loss_BC: 0.000e+00, loss_IC: 8.476e-08,loss_f: 8.152e-08
pinn: 0000, Iter: 700, total_loss: 3.598e-07, loss_BC: 0.000e+00, loss_IC: 5.618e-08,loss_f: 5.789e-08
pinn: 0300, Iter: 700, total_loss: 3.040e-07, loss_BC: 0.000e+00, loss_IC: 7.274e-08,loss_f: 8.428e-08
pinn: 0100, Iter: 800, total_loss: 6.023e-07, loss_BC: 0.000e+00, loss_IC: 8.967e-08,loss_f: 8.036e-08
pinn: 0200, Iter: 800, total_loss: 5.663e-07, loss_BC: 0.000e+00, loss_IC: 8.584e-08,loss_f: 8.127e-08
pinn: 0000, Iter: 800, total_loss: 3.576e-07, loss_BC: 0.000e+00, loss_IC: 5.430e-08,loss_f: 5.832e-08
pinn: 0300, Iter: 800, total_loss: 2.998e-07, loss_BC: 0.000e+00, loss_IC: 7.224e-08,loss_f: 8.163e-08
pinn: 0100, Iter: 900, total_loss: 5.957e-07, loss_BC: 0.000e+00, loss_IC: 9.026e-08,loss_f: 7.944e-08
pinn: 0200, Iter: 900, total_loss: 5.505e-07, loss_BC: 0.000e+00, loss_IC: 8.108e-08,loss_f: 8.340e-08
pinn: 0000, Iter: 900, total_loss: 3.525e-07, loss_BC: 0.000e+00, loss_IC: 5.236e-08,loss_f: 5.907e-08
pinn: 0300, Iter: 900, total_loss: 2.948e-07, loss_BC: 0.000e+00, loss_IC: 7.087e-08,loss_f: 7.846e-08
pinn: 0100, Iter: 1000, total_loss: 5.807e-07, loss_BC: 0.000e+00, loss_IC: 9.348e-08,loss_f: 8.475e-08
pinn: 0200, Iter: 1000, total_loss: 5.423e-07, loss_BC: 0.000e+00, loss_IC: 8.191e-08,loss_f: 8.499e-08
pinn: 0000, Iter: 1000, total_loss: 3.507e-07, loss_BC: 0.000e+00, loss_IC: 5.260e-08,loss_f: 5.807e-08
pinn: 0300, Iter: 1000, total_loss: 2.924e-07, loss_BC: 0.000e+00, loss_IC: 7.054e-08,loss_f: 7.657e-08
pinn: 0100, Iter: 1100, total_loss: 5.674e-07, loss_BC: 0.000e+00, loss_IC: 9.086e-08,loss_f: 9.053e-08
pinn: 0200, Iter: 1100, total_loss: 5.398e-07, loss_BC: 0.000e+00, loss_IC: 8.401e-08,loss_f: 8.596e-08
pinn: 0000, Iter: 1100, total_loss: 3.474e-07, loss_BC: 0.000e+00, loss_IC: 5.182e-08,loss_f: 5.858e-08
pinn: 0300, Iter: 1100, total_loss: 2.901e-07, loss_BC: 0.000e+00, loss_IC: 7.014e-08,loss_f: 7.488e-08
pinn: 0100, Iter: 1200, total_loss: 5.533e-07, loss_BC: 0.000e+00, loss_IC: 9.429e-08,loss_f: 9.648e-08
pinn: 0200, Iter: 1200, total_loss: 5.322e-07, loss_BC: 0.000e+00, loss_IC: 8.211e-08,loss_f: 8.934e-08
pinn: 0000, Iter: 1200, total_loss: 3.463e-07, loss_BC: 0.000e+00, loss_IC: 5.118e-08,loss_f: 5.935e-08
pinn: 0300, Iter: 1200, total_loss: 2.879e-07, loss_BC: 0.000e+00, loss_IC: 6.909e-08,loss_f: 7.364e-08
pinn: 0100, Iter: 1300, total_loss: 5.403e-07, loss_BC: 0.000e+00, loss_IC: 9.136e-08,loss_f: 9.808e-08
pinn: 0200, Iter: 1300, total_loss: 5.243e-07, loss_BC: 0.000e+00, loss_IC: 8.548e-08,loss_f: 9.322e-08
pinn: 0000, Iter: 1300, total_loss: 3.389e-07, loss_BC: 0.000e+00, loss_IC: 4.638e-08,loss_f: 6.279e-08
pinn: 0300, Iter: 1300, total_loss: 2.819e-07, loss_BC: 0.000e+00, loss_IC: 6.505e-08,loss_f: 7.141e-08
pinn: 0100, Iter: 1400, total_loss: 5.337e-07, loss_BC: 0.000e+00, loss_IC: 9.717e-08,loss_f: 1.041e-07
pinn: 0200, Iter: 1400, total_loss: 5.202e-07, loss_BC: 0.000e+00, loss_IC: 8.506e-08,loss_f: 9.622e-08
pinn: 0000, Iter: 1400, total_loss: 3.376e-07, loss_BC: 0.000e+00, loss_IC: 4.610e-08,loss_f: 6.338e-08
pinn: 0300, Iter: 1400, total_loss: 2.737e-07, loss_BC: 0.000e+00, loss_IC: 5.810e-08,loss_f: 6.948e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3415, Mean_loss of pinns: 4.149e-07, loss_BC: 0.000e+00, loss_IC: 7.162e-08, loss_f: 8.415e-08
 => minimum loss: 2.733e-07, corresponding pinn index: 0300
 => maximum loss: 5.326e-07, corresponding pinn  index: 0100

 max_loss: 6.774e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3417, total_loss: 5.001e-05, loss_BC: 4.960e-05, loss_IC: 7.222e-08, loss_f: 8.674e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.32000, t_max: 0.33000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3418 0 1

 -------------------------------------------------------------
  -----  Epoch: 3418 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.32000, t_max: 0.33000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3418 !!! 


==> Epoch: 3420, Mean_loss of pinns: 2.186e-03, loss_BC: 5.546e-05, loss_IC: 1.146e-07, loss_f: 2.130e-03
 => minimum loss: 1.633e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.213e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3430, Mean_loss of pinns: 1.685e-03, loss_BC: 5.430e-05, loss_IC: 3.573e-06, loss_f: 1.627e-03
 => minimum loss: 1.390e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.517e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3440, Mean_loss of pinns: 1.350e-03, loss_BC: 5.237e-05, loss_IC: 8.590e-06, loss_f: 1.288e-03
 => minimum loss: 1.243e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.000e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3450, Mean_loss of pinns: 1.101e-03, loss_BC: 5.196e-05, loss_IC: 1.359e-05, loss_f: 1.035e-03
 => minimum loss: 1.137e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.626e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3460, Mean_loss of pinns: 9.180e-04, loss_BC: 4.941e-05, loss_IC: 1.852e-05, loss_f: 8.498e-04
 => minimum loss: 1.033e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.352e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3470, Mean_loss of pinns: 7.819e-04, loss_BC: 4.874e-05, loss_IC: 2.202e-05, loss_f: 7.109e-04
 => minimum loss: 9.405e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.144e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3480, Mean_loss of pinns: 6.752e-04, loss_BC: 4.708e-05, loss_IC: 2.325e-05, loss_f: 6.046e-04
 => minimum loss: 8.492e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.828e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3490, Mean_loss of pinns: 5.906e-04, loss_BC: 4.585e-05, loss_IC: 2.271e-05, loss_f: 5.218e-04
 => minimum loss: 7.809e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.547e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3500, Mean_loss of pinns: 5.205e-04, loss_BC: 4.331e-05, loss_IC: 2.113e-05, loss_f: 4.558e-04
 => minimum loss: 7.016e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.499e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3510, Mean_loss of pinns: 4.629e-04, loss_BC: 4.140e-05, loss_IC: 1.893e-05, loss_f: 4.024e-04
 => minimum loss: 6.494e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.654e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3517

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 6.117e-07, loss_BC: 0.000e+00, loss_IC: 7.026e-08,loss_f: 2.826e-07
pinn: 0100, Iter: 100, total_loss: 4.187e-07, loss_BC: 0.000e+00, loss_IC: 8.580e-08,loss_f: 2.677e-07
pinn: 0300, Iter: 100, total_loss: 7.060e-07, loss_BC: 0.000e+00, loss_IC: 9.503e-08,loss_f: 3.676e-07
pinn: 0200, Iter: 200, total_loss: 4.203e-07, loss_BC: 0.000e+00, loss_IC: 5.029e-08,loss_f: 1.073e-07
pinn: 0100, Iter: 200, total_loss: 2.806e-07, loss_BC: 0.000e+00, loss_IC: 5.938e-08,loss_f: 1.547e-07
pinn: 0300, Iter: 200, total_loss: 4.211e-07, loss_BC: 0.000e+00, loss_IC: 6.685e-08,loss_f: 1.191e-07
pinn: 0200, Iter: 300, total_loss: 4.050e-07, loss_BC: 0.000e+00, loss_IC: 4.679e-08,loss_f: 9.371e-08
pinn: 0300, Iter: 300, total_loss: 3.786e-07, loss_BC: 0.000e+00, loss_IC: 5.601e-08,loss_f: 8.601e-08
pinn: 0100, Iter: 300, total_loss: 2.458e-07, loss_BC: 0.000e+00, loss_IC: 5.650e-08,loss_f: 1.216e-07
pinn: 0200, Iter: 400, total_loss: 3.974e-07, loss_BC: 0.000e+00, loss_IC: 4.467e-08,loss_f: 9.025e-08
pinn: 0300, Iter: 400, total_loss: 3.688e-07, loss_BC: 0.000e+00, loss_IC: 5.068e-08,loss_f: 8.064e-08
pinn: 0100, Iter: 400, total_loss: 2.339e-07, loss_BC: 0.000e+00, loss_IC: 5.731e-08,loss_f: 1.088e-07
pinn: 0200, Iter: 500, total_loss: 3.892e-07, loss_BC: 0.000e+00, loss_IC: 4.383e-08,loss_f: 8.617e-08
pinn: 0300, Iter: 500, total_loss: 3.617e-07, loss_BC: 0.000e+00, loss_IC: 4.684e-08,loss_f: 7.582e-08
pinn: 0100, Iter: 500, total_loss: 2.193e-07, loss_BC: 0.000e+00, loss_IC: 5.375e-08,loss_f: 9.809e-08
pinn: 0200, Iter: 600, total_loss: 3.852e-07, loss_BC: 0.000e+00, loss_IC: 4.430e-08,loss_f: 8.493e-08
pinn: 0300, Iter: 600, total_loss: 3.590e-07, loss_BC: 0.000e+00, loss_IC: 4.427e-08,loss_f: 7.453e-08
pinn: 0100, Iter: 600, total_loss: 2.079e-07, loss_BC: 0.000e+00, loss_IC: 5.058e-08,loss_f: 8.939e-08
pinn: 0200, Iter: 700, total_loss: 3.781e-07, loss_BC: 0.000e+00, loss_IC: 4.455e-08,loss_f: 7.998e-08
pinn: 0300, Iter: 700, total_loss: 3.537e-07, loss_BC: 0.000e+00, loss_IC: 4.179e-08,loss_f: 7.235e-08
pinn: 0100, Iter: 700, total_loss: 2.003e-07, loss_BC: 0.000e+00, loss_IC: 4.695e-08,loss_f: 8.429e-08
pinn: 0200, Iter: 800, total_loss: 3.756e-07, loss_BC: 0.000e+00, loss_IC: 4.537e-08,loss_f: 7.876e-08
pinn: 0300, Iter: 800, total_loss: 3.501e-07, loss_BC: 0.000e+00, loss_IC: 4.099e-08,loss_f: 7.079e-08
pinn: 0100, Iter: 800, total_loss: 1.919e-07, loss_BC: 0.000e+00, loss_IC: 4.118e-08,loss_f: 8.106e-08
pinn: 0200, Iter: 900, total_loss: 3.719e-07, loss_BC: 0.000e+00, loss_IC: 4.637e-08,loss_f: 7.610e-08
pinn: 0100, Iter: 900, total_loss: 1.841e-07, loss_BC: 0.000e+00, loss_IC: 3.510e-08,loss_f: 7.898e-08
pinn: 0300, Iter: 900, total_loss: 3.463e-07, loss_BC: 0.000e+00, loss_IC: 4.049e-08,loss_f: 6.985e-08
pinn: 0200, Iter: 1000, total_loss: 3.675e-07, loss_BC: 0.000e+00, loss_IC: 4.870e-08,loss_f: 7.168e-08
pinn: 0100, Iter: 1000, total_loss: 1.800e-07, loss_BC: 0.000e+00, loss_IC: 3.238e-08,loss_f: 7.710e-08
pinn: 0300, Iter: 1000, total_loss: 3.416e-07, loss_BC: 0.000e+00, loss_IC: 3.969e-08,loss_f: 6.862e-08
pinn: 0200, Iter: 1100, total_loss: 3.613e-07, loss_BC: 0.000e+00, loss_IC: 4.897e-08,loss_f: 6.979e-08
pinn: 0100, Iter: 1100, total_loss: 1.771e-07, loss_BC: 0.000e+00, loss_IC: 3.113e-08,loss_f: 7.543e-08
pinn: 0300, Iter: 1100, total_loss: 3.377e-07, loss_BC: 0.000e+00, loss_IC: 3.853e-08,loss_f: 6.826e-08
pinn: 0200, Iter: 1200, total_loss: 3.555e-07, loss_BC: 0.000e+00, loss_IC: 4.762e-08,loss_f: 7.047e-08
pinn: 0100, Iter: 1200, total_loss: 1.739e-07, loss_BC: 0.000e+00, loss_IC: 3.018e-08,loss_f: 7.340e-08
pinn: 0300, Iter: 1200, total_loss: 3.358e-07, loss_BC: 0.000e+00, loss_IC: 3.835e-08,loss_f: 6.830e-08
pinn: 0200, Iter: 1300, total_loss: 3.483e-07, loss_BC: 0.000e+00, loss_IC: 4.688e-08,loss_f: 6.994e-08
pinn: 0100, Iter: 1300, total_loss: 1.715e-07, loss_BC: 0.000e+00, loss_IC: 2.705e-08,loss_f: 7.401e-08
pinn: 0300, Iter: 1300, total_loss: 3.308e-07, loss_BC: 0.000e+00, loss_IC: 3.811e-08,loss_f: 6.785e-08
pinn: 0200, Iter: 1400, total_loss: 3.461e-07, loss_BC: 0.000e+00, loss_IC: 4.660e-08,loss_f: 6.884e-08
pinn: 0100, Iter: 1400, total_loss: 1.709e-07, loss_BC: 0.000e+00, loss_IC: 2.696e-08,loss_f: 7.358e-08
pinn: 0300, Iter: 1400, total_loss: 3.273e-07, loss_BC: 0.000e+00, loss_IC: 3.681e-08,loss_f: 6.952e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3517, Mean_loss of pinns: 2.804e-07, loss_BC: 0.000e+00, loss_IC: 3.672e-08, loss_f: 7.093e-08
 => minimum loss: 1.704e-07, corresponding pinn index: 0100
 => maximum loss: 3.445e-07, corresponding pinn  index: 0200

==> Epoch: 3520, Mean_loss of pinns: 5.716e-05, loss_BC: 4.948e-05, loss_IC: 1.811e-06, loss_f: 5.689e-06
 => minimum loss: 3.091e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.323e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0300

==> Epoch: 3530, Mean_loss of pinns: 5.287e-05, loss_BC: 4.546e-05, loss_IC: 1.891e-06, loss_f: 5.327e-06
 => minimum loss: 2.903e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.738e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0300

==> Epoch: 3540, Mean_loss of pinns: 4.928e-05, loss_BC: 4.142e-05, loss_IC: 2.731e-06, loss_f: 4.946e-06
 => minimum loss: 2.775e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.789e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

==> Epoch: 3550, Mean_loss of pinns: 4.764e-05, loss_BC: 3.936e-05, loss_IC: 3.518e-06, loss_f: 4.582e-06
 => minimum loss: 2.644e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.367e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.400e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3553, total_loss: 4.706e-05, loss_BC: 3.873e-05, loss_IC: 3.652e-06, loss_f: 4.488e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.33000, t_max: 0.34000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3554 0 1

 -------------------------------------------------------------
  -----  Epoch: 3554 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.33000, t_max: 0.34000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3554 !!! 


==> Epoch: 3560, Mean_loss of pinns: 4.965e-02, loss_BC: 4.362e-05, loss_IC: 8.382e-07, loss_f: 4.960e-02
 => minimum loss: 3.810e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.945e-01, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3570, Mean_loss of pinns: 4.386e-02, loss_BC: 4.396e-05, loss_IC: 4.797e-06, loss_f: 4.381e-02
 => minimum loss: 3.069e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.722e-01, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3580, Mean_loss of pinns: 3.883e-02, loss_BC: 4.490e-05, loss_IC: 8.971e-06, loss_f: 3.877e-02
 => minimum loss: 2.555e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.527e-01, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3590, Mean_loss of pinns: 3.450e-02, loss_BC: 4.523e-05, loss_IC: 1.185e-05, loss_f: 3.445e-02
 => minimum loss: 2.150e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.359e-01, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3600, Mean_loss of pinns: 3.078e-02, loss_BC: 4.498e-05, loss_IC: 1.340e-05, loss_f: 3.072e-02
 => minimum loss: 1.907e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.213e-01, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3610, Mean_loss of pinns: 2.757e-02, loss_BC: 4.373e-05, loss_IC: 1.379e-05, loss_f: 2.751e-02
 => minimum loss: 1.667e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.087e-01, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3620, Mean_loss of pinns: 2.479e-02, loss_BC: 4.337e-05, loss_IC: 1.333e-05, loss_f: 2.473e-02
 => minimum loss: 1.506e-04, corresponding pinn/batch index: 0200
 => maximum loss: 9.779e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3630, Mean_loss of pinns: 2.236e-02, loss_BC: 4.152e-05, loss_IC: 1.231e-05, loss_f: 2.230e-02
 => minimum loss: 1.370e-04, corresponding pinn/batch index: 0200
 => maximum loss: 8.823e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3640, Mean_loss of pinns: 2.022e-02, loss_BC: 3.978e-05, loss_IC: 1.094e-05, loss_f: 2.017e-02
 => minimum loss: 1.249e-04, corresponding pinn/batch index: 0200
 => maximum loss: 7.983e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3650, Mean_loss of pinns: 1.833e-02, loss_BC: 3.869e-05, loss_IC: 9.514e-06, loss_f: 1.828e-02
 => minimum loss: 1.143e-04, corresponding pinn/batch index: 0200
 => maximum loss: 7.238e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3653

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 4.627e-07, loss_BC: 0.000e+00, loss_IC: 1.577e-07,loss_f: 2.543e-07
pinn: 0100, Iter: 100, total_loss: 7.121e-07, loss_BC: 0.000e+00, loss_IC: 7.338e-08,loss_f: 3.060e-07
pinn: 0200, Iter: 100, total_loss: 9.727e-07, loss_BC: 0.000e+00, loss_IC: 4.167e-08,loss_f: 2.232e-07
pinn: 0000, Iter: 100, total_loss: 1.219e-06, loss_BC: 0.000e+00, loss_IC: 1.865e-07,loss_f: 8.123e-07
pinn: 0100, Iter: 200, total_loss: 5.248e-07, loss_BC: 0.000e+00, loss_IC: 7.761e-08,loss_f: 1.310e-07
pinn: 0300, Iter: 200, total_loss: 2.417e-07, loss_BC: 0.000e+00, loss_IC: 7.443e-08,loss_f: 1.178e-07
pinn: 0200, Iter: 200, total_loss: 8.190e-07, loss_BC: 0.000e+00, loss_IC: 5.191e-08,loss_f: 9.023e-08
pinn: 0000, Iter: 200, total_loss: 6.139e-07, loss_BC: 0.000e+00, loss_IC: 1.562e-07,loss_f: 2.404e-07
pinn: 0200, Iter: 300, total_loss: 7.950e-07, loss_BC: 0.000e+00, loss_IC: 4.479e-08,loss_f: 7.287e-08
pinn: 0300, Iter: 300, total_loss: 2.100e-07, loss_BC: 0.000e+00, loss_IC: 6.585e-08,loss_f: 9.431e-08
pinn: 0000, Iter: 300, total_loss: 4.881e-07, loss_BC: 0.000e+00, loss_IC: 1.632e-07,loss_f: 1.103e-07
pinn: 0100, Iter: 300, total_loss: 4.838e-07, loss_BC: 0.000e+00, loss_IC: 7.890e-08,loss_f: 9.437e-08
pinn: 0100, Iter: 400, total_loss: 4.736e-07, loss_BC: 0.000e+00, loss_IC: 7.954e-08,loss_f: 9.001e-08
pinn: 0200, Iter: 400, total_loss: 7.648e-07, loss_BC: 0.000e+00, loss_IC: 5.258e-08,loss_f: 6.616e-08
pinn: 0300, Iter: 400, total_loss: 1.964e-07, loss_BC: 0.000e+00, loss_IC: 5.823e-08,loss_f: 8.824e-08
pinn: 0000, Iter: 400, total_loss: 4.510e-07, loss_BC: 0.000e+00, loss_IC: 1.530e-07,loss_f: 8.392e-08
pinn: 0100, Iter: 500, total_loss: 4.601e-07, loss_BC: 0.000e+00, loss_IC: 8.409e-08,loss_f: 8.337e-08
pinn: 0300, Iter: 500, total_loss: 1.898e-07, loss_BC: 0.000e+00, loss_IC: 5.790e-08,loss_f: 8.190e-08
pinn: 0000, Iter: 500, total_loss: 4.340e-07, loss_BC: 0.000e+00, loss_IC: 1.537e-07,loss_f: 6.828e-08
pinn: 0200, Iter: 500, total_loss: 7.297e-07, loss_BC: 0.000e+00, loss_IC: 7.082e-08,loss_f: 6.373e-08
pinn: 0100, Iter: 600, total_loss: 4.487e-07, loss_BC: 0.000e+00, loss_IC: 8.278e-08,loss_f: 7.873e-08
pinn: 0300, Iter: 600, total_loss: 1.864e-07, loss_BC: 0.000e+00, loss_IC: 5.758e-08,loss_f: 7.890e-08
pinn: 0000, Iter: 600, total_loss: 4.233e-07, loss_BC: 0.000e+00, loss_IC: 1.403e-07,loss_f: 7.026e-08
pinn: 0200, Iter: 600, total_loss: 7.054e-07, loss_BC: 0.000e+00, loss_IC: 1.050e-07,loss_f: 5.477e-08
pinn: 0100, Iter: 700, total_loss: 4.604e-07, loss_BC: 0.000e+00, loss_IC: 8.513e-08,loss_f: 8.895e-08
pinn: 0300, Iter: 700, total_loss: 1.826e-07, loss_BC: 0.000e+00, loss_IC: 5.596e-08,loss_f: 7.677e-08
pinn: 0200, Iter: 700, total_loss: 6.844e-07, loss_BC: 0.000e+00, loss_IC: 1.030e-07,loss_f: 5.800e-08
pinn: 0000, Iter: 700, total_loss: 4.140e-07, loss_BC: 0.000e+00, loss_IC: 1.293e-07,loss_f: 7.020e-08
pinn: 0300, Iter: 800, total_loss: 1.740e-07, loss_BC: 0.000e+00, loss_IC: 5.227e-08,loss_f: 7.213e-08
pinn: 0100, Iter: 800, total_loss: 4.415e-07, loss_BC: 0.000e+00, loss_IC: 8.017e-08,loss_f: 7.840e-08
pinn: 0000, Iter: 800, total_loss: 4.073e-07, loss_BC: 0.000e+00, loss_IC: 1.213e-07,loss_f: 7.076e-08
pinn: 0200, Iter: 800, total_loss: 6.646e-07, loss_BC: 0.000e+00, loss_IC: 1.025e-07,loss_f: 6.655e-08
pinn: 0300, Iter: 900, total_loss: 1.713e-07, loss_BC: 0.000e+00, loss_IC: 4.917e-08,loss_f: 7.241e-08
pinn: 0200, Iter: 900, total_loss: 6.443e-07, loss_BC: 0.000e+00, loss_IC: 1.022e-07,loss_f: 7.035e-08
pinn: 0100, Iter: 900, total_loss: 4.350e-07, loss_BC: 0.000e+00, loss_IC: 7.247e-08,loss_f: 7.866e-08
pinn: 0000, Iter: 900, total_loss: 4.005e-07, loss_BC: 0.000e+00, loss_IC: 1.155e-07,loss_f: 7.004e-08
pinn: 0300, Iter: 1000, total_loss: 1.694e-07, loss_BC: 0.000e+00, loss_IC: 4.713e-08,loss_f: 7.234e-08
pinn: 0100, Iter: 1000, total_loss: 4.280e-07, loss_BC: 0.000e+00, loss_IC: 7.070e-08,loss_f: 7.882e-08
pinn: 0200, Iter: 1000, total_loss: 6.154e-07, loss_BC: 0.000e+00, loss_IC: 1.134e-07,loss_f: 7.800e-08
pinn: 0000, Iter: 1000, total_loss: 3.971e-07, loss_BC: 0.000e+00, loss_IC: 1.113e-07,loss_f: 7.073e-08
pinn: 0100, Iter: 1100, total_loss: 4.256e-07, loss_BC: 0.000e+00, loss_IC: 7.006e-08,loss_f: 7.988e-08
pinn: 0300, Iter: 1100, total_loss: 1.667e-07, loss_BC: 0.000e+00, loss_IC: 4.427e-08,loss_f: 7.209e-08
pinn: 0200, Iter: 1100, total_loss: 5.999e-07, loss_BC: 0.000e+00, loss_IC: 1.177e-07,loss_f: 8.145e-08
pinn: 0000, Iter: 1100, total_loss: 3.937e-07, loss_BC: 0.000e+00, loss_IC: 1.078e-07,loss_f: 7.102e-08
pinn: 0100, Iter: 1200, total_loss: 4.212e-07, loss_BC: 0.000e+00, loss_IC: 6.687e-08,loss_f: 8.203e-08
pinn: 0200, Iter: 1200, total_loss: 5.861e-07, loss_BC: 0.000e+00, loss_IC: 1.174e-07,loss_f: 8.153e-08
pinn: 0300, Iter: 1200, total_loss: 1.639e-07, loss_BC: 0.000e+00, loss_IC: 4.083e-08,loss_f: 7.234e-08
pinn: 0000, Iter: 1200, total_loss: 3.910e-07, loss_BC: 0.000e+00, loss_IC: 1.027e-07,loss_f: 7.340e-08
pinn: 0100, Iter: 1300, total_loss: 4.137e-07, loss_BC: 0.000e+00, loss_IC: 6.222e-08,loss_f: 8.688e-08
pinn: 0300, Iter: 1300, total_loss: 1.625e-07, loss_BC: 0.000e+00, loss_IC: 4.048e-08,loss_f: 7.121e-08
pinn: 0200, Iter: 1300, total_loss: 5.726e-07, loss_BC: 0.000e+00, loss_IC: 1.188e-07,loss_f: 8.564e-08
pinn: 0000, Iter: 1300, total_loss: 3.775e-07, loss_BC: 0.000e+00, loss_IC: 8.797e-08,loss_f: 7.888e-08
pinn: 0100, Iter: 1400, total_loss: 4.061e-07, loss_BC: 0.000e+00, loss_IC: 6.091e-08,loss_f: 8.808e-08
pinn: 0300, Iter: 1400, total_loss: 1.602e-07, loss_BC: 0.000e+00, loss_IC: 3.948e-08,loss_f: 6.974e-08
pinn: 0200, Iter: 1400, total_loss: 5.643e-07, loss_BC: 0.000e+00, loss_IC: 1.177e-07,loss_f: 8.645e-08
pinn: 0000, Iter: 1400, total_loss: 3.760e-07, loss_BC: 0.000e+00, loss_IC: 8.594e-08,loss_f: 7.961e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3653, Mean_loss of pinns: 3.757e-07, loss_BC: 0.000e+00, loss_IC: 7.439e-08, loss_f: 8.104e-08
 => minimum loss: 1.596e-07, corresponding pinn index: 0300
 => maximum loss: 5.630e-07, corresponding pinn  index: 0200

 max_loss: 6.401e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3655, total_loss: 4.106e-05, loss_BC: 4.068e-05, loss_IC: 7.562e-08, loss_f: 8.507e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.34000, t_max: 0.35000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3656 0 1

 -------------------------------------------------------------
  -----  Epoch: 3656 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.34000, t_max: 0.35000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3656 !!! 


==> Epoch: 3660, Mean_loss of pinns: 1.442e-03, loss_BC: 4.648e-05, loss_IC: 2.861e-07, loss_f: 1.395e-03
 => minimum loss: 8.557e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.889e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3670, Mean_loss of pinns: 1.136e-03, loss_BC: 4.633e-05, loss_IC: 3.030e-06, loss_f: 1.086e-03
 => minimum loss: 6.833e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.472e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3680, Mean_loss of pinns: 9.158e-04, loss_BC: 4.444e-05, loss_IC: 7.263e-06, loss_f: 8.640e-04
 => minimum loss: 5.552e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.173e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3690, Mean_loss of pinns: 7.598e-04, loss_BC: 4.238e-05, loss_IC: 1.183e-05, loss_f: 7.055e-04
 => minimum loss: 4.638e-04, corresponding pinn/batch index: 0200
 => maximum loss: 9.588e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3700, Mean_loss of pinns: 6.415e-04, loss_BC: 4.048e-05, loss_IC: 1.515e-05, loss_f: 5.857e-04
 => minimum loss: 3.963e-04, corresponding pinn/batch index: 0200
 => maximum loss: 8.018e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3710, Mean_loss of pinns: 5.511e-04, loss_BC: 3.856e-05, loss_IC: 1.626e-05, loss_f: 4.961e-04
 => minimum loss: 3.451e-04, corresponding pinn/batch index: 0200
 => maximum loss: 6.811e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3720, Mean_loss of pinns: 4.793e-04, loss_BC: 3.748e-05, loss_IC: 1.528e-05, loss_f: 4.264e-04
 => minimum loss: 3.044e-04, corresponding pinn/batch index: 0200
 => maximum loss: 5.871e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3730, Mean_loss of pinns: 4.200e-04, loss_BC: 3.546e-05, loss_IC: 1.334e-05, loss_f: 3.710e-04
 => minimum loss: 2.695e-04, corresponding pinn/batch index: 0200
 => maximum loss: 5.125e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3740, Mean_loss of pinns: 3.722e-04, loss_BC: 3.452e-05, loss_IC: 1.114e-05, loss_f: 3.263e-04
 => minimum loss: 2.411e-04, corresponding pinn/batch index: 0200
 => maximum loss: 4.517e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3750, Mean_loss of pinns: 3.322e-04, loss_BC: 3.339e-05, loss_IC: 9.180e-06, loss_f: 2.894e-04
 => minimum loss: 2.180e-04, corresponding pinn/batch index: 0200
 => maximum loss: 4.030e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3755

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 5.980e-07, loss_BC: 0.000e+00, loss_IC: 5.678e-08,loss_f: 3.174e-07
pinn: 0100, Iter: 100, total_loss: 6.476e-07, loss_BC: 0.000e+00, loss_IC: 1.259e-07,loss_f: 3.282e-07
pinn: 0300, Iter: 100, total_loss: 3.813e-07, loss_BC: 0.000e+00, loss_IC: 6.486e-08,loss_f: 2.055e-07
pinn: 0200, Iter: 100, total_loss: 4.480e-07, loss_BC: 0.000e+00, loss_IC: 5.673e-08,loss_f: 2.019e-07
pinn: 0300, Iter: 200, total_loss: 2.410e-07, loss_BC: 0.000e+00, loss_IC: 5.399e-08,loss_f: 8.044e-08
pinn: 0000, Iter: 200, total_loss: 4.285e-07, loss_BC: 0.000e+00, loss_IC: 4.982e-08,loss_f: 1.545e-07
pinn: 0200, Iter: 200, total_loss: 3.262e-07, loss_BC: 0.000e+00, loss_IC: 4.475e-08,loss_f: 9.865e-08
pinn: 0100, Iter: 200, total_loss: 3.874e-07, loss_BC: 0.000e+00, loss_IC: 5.649e-08,loss_f: 1.443e-07
pinn: 0300, Iter: 300, total_loss: 2.216e-07, loss_BC: 0.000e+00, loss_IC: 4.224e-08,loss_f: 7.154e-08
pinn: 0000, Iter: 300, total_loss: 3.995e-07, loss_BC: 0.000e+00, loss_IC: 4.811e-08,loss_f: 1.281e-07
pinn: 0200, Iter: 300, total_loss: 3.091e-07, loss_BC: 0.000e+00, loss_IC: 4.050e-08,loss_f: 8.615e-08
pinn: 0100, Iter: 300, total_loss: 3.355e-07, loss_BC: 0.000e+00, loss_IC: 3.556e-08,loss_f: 1.113e-07
pinn: 0000, Iter: 400, total_loss: 3.851e-07, loss_BC: 0.000e+00, loss_IC: 4.732e-08,loss_f: 1.135e-07
pinn: 0300, Iter: 400, total_loss: 2.088e-07, loss_BC: 0.000e+00, loss_IC: 3.232e-08,loss_f: 6.715e-08
pinn: 0200, Iter: 400, total_loss: 2.915e-07, loss_BC: 0.000e+00, loss_IC: 3.733e-08,loss_f: 7.490e-08
pinn: 0100, Iter: 400, total_loss: 3.205e-07, loss_BC: 0.000e+00, loss_IC: 3.072e-08,loss_f: 9.983e-08
pinn: 0000, Iter: 500, total_loss: 3.668e-07, loss_BC: 0.000e+00, loss_IC: 5.595e-08,loss_f: 9.037e-08
pinn: 0200, Iter: 500, total_loss: 2.800e-07, loss_BC: 0.000e+00, loss_IC: 3.153e-08,loss_f: 6.851e-08
pinn: 0300, Iter: 500, total_loss: 2.040e-07, loss_BC: 0.000e+00, loss_IC: 2.912e-08,loss_f: 6.435e-08
pinn: 0100, Iter: 500, total_loss: 3.108e-07, loss_BC: 0.000e+00, loss_IC: 2.928e-08,loss_f: 9.097e-08
pinn: 0300, Iter: 600, total_loss: 1.999e-07, loss_BC: 0.000e+00, loss_IC: 2.681e-08,loss_f: 6.176e-08
pinn: 0000, Iter: 600, total_loss: 3.595e-07, loss_BC: 0.000e+00, loss_IC: 5.838e-08,loss_f: 8.197e-08
pinn: 0200, Iter: 600, total_loss: 2.759e-07, loss_BC: 0.000e+00, loss_IC: 3.164e-08,loss_f: 6.597e-08
pinn: 0100, Iter: 600, total_loss: 2.989e-07, loss_BC: 0.000e+00, loss_IC: 2.701e-08,loss_f: 8.014e-08
pinn: 0200, Iter: 700, total_loss: 2.713e-07, loss_BC: 0.000e+00, loss_IC: 3.078e-08,loss_f: 6.283e-08
pinn: 0100, Iter: 700, total_loss: 2.939e-07, loss_BC: 0.000e+00, loss_IC: 2.678e-08,loss_f: 7.528e-08
pinn: 0300, Iter: 700, total_loss: 1.982e-07, loss_BC: 0.000e+00, loss_IC: 2.645e-08,loss_f: 6.026e-08
pinn: 0000, Iter: 700, total_loss: 3.525e-07, loss_BC: 0.000e+00, loss_IC: 5.909e-08,loss_f: 7.500e-08
pinn: 0200, Iter: 800, total_loss: 2.648e-07, loss_BC: 0.000e+00, loss_IC: 2.958e-08,loss_f: 5.878e-08
pinn: 0000, Iter: 800, total_loss: 3.449e-07, loss_BC: 0.000e+00, loss_IC: 5.938e-08,loss_f: 6.792e-08
pinn: 0300, Iter: 800, total_loss: 1.956e-07, loss_BC: 0.000e+00, loss_IC: 2.590e-08,loss_f: 5.837e-08
pinn: 0100, Iter: 800, total_loss: 2.852e-07, loss_BC: 0.000e+00, loss_IC: 2.828e-08,loss_f: 6.749e-08
pinn: 0200, Iter: 900, total_loss: 2.619e-07, loss_BC: 0.000e+00, loss_IC: 2.926e-08,loss_f: 5.694e-08
pinn: 0000, Iter: 900, total_loss: 3.433e-07, loss_BC: 0.000e+00, loss_IC: 6.001e-08,loss_f: 6.642e-08
pinn: 0300, Iter: 900, total_loss: 1.940e-07, loss_BC: 0.000e+00, loss_IC: 2.527e-08,loss_f: 5.768e-08
pinn: 0100, Iter: 900, total_loss: 2.818e-07, loss_BC: 0.000e+00, loss_IC: 2.935e-08,loss_f: 6.541e-08
pinn: 0200, Iter: 1000, total_loss: 2.584e-07, loss_BC: 0.000e+00, loss_IC: 2.707e-08,loss_f: 5.557e-08
pinn: 0000, Iter: 1000, total_loss: 3.352e-07, loss_BC: 0.000e+00, loss_IC: 5.897e-08,loss_f: 6.225e-08
pinn: 0100, Iter: 1000, total_loss: 2.781e-07, loss_BC: 0.000e+00, loss_IC: 3.140e-08,loss_f: 6.390e-08
pinn: 0300, Iter: 1000, total_loss: 1.916e-07, loss_BC: 0.000e+00, loss_IC: 2.380e-08,loss_f: 5.681e-08
pinn: 0200, Iter: 1100, total_loss: 2.566e-07, loss_BC: 0.000e+00, loss_IC: 2.580e-08,loss_f: 5.529e-08
pinn: 0000, Iter: 1100, total_loss: 3.302e-07, loss_BC: 0.000e+00, loss_IC: 5.973e-08,loss_f: 5.900e-08
pinn: 0300, Iter: 1100, total_loss: 1.877e-07, loss_BC: 0.000e+00, loss_IC: 2.244e-08,loss_f: 5.494e-08
pinn: 0100, Iter: 1100, total_loss: 2.763e-07, loss_BC: 0.000e+00, loss_IC: 3.224e-08,loss_f: 6.300e-08
pinn: 0200, Iter: 1200, total_loss: 2.540e-07, loss_BC: 0.000e+00, loss_IC: 2.416e-08,loss_f: 5.402e-08
pinn: 0000, Iter: 1200, total_loss: 3.231e-07, loss_BC: 0.000e+00, loss_IC: 5.762e-08,loss_f: 5.635e-08
pinn: 0300, Iter: 1200, total_loss: 1.869e-07, loss_BC: 0.000e+00, loss_IC: 2.252e-08,loss_f: 5.418e-08
pinn: 0100, Iter: 1200, total_loss: 2.731e-07, loss_BC: 0.000e+00, loss_IC: 3.261e-08,loss_f: 6.130e-08
pinn: 0300, Iter: 1300, total_loss: 1.852e-07, loss_BC: 0.000e+00, loss_IC: 2.168e-08,loss_f: 5.333e-08
pinn: 0000, Iter: 1300, total_loss: 3.159e-07, loss_BC: 0.000e+00, loss_IC: 5.312e-08,loss_f: 5.750e-08
pinn: 0200, Iter: 1300, total_loss: 2.508e-07, loss_BC: 0.000e+00, loss_IC: 2.215e-08,loss_f: 5.368e-08
pinn: 0100, Iter: 1300, total_loss: 2.712e-07, loss_BC: 0.000e+00, loss_IC: 3.386e-08,loss_f: 6.032e-08
pinn: 0000, Iter: 1400, total_loss: 3.135e-07, loss_BC: 0.000e+00, loss_IC: 5.157e-08,loss_f: 5.760e-08
pinn: 0200, Iter: 1400, total_loss: 2.491e-07, loss_BC: 0.000e+00, loss_IC: 2.160e-08,loss_f: 5.408e-08
pinn: 0300, Iter: 1400, total_loss: 1.846e-07, loss_BC: 0.000e+00, loss_IC: 2.124e-08,loss_f: 5.296e-08
pinn: 0100, Iter: 1400, total_loss: 2.713e-07, loss_BC: 0.000e+00, loss_IC: 3.409e-08,loss_f: 6.134e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3755, Mean_loss of pinns: 2.534e-07, loss_BC: 0.000e+00, loss_IC: 3.200e-08, loss_f: 5.622e-08
 => minimum loss: 1.843e-07, corresponding pinn index: 0300
 => maximum loss: 3.115e-07, corresponding pinn  index: 0000

==> Epoch: 3760, Mean_loss of pinns: 4.510e-05, loss_BC: 4.480e-05, loss_IC: 4.764e-08, loss_f: 8.947e-08
 => minimum loss: 3.039e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.165e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0300

==> Epoch: 3770, Mean_loss of pinns: 4.203e-05, loss_BC: 4.130e-05, loss_IC: 4.125e-07, loss_f: 1.580e-07
 => minimum loss: 2.750e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.600e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.358e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3774, total_loss: 4.088e-05, loss_BC: 3.984e-05, loss_IC: 7.106e-07, loss_f: 1.726e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.35000, t_max: 0.36000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3775 0 1

 -------------------------------------------------------------
  -----  Epoch: 3775 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.35000, t_max: 0.36000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3775 !!! 


==> Epoch: 3780, Mean_loss of pinns: 1.025e-03, loss_BC: 4.224e-05, loss_IC: 4.710e-07, loss_f: 9.819e-04
 => minimum loss: 4.992e-04, corresponding pinn/batch index: 0100
 => maximum loss: 2.111e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3790, Mean_loss of pinns: 8.051e-04, loss_BC: 4.035e-05, loss_IC: 3.806e-06, loss_f: 7.607e-04
 => minimum loss: 3.886e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.656e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3800, Mean_loss of pinns: 6.385e-04, loss_BC: 3.818e-05, loss_IC: 8.787e-06, loss_f: 5.913e-04
 => minimum loss: 3.136e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.290e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3810, Mean_loss of pinns: 5.259e-04, loss_BC: 3.575e-05, loss_IC: 1.301e-05, loss_f: 4.769e-04
 => minimum loss: 2.566e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.062e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3820, Mean_loss of pinns: 4.435e-04, loss_BC: 3.547e-05, loss_IC: 1.496e-05, loss_f: 3.928e-04
 => minimum loss: 2.137e-04, corresponding pinn/batch index: 0100
 => maximum loss: 8.921e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3830, Mean_loss of pinns: 3.804e-04, loss_BC: 3.403e-05, loss_IC: 1.480e-05, loss_f: 3.312e-04
 => minimum loss: 1.808e-04, corresponding pinn/batch index: 0100
 => maximum loss: 7.684e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3840, Mean_loss of pinns: 3.319e-04, loss_BC: 3.366e-05, loss_IC: 1.368e-05, loss_f: 2.843e-04
 => minimum loss: 1.571e-04, corresponding pinn/batch index: 0100
 => maximum loss: 6.706e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3850, Mean_loss of pinns: 2.926e-04, loss_BC: 3.285e-05, loss_IC: 1.224e-05, loss_f: 2.472e-04
 => minimum loss: 1.378e-04, corresponding pinn/batch index: 0100
 => maximum loss: 5.896e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3860, Mean_loss of pinns: 2.606e-04, loss_BC: 3.214e-05, loss_IC: 1.071e-05, loss_f: 2.175e-04
 => minimum loss: 1.225e-04, corresponding pinn/batch index: 0100
 => maximum loss: 5.245e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3870, Mean_loss of pinns: 2.343e-04, loss_BC: 3.135e-05, loss_IC: 9.367e-06, loss_f: 1.932e-04
 => minimum loss: 1.110e-04, corresponding pinn/batch index: 0100
 => maximum loss: 4.699e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3874

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 7.364e-07, loss_BC: 0.000e+00, loss_IC: 9.815e-08,loss_f: 1.820e-07
pinn: 0100, Iter: 100, total_loss: 4.910e-07, loss_BC: 0.000e+00, loss_IC: 8.060e-08,loss_f: 2.815e-07
pinn: 0000, Iter: 100, total_loss: 5.494e-07, loss_BC: 0.000e+00, loss_IC: 4.396e-08,loss_f: 2.631e-07
pinn: 0200, Iter: 100, total_loss: 5.474e-07, loss_BC: 0.000e+00, loss_IC: 4.422e-08,loss_f: 1.861e-07
pinn: 0300, Iter: 200, total_loss: 5.890e-07, loss_BC: 0.000e+00, loss_IC: 6.622e-08,loss_f: 7.954e-08
pinn: 0000, Iter: 200, total_loss: 3.958e-07, loss_BC: 0.000e+00, loss_IC: 3.344e-08,loss_f: 1.270e-07
pinn: 0100, Iter: 200, total_loss: 2.782e-07, loss_BC: 0.000e+00, loss_IC: 5.888e-08,loss_f: 9.254e-08
pinn: 0200, Iter: 200, total_loss: 4.614e-07, loss_BC: 0.000e+00, loss_IC: 4.113e-08,loss_f: 1.058e-07
pinn: 0300, Iter: 300, total_loss: 5.678e-07, loss_BC: 0.000e+00, loss_IC: 5.526e-08,loss_f: 6.494e-08
pinn: 0000, Iter: 300, total_loss: 3.607e-07, loss_BC: 0.000e+00, loss_IC: 3.372e-08,loss_f: 9.336e-08
pinn: 0100, Iter: 300, total_loss: 2.589e-07, loss_BC: 0.000e+00, loss_IC: 5.342e-08,loss_f: 7.667e-08
pinn: 0200, Iter: 300, total_loss: 4.354e-07, loss_BC: 0.000e+00, loss_IC: 3.683e-08,loss_f: 9.289e-08
pinn: 0300, Iter: 400, total_loss: 5.581e-07, loss_BC: 0.000e+00, loss_IC: 5.204e-08,loss_f: 6.335e-08
pinn: 0200, Iter: 400, total_loss: 4.128e-07, loss_BC: 0.000e+00, loss_IC: 3.689e-08,loss_f: 8.858e-08
pinn: 0100, Iter: 400, total_loss: 2.474e-07, loss_BC: 0.000e+00, loss_IC: 4.797e-08,loss_f: 7.009e-08
pinn: 0000, Iter: 400, total_loss: 3.418e-07, loss_BC: 0.000e+00, loss_IC: 3.315e-08,loss_f: 7.511e-08
pinn: 0300, Iter: 500, total_loss: 5.414e-07, loss_BC: 0.000e+00, loss_IC: 5.090e-08,loss_f: 5.596e-08
pinn: 0000, Iter: 500, total_loss: 3.338e-07, loss_BC: 0.000e+00, loss_IC: 3.370e-08,loss_f: 6.715e-08
pinn: 0100, Iter: 500, total_loss: 2.431e-07, loss_BC: 0.000e+00, loss_IC: 4.521e-08,loss_f: 6.739e-08
pinn: 0200, Iter: 500, total_loss: 4.000e-07, loss_BC: 0.000e+00, loss_IC: 3.669e-08,loss_f: 8.123e-08
pinn: 0300, Iter: 600, total_loss: 5.249e-07, loss_BC: 0.000e+00, loss_IC: 4.657e-08,loss_f: 5.444e-08
pinn: 0100, Iter: 600, total_loss: 2.383e-07, loss_BC: 0.000e+00, loss_IC: 4.006e-08,loss_f: 6.570e-08
pinn: 0000, Iter: 600, total_loss: 3.252e-07, loss_BC: 0.000e+00, loss_IC: 3.373e-08,loss_f: 6.021e-08
pinn: 0200, Iter: 600, total_loss: 3.831e-07, loss_BC: 0.000e+00, loss_IC: 4.420e-08,loss_f: 7.156e-08
pinn: 0300, Iter: 700, total_loss: 5.110e-07, loss_BC: 0.000e+00, loss_IC: 4.539e-08,loss_f: 5.827e-08
pinn: 0100, Iter: 700, total_loss: 2.343e-07, loss_BC: 0.000e+00, loss_IC: 3.737e-08,loss_f: 6.360e-08
pinn: 0000, Iter: 700, total_loss: 3.199e-07, loss_BC: 0.000e+00, loss_IC: 3.277e-08,loss_f: 5.722e-08
pinn: 0200, Iter: 700, total_loss: 3.732e-07, loss_BC: 0.000e+00, loss_IC: 4.494e-08,loss_f: 6.833e-08
pinn: 0300, Iter: 800, total_loss: 4.988e-07, loss_BC: 0.000e+00, loss_IC: 4.932e-08,loss_f: 6.252e-08
pinn: 0100, Iter: 800, total_loss: 2.311e-07, loss_BC: 0.000e+00, loss_IC: 3.452e-08,loss_f: 6.332e-08
pinn: 0000, Iter: 800, total_loss: 3.178e-07, loss_BC: 0.000e+00, loss_IC: 3.263e-08,loss_f: 5.599e-08
pinn: 0200, Iter: 800, total_loss: 3.683e-07, loss_BC: 0.000e+00, loss_IC: 4.670e-08,loss_f: 6.600e-08
pinn: 0300, Iter: 900, total_loss: 4.818e-07, loss_BC: 0.000e+00, loss_IC: 6.150e-08,loss_f: 6.594e-08
pinn: 0100, Iter: 900, total_loss: 2.272e-07, loss_BC: 0.000e+00, loss_IC: 3.092e-08,loss_f: 6.370e-08
pinn: 0000, Iter: 900, total_loss: 3.147e-07, loss_BC: 0.000e+00, loss_IC: 3.276e-08,loss_f: 5.540e-08
pinn: 0200, Iter: 900, total_loss: 3.633e-07, loss_BC: 0.000e+00, loss_IC: 4.539e-08,loss_f: 6.431e-08
pinn: 0300, Iter: 1000, total_loss: 4.733e-07, loss_BC: 0.000e+00, loss_IC: 6.433e-08,loss_f: 6.834e-08
pinn: 0000, Iter: 1000, total_loss: 3.109e-07, loss_BC: 0.000e+00, loss_IC: 3.520e-08,loss_f: 5.421e-08
pinn: 0100, Iter: 1000, total_loss: 2.246e-07, loss_BC: 0.000e+00, loss_IC: 2.858e-08,loss_f: 6.390e-08
pinn: 0200, Iter: 1000, total_loss: 3.599e-07, loss_BC: 0.000e+00, loss_IC: 4.678e-08,loss_f: 6.336e-08
pinn: 0300, Iter: 1100, total_loss: 4.644e-07, loss_BC: 0.000e+00, loss_IC: 7.221e-08,loss_f: 7.160e-08
pinn: 0100, Iter: 1100, total_loss: 2.226e-07, loss_BC: 0.000e+00, loss_IC: 2.745e-08,loss_f: 6.351e-08
pinn: 0000, Iter: 1100, total_loss: 3.041e-07, loss_BC: 0.000e+00, loss_IC: 3.817e-08,loss_f: 5.370e-08
pinn: 0200, Iter: 1100, total_loss: 3.584e-07, loss_BC: 0.000e+00, loss_IC: 4.873e-08,loss_f: 6.286e-08
pinn: 0300, Iter: 1200, total_loss: 4.492e-07, loss_BC: 0.000e+00, loss_IC: 7.384e-08,loss_f: 7.259e-08
pinn: 0000, Iter: 1200, total_loss: 3.020e-07, loss_BC: 0.000e+00, loss_IC: 3.879e-08,loss_f: 5.400e-08
pinn: 0100, Iter: 1200, total_loss: 2.211e-07, loss_BC: 0.000e+00, loss_IC: 2.646e-08,loss_f: 6.336e-08
pinn: 0200, Iter: 1200, total_loss: 3.556e-07, loss_BC: 0.000e+00, loss_IC: 5.004e-08,loss_f: 6.175e-08
pinn: 0300, Iter: 1300, total_loss: 4.310e-07, loss_BC: 0.000e+00, loss_IC: 6.592e-08,loss_f: 8.232e-08
pinn: 0100, Iter: 1300, total_loss: 2.197e-07, loss_BC: 0.000e+00, loss_IC: 2.460e-08,loss_f: 6.381e-08
pinn: 0000, Iter: 1300, total_loss: 2.973e-07, loss_BC: 0.000e+00, loss_IC: 4.005e-08,loss_f: 5.347e-08
pinn: 0200, Iter: 1300, total_loss: 3.509e-07, loss_BC: 0.000e+00, loss_IC: 5.408e-08,loss_f: 6.108e-08
pinn: 0300, Iter: 1400, total_loss: 4.208e-07, loss_BC: 0.000e+00, loss_IC: 6.795e-08,loss_f: 8.720e-08
pinn: 0100, Iter: 1400, total_loss: 2.174e-07, loss_BC: 0.000e+00, loss_IC: 2.176e-08,loss_f: 6.366e-08
pinn: 0000, Iter: 1400, total_loss: 2.948e-07, loss_BC: 0.000e+00, loss_IC: 4.051e-08,loss_f: 5.247e-08
pinn: 0200, Iter: 1400, total_loss: 3.423e-07, loss_BC: 0.000e+00, loss_IC: 5.329e-08,loss_f: 6.361e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3874, Mean_loss of pinns: 3.181e-07, loss_BC: 0.000e+00, loss_IC: 4.575e-08, loss_f: 6.596e-08
 => minimum loss: 2.168e-07, corresponding pinn index: 0100
 => maximum loss: 4.198e-07, corresponding pinn  index: 0300

 max_loss: 6.357e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3876, total_loss: 4.048e-05, loss_BC: 4.016e-05, loss_IC: 4.655e-08, loss_f: 6.787e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.36000, t_max: 0.37000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3877 0 1

 -------------------------------------------------------------
  -----  Epoch: 3877 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.36000, t_max: 0.37000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3877 !!! 


==> Epoch: 3880, Mean_loss of pinns: 1.952e-03, loss_BC: 4.290e-05, loss_IC: 2.083e-07, loss_f: 1.909e-03
 => minimum loss: 2.611e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.637e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3890, Mean_loss of pinns: 1.530e-03, loss_BC: 4.141e-05, loss_IC: 3.578e-06, loss_f: 1.484e-03
 => minimum loss: 2.151e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.094e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3900, Mean_loss of pinns: 1.219e-03, loss_BC: 3.975e-05, loss_IC: 9.514e-06, loss_f: 1.169e-03
 => minimum loss: 1.822e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.694e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3910, Mean_loss of pinns: 9.972e-04, loss_BC: 3.719e-05, loss_IC: 1.589e-05, loss_f: 9.438e-04
 => minimum loss: 1.579e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.390e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3920, Mean_loss of pinns: 8.345e-04, loss_BC: 3.645e-05, loss_IC: 2.132e-05, loss_f: 7.764e-04
 => minimum loss: 1.405e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.159e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3930, Mean_loss of pinns: 7.115e-04, loss_BC: 3.458e-05, loss_IC: 2.478e-05, loss_f: 6.518e-04
 => minimum loss: 1.253e-04, corresponding pinn/batch index: 0000
 => maximum loss: 9.843e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3940, Mean_loss of pinns: 6.161e-04, loss_BC: 3.345e-05, loss_IC: 2.586e-05, loss_f: 5.564e-04
 => minimum loss: 1.119e-04, corresponding pinn/batch index: 0000
 => maximum loss: 8.502e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3950, Mean_loss of pinns: 5.390e-04, loss_BC: 3.171e-05, loss_IC: 2.494e-05, loss_f: 4.820e-04
 => minimum loss: 1.007e-04, corresponding pinn/batch index: 0000
 => maximum loss: 7.415e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3960, Mean_loss of pinns: 4.769e-04, loss_BC: 3.093e-05, loss_IC: 2.273e-05, loss_f: 4.229e-04
 => minimum loss: 9.161e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.532e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3970, Mean_loss of pinns: 4.246e-04, loss_BC: 2.933e-05, loss_IC: 1.997e-05, loss_f: 3.750e-04
 => minimum loss: 8.319e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.815e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  3976

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 7.291e-07, loss_BC: 0.000e+00, loss_IC: 7.280e-08,loss_f: 3.147e-07
pinn: 0000, Iter: 100, total_loss: 8.448e-07, loss_BC: 0.000e+00, loss_IC: 5.510e-08,loss_f: 2.351e-07
pinn: 0200, Iter: 100, total_loss: 3.276e-07, loss_BC: 0.000e+00, loss_IC: 6.352e-08,loss_f: 1.912e-07
pinn: 0100, Iter: 100, total_loss: 7.184e-07, loss_BC: 0.000e+00, loss_IC: 8.627e-08,loss_f: 2.647e-07
pinn: 0300, Iter: 200, total_loss: 4.969e-07, loss_BC: 0.000e+00, loss_IC: 4.884e-08,loss_f: 1.193e-07
pinn: 0000, Iter: 200, total_loss: 7.031e-07, loss_BC: 0.000e+00, loss_IC: 4.517e-08,loss_f: 1.011e-07
pinn: 0200, Iter: 200, total_loss: 2.453e-07, loss_BC: 0.000e+00, loss_IC: 6.110e-08,loss_f: 1.116e-07
pinn: 0100, Iter: 200, total_loss: 5.485e-07, loss_BC: 0.000e+00, loss_IC: 4.784e-08,loss_f: 1.324e-07
pinn: 0300, Iter: 300, total_loss: 4.706e-07, loss_BC: 0.000e+00, loss_IC: 4.680e-08,loss_f: 9.548e-08
pinn: 0000, Iter: 300, total_loss: 6.770e-07, loss_BC: 0.000e+00, loss_IC: 4.616e-08,loss_f: 8.224e-08
pinn: 0200, Iter: 300, total_loss: 2.096e-07, loss_BC: 0.000e+00, loss_IC: 4.940e-08,loss_f: 8.764e-08
pinn: 0100, Iter: 300, total_loss: 5.155e-07, loss_BC: 0.000e+00, loss_IC: 4.077e-08,loss_f: 1.084e-07
pinn: 0300, Iter: 400, total_loss: 4.575e-07, loss_BC: 0.000e+00, loss_IC: 4.495e-08,loss_f: 8.731e-08
pinn: 0000, Iter: 400, total_loss: 6.594e-07, loss_BC: 0.000e+00, loss_IC: 5.506e-08,loss_f: 7.058e-08
pinn: 0100, Iter: 400, total_loss: 5.004e-07, loss_BC: 0.000e+00, loss_IC: 4.330e-08,loss_f: 1.018e-07
pinn: 0200, Iter: 400, total_loss: 1.864e-07, loss_BC: 0.000e+00, loss_IC: 4.060e-08,loss_f: 7.337e-08
pinn: 0300, Iter: 500, total_loss: 4.467e-07, loss_BC: 0.000e+00, loss_IC: 4.267e-08,loss_f: 8.008e-08
pinn: 0000, Iter: 500, total_loss: 6.439e-07, loss_BC: 0.000e+00, loss_IC: 5.976e-08,loss_f: 6.786e-08
pinn: 0200, Iter: 500, total_loss: 1.749e-07, loss_BC: 0.000e+00, loss_IC: 3.712e-08,loss_f: 6.569e-08
pinn: 0100, Iter: 500, total_loss: 4.844e-07, loss_BC: 0.000e+00, loss_IC: 4.510e-08,loss_f: 9.466e-08
pinn: 0300, Iter: 600, total_loss: 4.405e-07, loss_BC: 0.000e+00, loss_IC: 4.209e-08,loss_f: 7.608e-08
pinn: 0000, Iter: 600, total_loss: 6.319e-07, loss_BC: 0.000e+00, loss_IC: 6.454e-08,loss_f: 7.157e-08
pinn: 0200, Iter: 600, total_loss: 1.681e-07, loss_BC: 0.000e+00, loss_IC: 3.604e-08,loss_f: 5.980e-08
pinn: 0100, Iter: 600, total_loss: 4.743e-07, loss_BC: 0.000e+00, loss_IC: 4.456e-08,loss_f: 8.961e-08
pinn: 0300, Iter: 700, total_loss: 4.363e-07, loss_BC: 0.000e+00, loss_IC: 4.008e-08,loss_f: 7.494e-08
pinn: 0000, Iter: 700, total_loss: 6.148e-07, loss_BC: 0.000e+00, loss_IC: 6.690e-08,loss_f: 7.213e-08
pinn: 0200, Iter: 700, total_loss: 1.647e-07, loss_BC: 0.000e+00, loss_IC: 3.510e-08,loss_f: 5.724e-08
pinn: 0100, Iter: 700, total_loss: 4.612e-07, loss_BC: 0.000e+00, loss_IC: 4.444e-08,loss_f: 8.048e-08
pinn: 0300, Iter: 800, total_loss: 4.304e-07, loss_BC: 0.000e+00, loss_IC: 4.260e-08,loss_f: 7.219e-08
pinn: 0000, Iter: 800, total_loss: 5.956e-07, loss_BC: 0.000e+00, loss_IC: 6.180e-08,loss_f: 7.727e-08
pinn: 0200, Iter: 800, total_loss: 1.617e-07, loss_BC: 0.000e+00, loss_IC: 3.436e-08,loss_f: 5.492e-08
pinn: 0100, Iter: 800, total_loss: 4.550e-07, loss_BC: 0.000e+00, loss_IC: 4.467e-08,loss_f: 7.963e-08
pinn: 0300, Iter: 900, total_loss: 4.219e-07, loss_BC: 0.000e+00, loss_IC: 4.627e-08,loss_f: 6.957e-08
pinn: 0000, Iter: 900, total_loss: 5.742e-07, loss_BC: 0.000e+00, loss_IC: 6.245e-08,loss_f: 8.314e-08
pinn: 0200, Iter: 900, total_loss: 1.603e-07, loss_BC: 0.000e+00, loss_IC: 3.301e-08,loss_f: 5.460e-08
pinn: 0100, Iter: 900, total_loss: 4.511e-07, loss_BC: 0.000e+00, loss_IC: 4.673e-08,loss_f: 7.848e-08
pinn: 0300, Iter: 1000, total_loss: 4.156e-07, loss_BC: 0.000e+00, loss_IC: 4.868e-08,loss_f: 6.701e-08
pinn: 0000, Iter: 1000, total_loss: 5.537e-07, loss_BC: 0.000e+00, loss_IC: 5.279e-08,loss_f: 9.487e-08
pinn: 0200, Iter: 1000, total_loss: 1.599e-07, loss_BC: 0.000e+00, loss_IC: 3.282e-08,loss_f: 5.440e-08
pinn: 0100, Iter: 1000, total_loss: 4.487e-07, loss_BC: 0.000e+00, loss_IC: 5.039e-08,loss_f: 7.918e-08
pinn: 0300, Iter: 1100, total_loss: 4.113e-07, loss_BC: 0.000e+00, loss_IC: 5.252e-08,loss_f: 6.644e-08
pinn: 0000, Iter: 1100, total_loss: 5.397e-07, loss_BC: 0.000e+00, loss_IC: 5.401e-08,loss_f: 1.018e-07
pinn: 0100, Iter: 1100, total_loss: 4.353e-07, loss_BC: 0.000e+00, loss_IC: 5.620e-08,loss_f: 8.225e-08
pinn: 0200, Iter: 1100, total_loss: 1.577e-07, loss_BC: 0.000e+00, loss_IC: 3.025e-08,loss_f: 5.405e-08
pinn: 0300, Iter: 1200, total_loss: 4.018e-07, loss_BC: 0.000e+00, loss_IC: 5.269e-08,loss_f: 6.690e-08
pinn: 0000, Iter: 1200, total_loss: 5.321e-07, loss_BC: 0.000e+00, loss_IC: 5.971e-08,loss_f: 1.063e-07
pinn: 0100, Iter: 1200, total_loss: 4.327e-07, loss_BC: 0.000e+00, loss_IC: 5.981e-08,loss_f: 8.095e-08
pinn: 0200, Iter: 1200, total_loss: 1.556e-07, loss_BC: 0.000e+00, loss_IC: 2.797e-08,loss_f: 5.366e-08
pinn: 0300, Iter: 1300, total_loss: 3.926e-07, loss_BC: 0.000e+00, loss_IC: 4.812e-08,loss_f: 6.933e-08
pinn: 0000, Iter: 1300, total_loss: 5.232e-07, loss_BC: 0.000e+00, loss_IC: 6.279e-08,loss_f: 1.089e-07
pinn: 0100, Iter: 1300, total_loss: 4.262e-07, loss_BC: 0.000e+00, loss_IC: 6.102e-08,loss_f: 8.209e-08
pinn: 0200, Iter: 1300, total_loss: 1.541e-07, loss_BC: 0.000e+00, loss_IC: 2.664e-08,loss_f: 5.323e-08
pinn: 0300, Iter: 1400, total_loss: 3.850e-07, loss_BC: 0.000e+00, loss_IC: 4.858e-08,loss_f: 7.415e-08
pinn: 0000, Iter: 1400, total_loss: 5.144e-07, loss_BC: 0.000e+00, loss_IC: 6.814e-08,loss_f: 1.059e-07
pinn: 0100, Iter: 1400, total_loss: 4.241e-07, loss_BC: 0.000e+00, loss_IC: 5.952e-08,loss_f: 8.211e-08
pinn: 0200, Iter: 1400, total_loss: 1.535e-07, loss_BC: 0.000e+00, loss_IC: 2.560e-08,loss_f: 5.359e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 3976, Mean_loss of pinns: 3.667e-07, loss_BC: 0.000e+00, loss_IC: 5.119e-08, loss_f: 7.957e-08
 => minimum loss: 1.535e-07, corresponding pinn index: 0200
 => maximum loss: 5.076e-07, corresponding pinn  index: 0000

 max_loss: 6.640e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 3978, total_loss: 4.200e-05, loss_BC: 4.163e-05, loss_IC: 5.251e-08, loss_f: 8.154e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.37000, t_max: 0.38000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  3979 0 1

 -------------------------------------------------------------
  -----  Epoch: 3979 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.37000, t_max: 0.38000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  3979 !!! 


==> Epoch: 3980, Mean_loss of pinns: 2.145e-03, loss_BC: 4.589e-05, loss_IC: 1.979e-08, loss_f: 2.099e-03
 => minimum loss: 1.086e-03, corresponding pinn/batch index: 0200
 => maximum loss: 3.371e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 3990, Mean_loss of pinns: 1.701e-03, loss_BC: 4.582e-05, loss_IC: 2.113e-06, loss_f: 1.653e-03
 => minimum loss: 8.486e-04, corresponding pinn/batch index: 0200
 => maximum loss: 2.791e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4000, Mean_loss of pinns: 1.375e-03, loss_BC: 4.392e-05, loss_IC: 6.647e-06, loss_f: 1.325e-03
 => minimum loss: 6.732e-04, corresponding pinn/batch index: 0200
 => maximum loss: 2.319e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4010, Mean_loss of pinns: 1.133e-03, loss_BC: 4.278e-05, loss_IC: 1.210e-05, loss_f: 1.078e-03
 => minimum loss: 5.511e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.934e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4020, Mean_loss of pinns: 9.477e-04, loss_BC: 4.102e-05, loss_IC: 1.662e-05, loss_f: 8.899e-04
 => minimum loss: 4.613e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.626e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4030, Mean_loss of pinns: 8.047e-04, loss_BC: 3.932e-05, loss_IC: 1.883e-05, loss_f: 7.464e-04
 => minimum loss: 3.950e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.381e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4040, Mean_loss of pinns: 6.935e-04, loss_BC: 3.866e-05, loss_IC: 1.893e-05, loss_f: 6.358e-04
 => minimum loss: 3.431e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.187e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4050, Mean_loss of pinns: 6.044e-04, loss_BC: 3.756e-05, loss_IC: 1.757e-05, loss_f: 5.491e-04
 => minimum loss: 3.032e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.032e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4060, Mean_loss of pinns: 5.326e-04, loss_BC: 3.681e-05, loss_IC: 1.552e-05, loss_f: 4.801e-04
 => minimum loss: 2.699e-04, corresponding pinn/batch index: 0200
 => maximum loss: 9.073e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4070, Mean_loss of pinns: 4.732e-04, loss_BC: 3.547e-05, loss_IC: 1.350e-05, loss_f: 4.240e-04
 => minimum loss: 2.416e-04, corresponding pinn/batch index: 0200
 => maximum loss: 8.048e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  4078

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 5.755e-07, loss_BC: 0.000e+00, loss_IC: 6.091e-08,loss_f: 1.977e-07
pinn: 0300, Iter: 100, total_loss: 6.326e-07, loss_BC: 0.000e+00, loss_IC: 6.258e-08,loss_f: 2.872e-07
pinn: 0000, Iter: 100, total_loss: 3.711e-07, loss_BC: 0.000e+00, loss_IC: 5.841e-08,loss_f: 2.463e-07
pinn: 0200, Iter: 100, total_loss: 5.405e-07, loss_BC: 0.000e+00, loss_IC: 8.506e-08,loss_f: 1.969e-07
pinn: 0100, Iter: 200, total_loss: 5.052e-07, loss_BC: 0.000e+00, loss_IC: 4.946e-08,loss_f: 1.275e-07
pinn: 0000, Iter: 200, total_loss: 2.758e-07, loss_BC: 0.000e+00, loss_IC: 5.268e-08,loss_f: 1.565e-07
pinn: 0300, Iter: 200, total_loss: 4.890e-07, loss_BC: 0.000e+00, loss_IC: 3.554e-08,loss_f: 1.470e-07
pinn: 0200, Iter: 200, total_loss: 4.134e-07, loss_BC: 0.000e+00, loss_IC: 6.894e-08,loss_f: 9.089e-08
pinn: 0100, Iter: 300, total_loss: 4.770e-07, loss_BC: 0.000e+00, loss_IC: 4.638e-08,loss_f: 1.129e-07
pinn: 0300, Iter: 300, total_loss: 4.240e-07, loss_BC: 0.000e+00, loss_IC: 2.665e-08,loss_f: 1.235e-07
pinn: 0000, Iter: 300, total_loss: 2.514e-07, loss_BC: 0.000e+00, loss_IC: 5.190e-08,loss_f: 1.332e-07
pinn: 0200, Iter: 300, total_loss: 3.867e-07, loss_BC: 0.000e+00, loss_IC: 6.564e-08,loss_f: 7.194e-08
pinn: 0100, Iter: 400, total_loss: 4.643e-07, loss_BC: 0.000e+00, loss_IC: 4.802e-08,loss_f: 1.138e-07
pinn: 0300, Iter: 400, total_loss: 3.844e-07, loss_BC: 0.000e+00, loss_IC: 2.674e-08,loss_f: 1.215e-07
pinn: 0000, Iter: 400, total_loss: 2.247e-07, loss_BC: 0.000e+00, loss_IC: 5.779e-08,loss_f: 1.014e-07
pinn: 0200, Iter: 400, total_loss: 3.737e-07, loss_BC: 0.000e+00, loss_IC: 6.419e-08,loss_f: 6.642e-08
pinn: 0100, Iter: 500, total_loss: 4.514e-07, loss_BC: 0.000e+00, loss_IC: 5.264e-08,loss_f: 1.077e-07
pinn: 0300, Iter: 500, total_loss: 3.603e-07, loss_BC: 0.000e+00, loss_IC: 2.847e-08,loss_f: 1.061e-07
pinn: 0000, Iter: 500, total_loss: 2.097e-07, loss_BC: 0.000e+00, loss_IC: 5.835e-08,loss_f: 8.574e-08
pinn: 0200, Iter: 500, total_loss: 3.666e-07, loss_BC: 0.000e+00, loss_IC: 6.532e-08,loss_f: 6.302e-08
pinn: 0100, Iter: 600, total_loss: 4.367e-07, loss_BC: 0.000e+00, loss_IC: 5.671e-08,loss_f: 1.084e-07
pinn: 0300, Iter: 600, total_loss: 3.309e-07, loss_BC: 0.000e+00, loss_IC: 2.061e-08,loss_f: 9.778e-08
pinn: 0000, Iter: 600, total_loss: 1.953e-07, loss_BC: 0.000e+00, loss_IC: 5.811e-08,loss_f: 7.097e-08
pinn: 0200, Iter: 600, total_loss: 3.572e-07, loss_BC: 0.000e+00, loss_IC: 6.602e-08,loss_f: 5.972e-08
pinn: 0100, Iter: 700, total_loss: 4.253e-07, loss_BC: 0.000e+00, loss_IC: 5.768e-08,loss_f: 1.044e-07
pinn: 0300, Iter: 700, total_loss: 3.110e-07, loss_BC: 0.000e+00, loss_IC: 2.180e-08,loss_f: 8.936e-08
pinn: 0000, Iter: 700, total_loss: 1.871e-07, loss_BC: 0.000e+00, loss_IC: 5.329e-08,loss_f: 6.636e-08
pinn: 0200, Iter: 700, total_loss: 3.525e-07, loss_BC: 0.000e+00, loss_IC: 6.473e-08,loss_f: 5.986e-08
pinn: 0100, Iter: 800, total_loss: 4.004e-07, loss_BC: 0.000e+00, loss_IC: 5.702e-08,loss_f: 9.845e-08
pinn: 0000, Iter: 800, total_loss: 1.822e-07, loss_BC: 0.000e+00, loss_IC: 5.129e-08,loss_f: 6.251e-08
pinn: 0300, Iter: 800, total_loss: 2.982e-07, loss_BC: 0.000e+00, loss_IC: 2.233e-08,loss_f: 8.550e-08
pinn: 0200, Iter: 800, total_loss: 3.467e-07, loss_BC: 0.000e+00, loss_IC: 6.415e-08,loss_f: 5.889e-08
pinn: 0100, Iter: 900, total_loss: 3.903e-07, loss_BC: 0.000e+00, loss_IC: 4.980e-08,loss_f: 9.693e-08
pinn: 0000, Iter: 900, total_loss: 1.781e-07, loss_BC: 0.000e+00, loss_IC: 5.006e-08,loss_f: 5.876e-08
pinn: 0300, Iter: 900, total_loss: 2.905e-07, loss_BC: 0.000e+00, loss_IC: 2.136e-08,loss_f: 8.449e-08
pinn: 0200, Iter: 900, total_loss: 3.431e-07, loss_BC: 0.000e+00, loss_IC: 6.137e-08,loss_f: 6.019e-08
pinn: 0100, Iter: 1000, total_loss: 3.817e-07, loss_BC: 0.000e+00, loss_IC: 4.561e-08,loss_f: 9.848e-08
pinn: 0000, Iter: 1000, total_loss: 1.760e-07, loss_BC: 0.000e+00, loss_IC: 4.804e-08,loss_f: 5.834e-08
pinn: 0300, Iter: 1000, total_loss: 2.828e-07, loss_BC: 0.000e+00, loss_IC: 2.335e-08,loss_f: 7.993e-08
pinn: 0200, Iter: 1000, total_loss: 3.377e-07, loss_BC: 0.000e+00, loss_IC: 5.781e-08,loss_f: 6.194e-08
pinn: 0300, Iter: 1100, total_loss: 2.772e-07, loss_BC: 0.000e+00, loss_IC: 2.411e-08,loss_f: 7.394e-08
pinn: 0100, Iter: 1100, total_loss: 3.734e-07, loss_BC: 0.000e+00, loss_IC: 4.253e-08,loss_f: 9.486e-08
pinn: 0000, Iter: 1100, total_loss: 1.731e-07, loss_BC: 0.000e+00, loss_IC: 4.511e-08,loss_f: 5.795e-08
pinn: 0200, Iter: 1100, total_loss: 3.351e-07, loss_BC: 0.000e+00, loss_IC: 5.417e-08,loss_f: 6.213e-08
pinn: 0100, Iter: 1200, total_loss: 3.645e-07, loss_BC: 0.000e+00, loss_IC: 4.005e-08,loss_f: 9.516e-08
pinn: 0300, Iter: 1200, total_loss: 2.724e-07, loss_BC: 0.000e+00, loss_IC: 2.470e-08,loss_f: 7.287e-08
pinn: 0000, Iter: 1200, total_loss: 1.686e-07, loss_BC: 0.000e+00, loss_IC: 4.081e-08,loss_f: 5.714e-08
pinn: 0200, Iter: 1200, total_loss: 3.332e-07, loss_BC: 0.000e+00, loss_IC: 5.461e-08,loss_f: 6.324e-08
pinn: 0100, Iter: 1300, total_loss: 3.584e-07, loss_BC: 0.000e+00, loss_IC: 3.429e-08,loss_f: 9.818e-08
pinn: 0300, Iter: 1300, total_loss: 2.658e-07, loss_BC: 0.000e+00, loss_IC: 2.089e-08,loss_f: 7.199e-08
pinn: 0000, Iter: 1300, total_loss: 1.668e-07, loss_BC: 0.000e+00, loss_IC: 3.829e-08,loss_f: 5.704e-08
pinn: 0200, Iter: 1300, total_loss: 3.300e-07, loss_BC: 0.000e+00, loss_IC: 5.189e-08,loss_f: 6.445e-08
pinn: 0300, Iter: 1400, total_loss: 2.637e-07, loss_BC: 0.000e+00, loss_IC: 2.006e-08,loss_f: 7.098e-08
pinn: 0100, Iter: 1400, total_loss: 3.552e-07, loss_BC: 0.000e+00, loss_IC: 3.417e-08,loss_f: 9.499e-08
pinn: 0000, Iter: 1400, total_loss: 1.646e-07, loss_BC: 0.000e+00, loss_IC: 3.692e-08,loss_f: 5.608e-08
pinn: 0200, Iter: 1400, total_loss: 3.261e-07, loss_BC: 0.000e+00, loss_IC: 5.126e-08,loss_f: 6.324e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4078, Mean_loss of pinns: 2.762e-07, loss_BC: 0.000e+00, loss_IC: 3.488e-08, loss_f: 7.135e-08
 => minimum loss: 1.634e-07, corresponding pinn index: 0000
 => maximum loss: 3.534e-07, corresponding pinn  index: 0100

==> Epoch: 4080, Mean_loss of pinns: 4.942e-05, loss_BC: 4.914e-05, loss_IC: 3.576e-08, loss_f: 7.275e-08
 => minimum loss: 2.721e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.699e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0300

==> Epoch: 4090, Mean_loss of pinns: 4.422e-05, loss_BC: 4.359e-05, loss_IC: 3.098e-07, loss_f: 1.452e-07
 => minimum loss: 2.402e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.585e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.118e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4097, total_loss: 4.283e-05, loss_BC: 4.156e-05, loss_IC: 9.239e-07, loss_f: 1.812e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.38000, t_max: 0.39000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4098 0 1

 -------------------------------------------------------------
  -----  Epoch: 4098 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.38000, t_max: 0.39000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4098 !!! 


==> Epoch: 4100, Mean_loss of pinns: 1.312e-03, loss_BC: 4.346e-05, loss_IC: 1.335e-07, loss_f: 1.268e-03
 => minimum loss: 3.185e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.459e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4110, Mean_loss of pinns: 1.021e-03, loss_BC: 4.055e-05, loss_IC: 3.815e-06, loss_f: 9.767e-04
 => minimum loss: 2.637e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.921e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4120, Mean_loss of pinns: 8.119e-04, loss_BC: 3.845e-05, loss_IC: 9.434e-06, loss_f: 7.639e-04
 => minimum loss: 2.217e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.527e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4130, Mean_loss of pinns: 6.636e-04, loss_BC: 3.677e-05, loss_IC: 1.457e-05, loss_f: 6.121e-04
 => minimum loss: 1.876e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.255e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4140, Mean_loss of pinns: 5.558e-04, loss_BC: 3.637e-05, loss_IC: 1.798e-05, loss_f: 5.013e-04
 => minimum loss: 1.619e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.055e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4150, Mean_loss of pinns: 4.723e-04, loss_BC: 3.381e-05, loss_IC: 1.912e-05, loss_f: 4.193e-04
 => minimum loss: 1.401e-04, corresponding pinn/batch index: 0000
 => maximum loss: 9.008e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4160, Mean_loss of pinns: 4.078e-04, loss_BC: 3.192e-05, loss_IC: 1.837e-05, loss_f: 3.574e-04
 => minimum loss: 1.231e-04, corresponding pinn/batch index: 0000
 => maximum loss: 7.787e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4170, Mean_loss of pinns: 3.560e-04, loss_BC: 2.966e-05, loss_IC: 1.649e-05, loss_f: 3.097e-04
 => minimum loss: 1.094e-04, corresponding pinn/batch index: 0000
 => maximum loss: 6.806e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4180, Mean_loss of pinns: 3.143e-04, loss_BC: 2.792e-05, loss_IC: 1.430e-05, loss_f: 2.719e-04
 => minimum loss: 9.882e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.998e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4190, Mean_loss of pinns: 2.803e-04, loss_BC: 2.670e-05, loss_IC: 1.230e-05, loss_f: 2.412e-04
 => minimum loss: 8.996e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.335e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  4197

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 4.172e-07, loss_BC: 0.000e+00, loss_IC: 9.054e-08,loss_f: 2.677e-07
pinn: 0300, Iter: 100, total_loss: 3.449e-07, loss_BC: 0.000e+00, loss_IC: 6.047e-08,loss_f: 1.789e-07
pinn: 0000, Iter: 100, total_loss: 6.448e-07, loss_BC: 0.000e+00, loss_IC: 3.377e-08,loss_f: 2.268e-07
pinn: 0200, Iter: 100, total_loss: 2.925e-07, loss_BC: 0.000e+00, loss_IC: 6.955e-08,loss_f: 1.920e-07
pinn: 0100, Iter: 200, total_loss: 2.408e-07, loss_BC: 0.000e+00, loss_IC: 4.014e-08,loss_f: 1.426e-07
pinn: 0300, Iter: 200, total_loss: 2.318e-07, loss_BC: 0.000e+00, loss_IC: 3.795e-08,loss_f: 8.886e-08
pinn: 0000, Iter: 200, total_loss: 5.571e-07, loss_BC: 0.000e+00, loss_IC: 3.722e-08,loss_f: 1.154e-07
pinn: 0200, Iter: 200, total_loss: 1.842e-07, loss_BC: 0.000e+00, loss_IC: 5.039e-08,loss_f: 1.032e-07
pinn: 0300, Iter: 300, total_loss: 2.081e-07, loss_BC: 0.000e+00, loss_IC: 2.928e-08,loss_f: 7.284e-08
pinn: 0100, Iter: 300, total_loss: 2.041e-07, loss_BC: 0.000e+00, loss_IC: 3.229e-08,loss_f: 1.130e-07
pinn: 0000, Iter: 300, total_loss: 5.319e-07, loss_BC: 0.000e+00, loss_IC: 3.697e-08,loss_f: 1.071e-07
pinn: 0200, Iter: 300, total_loss: 1.624e-07, loss_BC: 0.000e+00, loss_IC: 4.741e-08,loss_f: 8.433e-08
pinn: 0100, Iter: 400, total_loss: 1.877e-07, loss_BC: 0.000e+00, loss_IC: 2.772e-08,loss_f: 1.008e-07
pinn: 0300, Iter: 400, total_loss: 1.954e-07, loss_BC: 0.000e+00, loss_IC: 2.806e-08,loss_f: 5.986e-08
pinn: 0000, Iter: 400, total_loss: 4.833e-07, loss_BC: 0.000e+00, loss_IC: 3.816e-08,loss_f: 1.041e-07
pinn: 0200, Iter: 400, total_loss: 1.512e-07, loss_BC: 0.000e+00, loss_IC: 4.261e-08,loss_f: 7.778e-08
pinn: 0300, Iter: 500, total_loss: 1.905e-07, loss_BC: 0.000e+00, loss_IC: 2.719e-08,loss_f: 5.519e-08
pinn: 0100, Iter: 500, total_loss: 1.766e-07, loss_BC: 0.000e+00, loss_IC: 2.699e-08,loss_f: 9.008e-08
pinn: 0000, Iter: 500, total_loss: 4.540e-07, loss_BC: 0.000e+00, loss_IC: 4.193e-08,loss_f: 9.872e-08
pinn: 0200, Iter: 500, total_loss: 1.450e-07, loss_BC: 0.000e+00, loss_IC: 3.948e-08,loss_f: 7.467e-08
pinn: 0300, Iter: 600, total_loss: 1.852e-07, loss_BC: 0.000e+00, loss_IC: 2.548e-08,loss_f: 5.162e-08
pinn: 0100, Iter: 600, total_loss: 1.653e-07, loss_BC: 0.000e+00, loss_IC: 2.683e-08,loss_f: 7.916e-08
pinn: 0000, Iter: 600, total_loss: 4.352e-07, loss_BC: 0.000e+00, loss_IC: 4.565e-08,loss_f: 8.941e-08
pinn: 0200, Iter: 600, total_loss: 1.429e-07, loss_BC: 0.000e+00, loss_IC: 3.826e-08,loss_f: 7.370e-08
pinn: 0300, Iter: 700, total_loss: 1.769e-07, loss_BC: 0.000e+00, loss_IC: 2.246e-08,loss_f: 4.693e-08
pinn: 0100, Iter: 700, total_loss: 1.611e-07, loss_BC: 0.000e+00, loss_IC: 2.682e-08,loss_f: 7.517e-08
pinn: 0000, Iter: 700, total_loss: 4.227e-07, loss_BC: 0.000e+00, loss_IC: 4.362e-08,loss_f: 8.315e-08
pinn: 0200, Iter: 700, total_loss: 1.405e-07, loss_BC: 0.000e+00, loss_IC: 3.723e-08,loss_f: 7.210e-08
pinn: 0300, Iter: 800, total_loss: 1.743e-07, loss_BC: 0.000e+00, loss_IC: 2.239e-08,loss_f: 4.532e-08
pinn: 0100, Iter: 800, total_loss: 1.559e-07, loss_BC: 0.000e+00, loss_IC: 2.652e-08,loss_f: 7.063e-08
pinn: 0000, Iter: 800, total_loss: 4.138e-07, loss_BC: 0.000e+00, loss_IC: 4.179e-08,loss_f: 7.817e-08
pinn: 0200, Iter: 800, total_loss: 1.351e-07, loss_BC: 0.000e+00, loss_IC: 3.401e-08,loss_f: 6.943e-08
pinn: 0300, Iter: 900, total_loss: 1.731e-07, loss_BC: 0.000e+00, loss_IC: 2.200e-08,loss_f: 4.472e-08
pinn: 0100, Iter: 900, total_loss: 1.516e-07, loss_BC: 0.000e+00, loss_IC: 2.528e-08,loss_f: 6.776e-08
pinn: 0000, Iter: 900, total_loss: 4.051e-07, loss_BC: 0.000e+00, loss_IC: 4.295e-08,loss_f: 7.597e-08
pinn: 0200, Iter: 900, total_loss: 1.333e-07, loss_BC: 0.000e+00, loss_IC: 3.281e-08,loss_f: 6.872e-08
pinn: 0300, Iter: 1000, total_loss: 1.715e-07, loss_BC: 0.000e+00, loss_IC: 2.178e-08,loss_f: 4.385e-08
pinn: 0100, Iter: 1000, total_loss: 1.484e-07, loss_BC: 0.000e+00, loss_IC: 2.470e-08,loss_f: 6.524e-08
pinn: 0000, Iter: 1000, total_loss: 4.012e-07, loss_BC: 0.000e+00, loss_IC: 4.267e-08,loss_f: 7.747e-08
pinn: 0200, Iter: 1000, total_loss: 1.309e-07, loss_BC: 0.000e+00, loss_IC: 3.138e-08,loss_f: 6.756e-08
pinn: 0300, Iter: 1100, total_loss: 1.702e-07, loss_BC: 0.000e+00, loss_IC: 2.186e-08,loss_f: 4.305e-08
pinn: 0100, Iter: 1100, total_loss: 1.473e-07, loss_BC: 0.000e+00, loss_IC: 2.424e-08,loss_f: 6.462e-08
pinn: 0000, Iter: 1100, total_loss: 3.978e-07, loss_BC: 0.000e+00, loss_IC: 4.367e-08,loss_f: 7.550e-08
pinn: 0200, Iter: 1100, total_loss: 1.295e-07, loss_BC: 0.000e+00, loss_IC: 2.985e-08,loss_f: 6.754e-08
pinn: 0300, Iter: 1200, total_loss: 1.691e-07, loss_BC: 0.000e+00, loss_IC: 2.179e-08,loss_f: 4.250e-08
pinn: 0100, Iter: 1200, total_loss: 1.456e-07, loss_BC: 0.000e+00, loss_IC: 2.356e-08,loss_f: 6.363e-08
pinn: 0000, Iter: 1200, total_loss: 3.954e-07, loss_BC: 0.000e+00, loss_IC: 4.517e-08,loss_f: 7.596e-08
pinn: 0200, Iter: 1200, total_loss: 1.286e-07, loss_BC: 0.000e+00, loss_IC: 2.868e-08,loss_f: 6.777e-08
pinn: 0300, Iter: 1300, total_loss: 1.673e-07, loss_BC: 0.000e+00, loss_IC: 2.090e-08,loss_f: 4.222e-08
pinn: 0100, Iter: 1300, total_loss: 1.446e-07, loss_BC: 0.000e+00, loss_IC: 2.252e-08,loss_f: 6.337e-08
pinn: 0000, Iter: 1300, total_loss: 3.939e-07, loss_BC: 0.000e+00, loss_IC: 4.623e-08,loss_f: 7.635e-08
pinn: 0200, Iter: 1300, total_loss: 1.270e-07, loss_BC: 0.000e+00, loss_IC: 2.666e-08,loss_f: 6.795e-08
pinn: 0300, Iter: 1400, total_loss: 1.666e-07, loss_BC: 0.000e+00, loss_IC: 2.031e-08,loss_f: 4.223e-08
pinn: 0100, Iter: 1400, total_loss: 1.418e-07, loss_BC: 0.000e+00, loss_IC: 2.169e-08,loss_f: 6.134e-08
pinn: 0000, Iter: 1400, total_loss: 3.895e-07, loss_BC: 0.000e+00, loss_IC: 4.869e-08,loss_f: 7.723e-08
pinn: 0200, Iter: 1400, total_loss: 1.252e-07, loss_BC: 0.000e+00, loss_IC: 2.406e-08,loss_f: 6.838e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4197, Mean_loss of pinns: 2.053e-07, loss_BC: 0.000e+00, loss_IC: 2.882e-08, loss_f: 6.199e-08
 => minimum loss: 1.249e-07, corresponding pinn index: 0200
 => maximum loss: 3.891e-07, corresponding pinn  index: 0000

 max_loss: 6.450e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4199, total_loss: 4.305e-05, loss_BC: 4.284e-05, loss_IC: 3.063e-08, loss_f: 6.373e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.39000, t_max: 0.40000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4200 0 1

 -------------------------------------------------------------
  -----  Epoch: 4200 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.39000, t_max: 0.40000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4200 !!! 


==> Epoch: 4200, Mean_loss of pinns: 7.879e-04, loss_BC: 4.719e-05, loss_IC: 0.000e+00, loss_f: 7.404e-04
 => minimum loss: 4.232e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.414e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4210, Mean_loss of pinns: 5.684e-04, loss_BC: 4.357e-05, loss_IC: 1.787e-06, loss_f: 5.228e-04
 => minimum loss: 3.004e-04, corresponding pinn/batch index: 0100
 => maximum loss: 9.381e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4220, Mean_loss of pinns: 4.518e-04, loss_BC: 4.073e-05, loss_IC: 5.750e-06, loss_f: 4.051e-04
 => minimum loss: 2.431e-04, corresponding pinn/batch index: 0100
 => maximum loss: 7.208e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4230, Mean_loss of pinns: 3.735e-04, loss_BC: 3.781e-05, loss_IC: 9.503e-06, loss_f: 3.259e-04
 => minimum loss: 2.001e-04, corresponding pinn/batch index: 0100
 => maximum loss: 5.900e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4240, Mean_loss of pinns: 3.151e-04, loss_BC: 3.602e-05, loss_IC: 1.116e-05, loss_f: 2.676e-04
 => minimum loss: 1.661e-04, corresponding pinn/batch index: 0100
 => maximum loss: 4.958e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4250, Mean_loss of pinns: 2.702e-04, loss_BC: 3.449e-05, loss_IC: 1.045e-05, loss_f: 2.250e-04
 => minimum loss: 1.404e-04, corresponding pinn/batch index: 0100
 => maximum loss: 4.238e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4260, Mean_loss of pinns: 2.349e-04, loss_BC: 3.335e-05, loss_IC: 8.903e-06, loss_f: 1.924e-04
 => minimum loss: 1.210e-04, corresponding pinn/batch index: 0100
 => maximum loss: 3.695e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4270, Mean_loss of pinns: 2.057e-04, loss_BC: 3.147e-05, loss_IC: 7.374e-06, loss_f: 1.666e-04
 => minimum loss: 1.059e-04, corresponding pinn/batch index: 0100
 => maximum loss: 3.229e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4280, Mean_loss of pinns: 1.827e-04, loss_BC: 3.037e-05, loss_IC: 6.187e-06, loss_f: 1.459e-04
 => minimum loss: 9.421e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.836e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4290, Mean_loss of pinns: 1.635e-04, loss_BC: 2.887e-05, loss_IC: 5.460e-06, loss_f: 1.289e-04
 => minimum loss: 8.496e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.516e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  4299

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 2.454e-07, loss_BC: 0.000e+00, loss_IC: 4.281e-08,loss_f: 1.767e-07
pinn: 0100, Iter: 100, total_loss: 6.089e-07, loss_BC: 0.000e+00, loss_IC: 3.956e-08,loss_f: 1.910e-07
pinn: 0000, Iter: 100, total_loss: 4.658e-07, loss_BC: 0.000e+00, loss_IC: 5.294e-08,loss_f: 2.310e-07
pinn: 0200, Iter: 100, total_loss: 7.068e-07, loss_BC: 0.000e+00, loss_IC: 6.269e-08,loss_f: 2.628e-07
pinn: 0000, Iter: 200, total_loss: 3.402e-07, loss_BC: 0.000e+00, loss_IC: 4.977e-08,loss_f: 1.079e-07
pinn: 0300, Iter: 200, total_loss: 1.472e-07, loss_BC: 0.000e+00, loss_IC: 4.421e-08,loss_f: 7.775e-08
pinn: 0200, Iter: 200, total_loss: 5.276e-07, loss_BC: 0.000e+00, loss_IC: 6.169e-08,loss_f: 9.724e-08
pinn: 0100, Iter: 200, total_loss: 4.887e-07, loss_BC: 0.000e+00, loss_IC: 3.604e-08,loss_f: 7.436e-08
pinn: 0000, Iter: 300, total_loss: 3.085e-07, loss_BC: 0.000e+00, loss_IC: 4.865e-08,loss_f: 7.895e-08
pinn: 0300, Iter: 300, total_loss: 1.292e-07, loss_BC: 0.000e+00, loss_IC: 3.943e-08,loss_f: 6.435e-08
pinn: 0200, Iter: 300, total_loss: 4.948e-07, loss_BC: 0.000e+00, loss_IC: 5.431e-08,loss_f: 7.787e-08
pinn: 0100, Iter: 300, total_loss: 4.683e-07, loss_BC: 0.000e+00, loss_IC: 3.042e-08,loss_f: 5.872e-08
pinn: 0000, Iter: 400, total_loss: 2.950e-07, loss_BC: 0.000e+00, loss_IC: 4.455e-08,loss_f: 6.900e-08
pinn: 0300, Iter: 400, total_loss: 1.191e-07, loss_BC: 0.000e+00, loss_IC: 3.656e-08,loss_f: 5.718e-08
pinn: 0200, Iter: 400, total_loss: 4.804e-07, loss_BC: 0.000e+00, loss_IC: 5.664e-08,loss_f: 7.174e-08
pinn: 0100, Iter: 400, total_loss: 4.503e-07, loss_BC: 0.000e+00, loss_IC: 3.076e-08,loss_f: 5.767e-08
pinn: 0000, Iter: 500, total_loss: 2.859e-07, loss_BC: 0.000e+00, loss_IC: 3.871e-08,loss_f: 6.554e-08
pinn: 0300, Iter: 500, total_loss: 1.154e-07, loss_BC: 0.000e+00, loss_IC: 3.512e-08,loss_f: 5.483e-08
pinn: 0200, Iter: 500, total_loss: 4.673e-07, loss_BC: 0.000e+00, loss_IC: 6.326e-08,loss_f: 6.535e-08
pinn: 0100, Iter: 500, total_loss: 4.389e-07, loss_BC: 0.000e+00, loss_IC: 2.688e-08,loss_f: 6.166e-08
pinn: 0300, Iter: 600, total_loss: 1.112e-07, loss_BC: 0.000e+00, loss_IC: 3.375e-08,loss_f: 5.193e-08
pinn: 0000, Iter: 600, total_loss: 2.805e-07, loss_BC: 0.000e+00, loss_IC: 3.454e-08,loss_f: 6.364e-08
pinn: 0200, Iter: 600, total_loss: 4.544e-07, loss_BC: 0.000e+00, loss_IC: 6.447e-08,loss_f: 6.138e-08
pinn: 0100, Iter: 600, total_loss: 4.280e-07, loss_BC: 0.000e+00, loss_IC: 2.677e-08,loss_f: 5.945e-08
pinn: 0300, Iter: 700, total_loss: 1.090e-07, loss_BC: 0.000e+00, loss_IC: 3.214e-08,loss_f: 5.133e-08
pinn: 0000, Iter: 700, total_loss: 2.765e-07, loss_BC: 0.000e+00, loss_IC: 3.232e-08,loss_f: 6.234e-08
pinn: 0100, Iter: 700, total_loss: 4.149e-07, loss_BC: 0.000e+00, loss_IC: 2.978e-08,loss_f: 5.892e-08
pinn: 0200, Iter: 700, total_loss: 4.494e-07, loss_BC: 0.000e+00, loss_IC: 6.678e-08,loss_f: 6.063e-08
pinn: 0300, Iter: 800, total_loss: 1.065e-07, loss_BC: 0.000e+00, loss_IC: 3.139e-08,loss_f: 4.959e-08
pinn: 0000, Iter: 800, total_loss: 2.736e-07, loss_BC: 0.000e+00, loss_IC: 2.955e-08,loss_f: 6.234e-08
pinn: 0200, Iter: 800, total_loss: 4.449e-07, loss_BC: 0.000e+00, loss_IC: 6.567e-08,loss_f: 6.089e-08
pinn: 0100, Iter: 800, total_loss: 4.072e-07, loss_BC: 0.000e+00, loss_IC: 3.788e-08,loss_f: 6.004e-08
pinn: 0000, Iter: 900, total_loss: 2.719e-07, loss_BC: 0.000e+00, loss_IC: 2.793e-08,loss_f: 6.264e-08
pinn: 0300, Iter: 900, total_loss: 1.053e-07, loss_BC: 0.000e+00, loss_IC: 3.146e-08,loss_f: 4.825e-08
pinn: 0200, Iter: 900, total_loss: 4.390e-07, loss_BC: 0.000e+00, loss_IC: 6.581e-08,loss_f: 6.251e-08
pinn: 0100, Iter: 900, total_loss: 3.898e-07, loss_BC: 0.000e+00, loss_IC: 3.876e-08,loss_f: 6.576e-08
pinn: 0300, Iter: 1000, total_loss: 1.044e-07, loss_BC: 0.000e+00, loss_IC: 3.101e-08,loss_f: 4.781e-08
pinn: 0000, Iter: 1000, total_loss: 2.674e-07, loss_BC: 0.000e+00, loss_IC: 2.543e-08,loss_f: 6.147e-08
pinn: 0200, Iter: 1000, total_loss: 4.311e-07, loss_BC: 0.000e+00, loss_IC: 6.724e-08,loss_f: 6.441e-08
pinn: 0100, Iter: 1000, total_loss: 3.796e-07, loss_BC: 0.000e+00, loss_IC: 4.025e-08,loss_f: 6.816e-08
pinn: 0300, Iter: 1100, total_loss: 1.033e-07, loss_BC: 0.000e+00, loss_IC: 3.118e-08,loss_f: 4.650e-08
pinn: 0000, Iter: 1100, total_loss: 2.639e-07, loss_BC: 0.000e+00, loss_IC: 2.464e-08,loss_f: 6.085e-08
pinn: 0200, Iter: 1100, total_loss: 4.285e-07, loss_BC: 0.000e+00, loss_IC: 6.566e-08,loss_f: 6.664e-08
pinn: 0100, Iter: 1100, total_loss: 3.735e-07, loss_BC: 0.000e+00, loss_IC: 4.103e-08,loss_f: 7.376e-08
pinn: 0300, Iter: 1200, total_loss: 1.004e-07, loss_BC: 0.000e+00, loss_IC: 2.847e-08,loss_f: 4.612e-08
pinn: 0200, Iter: 1200, total_loss: 4.227e-07, loss_BC: 0.000e+00, loss_IC: 6.869e-08,loss_f: 7.125e-08
pinn: 0000, Iter: 1200, total_loss: 2.593e-07, loss_BC: 0.000e+00, loss_IC: 2.329e-08,loss_f: 6.071e-08
pinn: 0100, Iter: 1200, total_loss: 3.682e-07, loss_BC: 0.000e+00, loss_IC: 4.398e-08,loss_f: 7.439e-08
pinn: 0300, Iter: 1300, total_loss: 9.946e-08, loss_BC: 0.000e+00, loss_IC: 2.744e-08,loss_f: 4.617e-08
pinn: 0200, Iter: 1300, total_loss: 4.156e-07, loss_BC: 0.000e+00, loss_IC: 6.819e-08,loss_f: 7.139e-08
pinn: 0000, Iter: 1300, total_loss: 2.586e-07, loss_BC: 0.000e+00, loss_IC: 2.318e-08,loss_f: 6.058e-08
pinn: 0100, Iter: 1300, total_loss: 3.634e-07, loss_BC: 0.000e+00, loss_IC: 4.643e-08,loss_f: 7.503e-08
pinn: 0300, Iter: 1400, total_loss: 9.744e-08, loss_BC: 0.000e+00, loss_IC: 2.404e-08,loss_f: 4.724e-08
pinn: 0200, Iter: 1400, total_loss: 4.131e-07, loss_BC: 0.000e+00, loss_IC: 6.784e-08,loss_f: 7.297e-08
pinn: 0000, Iter: 1400, total_loss: 2.568e-07, loss_BC: 0.000e+00, loss_IC: 2.295e-08,loss_f: 6.024e-08
pinn: 0100, Iter: 1400, total_loss: 3.547e-07, loss_BC: 0.000e+00, loss_IC: 4.866e-08,loss_f: 7.317e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4299, Mean_loss of pinns: 2.797e-07, loss_BC: 0.000e+00, loss_IC: 4.051e-08, loss_f: 6.355e-08
 => minimum loss: 9.718e-08, corresponding pinn index: 0300
 => maximum loss: 4.108e-07, corresponding pinn  index: 0200

==> Epoch: 4300, Mean_loss of pinns: 4.740e-05, loss_BC: 4.712e-05, loss_IC: 4.051e-08, loss_f: 6.355e-08
 => minimum loss: 2.107e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.039e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0300

==> Epoch: 4310, Mean_loss of pinns: 4.055e-05, loss_BC: 3.953e-05, loss_IC: 6.876e-07, loss_f: 1.626e-07
 => minimum loss: 1.701e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.723e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 4.839e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4318, total_loss: 3.723e-05, loss_BC: 3.478e-05, loss_IC: 2.113e-06, loss_f: 1.641e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.40000, t_max: 0.41000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4319 0 1

 -------------------------------------------------------------
  -----  Epoch: 4319 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.40000, t_max: 0.41000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4319 !!! 


==> Epoch: 4320, Mean_loss of pinns: 1.001e-03, loss_BC: 3.705e-05, loss_IC: 2.313e-08, loss_f: 9.636e-04
 => minimum loss: 3.008e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.467e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4330, Mean_loss of pinns: 7.507e-04, loss_BC: 3.528e-05, loss_IC: 2.609e-06, loss_f: 7.125e-04
 => minimum loss: 2.496e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.109e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4340, Mean_loss of pinns: 5.901e-04, loss_BC: 3.344e-05, loss_IC: 7.650e-06, loss_f: 5.487e-04
 => minimum loss: 2.131e-04, corresponding pinn/batch index: 0000
 => maximum loss: 8.652e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4350, Mean_loss of pinns: 4.823e-04, loss_BC: 3.152e-05, loss_IC: 1.222e-05, loss_f: 4.383e-04
 => minimum loss: 1.821e-04, corresponding pinn/batch index: 0000
 => maximum loss: 6.954e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4360, Mean_loss of pinns: 4.028e-04, loss_BC: 3.008e-05, loss_IC: 1.444e-05, loss_f: 3.580e-04
 => minimum loss: 1.574e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.709e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4370, Mean_loss of pinns: 3.426e-04, loss_BC: 2.887e-05, loss_IC: 1.423e-05, loss_f: 2.993e-04
 => minimum loss: 1.361e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.775e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4380, Mean_loss of pinns: 2.943e-04, loss_BC: 2.643e-05, loss_IC: 1.265e-05, loss_f: 2.550e-04
 => minimum loss: 1.186e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.058e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4390, Mean_loss of pinns: 2.563e-04, loss_BC: 2.492e-05, loss_IC: 1.055e-05, loss_f: 2.205e-04
 => minimum loss: 1.046e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.495e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4400, Mean_loss of pinns: 2.259e-04, loss_BC: 2.401e-05, loss_IC: 8.643e-06, loss_f: 1.930e-04
 => minimum loss: 9.415e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.050e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4410, Mean_loss of pinns: 2.012e-04, loss_BC: 2.323e-05, loss_IC: 7.246e-06, loss_f: 1.704e-04
 => minimum loss: 8.511e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.687e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  4418

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 5.536e-07, loss_BC: 0.000e+00, loss_IC: 5.274e-08,loss_f: 3.619e-07
pinn: 0000, Iter: 100, total_loss: 7.822e-07, loss_BC: 0.000e+00, loss_IC: 2.806e-08,loss_f: 2.884e-07
pinn: 0300, Iter: 100, total_loss: 5.660e-07, loss_BC: 0.000e+00, loss_IC: 3.823e-08,loss_f: 1.869e-07
pinn: 0200, Iter: 100, total_loss: 2.949e-07, loss_BC: 0.000e+00, loss_IC: 4.216e-08,loss_f: 1.441e-07
pinn: 0100, Iter: 200, total_loss: 3.022e-07, loss_BC: 0.000e+00, loss_IC: 3.406e-08,loss_f: 1.334e-07
pinn: 0300, Iter: 200, total_loss: 4.499e-07, loss_BC: 0.000e+00, loss_IC: 4.913e-08,loss_f: 7.300e-08
pinn: 0200, Iter: 200, total_loss: 2.232e-07, loss_BC: 0.000e+00, loss_IC: 3.824e-08,loss_f: 7.696e-08
pinn: 0000, Iter: 200, total_loss: 5.778e-07, loss_BC: 0.000e+00, loss_IC: 3.982e-08,loss_f: 9.392e-08
pinn: 0100, Iter: 300, total_loss: 2.640e-07, loss_BC: 0.000e+00, loss_IC: 3.460e-08,loss_f: 9.461e-08
pinn: 0000, Iter: 300, total_loss: 5.441e-07, loss_BC: 0.000e+00, loss_IC: 4.464e-08,loss_f: 6.575e-08
pinn: 0300, Iter: 300, total_loss: 4.344e-07, loss_BC: 0.000e+00, loss_IC: 4.641e-08,loss_f: 6.113e-08
pinn: 0200, Iter: 300, total_loss: 2.045e-07, loss_BC: 0.000e+00, loss_IC: 3.270e-08,loss_f: 6.352e-08
pinn: 0100, Iter: 400, total_loss: 2.504e-07, loss_BC: 0.000e+00, loss_IC: 3.722e-08,loss_f: 8.038e-08
pinn: 0000, Iter: 400, total_loss: 5.336e-07, loss_BC: 0.000e+00, loss_IC: 4.939e-08,loss_f: 6.118e-08
pinn: 0300, Iter: 400, total_loss: 4.269e-07, loss_BC: 0.000e+00, loss_IC: 4.906e-08,loss_f: 5.675e-08
pinn: 0200, Iter: 400, total_loss: 1.950e-07, loss_BC: 0.000e+00, loss_IC: 2.719e-08,loss_f: 5.843e-08
pinn: 0100, Iter: 500, total_loss: 2.375e-07, loss_BC: 0.000e+00, loss_IC: 3.922e-08,loss_f: 6.622e-08
pinn: 0200, Iter: 500, total_loss: 1.911e-07, loss_BC: 0.000e+00, loss_IC: 2.522e-08,loss_f: 5.581e-08
pinn: 0300, Iter: 500, total_loss: 4.186e-07, loss_BC: 0.000e+00, loss_IC: 4.618e-08,loss_f: 5.715e-08
pinn: 0000, Iter: 500, total_loss: 5.245e-07, loss_BC: 0.000e+00, loss_IC: 5.122e-08,loss_f: 5.890e-08
pinn: 0100, Iter: 600, total_loss: 2.345e-07, loss_BC: 0.000e+00, loss_IC: 3.984e-08,loss_f: 6.260e-08
pinn: 0200, Iter: 600, total_loss: 1.878e-07, loss_BC: 0.000e+00, loss_IC: 2.432e-08,loss_f: 5.303e-08
pinn: 0300, Iter: 600, total_loss: 4.103e-07, loss_BC: 0.000e+00, loss_IC: 4.101e-08,loss_f: 5.982e-08
pinn: 0000, Iter: 600, total_loss: 5.131e-07, loss_BC: 0.000e+00, loss_IC: 5.382e-08,loss_f: 5.796e-08
pinn: 0100, Iter: 700, total_loss: 2.274e-07, loss_BC: 0.000e+00, loss_IC: 3.782e-08,loss_f: 5.685e-08
pinn: 0200, Iter: 700, total_loss: 1.845e-07, loss_BC: 0.000e+00, loss_IC: 2.472e-08,loss_f: 4.973e-08
pinn: 0000, Iter: 700, total_loss: 4.914e-07, loss_BC: 0.000e+00, loss_IC: 5.636e-08,loss_f: 5.961e-08
pinn: 0300, Iter: 700, total_loss: 3.992e-07, loss_BC: 0.000e+00, loss_IC: 3.616e-08,loss_f: 6.319e-08
pinn: 0100, Iter: 800, total_loss: 2.212e-07, loss_BC: 0.000e+00, loss_IC: 3.668e-08,loss_f: 5.121e-08
pinn: 0300, Iter: 800, total_loss: 3.848e-07, loss_BC: 0.000e+00, loss_IC: 3.600e-08,loss_f: 6.772e-08
pinn: 0000, Iter: 800, total_loss: 4.774e-07, loss_BC: 0.000e+00, loss_IC: 6.251e-08,loss_f: 5.898e-08
pinn: 0200, Iter: 800, total_loss: 1.822e-07, loss_BC: 0.000e+00, loss_IC: 2.467e-08,loss_f: 4.761e-08
pinn: 0100, Iter: 900, total_loss: 2.183e-07, loss_BC: 0.000e+00, loss_IC: 3.473e-08,loss_f: 4.992e-08
pinn: 0200, Iter: 900, total_loss: 1.801e-07, loss_BC: 0.000e+00, loss_IC: 2.466e-08,loss_f: 4.573e-08
pinn: 0300, Iter: 900, total_loss: 3.715e-07, loss_BC: 0.000e+00, loss_IC: 3.619e-08,loss_f: 7.644e-08
pinn: 0000, Iter: 900, total_loss: 4.716e-07, loss_BC: 0.000e+00, loss_IC: 6.367e-08,loss_f: 5.800e-08
pinn: 0100, Iter: 1000, total_loss: 2.133e-07, loss_BC: 0.000e+00, loss_IC: 3.099e-08,loss_f: 4.796e-08
pinn: 0000, Iter: 1000, total_loss: 4.576e-07, loss_BC: 0.000e+00, loss_IC: 6.859e-08,loss_f: 6.051e-08
pinn: 0200, Iter: 1000, total_loss: 1.791e-07, loss_BC: 0.000e+00, loss_IC: 2.431e-08,loss_f: 4.525e-08
pinn: 0300, Iter: 1000, total_loss: 3.578e-07, loss_BC: 0.000e+00, loss_IC: 3.257e-08,loss_f: 7.995e-08
pinn: 0100, Iter: 1100, total_loss: 2.110e-07, loss_BC: 0.000e+00, loss_IC: 2.984e-08,loss_f: 4.728e-08
pinn: 0300, Iter: 1100, total_loss: 3.502e-07, loss_BC: 0.000e+00, loss_IC: 3.357e-08,loss_f: 8.337e-08
pinn: 0200, Iter: 1100, total_loss: 1.773e-07, loss_BC: 0.000e+00, loss_IC: 2.406e-08,loss_f: 4.416e-08
pinn: 0000, Iter: 1100, total_loss: 4.424e-07, loss_BC: 0.000e+00, loss_IC: 7.111e-08,loss_f: 6.279e-08
pinn: 0100, Iter: 1200, total_loss: 2.086e-07, loss_BC: 0.000e+00, loss_IC: 2.877e-08,loss_f: 4.676e-08
pinn: 0000, Iter: 1200, total_loss: 4.315e-07, loss_BC: 0.000e+00, loss_IC: 7.997e-08,loss_f: 6.940e-08
pinn: 0300, Iter: 1200, total_loss: 3.440e-07, loss_BC: 0.000e+00, loss_IC: 3.527e-08,loss_f: 8.313e-08
pinn: 0200, Iter: 1200, total_loss: 1.768e-07, loss_BC: 0.000e+00, loss_IC: 2.359e-08,loss_f: 4.407e-08
pinn: 0100, Iter: 1300, total_loss: 2.080e-07, loss_BC: 0.000e+00, loss_IC: 2.825e-08,loss_f: 4.680e-08
pinn: 0000, Iter: 1300, total_loss: 4.258e-07, loss_BC: 0.000e+00, loss_IC: 7.792e-08,loss_f: 6.419e-08
pinn: 0300, Iter: 1300, total_loss: 3.351e-07, loss_BC: 0.000e+00, loss_IC: 4.088e-08,loss_f: 8.792e-08
pinn: 0200, Iter: 1300, total_loss: 1.757e-07, loss_BC: 0.000e+00, loss_IC: 2.309e-08,loss_f: 4.354e-08
pinn: 0100, Iter: 1400, total_loss: 2.064e-07, loss_BC: 0.000e+00, loss_IC: 2.733e-08,loss_f: 4.643e-08
pinn: 0000, Iter: 1400, total_loss: 4.139e-07, loss_BC: 0.000e+00, loss_IC: 7.505e-08,loss_f: 6.500e-08
pinn: 0300, Iter: 1400, total_loss: 3.236e-07, loss_BC: 0.000e+00, loss_IC: 4.442e-08,loss_f: 8.017e-08
pinn: 0200, Iter: 1400, total_loss: 1.746e-07, loss_BC: 0.000e+00, loss_IC: 2.293e-08,loss_f: 4.283e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4418, Mean_loss of pinns: 2.788e-07, loss_BC: 0.000e+00, loss_IC: 4.251e-08, loss_f: 5.882e-08
 => minimum loss: 1.745e-07, corresponding pinn index: 0200
 => maximum loss: 4.110e-07, corresponding pinn  index: 0000

==> Epoch: 4420, Mean_loss of pinns: 3.919e-05, loss_BC: 3.891e-05, loss_IC: 4.341e-08, loss_f: 6.075e-08
 => minimum loss: 1.306e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.564e-05, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 5.564e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4420, total_loss: 3.919e-05, loss_BC: 3.891e-05, loss_IC: 4.341e-08, loss_f: 6.075e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.41000, t_max: 0.42000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4421 0 1

 -------------------------------------------------------------
  -----  Epoch: 4421 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.41000, t_max: 0.42000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4421 !!! 


==> Epoch: 4430, Mean_loss of pinns: 3.133e-04, loss_BC: 3.848e-05, loss_IC: 1.420e-06, loss_f: 2.732e-04
 => minimum loss: 2.503e-04, corresponding pinn/batch index: 0300
 => maximum loss: 4.988e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4440, Mean_loss of pinns: 2.564e-04, loss_BC: 3.508e-05, loss_IC: 4.121e-06, loss_f: 2.170e-04
 => minimum loss: 2.008e-04, corresponding pinn/batch index: 0300
 => maximum loss: 4.004e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4450, Mean_loss of pinns: 2.157e-04, loss_BC: 3.234e-05, loss_IC: 5.771e-06, loss_f: 1.774e-04
 => minimum loss: 1.720e-04, corresponding pinn/batch index: 0300
 => maximum loss: 3.282e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4460, Mean_loss of pinns: 1.829e-04, loss_BC: 2.966e-05, loss_IC: 5.563e-06, loss_f: 1.475e-04
 => minimum loss: 1.487e-04, corresponding pinn/batch index: 0300
 => maximum loss: 2.727e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4470, Mean_loss of pinns: 1.567e-04, loss_BC: 2.716e-05, loss_IC: 4.372e-06, loss_f: 1.250e-04
 => minimum loss: 1.296e-04, corresponding pinn/batch index: 0300
 => maximum loss: 2.296e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4480, Mean_loss of pinns: 1.373e-04, loss_BC: 2.602e-05, loss_IC: 3.560e-06, loss_f: 1.075e-04
 => minimum loss: 1.149e-04, corresponding pinn/batch index: 0300
 => maximum loss: 1.964e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4490, Mean_loss of pinns: 1.214e-04, loss_BC: 2.446e-05, loss_IC: 3.363e-06, loss_f: 9.339e-05
 => minimum loss: 1.035e-04, corresponding pinn/batch index: 0300
 => maximum loss: 1.702e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4500, Mean_loss of pinns: 1.092e-04, loss_BC: 2.370e-05, loss_IC: 3.442e-06, loss_f: 8.185e-05
 => minimum loss: 9.401e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.491e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4510, Mean_loss of pinns: 9.892e-05, loss_BC: 2.270e-05, loss_IC: 3.530e-06, loss_f: 7.247e-05
 => minimum loss: 8.651e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.318e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4520, Mean_loss of pinns: 9.089e-05, loss_BC: 2.226e-05, loss_IC: 3.562e-06, loss_f: 6.485e-05
 => minimum loss: 8.071e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.181e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  4520

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 4.013e-07, loss_BC: 0.000e+00, loss_IC: 2.400e-08,loss_f: 2.489e-07
pinn: 0100, Iter: 100, total_loss: 5.458e-07, loss_BC: 0.000e+00, loss_IC: 2.937e-08,loss_f: 1.469e-07
pinn: 0300, Iter: 100, total_loss: 4.483e-07, loss_BC: 0.000e+00, loss_IC: 2.286e-08,loss_f: 2.851e-07
pinn: 0200, Iter: 100, total_loss: 3.994e-07, loss_BC: 0.000e+00, loss_IC: 4.914e-08,loss_f: 1.901e-07
pinn: 0000, Iter: 200, total_loss: 2.617e-07, loss_BC: 0.000e+00, loss_IC: 2.677e-08,loss_f: 1.086e-07
pinn: 0200, Iter: 200, total_loss: 2.513e-07, loss_BC: 0.000e+00, loss_IC: 3.529e-08,loss_f: 5.824e-08
pinn: 0100, Iter: 200, total_loss: 4.462e-07, loss_BC: 0.000e+00, loss_IC: 2.380e-08,loss_f: 6.284e-08
pinn: 0300, Iter: 200, total_loss: 2.523e-07, loss_BC: 0.000e+00, loss_IC: 1.431e-08,loss_f: 1.043e-07
pinn: 0000, Iter: 300, total_loss: 2.462e-07, loss_BC: 0.000e+00, loss_IC: 2.678e-08,loss_f: 9.370e-08
pinn: 0100, Iter: 300, total_loss: 4.374e-07, loss_BC: 0.000e+00, loss_IC: 2.330e-08,loss_f: 5.632e-08
pinn: 0300, Iter: 300, total_loss: 2.173e-07, loss_BC: 0.000e+00, loss_IC: 9.888e-09,loss_f: 7.263e-08
pinn: 0200, Iter: 300, total_loss: 2.377e-07, loss_BC: 0.000e+00, loss_IC: 2.857e-08,loss_f: 5.197e-08
pinn: 0000, Iter: 400, total_loss: 2.361e-07, loss_BC: 0.000e+00, loss_IC: 2.660e-08,loss_f: 8.405e-08
pinn: 0100, Iter: 400, total_loss: 4.336e-07, loss_BC: 0.000e+00, loss_IC: 2.469e-08,loss_f: 5.528e-08
pinn: 0200, Iter: 400, total_loss: 2.285e-07, loss_BC: 0.000e+00, loss_IC: 2.281e-08,loss_f: 4.711e-08
pinn: 0300, Iter: 400, total_loss: 2.056e-07, loss_BC: 0.000e+00, loss_IC: 5.687e-09,loss_f: 6.364e-08
pinn: 0000, Iter: 500, total_loss: 2.191e-07, loss_BC: 0.000e+00, loss_IC: 2.467e-08,loss_f: 6.916e-08
pinn: 0200, Iter: 500, total_loss: 2.212e-07, loss_BC: 0.000e+00, loss_IC: 1.714e-08,loss_f: 4.288e-08
pinn: 0100, Iter: 500, total_loss: 4.224e-07, loss_BC: 0.000e+00, loss_IC: 2.801e-08,loss_f: 5.631e-08
pinn: 0300, Iter: 500, total_loss: 1.998e-07, loss_BC: 0.000e+00, loss_IC: 4.386e-09,loss_f: 5.830e-08
pinn: 0000, Iter: 600, total_loss: 2.147e-07, loss_BC: 0.000e+00, loss_IC: 2.264e-08,loss_f: 6.663e-08
pinn: 0200, Iter: 600, total_loss: 2.183e-07, loss_BC: 0.000e+00, loss_IC: 1.590e-08,loss_f: 4.086e-08
pinn: 0100, Iter: 600, total_loss: 4.170e-07, loss_BC: 0.000e+00, loss_IC: 2.966e-08,loss_f: 5.833e-08
pinn: 0300, Iter: 600, total_loss: 1.952e-07, loss_BC: 0.000e+00, loss_IC: 3.706e-09,loss_f: 5.396e-08
pinn: 0000, Iter: 700, total_loss: 2.104e-07, loss_BC: 0.000e+00, loss_IC: 2.150e-08,loss_f: 6.376e-08
pinn: 0200, Iter: 700, total_loss: 2.157e-07, loss_BC: 0.000e+00, loss_IC: 1.569e-08,loss_f: 3.943e-08
pinn: 0100, Iter: 700, total_loss: 3.940e-07, loss_BC: 0.000e+00, loss_IC: 3.238e-08,loss_f: 5.850e-08
pinn: 0300, Iter: 700, total_loss: 1.903e-07, loss_BC: 0.000e+00, loss_IC: 3.705e-09,loss_f: 4.942e-08
pinn: 0000, Iter: 800, total_loss: 2.055e-07, loss_BC: 0.000e+00, loss_IC: 1.961e-08,loss_f: 6.100e-08
pinn: 0200, Iter: 800, total_loss: 2.090e-07, loss_BC: 0.000e+00, loss_IC: 1.519e-08,loss_f: 3.775e-08
pinn: 0300, Iter: 800, total_loss: 1.841e-07, loss_BC: 0.000e+00, loss_IC: 4.462e-09,loss_f: 4.585e-08
pinn: 0100, Iter: 800, total_loss: 3.851e-07, loss_BC: 0.000e+00, loss_IC: 3.538e-08,loss_f: 6.155e-08
pinn: 0000, Iter: 900, total_loss: 2.014e-07, loss_BC: 0.000e+00, loss_IC: 1.747e-08,loss_f: 5.942e-08
pinn: 0200, Iter: 900, total_loss: 2.058e-07, loss_BC: 0.000e+00, loss_IC: 1.514e-08,loss_f: 3.689e-08
pinn: 0100, Iter: 900, total_loss: 3.749e-07, loss_BC: 0.000e+00, loss_IC: 3.415e-08,loss_f: 6.371e-08
pinn: 0300, Iter: 900, total_loss: 1.810e-07, loss_BC: 0.000e+00, loss_IC: 4.642e-09,loss_f: 4.472e-08
pinn: 0000, Iter: 1000, total_loss: 1.994e-07, loss_BC: 0.000e+00, loss_IC: 1.732e-08,loss_f: 5.804e-08
pinn: 0200, Iter: 1000, total_loss: 2.033e-07, loss_BC: 0.000e+00, loss_IC: 1.659e-08,loss_f: 3.552e-08
pinn: 0100, Iter: 1000, total_loss: 3.514e-07, loss_BC: 0.000e+00, loss_IC: 3.771e-08,loss_f: 6.783e-08
pinn: 0300, Iter: 1000, total_loss: 1.785e-07, loss_BC: 0.000e+00, loss_IC: 5.714e-09,loss_f: 4.373e-08
pinn: 0000, Iter: 1100, total_loss: 1.976e-07, loss_BC: 0.000e+00, loss_IC: 1.648e-08,loss_f: 5.741e-08
pinn: 0200, Iter: 1100, total_loss: 2.000e-07, loss_BC: 0.000e+00, loss_IC: 1.739e-08,loss_f: 3.485e-08
pinn: 0100, Iter: 1100, total_loss: 3.310e-07, loss_BC: 0.000e+00, loss_IC: 4.232e-08,loss_f: 6.786e-08
pinn: 0300, Iter: 1100, total_loss: 1.769e-07, loss_BC: 0.000e+00, loss_IC: 6.851e-09,loss_f: 4.287e-08
pinn: 0000, Iter: 1200, total_loss: 1.972e-07, loss_BC: 0.000e+00, loss_IC: 1.660e-08,loss_f: 5.725e-08
pinn: 0200, Iter: 1200, total_loss: 1.979e-07, loss_BC: 0.000e+00, loss_IC: 1.834e-08,loss_f: 3.455e-08
pinn: 0300, Iter: 1200, total_loss: 1.736e-07, loss_BC: 0.000e+00, loss_IC: 8.528e-09,loss_f: 4.050e-08
pinn: 0100, Iter: 1200, total_loss: 3.223e-07, loss_BC: 0.000e+00, loss_IC: 4.444e-08,loss_f: 6.695e-08
pinn: 0000, Iter: 1300, total_loss: 1.959e-07, loss_BC: 0.000e+00, loss_IC: 1.649e-08,loss_f: 5.689e-08
pinn: 0200, Iter: 1300, total_loss: 1.953e-07, loss_BC: 0.000e+00, loss_IC: 1.959e-08,loss_f: 3.406e-08
pinn: 0100, Iter: 1300, total_loss: 3.091e-07, loss_BC: 0.000e+00, loss_IC: 4.494e-08,loss_f: 6.496e-08
pinn: 0300, Iter: 1300, total_loss: 1.706e-07, loss_BC: 0.000e+00, loss_IC: 9.159e-09,loss_f: 3.865e-08
pinn: 0000, Iter: 1400, total_loss: 1.956e-07, loss_BC: 0.000e+00, loss_IC: 1.618e-08,loss_f: 5.696e-08
pinn: 0200, Iter: 1400, total_loss: 1.945e-07, loss_BC: 0.000e+00, loss_IC: 1.952e-08,loss_f: 3.445e-08
pinn: 0100, Iter: 1400, total_loss: 2.986e-07, loss_BC: 0.000e+00, loss_IC: 5.041e-08,loss_f: 7.139e-08
pinn: 0300, Iter: 1400, total_loss: 1.692e-07, loss_BC: 0.000e+00, loss_IC: 1.043e-08,loss_f: 3.777e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4520, Mean_loss of pinns: 2.137e-07, loss_BC: 0.000e+00, loss_IC: 2.394e-08, loss_f: 5.040e-08
 => minimum loss: 1.686e-07, corresponding pinn index: 0300
 => maximum loss: 2.965e-07, corresponding pinn  index: 0100

 max_loss: 6.198e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4522, total_loss: 4.212e-05, loss_BC: 4.191e-05, loss_IC: 2.489e-08, loss_f: 5.092e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.42000, t_max: 0.43000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4523 0 1

 -------------------------------------------------------------
  -----  Epoch: 4523 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.42000, t_max: 0.43000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4523 !!! 


==> Epoch: 4530, Mean_loss of pinns: 4.382e-04, loss_BC: 4.170e-05, loss_IC: 1.817e-06, loss_f: 3.945e-04
 => minimum loss: 1.611e-04, corresponding pinn/batch index: 0200
 => maximum loss: 1.000e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4540, Mean_loss of pinns: 3.459e-04, loss_BC: 3.758e-05, loss_IC: 5.729e-06, loss_f: 3.025e-04
 => minimum loss: 1.403e-04, corresponding pinn/batch index: 0200
 => maximum loss: 7.694e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4550, Mean_loss of pinns: 2.831e-04, loss_BC: 3.486e-05, loss_IC: 7.736e-06, loss_f: 2.404e-04
 => minimum loss: 1.224e-04, corresponding pinn/batch index: 0200
 => maximum loss: 6.223e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4560, Mean_loss of pinns: 2.373e-04, loss_BC: 3.266e-05, loss_IC: 8.675e-06, loss_f: 1.958e-04
 => minimum loss: 1.079e-04, corresponding pinn/batch index: 0200
 => maximum loss: 5.191e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4570, Mean_loss of pinns: 2.026e-04, loss_BC: 2.999e-05, loss_IC: 8.567e-06, loss_f: 1.640e-04
 => minimum loss: 9.732e-05, corresponding pinn/batch index: 0200
 => maximum loss: 4.414e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4580, Mean_loss of pinns: 1.760e-04, loss_BC: 2.789e-05, loss_IC: 8.101e-06, loss_f: 1.399e-04
 => minimum loss: 8.677e-05, corresponding pinn/batch index: 0200
 => maximum loss: 3.813e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4590, Mean_loss of pinns: 1.538e-04, loss_BC: 2.547e-05, loss_IC: 7.292e-06, loss_f: 1.209e-04
 => minimum loss: 7.754e-05, corresponding pinn/batch index: 0200
 => maximum loss: 3.313e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4600, Mean_loss of pinns: 1.366e-04, loss_BC: 2.423e-05, loss_IC: 6.511e-06, loss_f: 1.058e-04
 => minimum loss: 7.066e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.901e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4610, Mean_loss of pinns: 1.230e-04, loss_BC: 2.352e-05, loss_IC: 5.934e-06, loss_f: 9.342e-05
 => minimum loss: 6.556e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.572e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0300

==> Epoch: 4620, Mean_loss of pinns: 1.117e-04, loss_BC: 2.289e-05, loss_IC: 5.541e-06, loss_f: 8.319e-05
 => minimum loss: 6.063e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.304e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0300

 !!! Scipy optimize: !!! - Epoch:  4622

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0000, 0100, 0300


pinn: 0300, Iter: 100, total_loss: 2.619e-07, loss_BC: 0.000e+00, loss_IC: 1.967e-08,loss_f: 1.777e-07
pinn: 0000, Iter: 100, total_loss: 3.733e-07, loss_BC: 0.000e+00, loss_IC: 3.439e-08,loss_f: 1.982e-07
pinn: 0100, Iter: 100, total_loss: 4.186e-07, loss_BC: 0.000e+00, loss_IC: 3.330e-08,loss_f: 2.243e-07
pinn: 0300, Iter: 200, total_loss: 1.459e-07, loss_BC: 0.000e+00, loss_IC: 2.364e-08,loss_f: 5.990e-08
pinn: 0000, Iter: 200, total_loss: 2.698e-07, loss_BC: 0.000e+00, loss_IC: 4.255e-08,loss_f: 8.766e-08
pinn: 0100, Iter: 200, total_loss: 3.466e-07, loss_BC: 0.000e+00, loss_IC: 2.584e-08,loss_f: 1.369e-07
pinn: 0300, Iter: 300, total_loss: 1.345e-07, loss_BC: 0.000e+00, loss_IC: 2.330e-08,loss_f: 4.880e-08
pinn: 0000, Iter: 300, total_loss: 2.407e-07, loss_BC: 0.000e+00, loss_IC: 3.431e-08,loss_f: 6.730e-08
pinn: 0100, Iter: 300, total_loss: 2.948e-07, loss_BC: 0.000e+00, loss_IC: 1.859e-08,loss_f: 9.843e-08
pinn: 0300, Iter: 400, total_loss: 1.299e-07, loss_BC: 0.000e+00, loss_IC: 2.332e-08,loss_f: 4.457e-08
pinn: 0000, Iter: 400, total_loss: 2.326e-07, loss_BC: 0.000e+00, loss_IC: 3.371e-08,loss_f: 6.069e-08
pinn: 0100, Iter: 400, total_loss: 2.833e-07, loss_BC: 0.000e+00, loss_IC: 1.794e-08,loss_f: 9.504e-08
pinn: 0300, Iter: 500, total_loss: 1.270e-07, loss_BC: 0.000e+00, loss_IC: 2.296e-08,loss_f: 4.190e-08
pinn: 0000, Iter: 500, total_loss: 2.290e-07, loss_BC: 0.000e+00, loss_IC: 3.196e-08,loss_f: 5.872e-08
pinn: 0100, Iter: 500, total_loss: 2.736e-07, loss_BC: 0.000e+00, loss_IC: 1.631e-08,loss_f: 9.117e-08
pinn: 0300, Iter: 600, total_loss: 1.259e-07, loss_BC: 0.000e+00, loss_IC: 2.278e-08,loss_f: 4.107e-08
pinn: 0000, Iter: 600, total_loss: 2.266e-07, loss_BC: 0.000e+00, loss_IC: 3.174e-08,loss_f: 5.734e-08
pinn: 0100, Iter: 600, total_loss: 4.353e-07, loss_BC: 0.000e+00, loss_IC: 4.417e-08,loss_f: 2.353e-07
pinn: 0300, Iter: 700, total_loss: 1.245e-07, loss_BC: 0.000e+00, loss_IC: 2.276e-08,loss_f: 3.989e-08
pinn: 0000, Iter: 700, total_loss: 2.255e-07, loss_BC: 0.000e+00, loss_IC: 3.020e-08,loss_f: 5.794e-08
pinn: 0100, Iter: 700, total_loss: 2.488e-07, loss_BC: 0.000e+00, loss_IC: 1.467e-08,loss_f: 8.442e-08
pinn: 0300, Iter: 800, total_loss: 1.238e-07, loss_BC: 0.000e+00, loss_IC: 2.263e-08,loss_f: 3.935e-08
pinn: 0000, Iter: 800, total_loss: 2.240e-07, loss_BC: 0.000e+00, loss_IC: 3.019e-08,loss_f: 5.777e-08
pinn: 0100, Iter: 800, total_loss: 2.412e-07, loss_BC: 0.000e+00, loss_IC: 1.278e-08,loss_f: 8.166e-08
pinn: 0300, Iter: 900, total_loss: 1.232e-07, loss_BC: 0.000e+00, loss_IC: 2.243e-08,loss_f: 3.897e-08
pinn: 0000, Iter: 900, total_loss: 2.201e-07, loss_BC: 0.000e+00, loss_IC: 2.836e-08,loss_f: 5.850e-08
pinn: 0100, Iter: 900, total_loss: 2.378e-07, loss_BC: 0.000e+00, loss_IC: 1.257e-08,loss_f: 8.043e-08
pinn: 0300, Iter: 1000, total_loss: 1.226e-07, loss_BC: 0.000e+00, loss_IC: 2.228e-08,loss_f: 3.845e-08
pinn: 0000, Iter: 1000, total_loss: 2.178e-07, loss_BC: 0.000e+00, loss_IC: 2.744e-08,loss_f: 5.903e-08
pinn: 0100, Iter: 1000, total_loss: 2.348e-07, loss_BC: 0.000e+00, loss_IC: 1.278e-08,loss_f: 7.991e-08
pinn: 0300, Iter: 1100, total_loss: 1.217e-07, loss_BC: 0.000e+00, loss_IC: 2.190e-08,loss_f: 3.807e-08
pinn: 0000, Iter: 1100, total_loss: 2.141e-07, loss_BC: 0.000e+00, loss_IC: 2.552e-08,loss_f: 6.030e-08
pinn: 0100, Iter: 1100, total_loss: 2.329e-07, loss_BC: 0.000e+00, loss_IC: 1.306e-08,loss_f: 8.116e-08
pinn: 0300, Iter: 1200, total_loss: 1.197e-07, loss_BC: 0.000e+00, loss_IC: 2.152e-08,loss_f: 3.698e-08
pinn: 0000, Iter: 1200, total_loss: 2.133e-07, loss_BC: 0.000e+00, loss_IC: 2.543e-08,loss_f: 6.039e-08
pinn: 0100, Iter: 1200, total_loss: 2.206e-07, loss_BC: 0.000e+00, loss_IC: 1.553e-08,loss_f: 7.217e-08
pinn: 0300, Iter: 1300, total_loss: 1.184e-07, loss_BC: 0.000e+00, loss_IC: 2.147e-08,loss_f: 3.570e-08
pinn: 0000, Iter: 1300, total_loss: 2.116e-07, loss_BC: 0.000e+00, loss_IC: 2.460e-08,loss_f: 6.087e-08
pinn: 0100, Iter: 1300, total_loss: 2.124e-07, loss_BC: 0.000e+00, loss_IC: 1.536e-08,loss_f: 6.788e-08
pinn: 0300, Iter: 1400, total_loss: 1.172e-07, loss_BC: 0.000e+00, loss_IC: 2.099e-08,loss_f: 3.524e-08
pinn: 0000, Iter: 1400, total_loss: 2.094e-07, loss_BC: 0.000e+00, loss_IC: 2.275e-08,loss_f: 6.196e-08
pinn: 0100, Iter: 1400, total_loss: 2.103e-07, loss_BC: 0.000e+00, loss_IC: 1.630e-08,loss_f: 6.589e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4622, Mean_loss of pinns: 1.784e-07, loss_BC: 0.000e+00, loss_IC: 1.991e-08, loss_f: 5.434e-08
 => minimum loss: 1.171e-07, corresponding pinn index: 0300
 => maximum loss: 2.091e-07, corresponding pinn  index: 0000

 max_loss: 5.895e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4624, total_loss: 3.989e-05, loss_BC: 3.156e-05, loss_IC: 2.030e-06, loss_f: 6.202e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.43000, t_max: 0.44000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4625 0 1

 -------------------------------------------------------------
  -----  Epoch: 4625 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.43000, t_max: 0.44000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4625 !!! 


==> Epoch: 4630, Mean_loss of pinns: 8.965e-03, loss_BC: 3.455e-05, loss_IC: 4.897e-07, loss_f: 8.930e-03
 => minimum loss: 3.716e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.312e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4640, Mean_loss of pinns: 7.189e-03, loss_BC: 3.167e-05, loss_IC: 3.768e-06, loss_f: 7.153e-03
 => minimum loss: 3.038e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.658e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4650, Mean_loss of pinns: 5.828e-03, loss_BC: 3.016e-05, loss_IC: 8.722e-06, loss_f: 5.789e-03
 => minimum loss: 2.570e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.154e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4660, Mean_loss of pinns: 4.802e-03, loss_BC: 2.917e-05, loss_IC: 1.407e-05, loss_f: 4.759e-03
 => minimum loss: 2.253e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.773e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4670, Mean_loss of pinns: 4.032e-03, loss_BC: 2.831e-05, loss_IC: 1.838e-05, loss_f: 3.985e-03
 => minimum loss: 1.999e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.487e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4680, Mean_loss of pinns: 3.446e-03, loss_BC: 2.675e-05, loss_IC: 2.166e-05, loss_f: 3.397e-03
 => minimum loss: 1.768e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.271e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4690, Mean_loss of pinns: 2.995e-03, loss_BC: 2.707e-05, loss_IC: 2.403e-05, loss_f: 2.944e-03
 => minimum loss: 1.635e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.104e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4700, Mean_loss of pinns: 2.638e-03, loss_BC: 2.702e-05, loss_IC: 2.575e-05, loss_f: 2.585e-03
 => minimum loss: 1.502e-04, corresponding pinn/batch index: 0000
 => maximum loss: 9.720e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4710, Mean_loss of pinns: 2.349e-03, loss_BC: 2.593e-05, loss_IC: 2.719e-05, loss_f: 2.296e-03
 => minimum loss: 1.374e-04, corresponding pinn/batch index: 0000
 => maximum loss: 8.657e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4720, Mean_loss of pinns: 2.112e-03, loss_BC: 2.598e-05, loss_IC: 2.851e-05, loss_f: 2.058e-03
 => minimum loss: 1.282e-04, corresponding pinn/batch index: 0000
 => maximum loss: 7.782e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  4724

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 3.813e-07, loss_BC: 0.000e+00, loss_IC: 3.953e-08,loss_f: 3.005e-07
pinn: 0300, Iter: 100, total_loss: 6.145e-07, loss_BC: 0.000e+00, loss_IC: 2.473e-08,loss_f: 1.590e-07
pinn: 0100, Iter: 100, total_loss: 5.069e-07, loss_BC: 0.000e+00, loss_IC: 8.576e-08,loss_f: 1.755e-07
pinn: 0200, Iter: 100, total_loss: 1.105e-06, loss_BC: 0.000e+00, loss_IC: 1.656e-07,loss_f: 7.328e-07
pinn: 0000, Iter: 200, total_loss: 2.083e-07, loss_BC: 0.000e+00, loss_IC: 4.251e-08,loss_f: 1.100e-07
pinn: 0300, Iter: 200, total_loss: 4.965e-07, loss_BC: 0.000e+00, loss_IC: 3.247e-08,loss_f: 5.494e-08
pinn: 0100, Iter: 200, total_loss: 4.188e-07, loss_BC: 0.000e+00, loss_IC: 6.196e-08,loss_f: 1.110e-07
pinn: 0200, Iter: 200, total_loss: 4.602e-07, loss_BC: 0.000e+00, loss_IC: 1.109e-07,loss_f: 1.536e-07
pinn: 0000, Iter: 300, total_loss: 1.875e-07, loss_BC: 0.000e+00, loss_IC: 4.033e-08,loss_f: 8.890e-08
pinn: 0200, Iter: 300, total_loss: 3.617e-07, loss_BC: 0.000e+00, loss_IC: 8.083e-08,loss_f: 8.487e-08
pinn: 0100, Iter: 300, total_loss: 3.885e-07, loss_BC: 0.000e+00, loss_IC: 6.117e-08,loss_f: 8.753e-08
pinn: 0300, Iter: 300, total_loss: 4.756e-07, loss_BC: 0.000e+00, loss_IC: 3.743e-08,loss_f: 4.935e-08
pinn: 0000, Iter: 400, total_loss: 1.822e-07, loss_BC: 0.000e+00, loss_IC: 4.019e-08,loss_f: 8.282e-08
pinn: 0100, Iter: 400, total_loss: 3.734e-07, loss_BC: 0.000e+00, loss_IC: 5.777e-08,loss_f: 8.381e-08
pinn: 0200, Iter: 400, total_loss: 3.450e-07, loss_BC: 0.000e+00, loss_IC: 7.833e-08,loss_f: 7.091e-08
pinn: 0300, Iter: 400, total_loss: 4.599e-07, loss_BC: 0.000e+00, loss_IC: 4.506e-08,loss_f: 4.955e-08
pinn: 0000, Iter: 500, total_loss: 1.768e-07, loss_BC: 0.000e+00, loss_IC: 3.961e-08,loss_f: 7.814e-08
pinn: 0100, Iter: 500, total_loss: 3.685e-07, loss_BC: 0.000e+00, loss_IC: 5.821e-08,loss_f: 8.192e-08
pinn: 0200, Iter: 500, total_loss: 3.227e-07, loss_BC: 0.000e+00, loss_IC: 7.327e-08,loss_f: 5.455e-08
pinn: 0300, Iter: 500, total_loss: 4.503e-07, loss_BC: 0.000e+00, loss_IC: 4.905e-08,loss_f: 5.056e-08
pinn: 0000, Iter: 600, total_loss: 1.721e-07, loss_BC: 0.000e+00, loss_IC: 3.839e-08,loss_f: 7.573e-08
pinn: 0200, Iter: 600, total_loss: 3.123e-07, loss_BC: 0.000e+00, loss_IC: 7.216e-08,loss_f: 4.568e-08
pinn: 0100, Iter: 600, total_loss: 3.586e-07, loss_BC: 0.000e+00, loss_IC: 6.026e-08,loss_f: 7.692e-08
pinn: 0300, Iter: 600, total_loss: 4.356e-07, loss_BC: 0.000e+00, loss_IC: 5.254e-08,loss_f: 4.964e-08
pinn: 0000, Iter: 700, total_loss: 1.628e-07, loss_BC: 0.000e+00, loss_IC: 3.202e-08,loss_f: 7.914e-08
pinn: 0200, Iter: 700, total_loss: 3.052e-07, loss_BC: 0.000e+00, loss_IC: 6.935e-08,loss_f: 4.288e-08
pinn: 0100, Iter: 700, total_loss: 3.520e-07, loss_BC: 0.000e+00, loss_IC: 5.972e-08,loss_f: 7.200e-08
pinn: 0300, Iter: 700, total_loss: 4.180e-07, loss_BC: 0.000e+00, loss_IC: 5.932e-08,loss_f: 4.813e-08
pinn: 0000, Iter: 800, total_loss: 1.587e-07, loss_BC: 0.000e+00, loss_IC: 2.947e-08,loss_f: 7.862e-08
pinn: 0200, Iter: 800, total_loss: 3.017e-07, loss_BC: 0.000e+00, loss_IC: 6.851e-08,loss_f: 4.140e-08
pinn: 0100, Iter: 800, total_loss: 3.413e-07, loss_BC: 0.000e+00, loss_IC: 5.555e-08,loss_f: 6.691e-08
pinn: 0300, Iter: 800, total_loss: 3.952e-07, loss_BC: 0.000e+00, loss_IC: 5.113e-08,loss_f: 5.947e-08
pinn: 0000, Iter: 900, total_loss: 1.513e-07, loss_BC: 0.000e+00, loss_IC: 2.576e-08,loss_f: 7.867e-08
pinn: 0100, Iter: 900, total_loss: 3.370e-07, loss_BC: 0.000e+00, loss_IC: 5.398e-08,loss_f: 6.611e-08
pinn: 0200, Iter: 900, total_loss: 2.982e-07, loss_BC: 0.000e+00, loss_IC: 6.778e-08,loss_f: 4.083e-08
pinn: 0300, Iter: 900, total_loss: 3.829e-07, loss_BC: 0.000e+00, loss_IC: 5.665e-08,loss_f: 7.100e-08
pinn: 0000, Iter: 1000, total_loss: 1.464e-07, loss_BC: 0.000e+00, loss_IC: 2.428e-08,loss_f: 7.645e-08
pinn: 0200, Iter: 1000, total_loss: 2.930e-07, loss_BC: 0.000e+00, loss_IC: 6.512e-08,loss_f: 4.174e-08
pinn: 0100, Iter: 1000, total_loss: 3.278e-07, loss_BC: 0.000e+00, loss_IC: 4.972e-08,loss_f: 6.546e-08
pinn: 0300, Iter: 1000, total_loss: 3.645e-07, loss_BC: 0.000e+00, loss_IC: 5.877e-08,loss_f: 7.424e-08
pinn: 0000, Iter: 1100, total_loss: 1.451e-07, loss_BC: 0.000e+00, loss_IC: 2.408e-08,loss_f: 7.442e-08
pinn: 0100, Iter: 1100, total_loss: 3.251e-07, loss_BC: 0.000e+00, loss_IC: 4.898e-08,loss_f: 6.674e-08
pinn: 0200, Iter: 1100, total_loss: 2.905e-07, loss_BC: 0.000e+00, loss_IC: 6.416e-08,loss_f: 4.290e-08
pinn: 0300, Iter: 1100, total_loss: 3.494e-07, loss_BC: 0.000e+00, loss_IC: 5.965e-08,loss_f: 8.116e-08
pinn: 0000, Iter: 1200, total_loss: 1.414e-07, loss_BC: 0.000e+00, loss_IC: 2.080e-08,loss_f: 7.633e-08
pinn: 0200, Iter: 1200, total_loss: 2.892e-07, loss_BC: 0.000e+00, loss_IC: 6.379e-08,loss_f: 4.308e-08
pinn: 0300, Iter: 1200, total_loss: 3.255e-07, loss_BC: 0.000e+00, loss_IC: 6.467e-08,loss_f: 7.692e-08
pinn: 0100, Iter: 1200, total_loss: 3.224e-07, loss_BC: 0.000e+00, loss_IC: 4.608e-08,loss_f: 6.723e-08
pinn: 0000, Iter: 1300, total_loss: 1.406e-07, loss_BC: 0.000e+00, loss_IC: 2.030e-08,loss_f: 7.635e-08
pinn: 0200, Iter: 1300, total_loss: 2.859e-07, loss_BC: 0.000e+00, loss_IC: 6.117e-08,loss_f: 4.386e-08
pinn: 0300, Iter: 1300, total_loss: 3.237e-07, loss_BC: 0.000e+00, loss_IC: 6.907e-08,loss_f: 8.422e-08
pinn: 0100, Iter: 1300, total_loss: 3.176e-07, loss_BC: 0.000e+00, loss_IC: 4.649e-08,loss_f: 6.731e-08
pinn: 0000, Iter: 1400, total_loss: 1.388e-07, loss_BC: 0.000e+00, loss_IC: 1.822e-08,loss_f: 7.799e-08
pinn: 0300, Iter: 1400, total_loss: 3.148e-07, loss_BC: 0.000e+00, loss_IC: 7.083e-08,loss_f: 8.199e-08
pinn: 0200, Iter: 1400, total_loss: 2.842e-07, loss_BC: 0.000e+00, loss_IC: 6.044e-08,loss_f: 4.533e-08
pinn: 0100, Iter: 1400, total_loss: 3.128e-07, loss_BC: 0.000e+00, loss_IC: 4.229e-08,loss_f: 6.901e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4724, Mean_loss of pinns: 2.620e-07, loss_BC: 0.000e+00, loss_IC: 4.807e-08, loss_f: 6.898e-08
 => minimum loss: 1.382e-07, corresponding pinn index: 0000
 => maximum loss: 3.132e-07, corresponding pinn  index: 0300

 max_loss: 4.950e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4726, total_loss: 3.512e-05, loss_BC: 3.486e-05, loss_IC: 4.899e-08, loss_f: 7.041e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.44000, t_max: 0.45000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4727 0 1

 -------------------------------------------------------------
  -----  Epoch: 4727 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.44000, t_max: 0.45000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4727 !!! 


==> Epoch: 4730, Mean_loss of pinns: 6.711e-04, loss_BC: 3.722e-05, loss_IC: 2.402e-07, loss_f: 6.334e-04
 => minimum loss: 2.593e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.453e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4740, Mean_loss of pinns: 5.171e-04, loss_BC: 3.458e-05, loss_IC: 3.865e-06, loss_f: 4.785e-04
 => minimum loss: 2.180e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.086e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4750, Mean_loss of pinns: 4.097e-04, loss_BC: 3.224e-05, loss_IC: 8.787e-06, loss_f: 3.685e-04
 => minimum loss: 1.854e-04, corresponding pinn/batch index: 0000
 => maximum loss: 8.371e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4760, Mean_loss of pinns: 3.362e-04, loss_BC: 3.101e-05, loss_IC: 1.189e-05, loss_f: 2.931e-04
 => minimum loss: 1.614e-04, corresponding pinn/batch index: 0000
 => maximum loss: 6.756e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4770, Mean_loss of pinns: 2.832e-04, loss_BC: 2.959e-05, loss_IC: 1.255e-05, loss_f: 2.408e-04
 => minimum loss: 1.394e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.671e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4780, Mean_loss of pinns: 2.427e-04, loss_BC: 2.804e-05, loss_IC: 1.182e-05, loss_f: 2.026e-04
 => minimum loss: 1.200e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.881e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4790, Mean_loss of pinns: 2.114e-04, loss_BC: 2.712e-05, loss_IC: 1.045e-05, loss_f: 1.736e-04
 => minimum loss: 1.073e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.215e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4800, Mean_loss of pinns: 1.854e-04, loss_BC: 2.528e-05, loss_IC: 9.011e-06, loss_f: 1.510e-04
 => minimum loss: 9.543e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.705e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4810, Mean_loss of pinns: 1.649e-04, loss_BC: 2.401e-05, loss_IC: 7.785e-06, loss_f: 1.329e-04
 => minimum loss: 8.737e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.271e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4820, Mean_loss of pinns: 1.486e-04, loss_BC: 2.331e-05, loss_IC: 6.912e-06, loss_f: 1.181e-04
 => minimum loss: 8.085e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.912e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  4826

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 5.987e-07, loss_BC: 0.000e+00, loss_IC: 2.440e-08,loss_f: 4.046e-07
pinn: 0200, Iter: 100, total_loss: 3.861e-07, loss_BC: 0.000e+00, loss_IC: 6.169e-08,loss_f: 1.251e-07
pinn: 0000, Iter: 100, total_loss: 6.037e-07, loss_BC: 0.000e+00, loss_IC: 4.107e-08,loss_f: 3.535e-07
pinn: 0100, Iter: 100, total_loss: 4.297e-07, loss_BC: 0.000e+00, loss_IC: 3.821e-08,loss_f: 1.576e-07
pinn: 0200, Iter: 200, total_loss: 3.172e-07, loss_BC: 0.000e+00, loss_IC: 4.559e-08,loss_f: 7.507e-08
pinn: 0000, Iter: 200, total_loss: 3.452e-07, loss_BC: 0.000e+00, loss_IC: 4.154e-08,loss_f: 9.847e-08
pinn: 0100, Iter: 200, total_loss: 3.624e-07, loss_BC: 0.000e+00, loss_IC: 3.115e-08,loss_f: 9.867e-08
pinn: 0300, Iter: 200, total_loss: 3.515e-07, loss_BC: 0.000e+00, loss_IC: 2.056e-08,loss_f: 1.424e-07
pinn: 0200, Iter: 300, total_loss: 3.041e-07, loss_BC: 0.000e+00, loss_IC: 4.501e-08,loss_f: 6.502e-08
pinn: 0100, Iter: 300, total_loss: 3.494e-07, loss_BC: 0.000e+00, loss_IC: 2.910e-08,loss_f: 8.848e-08
pinn: 0000, Iter: 300, total_loss: 3.131e-07, loss_BC: 0.000e+00, loss_IC: 3.376e-08,loss_f: 7.354e-08
pinn: 0300, Iter: 300, total_loss: 3.202e-07, loss_BC: 0.000e+00, loss_IC: 1.702e-08,loss_f: 1.214e-07
pinn: 0200, Iter: 400, total_loss: 2.928e-07, loss_BC: 0.000e+00, loss_IC: 4.076e-08,loss_f: 5.920e-08
pinn: 0100, Iter: 400, total_loss: 3.407e-07, loss_BC: 0.000e+00, loss_IC: 2.975e-08,loss_f: 8.428e-08
pinn: 0300, Iter: 400, total_loss: 2.976e-07, loss_BC: 0.000e+00, loss_IC: 1.674e-08,loss_f: 1.076e-07
pinn: 0000, Iter: 400, total_loss: 3.022e-07, loss_BC: 0.000e+00, loss_IC: 3.316e-08,loss_f: 6.519e-08
pinn: 0100, Iter: 500, total_loss: 3.321e-07, loss_BC: 0.000e+00, loss_IC: 3.186e-08,loss_f: 7.805e-08
pinn: 0200, Iter: 500, total_loss: 2.874e-07, loss_BC: 0.000e+00, loss_IC: 4.077e-08,loss_f: 5.651e-08
pinn: 0300, Iter: 500, total_loss: 2.710e-07, loss_BC: 0.000e+00, loss_IC: 1.834e-08,loss_f: 9.008e-08
pinn: 0000, Iter: 500, total_loss: 2.970e-07, loss_BC: 0.000e+00, loss_IC: 3.054e-08,loss_f: 6.261e-08
pinn: 0100, Iter: 600, total_loss: 3.250e-07, loss_BC: 0.000e+00, loss_IC: 3.307e-08,loss_f: 7.315e-08
pinn: 0200, Iter: 600, total_loss: 2.842e-07, loss_BC: 0.000e+00, loss_IC: 4.065e-08,loss_f: 5.485e-08
pinn: 0300, Iter: 600, total_loss: 2.451e-07, loss_BC: 0.000e+00, loss_IC: 1.601e-08,loss_f: 7.076e-08
pinn: 0000, Iter: 600, total_loss: 2.865e-07, loss_BC: 0.000e+00, loss_IC: 2.856e-08,loss_f: 5.693e-08
pinn: 0100, Iter: 700, total_loss: 3.195e-07, loss_BC: 0.000e+00, loss_IC: 3.354e-08,loss_f: 6.928e-08
pinn: 0300, Iter: 700, total_loss: 2.371e-07, loss_BC: 0.000e+00, loss_IC: 1.481e-08,loss_f: 6.673e-08
pinn: 0200, Iter: 700, total_loss: 2.788e-07, loss_BC: 0.000e+00, loss_IC: 3.976e-08,loss_f: 5.299e-08
pinn: 0000, Iter: 700, total_loss: 2.759e-07, loss_BC: 0.000e+00, loss_IC: 2.957e-08,loss_f: 5.132e-08
pinn: 0100, Iter: 800, total_loss: 3.160e-07, loss_BC: 0.000e+00, loss_IC: 3.233e-08,loss_f: 6.793e-08
pinn: 0200, Iter: 800, total_loss: 2.761e-07, loss_BC: 0.000e+00, loss_IC: 3.794e-08,loss_f: 5.312e-08
pinn: 0300, Iter: 800, total_loss: 2.325e-07, loss_BC: 0.000e+00, loss_IC: 1.426e-08,loss_f: 6.541e-08
pinn: 0000, Iter: 800, total_loss: 2.712e-07, loss_BC: 0.000e+00, loss_IC: 2.940e-08,loss_f: 5.027e-08
pinn: 0100, Iter: 900, total_loss: 3.118e-07, loss_BC: 0.000e+00, loss_IC: 2.955e-08,loss_f: 6.685e-08
pinn: 0200, Iter: 900, total_loss: 2.732e-07, loss_BC: 0.000e+00, loss_IC: 3.586e-08,loss_f: 5.326e-08
pinn: 0300, Iter: 900, total_loss: 2.275e-07, loss_BC: 0.000e+00, loss_IC: 1.353e-08,loss_f: 6.347e-08
pinn: 0000, Iter: 900, total_loss: 2.683e-07, loss_BC: 0.000e+00, loss_IC: 2.864e-08,loss_f: 5.239e-08
pinn: 0100, Iter: 1000, total_loss: 3.093e-07, loss_BC: 0.000e+00, loss_IC: 2.831e-08,loss_f: 6.692e-08
pinn: 0300, Iter: 1000, total_loss: 2.215e-07, loss_BC: 0.000e+00, loss_IC: 1.240e-08,loss_f: 6.122e-08
pinn: 0200, Iter: 1000, total_loss: 2.703e-07, loss_BC: 0.000e+00, loss_IC: 3.536e-08,loss_f: 5.406e-08
pinn: 0000, Iter: 1000, total_loss: 2.653e-07, loss_BC: 0.000e+00, loss_IC: 2.889e-08,loss_f: 5.089e-08
pinn: 0100, Iter: 1100, total_loss: 3.037e-07, loss_BC: 0.000e+00, loss_IC: 2.787e-08,loss_f: 6.689e-08
pinn: 0300, Iter: 1100, total_loss: 2.134e-07, loss_BC: 0.000e+00, loss_IC: 1.585e-08,loss_f: 5.731e-08
pinn: 0200, Iter: 1100, total_loss: 2.666e-07, loss_BC: 0.000e+00, loss_IC: 3.246e-08,loss_f: 5.509e-08
pinn: 0000, Iter: 1100, total_loss: 2.599e-07, loss_BC: 0.000e+00, loss_IC: 2.983e-08,loss_f: 4.989e-08
pinn: 0100, Iter: 1200, total_loss: 2.997e-07, loss_BC: 0.000e+00, loss_IC: 2.757e-08,loss_f: 6.902e-08
pinn: 0300, Iter: 1200, total_loss: 2.093e-07, loss_BC: 0.000e+00, loss_IC: 1.593e-08,loss_f: 5.599e-08
pinn: 0200, Iter: 1200, total_loss: 2.602e-07, loss_BC: 0.000e+00, loss_IC: 3.023e-08,loss_f: 5.663e-08
pinn: 0000, Iter: 1200, total_loss: 2.543e-07, loss_BC: 0.000e+00, loss_IC: 2.862e-08,loss_f: 4.965e-08
pinn: 0100, Iter: 1300, total_loss: 2.967e-07, loss_BC: 0.000e+00, loss_IC: 2.763e-08,loss_f: 6.870e-08
pinn: 0300, Iter: 1300, total_loss: 2.075e-07, loss_BC: 0.000e+00, loss_IC: 1.601e-08,loss_f: 5.587e-08
pinn: 0200, Iter: 1300, total_loss: 2.575e-07, loss_BC: 0.000e+00, loss_IC: 2.991e-08,loss_f: 5.815e-08
pinn: 0000, Iter: 1300, total_loss: 2.532e-07, loss_BC: 0.000e+00, loss_IC: 2.976e-08,loss_f: 4.975e-08
pinn: 0100, Iter: 1400, total_loss: 2.841e-07, loss_BC: 0.000e+00, loss_IC: 2.665e-08,loss_f: 7.741e-08
pinn: 0300, Iter: 1400, total_loss: 2.041e-07, loss_BC: 0.000e+00, loss_IC: 1.500e-08,loss_f: 5.676e-08
pinn: 0200, Iter: 1400, total_loss: 2.564e-07, loss_BC: 0.000e+00, loss_IC: 2.955e-08,loss_f: 5.758e-08
pinn: 0000, Iter: 1400, total_loss: 2.492e-07, loss_BC: 0.000e+00, loss_IC: 2.872e-08,loss_f: 5.025e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4826, Mean_loss of pinns: 2.481e-07, loss_BC: 0.000e+00, loss_IC: 2.533e-08, loss_f: 6.005e-08
 => minimum loss: 2.036e-07, corresponding pinn index: 0300
 => maximum loss: 2.839e-07, corresponding pinn  index: 0100

 max_loss: 5.664e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4828, total_loss: 3.634e-05, loss_BC: 3.609e-05, loss_IC: 2.634e-08, loss_f: 6.089e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.45000, t_max: 0.46000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4829 0 1

 -------------------------------------------------------------
  -----  Epoch: 4829 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.45000, t_max: 0.46000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4829 !!! 


==> Epoch: 4830, Mean_loss of pinns: 5.500e-04, loss_BC: 3.882e-05, loss_IC: 3.137e-08, loss_f: 5.109e-04
 => minimum loss: 2.281e-04, corresponding pinn/batch index: 0000
 => maximum loss: 8.943e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4840, Mean_loss of pinns: 4.232e-04, loss_BC: 3.681e-05, loss_IC: 3.199e-06, loss_f: 3.829e-04
 => minimum loss: 2.000e-04, corresponding pinn/batch index: 0200
 => maximum loss: 6.641e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4850, Mean_loss of pinns: 3.397e-04, loss_BC: 3.448e-05, loss_IC: 7.499e-06, loss_f: 2.974e-04
 => minimum loss: 1.687e-04, corresponding pinn/batch index: 0200
 => maximum loss: 5.224e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4860, Mean_loss of pinns: 2.820e-04, loss_BC: 3.216e-05, loss_IC: 1.046e-05, loss_f: 2.391e-04
 => minimum loss: 1.435e-04, corresponding pinn/batch index: 0200
 => maximum loss: 4.314e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4870, Mean_loss of pinns: 2.393e-04, loss_BC: 3.060e-05, loss_IC: 1.070e-05, loss_f: 1.977e-04
 => minimum loss: 1.253e-04, corresponding pinn/batch index: 0200
 => maximum loss: 3.665e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4880, Mean_loss of pinns: 2.051e-04, loss_BC: 2.835e-05, loss_IC: 9.480e-06, loss_f: 1.670e-04
 => minimum loss: 1.090e-04, corresponding pinn/batch index: 0200
 => maximum loss: 3.153e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4890, Mean_loss of pinns: 1.777e-04, loss_BC: 2.591e-05, loss_IC: 7.841e-06, loss_f: 1.436e-04
 => minimum loss: 9.468e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.714e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4900, Mean_loss of pinns: 1.562e-04, loss_BC: 2.427e-05, loss_IC: 6.394e-06, loss_f: 1.253e-04
 => minimum loss: 8.423e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.375e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4910, Mean_loss of pinns: 1.390e-04, loss_BC: 2.299e-05, loss_IC: 5.430e-06, loss_f: 1.103e-04
 => minimum loss: 7.575e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.089e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4920, Mean_loss of pinns: 1.247e-04, loss_BC: 2.171e-05, loss_IC: 4.945e-06, loss_f: 9.777e-05
 => minimum loss: 6.976e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.853e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0300

 !!! Scipy optimize: !!! - Epoch:  4928

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0000, 0100, 0300


pinn: 0000, Iter: 100, total_loss: 5.003e-07, loss_BC: 0.000e+00, loss_IC: 3.258e-08,loss_f: 2.326e-07
pinn: 0300, Iter: 100, total_loss: 3.812e-07, loss_BC: 0.000e+00, loss_IC: 2.998e-08,loss_f: 2.048e-07
pinn: 0100, Iter: 100, total_loss: 6.277e-07, loss_BC: 0.000e+00, loss_IC: 2.422e-08,loss_f: 2.176e-07
pinn: 0100, Iter: 200, total_loss: 4.963e-07, loss_BC: 0.000e+00, loss_IC: 2.175e-08,loss_f: 9.780e-08
pinn: 0000, Iter: 200, total_loss: 3.566e-07, loss_BC: 0.000e+00, loss_IC: 3.435e-08,loss_f: 9.014e-08
pinn: 0300, Iter: 200, total_loss: 2.247e-07, loss_BC: 0.000e+00, loss_IC: 1.972e-08,loss_f: 6.426e-08
pinn: 0100, Iter: 300, total_loss: 4.632e-07, loss_BC: 0.000e+00, loss_IC: 2.180e-08,loss_f: 7.769e-08
pinn: 0000, Iter: 300, total_loss: 3.350e-07, loss_BC: 0.000e+00, loss_IC: 2.992e-08,loss_f: 7.373e-08
pinn: 0300, Iter: 300, total_loss: 1.976e-07, loss_BC: 0.000e+00, loss_IC: 1.843e-08,loss_f: 4.536e-08
pinn: 0100, Iter: 400, total_loss: 4.514e-07, loss_BC: 0.000e+00, loss_IC: 2.800e-08,loss_f: 7.723e-08
pinn: 0000, Iter: 400, total_loss: 3.296e-07, loss_BC: 0.000e+00, loss_IC: 3.012e-08,loss_f: 6.977e-08
pinn: 0300, Iter: 400, total_loss: 1.875e-07, loss_BC: 0.000e+00, loss_IC: 2.038e-08,loss_f: 3.802e-08
pinn: 0100, Iter: 500, total_loss: 4.400e-07, loss_BC: 0.000e+00, loss_IC: 3.344e-08,loss_f: 7.184e-08
pinn: 0000, Iter: 500, total_loss: 3.228e-07, loss_BC: 0.000e+00, loss_IC: 2.897e-08,loss_f: 6.649e-08
pinn: 0300, Iter: 500, total_loss: 1.819e-07, loss_BC: 0.000e+00, loss_IC: 2.019e-08,loss_f: 3.491e-08
pinn: 0100, Iter: 600, total_loss: 4.273e-07, loss_BC: 0.000e+00, loss_IC: 4.025e-08,loss_f: 6.436e-08
pinn: 0000, Iter: 600, total_loss: 3.190e-07, loss_BC: 0.000e+00, loss_IC: 2.858e-08,loss_f: 6.519e-08
pinn: 0300, Iter: 600, total_loss: 1.808e-07, loss_BC: 0.000e+00, loss_IC: 1.927e-08,loss_f: 3.418e-08
pinn: 0000, Iter: 700, total_loss: 3.123e-07, loss_BC: 0.000e+00, loss_IC: 2.841e-08,loss_f: 6.269e-08
pinn: 0100, Iter: 700, total_loss: 4.190e-07, loss_BC: 0.000e+00, loss_IC: 4.206e-08,loss_f: 6.055e-08
pinn: 0300, Iter: 700, total_loss: 1.789e-07, loss_BC: 0.000e+00, loss_IC: 1.976e-08,loss_f: 3.280e-08
pinn: 0100, Iter: 800, total_loss: 4.129e-07, loss_BC: 0.000e+00, loss_IC: 4.060e-08,loss_f: 6.211e-08
pinn: 0000, Iter: 800, total_loss: 3.092e-07, loss_BC: 0.000e+00, loss_IC: 2.770e-08,loss_f: 6.319e-08
pinn: 0300, Iter: 800, total_loss: 1.764e-07, loss_BC: 0.000e+00, loss_IC: 2.157e-08,loss_f: 3.117e-08
pinn: 0100, Iter: 900, total_loss: 4.097e-07, loss_BC: 0.000e+00, loss_IC: 3.834e-08,loss_f: 6.174e-08
pinn: 0000, Iter: 900, total_loss: 2.994e-07, loss_BC: 0.000e+00, loss_IC: 2.691e-08,loss_f: 6.393e-08
pinn: 0300, Iter: 900, total_loss: 1.751e-07, loss_BC: 0.000e+00, loss_IC: 2.187e-08,loss_f: 3.062e-08
pinn: 0100, Iter: 1000, total_loss: 4.016e-07, loss_BC: 0.000e+00, loss_IC: 3.730e-08,loss_f: 6.537e-08
pinn: 0000, Iter: 1000, total_loss: 2.934e-07, loss_BC: 0.000e+00, loss_IC: 2.662e-08,loss_f: 6.388e-08
pinn: 0300, Iter: 1000, total_loss: 1.709e-07, loss_BC: 0.000e+00, loss_IC: 2.118e-08,loss_f: 3.007e-08
pinn: 0100, Iter: 1100, total_loss: 4.134e-07, loss_BC: 0.000e+00, loss_IC: 4.706e-08,loss_f: 8.783e-08
pinn: 0000, Iter: 1100, total_loss: 2.866e-07, loss_BC: 0.000e+00, loss_IC: 3.038e-08,loss_f: 6.307e-08
pinn: 0300, Iter: 1100, total_loss: 1.661e-07, loss_BC: 0.000e+00, loss_IC: 2.301e-08,loss_f: 2.884e-08
pinn: 0000, Iter: 1200, total_loss: 2.796e-07, loss_BC: 0.000e+00, loss_IC: 3.146e-08,loss_f: 6.333e-08
pinn: 0100, Iter: 1200, total_loss: 3.845e-07, loss_BC: 0.000e+00, loss_IC: 3.842e-08,loss_f: 6.754e-08
pinn: 0300, Iter: 1200, total_loss: 1.649e-07, loss_BC: 0.000e+00, loss_IC: 2.285e-08,loss_f: 2.913e-08
pinn: 0000, Iter: 1300, total_loss: 2.726e-07, loss_BC: 0.000e+00, loss_IC: 3.158e-08,loss_f: 6.501e-08
pinn: 0100, Iter: 1300, total_loss: 3.697e-07, loss_BC: 0.000e+00, loss_IC: 4.199e-08,loss_f: 7.303e-08
pinn: 0300, Iter: 1300, total_loss: 1.633e-07, loss_BC: 0.000e+00, loss_IC: 2.290e-08,loss_f: 2.911e-08
pinn: 0000, Iter: 1400, total_loss: 2.682e-07, loss_BC: 0.000e+00, loss_IC: 3.159e-08,loss_f: 6.598e-08
pinn: 0100, Iter: 1400, total_loss: 3.651e-07, loss_BC: 0.000e+00, loss_IC: 4.650e-08,loss_f: 7.750e-08
pinn: 0300, Iter: 1400, total_loss: 1.605e-07, loss_BC: 0.000e+00, loss_IC: 2.396e-08,loss_f: 2.964e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 4928, Mean_loss of pinns: 2.612e-07, loss_BC: 0.000e+00, loss_IC: 3.462e-08, loss_f: 5.790e-08
 => minimum loss: 1.590e-07, corresponding pinn index: 0300
 => maximum loss: 3.570e-07, corresponding pinn  index: 0100

==> Epoch: 4930, Mean_loss of pinns: 4.289e-05, loss_BC: 3.178e-05, loss_IC: 1.415e-06, loss_f: 9.486e-06
 => minimum loss: 1.379e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.448e-05, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.448e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 4930, total_loss: 4.289e-05, loss_BC: 3.178e-05, loss_IC: 1.415e-06, loss_f: 9.486e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.46000, t_max: 0.47000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  4931 0 1

 -------------------------------------------------------------
  -----  Epoch: 4931 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.46000, t_max: 0.47000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  4931 !!! 


==> Epoch: 4940, Mean_loss of pinns: 5.339e-03, loss_BC: 3.056e-05, loss_IC: 1.659e-06, loss_f: 5.307e-03
 => minimum loss: 1.078e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.033e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4950, Mean_loss of pinns: 4.505e-03, loss_BC: 2.886e-05, loss_IC: 4.801e-06, loss_f: 4.471e-03
 => minimum loss: 9.824e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.722e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4960, Mean_loss of pinns: 3.798e-03, loss_BC: 2.605e-05, loss_IC: 8.561e-06, loss_f: 3.763e-03
 => minimum loss: 9.227e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.453e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4970, Mean_loss of pinns: 3.202e-03, loss_BC: 2.518e-05, loss_IC: 1.239e-05, loss_f: 3.164e-03
 => minimum loss: 9.147e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.225e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4980, Mean_loss of pinns: 2.706e-03, loss_BC: 2.445e-05, loss_IC: 1.662e-05, loss_f: 2.665e-03
 => minimum loss: 8.974e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.034e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 4990, Mean_loss of pinns: 2.299e-03, loss_BC: 2.469e-05, loss_IC: 2.137e-05, loss_f: 2.253e-03
 => minimum loss: 8.946e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.768e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5000, Mean_loss of pinns: 1.970e-03, loss_BC: 2.654e-05, loss_IC: 2.685e-05, loss_f: 1.917e-03
 => minimum loss: 8.967e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.493e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5010, Mean_loss of pinns: 1.705e-03, loss_BC: 2.775e-05, loss_IC: 3.276e-05, loss_f: 1.644e-03
 => minimum loss: 8.901e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.462e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5020, Mean_loss of pinns: 1.491e-03, loss_BC: 2.926e-05, loss_IC: 3.858e-05, loss_f: 1.423e-03
 => minimum loss: 8.245e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.634e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5030, Mean_loss of pinns: 1.319e-03, loss_BC: 3.082e-05, loss_IC: 4.375e-05, loss_f: 1.244e-03
 => minimum loss: 7.427e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.961e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  5030

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 3.217e-07, loss_BC: 0.000e+00, loss_IC: 3.118e-08,loss_f: 2.486e-07
pinn: 0000, Iter: 100, total_loss: 4.339e-07, loss_BC: 0.000e+00, loss_IC: 1.467e-08,loss_f: 2.353e-07
pinn: 0100, Iter: 100, total_loss: 3.974e-07, loss_BC: 0.000e+00, loss_IC: 3.959e-08,loss_f: 1.769e-07
pinn: 0200, Iter: 100, total_loss: 9.738e-07, loss_BC: 0.000e+00, loss_IC: 1.282e-07,loss_f: 7.383e-07
pinn: 0000, Iter: 200, total_loss: 2.915e-07, loss_BC: 0.000e+00, loss_IC: 1.879e-08,loss_f: 9.230e-08
pinn: 0100, Iter: 200, total_loss: 3.161e-07, loss_BC: 0.000e+00, loss_IC: 2.689e-08,loss_f: 1.020e-07
pinn: 0200, Iter: 200, total_loss: 3.812e-07, loss_BC: 0.000e+00, loss_IC: 1.402e-07,loss_f: 1.369e-07
pinn: 0300, Iter: 200, total_loss: 1.435e-07, loss_BC: 0.000e+00, loss_IC: 3.200e-08,loss_f: 7.096e-08
pinn: 0000, Iter: 300, total_loss: 2.607e-07, loss_BC: 0.000e+00, loss_IC: 1.606e-08,loss_f: 6.584e-08
pinn: 0100, Iter: 300, total_loss: 2.830e-07, loss_BC: 0.000e+00, loss_IC: 2.671e-08,loss_f: 7.576e-08
pinn: 0200, Iter: 300, total_loss: 2.530e-07, loss_BC: 0.000e+00, loss_IC: 6.461e-08,loss_f: 8.239e-08
pinn: 0300, Iter: 300, total_loss: 1.217e-07, loss_BC: 0.000e+00, loss_IC: 2.267e-08,loss_f: 5.907e-08
pinn: 0200, Iter: 400, total_loss: 2.143e-07, loss_BC: 0.000e+00, loss_IC: 4.246e-08,loss_f: 6.137e-08
pinn: 0000, Iter: 400, total_loss: 2.502e-07, loss_BC: 0.000e+00, loss_IC: 1.656e-08,loss_f: 5.600e-08
pinn: 0100, Iter: 400, total_loss: 2.757e-07, loss_BC: 0.000e+00, loss_IC: 2.566e-08,loss_f: 7.343e-08
pinn: 0300, Iter: 400, total_loss: 1.139e-07, loss_BC: 0.000e+00, loss_IC: 2.144e-08,loss_f: 5.304e-08
pinn: 0200, Iter: 500, total_loss: 1.908e-07, loss_BC: 0.000e+00, loss_IC: 2.714e-08,loss_f: 5.047e-08
pinn: 0100, Iter: 500, total_loss: 2.685e-07, loss_BC: 0.000e+00, loss_IC: 2.571e-08,loss_f: 7.112e-08
pinn: 0300, Iter: 500, total_loss: 1.086e-07, loss_BC: 0.000e+00, loss_IC: 1.914e-08,loss_f: 5.006e-08
pinn: 0000, Iter: 500, total_loss: 2.425e-07, loss_BC: 0.000e+00, loss_IC: 1.736e-08,loss_f: 4.936e-08
pinn: 0200, Iter: 600, total_loss: 1.829e-07, loss_BC: 0.000e+00, loss_IC: 2.285e-08,loss_f: 4.654e-08
pinn: 0300, Iter: 600, total_loss: 1.032e-07, loss_BC: 0.000e+00, loss_IC: 1.565e-08,loss_f: 4.789e-08
pinn: 0100, Iter: 600, total_loss: 2.598e-07, loss_BC: 0.000e+00, loss_IC: 2.390e-08,loss_f: 6.865e-08
pinn: 0000, Iter: 600, total_loss: 2.372e-07, loss_BC: 0.000e+00, loss_IC: 1.727e-08,loss_f: 4.616e-08
pinn: 0300, Iter: 700, total_loss: 9.996e-08, loss_BC: 0.000e+00, loss_IC: 1.408e-08,loss_f: 4.609e-08
pinn: 0100, Iter: 700, total_loss: 2.574e-07, loss_BC: 0.000e+00, loss_IC: 2.297e-08,loss_f: 6.874e-08
pinn: 0200, Iter: 700, total_loss: 1.778e-07, loss_BC: 0.000e+00, loss_IC: 2.166e-08,loss_f: 4.278e-08
pinn: 0000, Iter: 700, total_loss: 2.320e-07, loss_BC: 0.000e+00, loss_IC: 1.613e-08,loss_f: 4.435e-08
pinn: 0100, Iter: 800, total_loss: 2.501e-07, loss_BC: 0.000e+00, loss_IC: 2.158e-08,loss_f: 6.264e-08
pinn: 0300, Iter: 800, total_loss: 9.494e-08, loss_BC: 0.000e+00, loss_IC: 1.194e-08,loss_f: 4.299e-08
pinn: 0000, Iter: 800, total_loss: 2.253e-07, loss_BC: 0.000e+00, loss_IC: 1.690e-08,loss_f: 4.328e-08
pinn: 0200, Iter: 800, total_loss: 1.747e-07, loss_BC: 0.000e+00, loss_IC: 2.160e-08,loss_f: 4.008e-08
pinn: 0100, Iter: 900, total_loss: 2.478e-07, loss_BC: 0.000e+00, loss_IC: 2.161e-08,loss_f: 6.324e-08
pinn: 0300, Iter: 900, total_loss: 9.317e-08, loss_BC: 0.000e+00, loss_IC: 1.087e-08,loss_f: 4.225e-08
pinn: 0000, Iter: 900, total_loss: 2.235e-07, loss_BC: 0.000e+00, loss_IC: 1.662e-08,loss_f: 4.309e-08
pinn: 0200, Iter: 900, total_loss: 1.706e-07, loss_BC: 0.000e+00, loss_IC: 2.197e-08,loss_f: 3.639e-08
pinn: 0300, Iter: 1000, total_loss: 9.151e-08, loss_BC: 0.000e+00, loss_IC: 9.666e-09,loss_f: 4.191e-08
pinn: 0100, Iter: 1000, total_loss: 2.459e-07, loss_BC: 0.000e+00, loss_IC: 2.120e-08,loss_f: 6.221e-08
pinn: 0200, Iter: 1000, total_loss: 1.674e-07, loss_BC: 0.000e+00, loss_IC: 2.306e-08,loss_f: 3.397e-08
pinn: 0000, Iter: 1000, total_loss: 2.219e-07, loss_BC: 0.000e+00, loss_IC: 1.770e-08,loss_f: 4.231e-08
pinn: 0300, Iter: 1100, total_loss: 9.057e-08, loss_BC: 0.000e+00, loss_IC: 9.441e-09,loss_f: 4.143e-08
pinn: 0100, Iter: 1100, total_loss: 2.437e-07, loss_BC: 0.000e+00, loss_IC: 2.054e-08,loss_f: 6.348e-08
pinn: 0200, Iter: 1100, total_loss: 1.667e-07, loss_BC: 0.000e+00, loss_IC: 2.307e-08,loss_f: 3.351e-08
pinn: 0000, Iter: 1100, total_loss: 2.165e-07, loss_BC: 0.000e+00, loss_IC: 2.020e-08,loss_f: 4.250e-08
pinn: 0300, Iter: 1200, total_loss: 9.045e-08, loss_BC: 0.000e+00, loss_IC: 9.347e-09,loss_f: 4.137e-08
pinn: 0200, Iter: 1200, total_loss: 1.662e-07, loss_BC: 0.000e+00, loss_IC: 2.318e-08,loss_f: 3.323e-08
pinn: 0100, Iter: 1200, total_loss: 2.354e-07, loss_BC: 0.000e+00, loss_IC: 2.025e-08,loss_f: 6.468e-08
pinn: 0000, Iter: 1200, total_loss: 2.145e-07, loss_BC: 0.000e+00, loss_IC: 2.063e-08,loss_f: 4.333e-08
pinn: 0300, Iter: 1300, total_loss: 8.970e-08, loss_BC: 0.000e+00, loss_IC: 8.824e-09,loss_f: 4.123e-08
pinn: 0200, Iter: 1300, total_loss: 1.655e-07, loss_BC: 0.000e+00, loss_IC: 2.243e-08,loss_f: 3.343e-08
pinn: 0100, Iter: 1300, total_loss: 2.345e-07, loss_BC: 0.000e+00, loss_IC: 2.006e-08,loss_f: 6.506e-08
pinn: 0000, Iter: 1300, total_loss: 2.114e-07, loss_BC: 0.000e+00, loss_IC: 2.100e-08,loss_f: 4.306e-08
pinn: 0300, Iter: 1400, total_loss: 8.944e-08, loss_BC: 0.000e+00, loss_IC: 8.965e-09,loss_f: 4.095e-08
pinn: 0200, Iter: 1400, total_loss: 1.641e-07, loss_BC: 0.000e+00, loss_IC: 2.147e-08,loss_f: 3.331e-08
pinn: 0100, Iter: 1400, total_loss: 2.279e-07, loss_BC: 0.000e+00, loss_IC: 1.991e-08,loss_f: 6.289e-08
pinn: 0000, Iter: 1400, total_loss: 2.100e-07, loss_BC: 0.000e+00, loss_IC: 2.005e-08,loss_f: 4.386e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5030, Mean_loss of pinns: 1.726e-07, loss_BC: 0.000e+00, loss_IC: 1.747e-08, loss_f: 4.527e-08
 => minimum loss: 8.911e-08, corresponding pinn index: 0300
 => maximum loss: 2.273e-07, corresponding pinn  index: 0100

 max_loss: 5.828e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5032, total_loss: 3.344e-05, loss_BC: 3.326e-05, loss_IC: 2.009e-08, loss_f: 4.637e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.47000, t_max: 0.48000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5033 0 1

 -------------------------------------------------------------
  -----  Epoch: 5033 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.47000, t_max: 0.48000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5033 !!! 


==> Epoch: 5040, Mean_loss of pinns: 2.794e-04, loss_BC: 3.289e-05, loss_IC: 1.184e-06, loss_f: 2.451e-04
 => minimum loss: 1.479e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.214e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5050, Mean_loss of pinns: 2.216e-04, loss_BC: 2.930e-05, loss_IC: 3.966e-06, loss_f: 1.882e-04
 => minimum loss: 1.301e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.997e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5060, Mean_loss of pinns: 1.828e-04, loss_BC: 2.666e-05, loss_IC: 5.433e-06, loss_f: 1.505e-04
 => minimum loss: 1.146e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.273e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5070, Mean_loss of pinns: 1.533e-04, loss_BC: 2.387e-05, loss_IC: 5.450e-06, loss_f: 1.238e-04
 => minimum loss: 9.915e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.757e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5080, Mean_loss of pinns: 1.315e-04, loss_BC: 2.262e-05, loss_IC: 4.955e-06, loss_f: 1.037e-04
 => minimum loss: 8.989e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.353e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5090, Mean_loss of pinns: 1.135e-04, loss_BC: 2.050e-05, loss_IC: 4.590e-06, loss_f: 8.821e-05
 => minimum loss: 8.005e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.021e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5100, Mean_loss of pinns: 9.994e-05, loss_BC: 1.927e-05, loss_IC: 4.413e-06, loss_f: 7.609e-05
 => minimum loss: 7.324e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.764e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5110, Mean_loss of pinns: 8.947e-05, loss_BC: 1.852e-05, loss_IC: 4.343e-06, loss_f: 6.644e-05
 => minimum loss: 6.434e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.552e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0300

==> Epoch: 5120, Mean_loss of pinns: 8.136e-05, loss_BC: 1.819e-05, loss_IC: 4.376e-06, loss_f: 5.862e-05
 => minimum loss: 5.736e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.393e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0300

==> Epoch: 5130, Mean_loss of pinns: 7.452e-05, loss_BC: 1.765e-05, loss_IC: 4.479e-06, loss_f: 5.222e-05
 => minimum loss: 5.183e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.249e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0300

 !!! Scipy optimize: !!! - Epoch:  5132

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0300


pinn: 0300, Iter: 100, total_loss: 5.881e-07, loss_BC: 0.000e+00, loss_IC: 5.444e-08,loss_f: 2.359e-07
pinn: 0300, Iter: 200, total_loss: 3.522e-07, loss_BC: 0.000e+00, loss_IC: 1.686e-08,loss_f: 5.882e-08
pinn: 0300, Iter: 300, total_loss: 3.231e-07, loss_BC: 0.000e+00, loss_IC: 1.593e-08,loss_f: 4.099e-08
pinn: 0300, Iter: 400, total_loss: 3.134e-07, loss_BC: 0.000e+00, loss_IC: 1.987e-08,loss_f: 3.896e-08
pinn: 0300, Iter: 500, total_loss: 3.059e-07, loss_BC: 0.000e+00, loss_IC: 2.514e-08,loss_f: 3.678e-08
pinn: 0300, Iter: 600, total_loss: 2.995e-07, loss_BC: 0.000e+00, loss_IC: 2.373e-08,loss_f: 3.739e-08
pinn: 0300, Iter: 700, total_loss: 2.947e-07, loss_BC: 0.000e+00, loss_IC: 2.426e-08,loss_f: 3.866e-08
pinn: 0300, Iter: 800, total_loss: 2.829e-07, loss_BC: 0.000e+00, loss_IC: 2.360e-08,loss_f: 3.805e-08
pinn: 0300, Iter: 900, total_loss: 2.704e-07, loss_BC: 0.000e+00, loss_IC: 2.339e-08,loss_f: 3.930e-08
pinn: 0300, Iter: 1000, total_loss: 2.579e-07, loss_BC: 0.000e+00, loss_IC: 2.874e-08,loss_f: 4.671e-08
pinn: 0300, Iter: 1100, total_loss: 2.437e-07, loss_BC: 0.000e+00, loss_IC: 3.481e-08,loss_f: 4.502e-08
pinn: 0300, Iter: 1200, total_loss: 2.345e-07, loss_BC: 0.000e+00, loss_IC: 3.440e-08,loss_f: 4.354e-08
pinn: 0300, Iter: 1300, total_loss: 2.240e-07, loss_BC: 0.000e+00, loss_IC: 3.845e-08,loss_f: 4.700e-08
pinn: 0300, Iter: 1400, total_loss: 2.142e-07, loss_BC: 0.000e+00, loss_IC: 3.577e-08,loss_f: 4.557e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5132, Mean_loss of pinns: 2.140e-07, loss_BC: 0.000e+00, loss_IC: 3.534e-08, loss_f: 4.557e-08
 => minimum loss: 2.140e-07, corresponding pinn index: 0300
 => maximum loss: 2.140e-07, corresponding pinn  index: 0300

 max_loss: 6.354e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5134, total_loss: 5.337e-05, loss_BC: 2.380e-05, loss_IC: 2.978e-06, loss_f: 2.645e-05

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.48000, t_max: 0.49000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5135 0 1

 -------------------------------------------------------------
  -----  Epoch: 5135 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.48000, t_max: 0.49000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5135 !!! 


==> Epoch: 5140, Mean_loss of pinns: 3.772e-02, loss_BC: 2.639e-05, loss_IC: 5.036e-07, loss_f: 3.770e-02
 => minimum loss: 2.163e-04, corresponding pinn/batch index: 0300
 => maximum loss: 1.004e-01, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5150, Mean_loss of pinns: 3.071e-02, loss_BC: 2.700e-05, loss_IC: 3.896e-06, loss_f: 3.068e-02
 => minimum loss: 1.671e-04, corresponding pinn/batch index: 0300
 => maximum loss: 8.172e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5160, Mean_loss of pinns: 2.533e-02, loss_BC: 2.826e-05, loss_IC: 1.044e-05, loss_f: 2.529e-02
 => minimum loss: 1.466e-04, corresponding pinn/batch index: 0300
 => maximum loss: 6.742e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5170, Mean_loss of pinns: 2.121e-02, loss_BC: 2.912e-05, loss_IC: 1.895e-05, loss_f: 2.116e-02
 => minimum loss: 1.357e-04, corresponding pinn/batch index: 0300
 => maximum loss: 5.649e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5180, Mean_loss of pinns: 1.804e-02, loss_BC: 3.150e-05, loss_IC: 2.848e-05, loss_f: 1.798e-02
 => minimum loss: 1.224e-04, corresponding pinn/batch index: 0300
 => maximum loss: 4.802e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5190, Mean_loss of pinns: 1.555e-02, loss_BC: 3.463e-05, loss_IC: 3.840e-05, loss_f: 1.547e-02
 => minimum loss: 1.198e-04, corresponding pinn/batch index: 0300
 => maximum loss: 4.132e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5200, Mean_loss of pinns: 1.356e-02, loss_BC: 3.736e-05, loss_IC: 4.874e-05, loss_f: 1.347e-02
 => minimum loss: 1.207e-04, corresponding pinn/batch index: 0300
 => maximum loss: 3.590e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5210, Mean_loss of pinns: 1.193e-02, loss_BC: 4.045e-05, loss_IC: 5.924e-05, loss_f: 1.184e-02
 => minimum loss: 1.215e-04, corresponding pinn/batch index: 0300
 => maximum loss: 3.144e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5220, Mean_loss of pinns: 1.059e-02, loss_BC: 4.351e-05, loss_IC: 6.955e-05, loss_f: 1.048e-02
 => minimum loss: 1.221e-04, corresponding pinn/batch index: 0300
 => maximum loss: 2.772e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5230, Mean_loss of pinns: 9.456e-03, loss_BC: 4.700e-05, loss_IC: 7.949e-05, loss_f: 9.330e-03
 => minimum loss: 1.264e-04, corresponding pinn/batch index: 0300
 => maximum loss: 2.457e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  5234

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 3.951e-07, loss_BC: 0.000e+00, loss_IC: 2.766e-08,loss_f: 2.049e-07
pinn: 0200, Iter: 100, total_loss: 1.477e-06, loss_BC: 0.000e+00, loss_IC: 1.740e-07,loss_f: 9.223e-07
pinn: 0100, Iter: 100, total_loss: 1.035e-06, loss_BC: 0.000e+00, loss_IC: 1.273e-07,loss_f: 8.350e-07
pinn: 0000, Iter: 100, total_loss: 1.304e-06, loss_BC: 0.000e+00, loss_IC: 1.131e-07,loss_f: 1.162e-06
pinn: 0100, Iter: 200, total_loss: 3.117e-07, loss_BC: 0.000e+00, loss_IC: 6.954e-08,loss_f: 1.719e-07
pinn: 0200, Iter: 200, total_loss: 6.747e-07, loss_BC: 0.000e+00, loss_IC: 1.479e-07,loss_f: 1.762e-07
pinn: 0300, Iter: 200, total_loss: 2.747e-07, loss_BC: 0.000e+00, loss_IC: 2.047e-08,loss_f: 9.282e-08
pinn: 0000, Iter: 200, total_loss: 2.207e-07, loss_BC: 0.000e+00, loss_IC: 7.428e-08,loss_f: 1.196e-07
pinn: 0100, Iter: 300, total_loss: 2.826e-07, loss_BC: 0.000e+00, loss_IC: 6.391e-08,loss_f: 1.484e-07
pinn: 0300, Iter: 300, total_loss: 2.458e-07, loss_BC: 0.000e+00, loss_IC: 1.746e-08,loss_f: 7.346e-08
pinn: 0200, Iter: 300, total_loss: 5.469e-07, loss_BC: 0.000e+00, loss_IC: 9.642e-08,loss_f: 9.510e-08
pinn: 0000, Iter: 300, total_loss: 1.463e-07, loss_BC: 0.000e+00, loss_IC: 5.527e-08,loss_f: 6.408e-08
pinn: 0100, Iter: 400, total_loss: 2.234e-07, loss_BC: 0.000e+00, loss_IC: 5.327e-08,loss_f: 9.904e-08
pinn: 0300, Iter: 400, total_loss: 2.388e-07, loss_BC: 0.000e+00, loss_IC: 1.558e-08,loss_f: 7.192e-08
pinn: 0200, Iter: 400, total_loss: 5.300e-07, loss_BC: 0.000e+00, loss_IC: 9.121e-08,loss_f: 8.015e-08
pinn: 0000, Iter: 400, total_loss: 1.228e-07, loss_BC: 0.000e+00, loss_IC: 4.150e-08,loss_f: 5.347e-08
pinn: 0100, Iter: 500, total_loss: 2.136e-07, loss_BC: 0.000e+00, loss_IC: 5.184e-08,loss_f: 9.074e-08
pinn: 0300, Iter: 500, total_loss: 2.247e-07, loss_BC: 0.000e+00, loss_IC: 1.475e-08,loss_f: 6.261e-08
pinn: 0200, Iter: 500, total_loss: 5.083e-07, loss_BC: 0.000e+00, loss_IC: 8.067e-08,loss_f: 6.878e-08
pinn: 0000, Iter: 500, total_loss: 1.116e-07, loss_BC: 0.000e+00, loss_IC: 3.734e-08,loss_f: 4.600e-08
pinn: 0100, Iter: 600, total_loss: 2.026e-07, loss_BC: 0.000e+00, loss_IC: 5.025e-08,loss_f: 8.172e-08
pinn: 0200, Iter: 600, total_loss: 4.919e-07, loss_BC: 0.000e+00, loss_IC: 7.793e-08,loss_f: 6.284e-08
pinn: 0300, Iter: 600, total_loss: 2.189e-07, loss_BC: 0.000e+00, loss_IC: 1.433e-08,loss_f: 5.689e-08
pinn: 0000, Iter: 600, total_loss: 1.087e-07, loss_BC: 0.000e+00, loss_IC: 3.645e-08,loss_f: 4.382e-08
pinn: 0100, Iter: 700, total_loss: 1.929e-07, loss_BC: 0.000e+00, loss_IC: 4.892e-08,loss_f: 7.384e-08
pinn: 0200, Iter: 700, total_loss: 4.789e-07, loss_BC: 0.000e+00, loss_IC: 7.925e-08,loss_f: 6.380e-08
pinn: 0300, Iter: 700, total_loss: 2.129e-07, loss_BC: 0.000e+00, loss_IC: 1.363e-08,loss_f: 5.157e-08
pinn: 0000, Iter: 700, total_loss: 1.063e-07, loss_BC: 0.000e+00, loss_IC: 3.539e-08,loss_f: 4.245e-08
pinn: 0100, Iter: 800, total_loss: 1.888e-07, loss_BC: 0.000e+00, loss_IC: 4.652e-08,loss_f: 7.212e-08
pinn: 0200, Iter: 800, total_loss: 4.672e-07, loss_BC: 0.000e+00, loss_IC: 8.041e-08,loss_f: 6.771e-08
pinn: 0300, Iter: 800, total_loss: 2.050e-07, loss_BC: 0.000e+00, loss_IC: 1.188e-08,loss_f: 4.837e-08
pinn: 0000, Iter: 800, total_loss: 1.004e-07, loss_BC: 0.000e+00, loss_IC: 3.180e-08,loss_f: 4.003e-08
pinn: 0100, Iter: 900, total_loss: 1.872e-07, loss_BC: 0.000e+00, loss_IC: 4.608e-08,loss_f: 7.103e-08
pinn: 0300, Iter: 900, total_loss: 2.019e-07, loss_BC: 0.000e+00, loss_IC: 1.045e-08,loss_f: 4.788e-08
pinn: 0200, Iter: 900, total_loss: 4.617e-07, loss_BC: 0.000e+00, loss_IC: 8.131e-08,loss_f: 6.902e-08
pinn: 0000, Iter: 900, total_loss: 9.797e-08, loss_BC: 0.000e+00, loss_IC: 3.049e-08,loss_f: 3.883e-08
pinn: 0100, Iter: 1000, total_loss: 1.865e-07, loss_BC: 0.000e+00, loss_IC: 4.467e-08,loss_f: 7.172e-08
pinn: 0300, Iter: 1000, total_loss: 1.967e-07, loss_BC: 0.000e+00, loss_IC: 9.439e-09,loss_f: 4.695e-08
pinn: 0200, Iter: 1000, total_loss: 4.550e-07, loss_BC: 0.000e+00, loss_IC: 8.311e-08,loss_f: 6.928e-08
pinn: 0000, Iter: 1000, total_loss: 9.406e-08, loss_BC: 0.000e+00, loss_IC: 2.798e-08,loss_f: 3.741e-08
pinn: 0100, Iter: 1100, total_loss: 1.846e-07, loss_BC: 0.000e+00, loss_IC: 4.338e-08,loss_f: 7.129e-08
pinn: 0300, Iter: 1100, total_loss: 1.938e-07, loss_BC: 0.000e+00, loss_IC: 8.769e-09,loss_f: 4.660e-08
pinn: 0200, Iter: 1100, total_loss: 4.489e-07, loss_BC: 0.000e+00, loss_IC: 8.503e-08,loss_f: 7.450e-08
pinn: 0000, Iter: 1100, total_loss: 9.324e-08, loss_BC: 0.000e+00, loss_IC: 2.770e-08,loss_f: 3.691e-08
pinn: 0100, Iter: 1200, total_loss: 1.840e-07, loss_BC: 0.000e+00, loss_IC: 4.291e-08,loss_f: 7.111e-08
pinn: 0300, Iter: 1200, total_loss: 1.902e-07, loss_BC: 0.000e+00, loss_IC: 8.038e-09,loss_f: 4.616e-08
pinn: 0200, Iter: 1200, total_loss: 4.396e-07, loss_BC: 0.000e+00, loss_IC: 7.766e-08,loss_f: 9.170e-08
pinn: 0000, Iter: 1200, total_loss: 9.238e-08, loss_BC: 0.000e+00, loss_IC: 2.622e-08,loss_f: 3.739e-08
pinn: 0100, Iter: 1300, total_loss: 1.814e-07, loss_BC: 0.000e+00, loss_IC: 4.074e-08,loss_f: 7.079e-08
pinn: 0300, Iter: 1300, total_loss: 1.889e-07, loss_BC: 0.000e+00, loss_IC: 7.465e-09,loss_f: 4.655e-08
pinn: 0200, Iter: 1300, total_loss: 4.153e-07, loss_BC: 0.000e+00, loss_IC: 7.547e-08,loss_f: 8.905e-08
pinn: 0000, Iter: 1300, total_loss: 9.055e-08, loss_BC: 0.000e+00, loss_IC: 2.334e-08,loss_f: 3.809e-08
pinn: 0100, Iter: 1400, total_loss: 1.804e-07, loss_BC: 0.000e+00, loss_IC: 4.064e-08,loss_f: 7.010e-08
pinn: 0300, Iter: 1400, total_loss: 1.837e-07, loss_BC: 0.000e+00, loss_IC: 6.786e-09,loss_f: 4.767e-08
pinn: 0200, Iter: 1400, total_loss: 4.105e-07, loss_BC: 0.000e+00, loss_IC: 7.085e-08,loss_f: 9.418e-08
pinn: 0000, Iter: 1400, total_loss: 8.999e-08, loss_BC: 0.000e+00, loss_IC: 2.360e-08,loss_f: 3.733e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5234, Mean_loss of pinns: 2.150e-07, loss_BC: 0.000e+00, loss_IC: 3.515e-08, loss_f: 6.266e-08
 => minimum loss: 8.997e-08, corresponding pinn index: 0000
 => maximum loss: 4.069e-07, corresponding pinn  index: 0200

 max_loss: 3.989e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5236, total_loss: 2.667e-05, loss_BC: 2.645e-05, loss_IC: 3.852e-08, loss_f: 6.586e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.49000, t_max: 0.50000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5237 0 1

 -------------------------------------------------------------
  -----  Epoch: 5237 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.49000, t_max: 0.50000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5237 !!! 


==> Epoch: 5240, Mean_loss of pinns: 3.106e-04, loss_BC: 2.858e-05, loss_IC: 2.432e-07, loss_f: 2.816e-04
 => minimum loss: 1.593e-04, corresponding pinn/batch index: 0100
 => maximum loss: 6.568e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5250, Mean_loss of pinns: 2.427e-04, loss_BC: 2.614e-05, loss_IC: 3.088e-06, loss_f: 2.133e-04
 => minimum loss: 1.212e-04, corresponding pinn/batch index: 0100
 => maximum loss: 4.908e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5260, Mean_loss of pinns: 1.959e-04, loss_BC: 2.340e-05, loss_IC: 5.366e-06, loss_f: 1.670e-04
 => minimum loss: 9.423e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.907e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5270, Mean_loss of pinns: 1.641e-04, loss_BC: 2.216e-05, loss_IC: 6.152e-06, loss_f: 1.356e-04
 => minimum loss: 7.500e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.260e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5280, Mean_loss of pinns: 1.391e-04, loss_BC: 2.039e-05, loss_IC: 5.804e-06, loss_f: 1.127e-04
 => minimum loss: 6.125e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.762e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5290, Mean_loss of pinns: 1.206e-04, loss_BC: 1.990e-05, loss_IC: 4.989e-06, loss_f: 9.553e-05
 => minimum loss: 5.189e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.369e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5300, Mean_loss of pinns: 1.053e-04, loss_BC: 1.855e-05, loss_IC: 4.241e-06, loss_f: 8.238e-05
 => minimum loss: 4.519e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.056e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5310, Mean_loss of pinns: 9.346e-05, loss_BC: 1.761e-05, loss_IC: 3.758e-06, loss_f: 7.193e-05
 => minimum loss: 4.016e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.796e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0300

==> Epoch: 5320, Mean_loss of pinns: 8.433e-05, loss_BC: 1.725e-05, loss_IC: 3.511e-06, loss_f: 6.341e-05
 => minimum loss: 3.637e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.600e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0300

==> Epoch: 5330, Mean_loss of pinns: 7.657e-05, loss_BC: 1.657e-05, loss_IC: 3.433e-06, loss_f: 5.641e-05
 => minimum loss: 3.298e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.432e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0300

 !!! Scipy optimize: !!! - Epoch:  5336

 ! Scipy iteration number:  1
Processes:  2
Number of pinns to optimize weights:  2
 !!! pinns to optimize ==> 0000, 0300


pinn: 0000, Iter: 100, total_loss: 2.701e-07, loss_BC: 0.000e+00, loss_IC: 2.692e-08,loss_f: 1.987e-07
pinn: 0300, Iter: 100, total_loss: 2.977e-07, loss_BC: 0.000e+00, loss_IC: 2.071e-08,loss_f: 2.008e-07
pinn: 0300, Iter: 200, total_loss: 1.754e-07, loss_BC: 0.000e+00, loss_IC: 2.100e-08,loss_f: 7.879e-08
pinn: 0000, Iter: 200, total_loss: 1.365e-07, loss_BC: 0.000e+00, loss_IC: 2.115e-08,loss_f: 7.057e-08
pinn: 0000, Iter: 300, total_loss: 1.183e-07, loss_BC: 0.000e+00, loss_IC: 2.106e-08,loss_f: 5.272e-08
pinn: 0300, Iter: 300, total_loss: 1.600e-07, loss_BC: 0.000e+00, loss_IC: 1.716e-08,loss_f: 6.829e-08
pinn: 0000, Iter: 400, total_loss: 1.131e-07, loss_BC: 0.000e+00, loss_IC: 2.108e-08,loss_f: 4.747e-08
pinn: 0300, Iter: 400, total_loss: 1.542e-07, loss_BC: 0.000e+00, loss_IC: 1.535e-08,loss_f: 6.520e-08
pinn: 0300, Iter: 500, total_loss: 1.483e-07, loss_BC: 0.000e+00, loss_IC: 1.399e-08,loss_f: 6.121e-08
pinn: 0000, Iter: 500, total_loss: 1.094e-07, loss_BC: 0.000e+00, loss_IC: 2.121e-08,loss_f: 4.354e-08
pinn: 0000, Iter: 600, total_loss: 1.077e-07, loss_BC: 0.000e+00, loss_IC: 2.104e-08,loss_f: 4.193e-08
pinn: 0300, Iter: 600, total_loss: 1.431e-07, loss_BC: 0.000e+00, loss_IC: 1.344e-08,loss_f: 5.719e-08
pinn: 0000, Iter: 700, total_loss: 1.056e-07, loss_BC: 0.000e+00, loss_IC: 1.938e-08,loss_f: 4.158e-08
pinn: 0300, Iter: 700, total_loss: 1.412e-07, loss_BC: 0.000e+00, loss_IC: 1.305e-08,loss_f: 5.569e-08
pinn: 0000, Iter: 800, total_loss: 1.045e-07, loss_BC: 0.000e+00, loss_IC: 1.893e-08,loss_f: 4.110e-08
pinn: 0300, Iter: 800, total_loss: 1.390e-07, loss_BC: 0.000e+00, loss_IC: 1.252e-08,loss_f: 5.421e-08
pinn: 0000, Iter: 900, total_loss: 1.037e-07, loss_BC: 0.000e+00, loss_IC: 1.883e-08,loss_f: 4.050e-08
pinn: 0300, Iter: 900, total_loss: 1.368e-07, loss_BC: 0.000e+00, loss_IC: 1.212e-08,loss_f: 5.273e-08
pinn: 0000, Iter: 1000, total_loss: 1.025e-07, loss_BC: 0.000e+00, loss_IC: 1.859e-08,loss_f: 3.978e-08
pinn: 0300, Iter: 1000, total_loss: 1.344e-07, loss_BC: 0.000e+00, loss_IC: 1.137e-08,loss_f: 5.179e-08
pinn: 0000, Iter: 1100, total_loss: 1.014e-07, loss_BC: 0.000e+00, loss_IC: 1.793e-08,loss_f: 3.943e-08
pinn: 0300, Iter: 1100, total_loss: 1.338e-07, loss_BC: 0.000e+00, loss_IC: 1.142e-08,loss_f: 5.124e-08
pinn: 0000, Iter: 1200, total_loss: 1.010e-07, loss_BC: 0.000e+00, loss_IC: 1.761e-08,loss_f: 3.943e-08
pinn: 0300, Iter: 1200, total_loss: 1.320e-07, loss_BC: 0.000e+00, loss_IC: 1.136e-08,loss_f: 5.026e-08
pinn: 0000, Iter: 1300, total_loss: 1.002e-07, loss_BC: 0.000e+00, loss_IC: 1.700e-08,loss_f: 3.939e-08
pinn: 0300, Iter: 1300, total_loss: 1.292e-07, loss_BC: 0.000e+00, loss_IC: 9.407e-09,loss_f: 4.954e-08
pinn: 0000, Iter: 1400, total_loss: 9.989e-08, loss_BC: 0.000e+00, loss_IC: 1.656e-08,loss_f: 3.951e-08
pinn: 0300, Iter: 1400, total_loss: 1.321e-07, loss_BC: 0.000e+00, loss_IC: 9.671e-09,loss_f: 5.282e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5336, Mean_loss of pinns: 1.136e-07, loss_BC: 0.000e+00, loss_IC: 1.261e-08, loss_f: 4.445e-08
 => minimum loss: 9.949e-08, corresponding pinn index: 0000
 => maximum loss: 1.277e-07, corresponding pinn  index: 0300

 max_loss: 5.035e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5338, total_loss: 3.806e-05, loss_BC: 2.238e-05, loss_IC: 1.309e-06, loss_f: 1.421e-05

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.50000, t_max: 0.51000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5339 0 1

 -------------------------------------------------------------
  -----  Epoch: 5339 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.50000, t_max: 0.51000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5339 !!! 


==> Epoch: 5340, Mean_loss of pinns: 9.746e-03, loss_BC: 2.387e-05, loss_IC: 3.090e-08, loss_f: 9.722e-03
 => minimum loss: 1.289e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.093e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5350, Mean_loss of pinns: 7.790e-03, loss_BC: 2.330e-05, loss_IC: 3.513e-06, loss_f: 7.763e-03
 => minimum loss: 1.162e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.667e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5360, Mean_loss of pinns: 6.320e-03, loss_BC: 2.301e-05, loss_IC: 1.132e-05, loss_f: 6.285e-03
 => minimum loss: 1.069e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.347e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5370, Mean_loss of pinns: 5.201e-03, loss_BC: 2.281e-05, loss_IC: 2.198e-05, loss_f: 5.156e-03
 => minimum loss: 9.881e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.107e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5380, Mean_loss of pinns: 4.357e-03, loss_BC: 2.380e-05, loss_IC: 3.340e-05, loss_f: 4.300e-03
 => minimum loss: 9.466e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.273e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5390, Mean_loss of pinns: 3.712e-03, loss_BC: 2.473e-05, loss_IC: 4.405e-05, loss_f: 3.643e-03
 => minimum loss: 9.156e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.913e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5400, Mean_loss of pinns: 3.209e-03, loss_BC: 2.656e-05, loss_IC: 5.300e-05, loss_f: 3.129e-03
 => minimum loss: 8.792e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.863e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5410, Mean_loss of pinns: 2.810e-03, loss_BC: 2.872e-05, loss_IC: 6.017e-05, loss_f: 2.721e-03
 => minimum loss: 8.426e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.030e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5420, Mean_loss of pinns: 2.488e-03, loss_BC: 3.269e-05, loss_IC: 6.590e-05, loss_f: 2.390e-03
 => minimum loss: 8.631e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.357e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5430, Mean_loss of pinns: 2.222e-03, loss_BC: 3.437e-05, loss_IC: 7.021e-05, loss_f: 2.118e-03
 => minimum loss: 8.173e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.801e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  5438

 ! Scipy iteration number:  1
Processes:  4
Number of pinns to optimize weights:  4
 !!! pinns to optimize ==> 0000, 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 2.579e-07, loss_BC: 0.000e+00, loss_IC: 3.347e-08,loss_f: 1.504e-07
pinn: 0000, Iter: 100, total_loss: 5.290e-07, loss_BC: 0.000e+00, loss_IC: 1.898e-08,loss_f: 2.569e-07
pinn: 0200, Iter: 100, total_loss: 1.547e-06, loss_BC: 0.000e+00, loss_IC: 1.850e-07,loss_f: 1.215e-06
pinn: 0100, Iter: 100, total_loss: 1.093e-06, loss_BC: 0.000e+00, loss_IC: 4.793e-08,loss_f: 8.439e-07
pinn: 0300, Iter: 200, total_loss: 1.691e-07, loss_BC: 0.000e+00, loss_IC: 2.404e-08,loss_f: 7.078e-08
pinn: 0000, Iter: 200, total_loss: 3.289e-07, loss_BC: 0.000e+00, loss_IC: 2.490e-08,loss_f: 5.704e-08
pinn: 0100, Iter: 200, total_loss: 3.834e-07, loss_BC: 0.000e+00, loss_IC: 4.012e-08,loss_f: 1.485e-07
pinn: 0200, Iter: 200, total_loss: 4.635e-07, loss_BC: 0.000e+00, loss_IC: 1.079e-07,loss_f: 2.270e-07
pinn: 0300, Iter: 300, total_loss: 1.535e-07, loss_BC: 0.000e+00, loss_IC: 2.220e-08,loss_f: 5.916e-08
pinn: 0000, Iter: 300, total_loss: 3.113e-07, loss_BC: 0.000e+00, loss_IC: 2.490e-08,loss_f: 4.226e-08
pinn: 0100, Iter: 300, total_loss: 3.222e-07, loss_BC: 0.000e+00, loss_IC: 3.234e-08,loss_f: 9.585e-08
pinn: 0200, Iter: 300, total_loss: 3.039e-07, loss_BC: 0.000e+00, loss_IC: 7.471e-08,loss_f: 9.748e-08
pinn: 0300, Iter: 400, total_loss: 1.478e-07, loss_BC: 0.000e+00, loss_IC: 2.250e-08,loss_f: 5.565e-08
pinn: 0200, Iter: 400, total_loss: 2.798e-07, loss_BC: 0.000e+00, loss_IC: 6.472e-08,loss_f: 8.360e-08
pinn: 0100, Iter: 400, total_loss: 2.955e-07, loss_BC: 0.000e+00, loss_IC: 2.515e-08,loss_f: 7.391e-08
pinn: 0000, Iter: 400, total_loss: 3.019e-07, loss_BC: 0.000e+00, loss_IC: 2.865e-08,loss_f: 3.726e-08
pinn: 0300, Iter: 500, total_loss: 1.430e-07, loss_BC: 0.000e+00, loss_IC: 2.284e-08,loss_f: 5.185e-08
pinn: 0200, Iter: 500, total_loss: 3.179e-07, loss_BC: 0.000e+00, loss_IC: 7.213e-08,loss_f: 1.136e-07
pinn: 0000, Iter: 500, total_loss: 2.974e-07, loss_BC: 0.000e+00, loss_IC: 2.963e-08,loss_f: 3.606e-08
pinn: 0100, Iter: 500, total_loss: 2.874e-07, loss_BC: 0.000e+00, loss_IC: 2.083e-08,loss_f: 7.031e-08
pinn: 0300, Iter: 600, total_loss: 1.393e-07, loss_BC: 0.000e+00, loss_IC: 2.137e-08,loss_f: 4.959e-08
pinn: 0200, Iter: 600, total_loss: 2.546e-07, loss_BC: 0.000e+00, loss_IC: 5.062e-08,loss_f: 6.990e-08
pinn: 0100, Iter: 600, total_loss: 2.809e-07, loss_BC: 0.000e+00, loss_IC: 1.906e-08,loss_f: 6.660e-08
pinn: 0000, Iter: 600, total_loss: 2.910e-07, loss_BC: 0.000e+00, loss_IC: 2.978e-08,loss_f: 3.617e-08
pinn: 0300, Iter: 700, total_loss: 1.372e-07, loss_BC: 0.000e+00, loss_IC: 2.053e-08,loss_f: 4.801e-08
pinn: 0200, Iter: 700, total_loss: 2.501e-07, loss_BC: 0.000e+00, loss_IC: 5.207e-08,loss_f: 6.500e-08
pinn: 0100, Iter: 700, total_loss: 2.711e-07, loss_BC: 0.000e+00, loss_IC: 1.985e-08,loss_f: 6.659e-08
pinn: 0000, Iter: 700, total_loss: 2.861e-07, loss_BC: 0.000e+00, loss_IC: 2.979e-08,loss_f: 3.696e-08
pinn: 0300, Iter: 800, total_loss: 1.361e-07, loss_BC: 0.000e+00, loss_IC: 2.037e-08,loss_f: 4.715e-08
pinn: 0200, Iter: 800, total_loss: 2.467e-07, loss_BC: 0.000e+00, loss_IC: 5.204e-08,loss_f: 6.256e-08
pinn: 0100, Iter: 800, total_loss: 2.663e-07, loss_BC: 0.000e+00, loss_IC: 2.189e-08,loss_f: 6.576e-08
pinn: 0000, Iter: 800, total_loss: 2.769e-07, loss_BC: 0.000e+00, loss_IC: 2.924e-08,loss_f: 4.028e-08
pinn: 0300, Iter: 900, total_loss: 1.335e-07, loss_BC: 0.000e+00, loss_IC: 2.083e-08,loss_f: 4.521e-08
pinn: 0200, Iter: 900, total_loss: 2.440e-07, loss_BC: 0.000e+00, loss_IC: 5.230e-08,loss_f: 6.062e-08
pinn: 0000, Iter: 900, total_loss: 2.656e-07, loss_BC: 0.000e+00, loss_IC: 2.800e-08,loss_f: 4.682e-08
pinn: 0100, Iter: 900, total_loss: 2.564e-07, loss_BC: 0.000e+00, loss_IC: 2.221e-08,loss_f: 6.727e-08
pinn: 0300, Iter: 1000, total_loss: 1.323e-07, loss_BC: 0.000e+00, loss_IC: 2.087e-08,loss_f: 4.456e-08
pinn: 0200, Iter: 1000, total_loss: 2.428e-07, loss_BC: 0.000e+00, loss_IC: 5.285e-08,loss_f: 5.924e-08
pinn: 0000, Iter: 1000, total_loss: 2.593e-07, loss_BC: 0.000e+00, loss_IC: 2.895e-08,loss_f: 4.679e-08
pinn: 0100, Iter: 1000, total_loss: 2.536e-07, loss_BC: 0.000e+00, loss_IC: 2.194e-08,loss_f: 6.606e-08
pinn: 0300, Iter: 1100, total_loss: 1.316e-07, loss_BC: 0.000e+00, loss_IC: 2.102e-08,loss_f: 4.417e-08
pinn: 0000, Iter: 1100, total_loss: 2.516e-07, loss_BC: 0.000e+00, loss_IC: 2.856e-08,loss_f: 5.098e-08
pinn: 0200, Iter: 1100, total_loss: 2.410e-07, loss_BC: 0.000e+00, loss_IC: 5.337e-08,loss_f: 5.775e-08
pinn: 0100, Iter: 1100, total_loss: 2.461e-07, loss_BC: 0.000e+00, loss_IC: 2.140e-08,loss_f: 6.680e-08
pinn: 0300, Iter: 1200, total_loss: 1.295e-07, loss_BC: 0.000e+00, loss_IC: 2.080e-08,loss_f: 4.300e-08
pinn: 0200, Iter: 1200, total_loss: 2.401e-07, loss_BC: 0.000e+00, loss_IC: 5.293e-08,loss_f: 5.719e-08
pinn: 0000, Iter: 1200, total_loss: 2.430e-07, loss_BC: 0.000e+00, loss_IC: 3.053e-08,loss_f: 5.726e-08
pinn: 0100, Iter: 1200, total_loss: 2.336e-07, loss_BC: 0.000e+00, loss_IC: 2.569e-08,loss_f: 6.731e-08
pinn: 0300, Iter: 1300, total_loss: 1.283e-07, loss_BC: 0.000e+00, loss_IC: 2.041e-08,loss_f: 4.261e-08
pinn: 0200, Iter: 1300, total_loss: 2.382e-07, loss_BC: 0.000e+00, loss_IC: 5.234e-08,loss_f: 5.655e-08
pinn: 0000, Iter: 1300, total_loss: 2.367e-07, loss_BC: 0.000e+00, loss_IC: 3.223e-08,loss_f: 6.005e-08
pinn: 0100, Iter: 1300, total_loss: 2.245e-07, loss_BC: 0.000e+00, loss_IC: 2.842e-08,loss_f: 6.706e-08
pinn: 0300, Iter: 1400, total_loss: 1.273e-07, loss_BC: 0.000e+00, loss_IC: 1.961e-08,loss_f: 4.255e-08
pinn: 0200, Iter: 1400, total_loss: 2.344e-07, loss_BC: 0.000e+00, loss_IC: 4.884e-08,loss_f: 5.663e-08
pinn: 0000, Iter: 1400, total_loss: 2.286e-07, loss_BC: 0.000e+00, loss_IC: 3.368e-08,loss_f: 5.798e-08
pinn: 0100, Iter: 1400, total_loss: 2.204e-07, loss_BC: 0.000e+00, loss_IC: 2.756e-08,loss_f: 6.690e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5438, Mean_loss of pinns: 2.020e-07, loss_BC: 0.000e+00, loss_IC: 3.231e-08, loss_f: 5.625e-08
 => minimum loss: 1.273e-07, corresponding pinn index: 0300
 => maximum loss: 2.324e-07, corresponding pinn  index: 0200

==> Epoch: 5440, Mean_loss of pinns: 2.265e-05, loss_BC: 2.244e-05, loss_IC: 3.318e-08, loss_f: 5.717e-08
 => minimum loss: 6.151e-06, corresponding pinn/batch index: 0100
 => maximum loss: 4.439e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 4.439e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5440, total_loss: 2.265e-05, loss_BC: 2.244e-05, loss_IC: 3.318e-08, loss_f: 5.717e-08

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.51000, t_max: 0.52000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5441 0 1

 -------------------------------------------------------------
  -----  Epoch: 5441 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.51000, t_max: 0.52000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5441 !!! 


==> Epoch: 5450, Mean_loss of pinns: 2.482e-04, loss_BC: 2.423e-05, loss_IC: 1.308e-06, loss_f: 2.226e-04
 => minimum loss: 1.064e-04, corresponding pinn/batch index: 0300
 => maximum loss: 3.064e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5460, Mean_loss of pinns: 2.041e-04, loss_BC: 2.284e-05, loss_IC: 3.596e-06, loss_f: 1.776e-04
 => minimum loss: 9.145e-05, corresponding pinn/batch index: 0300
 => maximum loss: 2.599e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5470, Mean_loss of pinns: 1.701e-04, loss_BC: 2.062e-05, loss_IC: 4.378e-06, loss_f: 1.450e-04
 => minimum loss: 7.882e-05, corresponding pinn/batch index: 0300
 => maximum loss: 2.207e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5480, Mean_loss of pinns: 1.437e-04, loss_BC: 1.963e-05, loss_IC: 3.606e-06, loss_f: 1.204e-04
 => minimum loss: 6.836e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.898e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0200

==> Epoch: 5490, Mean_loss of pinns: 1.226e-04, loss_BC: 1.808e-05, loss_IC: 2.521e-06, loss_f: 1.019e-04
 => minimum loss: 6.017e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.635e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0200

==> Epoch: 5500, Mean_loss of pinns: 1.070e-04, loss_BC: 1.765e-05, loss_IC: 2.051e-06, loss_f: 8.720e-05
 => minimum loss: 5.359e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.446e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0200

==> Epoch: 5510, Mean_loss of pinns: 9.516e-05, loss_BC: 1.768e-05, loss_IC: 2.033e-06, loss_f: 7.535e-05
 => minimum loss: 4.861e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.298e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0200

==> Epoch: 5520, Mean_loss of pinns: 8.501e-05, loss_BC: 1.692e-05, loss_IC: 2.109e-06, loss_f: 6.588e-05
 => minimum loss: 4.380e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.173e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0200

==> Epoch: 5530, Mean_loss of pinns: 7.699e-05, loss_BC: 1.641e-05, loss_IC: 2.139e-06, loss_f: 5.834e-05
 => minimum loss: 4.092e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.072e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0200

==> Epoch: 5540, Mean_loss of pinns: 7.030e-05, loss_BC: 1.581e-05, loss_IC: 2.144e-06, loss_f: 5.225e-05
 => minimum loss: 3.853e-05, corresponding pinn/batch index: 0300
 => maximum loss: 9.937e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

 !!! Scipy optimize: !!! - Epoch:  5540

 ! Scipy iteration number:  1
Processes:  2
Number of pinns to optimize weights:  2
 !!! pinns to optimize ==> 0000, 0200


pinn: 0000, Iter: 100, total_loss: 4.295e-07, loss_BC: 0.000e+00, loss_IC: 3.171e-08,loss_f: 3.083e-07
pinn: 0200, Iter: 100, total_loss: 4.651e-07, loss_BC: 0.000e+00, loss_IC: 3.067e-08,loss_f: 2.169e-07
pinn: 0000, Iter: 200, total_loss: 2.098e-07, loss_BC: 0.000e+00, loss_IC: 3.056e-08,loss_f: 9.104e-08
pinn: 0200, Iter: 200, total_loss: 3.144e-07, loss_BC: 0.000e+00, loss_IC: 2.403e-08,loss_f: 7.309e-08
pinn: 0000, Iter: 300, total_loss: 1.925e-07, loss_BC: 0.000e+00, loss_IC: 2.733e-08,loss_f: 7.765e-08
pinn: 0200, Iter: 300, total_loss: 2.946e-07, loss_BC: 0.000e+00, loss_IC: 2.071e-08,loss_f: 5.724e-08
pinn: 0000, Iter: 400, total_loss: 1.833e-07, loss_BC: 0.000e+00, loss_IC: 2.617e-08,loss_f: 7.002e-08
pinn: 0200, Iter: 400, total_loss: 2.869e-07, loss_BC: 0.000e+00, loss_IC: 2.063e-08,loss_f: 5.237e-08
pinn: 0000, Iter: 500, total_loss: 1.739e-07, loss_BC: 0.000e+00, loss_IC: 2.401e-08,loss_f: 6.283e-08
pinn: 0200, Iter: 500, total_loss: 2.794e-07, loss_BC: 0.000e+00, loss_IC: 1.909e-08,loss_f: 4.830e-08
pinn: 0000, Iter: 600, total_loss: 1.637e-07, loss_BC: 0.000e+00, loss_IC: 2.140e-08,loss_f: 5.513e-08
pinn: 0200, Iter: 600, total_loss: 2.677e-07, loss_BC: 0.000e+00, loss_IC: 2.179e-08,loss_f: 4.351e-08
pinn: 0000, Iter: 700, total_loss: 1.590e-07, loss_BC: 0.000e+00, loss_IC: 1.982e-08,loss_f: 5.204e-08
pinn: 0200, Iter: 700, total_loss: 2.599e-07, loss_BC: 0.000e+00, loss_IC: 2.634e-08,loss_f: 3.906e-08
pinn: 0000, Iter: 800, total_loss: 1.535e-07, loss_BC: 0.000e+00, loss_IC: 1.760e-08,loss_f: 4.912e-08
pinn: 0200, Iter: 800, total_loss: 2.554e-07, loss_BC: 0.000e+00, loss_IC: 2.985e-08,loss_f: 3.792e-08
pinn: 0000, Iter: 900, total_loss: 1.525e-07, loss_BC: 0.000e+00, loss_IC: 1.721e-08,loss_f: 4.910e-08
pinn: 0200, Iter: 900, total_loss: 2.527e-07, loss_BC: 0.000e+00, loss_IC: 3.290e-08,loss_f: 3.740e-08
pinn: 0000, Iter: 1000, total_loss: 1.513e-07, loss_BC: 0.000e+00, loss_IC: 1.744e-08,loss_f: 4.839e-08
pinn: 0200, Iter: 1000, total_loss: 2.490e-07, loss_BC: 0.000e+00, loss_IC: 3.551e-08,loss_f: 3.705e-08
pinn: 0000, Iter: 1100, total_loss: 1.502e-07, loss_BC: 0.000e+00, loss_IC: 1.731e-08,loss_f: 4.811e-08
pinn: 0200, Iter: 1100, total_loss: 2.452e-07, loss_BC: 0.000e+00, loss_IC: 4.014e-08,loss_f: 3.543e-08
pinn: 0000, Iter: 1200, total_loss: 1.499e-07, loss_BC: 0.000e+00, loss_IC: 1.701e-08,loss_f: 4.823e-08
pinn: 0200, Iter: 1200, total_loss: 2.423e-07, loss_BC: 0.000e+00, loss_IC: 3.992e-08,loss_f: 3.561e-08
pinn: 0000, Iter: 1300, total_loss: 1.483e-07, loss_BC: 0.000e+00, loss_IC: 1.605e-08,loss_f: 4.805e-08
pinn: 0200, Iter: 1300, total_loss: 2.375e-07, loss_BC: 0.000e+00, loss_IC: 4.066e-08,loss_f: 3.420e-08
pinn: 0000, Iter: 1400, total_loss: 1.470e-07, loss_BC: 0.000e+00, loss_IC: 1.546e-08,loss_f: 4.762e-08
pinn: 0200, Iter: 1400, total_loss: 2.346e-07, loss_BC: 0.000e+00, loss_IC: 4.337e-08,loss_f: 3.316e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5540, Mean_loss of pinns: 1.904e-07, loss_BC: 0.000e+00, loss_IC: 2.881e-08, loss_f: 4.028e-08
 => minimum loss: 1.469e-07, corresponding pinn index: 0000
 => maximum loss: 2.340e-07, corresponding pinn  index: 0200

 max_loss: 6.646e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5542, total_loss: 4.611e-05, loss_BC: 2.511e-05, loss_IC: 6.616e-07, loss_f: 2.027e-05

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.52000, t_max: 0.53000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5543 0 1

 -------------------------------------------------------------
  -----  Epoch: 5543 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.52000, t_max: 0.53000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5543 !!! 


==> Epoch: 5550, Mean_loss of pinns: 1.836e-02, loss_BC: 2.709e-05, loss_IC: 1.708e-06, loss_f: 1.833e-02
 => minimum loss: 1.060e-04, corresponding pinn/batch index: 0200
 => maximum loss: 4.039e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5560, Mean_loss of pinns: 1.458e-02, loss_BC: 2.499e-05, loss_IC: 7.448e-06, loss_f: 1.454e-02
 => minimum loss: 8.725e-05, corresponding pinn/batch index: 0200
 => maximum loss: 3.243e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5570, Mean_loss of pinns: 1.182e-02, loss_BC: 2.331e-05, loss_IC: 1.578e-05, loss_f: 1.178e-02
 => minimum loss: 7.664e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.645e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5580, Mean_loss of pinns: 9.795e-03, loss_BC: 2.964e-05, loss_IC: 2.688e-05, loss_f: 9.739e-03
 => minimum loss: 8.631e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.184e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5590, Mean_loss of pinns: 8.249e-03, loss_BC: 2.263e-05, loss_IC: 3.936e-05, loss_f: 8.187e-03
 => minimum loss: 6.554e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.823e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0300

==> Epoch: 5600, Mean_loss of pinns: 7.065e-03, loss_BC: 2.399e-05, loss_IC: 5.243e-05, loss_f: 6.989e-03
 => minimum loss: 6.443e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.539e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0300

==> Epoch: 5610, Mean_loss of pinns: 6.140e-03, loss_BC: 2.491e-05, loss_IC: 6.537e-05, loss_f: 6.050e-03
 => minimum loss: 6.214e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.313e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 5620, Mean_loss of pinns: 5.406e-03, loss_BC: 2.592e-05, loss_IC: 7.780e-05, loss_f: 5.303e-03
 => minimum loss: 5.888e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.131e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 5630, Mean_loss of pinns: 4.816e-03, loss_BC: 2.879e-05, loss_IC: 8.940e-05, loss_f: 4.698e-03
 => minimum loss: 6.045e-05, corresponding pinn/batch index: 0200
 => maximum loss: 9.843e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 5640, Mean_loss of pinns: 4.330e-03, loss_BC: 2.895e-05, loss_IC: 1.001e-04, loss_f: 4.201e-03
 => minimum loss: 5.565e-05, corresponding pinn/batch index: 0200
 => maximum loss: 8.649e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

 !!! Scipy optimize: !!! - Epoch:  5642

 ! Scipy iteration number:  1
Processes:  2
Number of pinns to optimize weights:  2
 !!! pinns to optimize ==> 0100, 0300


pinn: 0100, Iter: 100, total_loss: 1.660e-06, loss_BC: 0.000e+00, loss_IC: 1.473e-07,loss_f: 1.268e-06
pinn: 0300, Iter: 100, total_loss: 9.892e-07, loss_BC: 0.000e+00, loss_IC: 5.968e-08,loss_f: 8.626e-07
pinn: 0300, Iter: 200, total_loss: 2.506e-07, loss_BC: 0.000e+00, loss_IC: 3.261e-08,loss_f: 1.539e-07
pinn: 0100, Iter: 200, total_loss: 4.608e-07, loss_BC: 0.000e+00, loss_IC: 4.661e-08,loss_f: 1.902e-07
pinn: 0100, Iter: 300, total_loss: 3.661e-07, loss_BC: 0.000e+00, loss_IC: 4.642e-08,loss_f: 1.041e-07
pinn: 0300, Iter: 300, total_loss: 1.605e-07, loss_BC: 0.000e+00, loss_IC: 3.025e-08,loss_f: 6.833e-08
pinn: 0100, Iter: 400, total_loss: 3.437e-07, loss_BC: 0.000e+00, loss_IC: 4.384e-08,loss_f: 8.746e-08
pinn: 0300, Iter: 400, total_loss: 1.474e-07, loss_BC: 0.000e+00, loss_IC: 2.811e-08,loss_f: 5.827e-08
pinn: 0100, Iter: 500, total_loss: 3.288e-07, loss_BC: 0.000e+00, loss_IC: 5.068e-08,loss_f: 7.421e-08
pinn: 0300, Iter: 500, total_loss: 1.359e-07, loss_BC: 0.000e+00, loss_IC: 2.374e-08,loss_f: 5.079e-08
pinn: 0300, Iter: 600, total_loss: 1.319e-07, loss_BC: 0.000e+00, loss_IC: 2.256e-08,loss_f: 4.868e-08
pinn: 0100, Iter: 600, total_loss: 3.215e-07, loss_BC: 0.000e+00, loss_IC: 4.829e-08,loss_f: 6.964e-08
pinn: 0100, Iter: 700, total_loss: 3.074e-07, loss_BC: 0.000e+00, loss_IC: 4.666e-08,loss_f: 6.068e-08
pinn: 0300, Iter: 700, total_loss: 1.270e-07, loss_BC: 0.000e+00, loss_IC: 2.215e-08,loss_f: 4.534e-08
pinn: 0100, Iter: 800, total_loss: 3.034e-07, loss_BC: 0.000e+00, loss_IC: 4.629e-08,loss_f: 5.742e-08
pinn: 0300, Iter: 800, total_loss: 1.237e-07, loss_BC: 0.000e+00, loss_IC: 2.162e-08,loss_f: 4.307e-08
pinn: 0100, Iter: 900, total_loss: 2.973e-07, loss_BC: 0.000e+00, loss_IC: 4.702e-08,loss_f: 5.515e-08
pinn: 0300, Iter: 900, total_loss: 1.203e-07, loss_BC: 0.000e+00, loss_IC: 2.004e-08,loss_f: 4.124e-08
pinn: 0100, Iter: 1000, total_loss: 2.909e-07, loss_BC: 0.000e+00, loss_IC: 4.977e-08,loss_f: 5.447e-08
pinn: 0300, Iter: 1000, total_loss: 1.165e-07, loss_BC: 0.000e+00, loss_IC: 1.939e-08,loss_f: 3.826e-08
pinn: 0300, Iter: 1100, total_loss: 1.151e-07, loss_BC: 0.000e+00, loss_IC: 1.884e-08,loss_f: 3.755e-08
pinn: 0100, Iter: 1100, total_loss: 2.834e-07, loss_BC: 0.000e+00, loss_IC: 5.297e-08,loss_f: 5.351e-08
pinn: 0100, Iter: 1200, total_loss: 2.802e-07, loss_BC: 0.000e+00, loss_IC: 5.302e-08,loss_f: 5.388e-08
pinn: 0300, Iter: 1200, total_loss: 1.140e-07, loss_BC: 0.000e+00, loss_IC: 1.859e-08,loss_f: 3.670e-08
pinn: 0100, Iter: 1300, total_loss: 2.766e-07, loss_BC: 0.000e+00, loss_IC: 5.094e-08,loss_f: 5.282e-08
pinn: 0300, Iter: 1300, total_loss: 1.122e-07, loss_BC: 0.000e+00, loss_IC: 1.723e-08,loss_f: 3.658e-08
pinn: 0100, Iter: 1400, total_loss: 2.687e-07, loss_BC: 0.000e+00, loss_IC: 5.062e-08,loss_f: 5.596e-08
pinn: 0300, Iter: 1400, total_loss: 1.114e-07, loss_BC: 0.000e+00, loss_IC: 1.685e-08,loss_f: 3.665e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5642, Mean_loss of pinns: 1.899e-07, loss_BC: 0.000e+00, loss_IC: 3.372e-08, loss_f: 4.642e-08
 => minimum loss: 1.114e-07, corresponding pinn index: 0300
 => maximum loss: 2.685e-07, corresponding pinn  index: 0100

 max_loss: 6.843e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5644, total_loss: 3.166e-05, loss_BC: 1.810e-05, loss_IC: 4.144e-06, loss_f: 9.312e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.53000, t_max: 0.54000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5645 0 1

 -------------------------------------------------------------
  -----  Epoch: 5645 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.53000, t_max: 0.54000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5645 !!! 


==> Epoch: 5650, Mean_loss of pinns: 1.274e-02, loss_BC: 1.944e-05, loss_IC: 3.879e-07, loss_f: 1.272e-02
 => minimum loss: 1.779e-04, corresponding pinn/batch index: 0100
 => maximum loss: 2.778e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5660, Mean_loss of pinns: 1.072e-02, loss_BC: 2.033e-05, loss_IC: 2.423e-06, loss_f: 1.070e-02
 => minimum loss: 1.394e-04, corresponding pinn/batch index: 0100
 => maximum loss: 2.289e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5670, Mean_loss of pinns: 9.100e-03, loss_BC: 2.188e-05, loss_IC: 5.170e-06, loss_f: 9.072e-03
 => minimum loss: 1.108e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.904e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5680, Mean_loss of pinns: 7.778e-03, loss_BC: 2.490e-05, loss_IC: 7.684e-06, loss_f: 7.746e-03
 => minimum loss: 8.920e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.599e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5690, Mean_loss of pinns: 6.703e-03, loss_BC: 2.853e-05, loss_IC: 1.068e-05, loss_f: 6.664e-03
 => minimum loss: 7.359e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.359e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5700, Mean_loss of pinns: 5.823e-03, loss_BC: 3.230e-05, loss_IC: 1.439e-05, loss_f: 5.777e-03
 => minimum loss: 6.202e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.168e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5710, Mean_loss of pinns: 5.098e-03, loss_BC: 3.489e-05, loss_IC: 1.884e-05, loss_f: 5.044e-03
 => minimum loss: 5.304e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.013e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5720, Mean_loss of pinns: 4.496e-03, loss_BC: 3.696e-05, loss_IC: 2.362e-05, loss_f: 4.435e-03
 => minimum loss: 4.655e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.977e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5730, Mean_loss of pinns: 3.994e-03, loss_BC: 4.038e-05, loss_IC: 2.827e-05, loss_f: 3.925e-03
 => minimum loss: 4.140e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.012e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5740, Mean_loss of pinns: 3.571e-03, loss_BC: 4.189e-05, loss_IC: 3.270e-05, loss_f: 3.497e-03
 => minimum loss: 3.742e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.191e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  5744

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0000, 0200, 0300


pinn: 0000, Iter: 100, total_loss: 1.132e-06, loss_BC: 0.000e+00, loss_IC: 1.750e-07,loss_f: 7.481e-07
pinn: 0200, Iter: 100, total_loss: 1.204e-06, loss_BC: 0.000e+00, loss_IC: 1.761e-07,loss_f: 8.758e-07
pinn: 0300, Iter: 100, total_loss: 2.292e-07, loss_BC: 0.000e+00, loss_IC: 1.648e-08,loss_f: 1.841e-07
pinn: 0000, Iter: 200, total_loss: 4.232e-07, loss_BC: 0.000e+00, loss_IC: 5.620e-08,loss_f: 1.592e-07
pinn: 0300, Iter: 200, total_loss: 1.156e-07, loss_BC: 0.000e+00, loss_IC: 1.829e-08,loss_f: 6.932e-08
pinn: 0200, Iter: 200, total_loss: 4.561e-07, loss_BC: 0.000e+00, loss_IC: 1.624e-07,loss_f: 1.472e-07
pinn: 0000, Iter: 300, total_loss: 3.474e-07, loss_BC: 0.000e+00, loss_IC: 5.168e-08,loss_f: 9.067e-08
pinn: 0300, Iter: 300, total_loss: 8.927e-08, loss_BC: 0.000e+00, loss_IC: 1.797e-08,loss_f: 4.368e-08
pinn: 0200, Iter: 300, total_loss: 3.705e-07, loss_BC: 0.000e+00, loss_IC: 1.415e-07,loss_f: 8.664e-08
pinn: 0000, Iter: 400, total_loss: 3.244e-07, loss_BC: 0.000e+00, loss_IC: 4.564e-08,loss_f: 7.419e-08
pinn: 0300, Iter: 400, total_loss: 8.567e-08, loss_BC: 0.000e+00, loss_IC: 1.634e-08,loss_f: 4.178e-08
pinn: 0200, Iter: 400, total_loss: 3.369e-07, loss_BC: 0.000e+00, loss_IC: 1.166e-07,loss_f: 8.066e-08
pinn: 0000, Iter: 500, total_loss: 3.094e-07, loss_BC: 0.000e+00, loss_IC: 3.857e-08,loss_f: 6.446e-08
pinn: 0300, Iter: 500, total_loss: 8.167e-08, loss_BC: 0.000e+00, loss_IC: 1.376e-08,loss_f: 4.045e-08
pinn: 0200, Iter: 500, total_loss: 3.198e-07, loss_BC: 0.000e+00, loss_IC: 1.094e-07,loss_f: 7.156e-08
pinn: 0000, Iter: 600, total_loss: 3.038e-07, loss_BC: 0.000e+00, loss_IC: 3.613e-08,loss_f: 6.103e-08
pinn: 0200, Iter: 600, total_loss: 3.103e-07, loss_BC: 0.000e+00, loss_IC: 1.005e-07,loss_f: 7.078e-08
pinn: 0300, Iter: 600, total_loss: 7.866e-08, loss_BC: 0.000e+00, loss_IC: 1.274e-08,loss_f: 3.854e-08
pinn: 0000, Iter: 700, total_loss: 2.984e-07, loss_BC: 0.000e+00, loss_IC: 3.583e-08,loss_f: 5.859e-08
pinn: 0200, Iter: 700, total_loss: 2.983e-07, loss_BC: 0.000e+00, loss_IC: 9.322e-08,loss_f: 6.555e-08
pinn: 0300, Iter: 700, total_loss: 7.731e-08, loss_BC: 0.000e+00, loss_IC: 1.213e-08,loss_f: 3.794e-08
pinn: 0000, Iter: 800, total_loss: 2.921e-07, loss_BC: 0.000e+00, loss_IC: 3.613e-08,loss_f: 5.709e-08
pinn: 0300, Iter: 800, total_loss: 7.545e-08, loss_BC: 0.000e+00, loss_IC: 1.131e-08,loss_f: 3.691e-08
pinn: 0200, Iter: 800, total_loss: 2.881e-07, loss_BC: 0.000e+00, loss_IC: 8.144e-08,loss_f: 6.606e-08
pinn: 0000, Iter: 900, total_loss: 2.860e-07, loss_BC: 0.000e+00, loss_IC: 3.625e-08,loss_f: 5.658e-08
pinn: 0200, Iter: 900, total_loss: 2.737e-07, loss_BC: 0.000e+00, loss_IC: 6.566e-08,loss_f: 6.581e-08
pinn: 0300, Iter: 900, total_loss: 7.370e-08, loss_BC: 0.000e+00, loss_IC: 1.093e-08,loss_f: 3.573e-08
pinn: 0000, Iter: 1000, total_loss: 2.811e-07, loss_BC: 0.000e+00, loss_IC: 3.454e-08,loss_f: 5.692e-08
pinn: 0200, Iter: 1000, total_loss: 2.626e-07, loss_BC: 0.000e+00, loss_IC: 5.188e-08,loss_f: 6.810e-08
pinn: 0300, Iter: 1000, total_loss: 7.304e-08, loss_BC: 0.000e+00, loss_IC: 1.057e-08,loss_f: 3.545e-08
pinn: 0000, Iter: 1100, total_loss: 2.762e-07, loss_BC: 0.000e+00, loss_IC: 3.253e-08,loss_f: 5.818e-08
pinn: 0200, Iter: 1100, total_loss: 2.565e-07, loss_BC: 0.000e+00, loss_IC: 4.542e-08,loss_f: 6.910e-08
pinn: 0300, Iter: 1100, total_loss: 7.168e-08, loss_BC: 0.000e+00, loss_IC: 9.958e-09,loss_f: 3.486e-08
pinn: 0000, Iter: 1200, total_loss: 2.716e-07, loss_BC: 0.000e+00, loss_IC: 3.045e-08,loss_f: 5.820e-08
pinn: 0200, Iter: 1200, total_loss: 2.534e-07, loss_BC: 0.000e+00, loss_IC: 4.133e-08,loss_f: 6.968e-08
pinn: 0300, Iter: 1200, total_loss: 6.910e-08, loss_BC: 0.000e+00, loss_IC: 8.563e-09,loss_f: 3.390e-08
pinn: 0000, Iter: 1300, total_loss: 2.696e-07, loss_BC: 0.000e+00, loss_IC: 2.873e-08,loss_f: 6.090e-08
pinn: 0200, Iter: 1300, total_loss: 2.523e-07, loss_BC: 0.000e+00, loss_IC: 3.820e-08,loss_f: 7.184e-08
pinn: 0300, Iter: 1300, total_loss: 6.868e-08, loss_BC: 0.000e+00, loss_IC: 8.499e-09,loss_f: 3.362e-08
pinn: 0000, Iter: 1400, total_loss: 2.625e-07, loss_BC: 0.000e+00, loss_IC: 2.945e-08,loss_f: 6.650e-08
pinn: 0200, Iter: 1400, total_loss: 2.489e-07, loss_BC: 0.000e+00, loss_IC: 3.429e-08,loss_f: 7.234e-08
pinn: 0300, Iter: 1400, total_loss: 6.793e-08, loss_BC: 0.000e+00, loss_IC: 7.911e-09,loss_f: 3.338e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5744, Mean_loss of pinns: 1.924e-07, loss_BC: 0.000e+00, loss_IC: 2.362e-08, loss_f: 5.740e-08
 => minimum loss: 6.790e-08, corresponding pinn index: 0300
 => maximum loss: 2.609e-07, corresponding pinn  index: 0000

 max_loss: 5.060e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5746, total_loss: 2.860e-05, loss_BC: 2.027e-05, loss_IC: 1.862e-07, loss_f: 8.039e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.54000, t_max: 0.55000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5747 0 1

 -------------------------------------------------------------
  -----  Epoch: 5747 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.54000, t_max: 0.55000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5747 !!! 


==> Epoch: 5750, Mean_loss of pinns: 1.155e-02, loss_BC: 2.119e-05, loss_IC: 2.216e-07, loss_f: 1.153e-02
 => minimum loss: 1.290e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.565e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5760, Mean_loss of pinns: 9.493e-03, loss_BC: 2.047e-05, loss_IC: 2.527e-06, loss_f: 9.470e-03
 => minimum loss: 1.119e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.753e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5770, Mean_loss of pinns: 7.811e-03, loss_BC: 1.839e-05, loss_IC: 6.394e-06, loss_f: 7.787e-03
 => minimum loss: 9.048e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.088e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5780, Mean_loss of pinns: 6.429e-03, loss_BC: 1.873e-05, loss_IC: 1.171e-05, loss_f: 6.398e-03
 => minimum loss: 7.933e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.540e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5790, Mean_loss of pinns: 5.300e-03, loss_BC: 2.005e-05, loss_IC: 1.865e-05, loss_f: 5.262e-03
 => minimum loss: 6.708e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.093e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 5800, Mean_loss of pinns: 4.398e-03, loss_BC: 2.391e-05, loss_IC: 2.751e-05, loss_f: 4.346e-03
 => minimum loss: 6.345e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.734e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 5810, Mean_loss of pinns: 3.682e-03, loss_BC: 2.736e-05, loss_IC: 3.821e-05, loss_f: 3.616e-03
 => minimum loss: 5.633e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.449e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 5820, Mean_loss of pinns: 3.119e-03, loss_BC: 3.033e-05, loss_IC: 5.004e-05, loss_f: 3.038e-03
 => minimum loss: 5.212e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.225e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 5830, Mean_loss of pinns: 2.677e-03, loss_BC: 3.349e-05, loss_IC: 6.212e-05, loss_f: 2.581e-03
 => minimum loss: 4.994e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.049e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 5840, Mean_loss of pinns: 2.329e-03, loss_BC: 3.683e-05, loss_IC: 7.385e-05, loss_f: 2.218e-03
 => minimum loss: 4.776e-05, corresponding pinn/batch index: 0200
 => maximum loss: 9.094e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

 !!! Scipy optimize: !!! - Epoch:  5846

 ! Scipy iteration number:  1
Processes:  2
Number of pinns to optimize weights:  2
 !!! pinns to optimize ==> 0100, 0300


pinn: 0300, Iter: 100, total_loss: 2.420e-07, loss_BC: 0.000e+00, loss_IC: 1.961e-08,loss_f: 2.034e-07
pinn: 0100, Iter: 100, total_loss: 1.418e-06, loss_BC: 0.000e+00, loss_IC: 1.994e-07,loss_f: 1.118e-06
pinn: 0300, Iter: 200, total_loss: 8.787e-08, loss_BC: 0.000e+00, loss_IC: 1.100e-08,loss_f: 5.859e-08
pinn: 0100, Iter: 200, total_loss: 3.143e-07, loss_BC: 0.000e+00, loss_IC: 5.051e-08,loss_f: 1.694e-07
pinn: 0300, Iter: 300, total_loss: 7.144e-08, loss_BC: 0.000e+00, loss_IC: 8.997e-09,loss_f: 4.422e-08
pinn: 0100, Iter: 300, total_loss: 2.443e-07, loss_BC: 0.000e+00, loss_IC: 3.788e-08,loss_f: 1.110e-07
pinn: 0300, Iter: 400, total_loss: 6.901e-08, loss_BC: 0.000e+00, loss_IC: 8.693e-09,loss_f: 4.212e-08
pinn: 0100, Iter: 400, total_loss: 2.206e-07, loss_BC: 0.000e+00, loss_IC: 3.532e-08,loss_f: 8.811e-08
pinn: 0300, Iter: 500, total_loss: 6.753e-08, loss_BC: 0.000e+00, loss_IC: 8.593e-09,loss_f: 4.074e-08
pinn: 0100, Iter: 500, total_loss: 2.099e-07, loss_BC: 0.000e+00, loss_IC: 3.514e-08,loss_f: 7.698e-08
pinn: 0300, Iter: 600, total_loss: 6.535e-08, loss_BC: 0.000e+00, loss_IC: 8.052e-09,loss_f: 3.907e-08
pinn: 0100, Iter: 600, total_loss: 2.010e-07, loss_BC: 0.000e+00, loss_IC: 3.459e-08,loss_f: 6.905e-08
pinn: 0300, Iter: 700, total_loss: 6.447e-08, loss_BC: 0.000e+00, loss_IC: 8.019e-09,loss_f: 3.826e-08
pinn: 0100, Iter: 700, total_loss: 1.945e-07, loss_BC: 0.000e+00, loss_IC: 3.279e-08,loss_f: 6.583e-08
pinn: 0300, Iter: 800, total_loss: 6.342e-08, loss_BC: 0.000e+00, loss_IC: 7.543e-09,loss_f: 3.776e-08
pinn: 0100, Iter: 800, total_loss: 1.913e-07, loss_BC: 0.000e+00, loss_IC: 3.234e-08,loss_f: 6.346e-08
pinn: 0300, Iter: 900, total_loss: 6.303e-08, loss_BC: 0.000e+00, loss_IC: 7.615e-09,loss_f: 3.734e-08
pinn: 0100, Iter: 900, total_loss: 1.868e-07, loss_BC: 0.000e+00, loss_IC: 3.207e-08,loss_f: 6.031e-08
pinn: 0300, Iter: 1000, total_loss: 6.216e-08, loss_BC: 0.000e+00, loss_IC: 7.320e-09,loss_f: 3.672e-08
pinn: 0100, Iter: 1000, total_loss: 1.827e-07, loss_BC: 0.000e+00, loss_IC: 3.081e-08,loss_f: 5.944e-08
pinn: 0300, Iter: 1100, total_loss: 6.172e-08, loss_BC: 0.000e+00, loss_IC: 7.310e-09,loss_f: 3.632e-08
pinn: 0100, Iter: 1100, total_loss: 1.808e-07, loss_BC: 0.000e+00, loss_IC: 2.984e-08,loss_f: 5.918e-08
pinn: 0300, Iter: 1200, total_loss: 6.111e-08, loss_BC: 0.000e+00, loss_IC: 7.363e-09,loss_f: 3.577e-08
pinn: 0100, Iter: 1200, total_loss: 1.780e-07, loss_BC: 0.000e+00, loss_IC: 2.926e-08,loss_f: 5.782e-08
pinn: 0300, Iter: 1300, total_loss: 5.942e-08, loss_BC: 0.000e+00, loss_IC: 7.617e-09,loss_f: 3.399e-08
pinn: 0100, Iter: 1300, total_loss: 1.770e-07, loss_BC: 0.000e+00, loss_IC: 2.947e-08,loss_f: 5.704e-08
pinn: 0300, Iter: 1400, total_loss: 5.920e-08, loss_BC: 0.000e+00, loss_IC: 7.655e-09,loss_f: 3.376e-08
pinn: 0100, Iter: 1400, total_loss: 1.722e-07, loss_BC: 0.000e+00, loss_IC: 2.827e-08,loss_f: 5.612e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5846, Mean_loss of pinns: 1.156e-07, loss_BC: 0.000e+00, loss_IC: 1.796e-08, loss_f: 4.490e-08
 => minimum loss: 5.916e-08, corresponding pinn index: 0300
 => maximum loss: 1.721e-07, corresponding pinn  index: 0100

 max_loss: 6.660e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5848, total_loss: 3.322e-05, loss_BC: 1.899e-05, loss_IC: 1.155e-06, loss_f: 1.294e-05

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.55000, t_max: 0.56000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5849 0 1

 -------------------------------------------------------------
  -----  Epoch: 5849 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.55000, t_max: 0.56000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5849 !!! 


==> Epoch: 5850, Mean_loss of pinns: 7.988e-03, loss_BC: 2.054e-05, loss_IC: 2.634e-08, loss_f: 7.967e-03
 => minimum loss: 1.978e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.623e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5860, Mean_loss of pinns: 6.594e-03, loss_BC: 2.027e-05, loss_IC: 2.415e-06, loss_f: 6.571e-03
 => minimum loss: 1.524e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.331e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5870, Mean_loss of pinns: 5.524e-03, loss_BC: 2.176e-05, loss_IC: 6.774e-06, loss_f: 5.495e-03
 => minimum loss: 1.232e-04, corresponding pinn/batch index: 0100
 => maximum loss: 1.121e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5880, Mean_loss of pinns: 4.663e-03, loss_BC: 2.440e-05, loss_IC: 1.092e-05, loss_f: 4.628e-03
 => minimum loss: 1.008e-04, corresponding pinn/batch index: 0100
 => maximum loss: 9.559e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5890, Mean_loss of pinns: 3.965e-03, loss_BC: 2.861e-05, loss_IC: 1.467e-05, loss_f: 3.922e-03
 => minimum loss: 8.370e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.229e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5900, Mean_loss of pinns: 3.402e-03, loss_BC: 3.274e-05, loss_IC: 1.876e-05, loss_f: 3.351e-03
 => minimum loss: 7.060e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.155e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5910, Mean_loss of pinns: 2.947e-03, loss_BC: 3.769e-05, loss_IC: 2.344e-05, loss_f: 2.886e-03
 => minimum loss: 6.020e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.274e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5920, Mean_loss of pinns: 2.575e-03, loss_BC: 4.120e-05, loss_IC: 2.838e-05, loss_f: 2.505e-03
 => minimum loss: 5.248e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.541e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5930, Mean_loss of pinns: 2.269e-03, loss_BC: 4.296e-05, loss_IC: 3.310e-05, loss_f: 2.192e-03
 => minimum loss: 4.656e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.925e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 5940, Mean_loss of pinns: 2.015e-03, loss_BC: 4.459e-05, loss_IC: 3.694e-05, loss_f: 1.934e-03
 => minimum loss: 4.204e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.403e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  5948

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0000, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 3.405e-07, loss_BC: 0.000e+00, loss_IC: 3.344e-08,loss_f: 2.911e-07
pinn: 0200, Iter: 100, total_loss: 1.203e-06, loss_BC: 0.000e+00, loss_IC: 7.914e-08,loss_f: 7.504e-07
pinn: 0000, Iter: 100, total_loss: 9.172e-07, loss_BC: 0.000e+00, loss_IC: 1.113e-07,loss_f: 7.225e-07
pinn: 0300, Iter: 200, total_loss: 1.014e-07, loss_BC: 0.000e+00, loss_IC: 1.494e-08,loss_f: 7.104e-08
pinn: 0200, Iter: 200, total_loss: 6.144e-07, loss_BC: 0.000e+00, loss_IC: 8.087e-08,loss_f: 1.830e-07
pinn: 0000, Iter: 200, total_loss: 2.606e-07, loss_BC: 0.000e+00, loss_IC: 3.355e-08,loss_f: 1.455e-07
pinn: 0200, Iter: 300, total_loss: 4.734e-07, loss_BC: 0.000e+00, loss_IC: 5.051e-08,loss_f: 6.668e-08
pinn: 0300, Iter: 300, total_loss: 7.741e-08, loss_BC: 0.000e+00, loss_IC: 8.617e-09,loss_f: 5.350e-08
pinn: 0000, Iter: 300, total_loss: 1.771e-07, loss_BC: 0.000e+00, loss_IC: 2.328e-08,loss_f: 7.292e-08
pinn: 0200, Iter: 400, total_loss: 4.560e-07, loss_BC: 0.000e+00, loss_IC: 4.829e-08,loss_f: 5.637e-08
pinn: 0300, Iter: 400, total_loss: 7.050e-08, loss_BC: 0.000e+00, loss_IC: 8.262e-09,loss_f: 4.701e-08
pinn: 0000, Iter: 400, total_loss: 1.654e-07, loss_BC: 0.000e+00, loss_IC: 2.232e-08,loss_f: 6.199e-08
pinn: 0300, Iter: 500, total_loss: 6.806e-08, loss_BC: 0.000e+00, loss_IC: 8.202e-09,loss_f: 4.462e-08
pinn: 0200, Iter: 500, total_loss: 4.420e-07, loss_BC: 0.000e+00, loss_IC: 4.771e-08,loss_f: 5.064e-08
pinn: 0000, Iter: 500, total_loss: 1.566e-07, loss_BC: 0.000e+00, loss_IC: 1.941e-08,loss_f: 5.531e-08
pinn: 0200, Iter: 600, total_loss: 4.306e-07, loss_BC: 0.000e+00, loss_IC: 4.572e-08,loss_f: 4.796e-08
pinn: 0300, Iter: 600, total_loss: 6.360e-08, loss_BC: 0.000e+00, loss_IC: 8.430e-09,loss_f: 3.992e-08
pinn: 0000, Iter: 600, total_loss: 1.526e-07, loss_BC: 0.000e+00, loss_IC: 1.934e-08,loss_f: 5.111e-08
pinn: 0200, Iter: 700, total_loss: 4.191e-07, loss_BC: 0.000e+00, loss_IC: 5.124e-08,loss_f: 5.014e-08
pinn: 0300, Iter: 700, total_loss: 6.274e-08, loss_BC: 0.000e+00, loss_IC: 8.151e-09,loss_f: 3.936e-08
pinn: 0000, Iter: 700, total_loss: 1.495e-07, loss_BC: 0.000e+00, loss_IC: 1.861e-08,loss_f: 4.889e-08
pinn: 0200, Iter: 800, total_loss: 4.084e-07, loss_BC: 0.000e+00, loss_IC: 5.667e-08,loss_f: 5.029e-08
pinn: 0300, Iter: 800, total_loss: 6.060e-08, loss_BC: 0.000e+00, loss_IC: 8.041e-09,loss_f: 3.742e-08
pinn: 0000, Iter: 800, total_loss: 1.480e-07, loss_BC: 0.000e+00, loss_IC: 1.879e-08,loss_f: 4.781e-08
pinn: 0200, Iter: 900, total_loss: 3.942e-07, loss_BC: 0.000e+00, loss_IC: 5.967e-08,loss_f: 5.469e-08
pinn: 0300, Iter: 900, total_loss: 5.995e-08, loss_BC: 0.000e+00, loss_IC: 8.091e-09,loss_f: 3.671e-08
pinn: 0000, Iter: 900, total_loss: 1.456e-07, loss_BC: 0.000e+00, loss_IC: 2.111e-08,loss_f: 4.489e-08
pinn: 0200, Iter: 1000, total_loss: 3.895e-07, loss_BC: 0.000e+00, loss_IC: 6.355e-08,loss_f: 5.725e-08
pinn: 0300, Iter: 1000, total_loss: 5.884e-08, loss_BC: 0.000e+00, loss_IC: 8.205e-09,loss_f: 3.547e-08
pinn: 0000, Iter: 1000, total_loss: 1.439e-07, loss_BC: 0.000e+00, loss_IC: 2.043e-08,loss_f: 4.395e-08
pinn: 0200, Iter: 1100, total_loss: 3.878e-07, loss_BC: 0.000e+00, loss_IC: 6.305e-08,loss_f: 5.854e-08
pinn: 0300, Iter: 1100, total_loss: 5.782e-08, loss_BC: 0.000e+00, loss_IC: 8.235e-09,loss_f: 3.447e-08
pinn: 0000, Iter: 1100, total_loss: 1.417e-07, loss_BC: 0.000e+00, loss_IC: 2.157e-08,loss_f: 4.224e-08
pinn: 0200, Iter: 1200, total_loss: 3.768e-07, loss_BC: 0.000e+00, loss_IC: 7.841e-08,loss_f: 5.863e-08
pinn: 0300, Iter: 1200, total_loss: 5.683e-08, loss_BC: 0.000e+00, loss_IC: 8.062e-09,loss_f: 3.368e-08
pinn: 0000, Iter: 1200, total_loss: 1.412e-07, loss_BC: 0.000e+00, loss_IC: 2.191e-08,loss_f: 4.193e-08
pinn: 0200, Iter: 1300, total_loss: 3.637e-07, loss_BC: 0.000e+00, loss_IC: 8.535e-08,loss_f: 6.081e-08
pinn: 0300, Iter: 1300, total_loss: 5.619e-08, loss_BC: 0.000e+00, loss_IC: 7.913e-09,loss_f: 3.318e-08
pinn: 0000, Iter: 1300, total_loss: 1.378e-07, loss_BC: 0.000e+00, loss_IC: 2.000e-08,loss_f: 4.081e-08
pinn: 0200, Iter: 1400, total_loss: 3.410e-07, loss_BC: 0.000e+00, loss_IC: 9.066e-08,loss_f: 6.447e-08
pinn: 0300, Iter: 1400, total_loss: 5.565e-08, loss_BC: 0.000e+00, loss_IC: 7.789e-09,loss_f: 3.281e-08
pinn: 0000, Iter: 1400, total_loss: 1.362e-07, loss_BC: 0.000e+00, loss_IC: 2.005e-08,loss_f: 3.996e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 5948, Mean_loss of pinns: 1.737e-07, loss_BC: 0.000e+00, loss_IC: 3.867e-08, loss_f: 4.564e-08
 => minimum loss: 5.529e-08, corresponding pinn index: 0300
 => maximum loss: 3.297e-07, corresponding pinn  index: 0200

==> Epoch: 5950, Mean_loss of pinns: 3.054e-05, loss_BC: 2.199e-05, loss_IC: 3.273e-07, loss_f: 8.137e-06
 => minimum loss: 1.157e-05, corresponding pinn/batch index: 0200
 => maximum loss: 5.575e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 5.575e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 5950, total_loss: 3.054e-05, loss_BC: 2.199e-05, loss_IC: 3.273e-07, loss_f: 8.137e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.56000, t_max: 0.57000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  5951 0 1

 -------------------------------------------------------------
  -----  Epoch: 5951 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.56000, t_max: 0.57000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  5951 !!! 


==> Epoch: 5960, Mean_loss of pinns: 5.567e-03, loss_BC: 2.140e-05, loss_IC: 1.807e-06, loss_f: 5.544e-03
 => minimum loss: 1.325e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.172e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5970, Mean_loss of pinns: 4.434e-03, loss_BC: 1.974e-05, loss_IC: 6.162e-06, loss_f: 4.408e-03
 => minimum loss: 1.099e-04, corresponding pinn/batch index: 0000
 => maximum loss: 1.729e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5980, Mean_loss of pinns: 3.549e-03, loss_BC: 1.952e-05, loss_IC: 1.218e-05, loss_f: 3.518e-03
 => minimum loss: 9.150e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.382e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 5990, Mean_loss of pinns: 2.870e-03, loss_BC: 2.175e-05, loss_IC: 1.932e-05, loss_f: 2.829e-03
 => minimum loss: 7.906e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.115e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6000, Mean_loss of pinns: 2.358e-03, loss_BC: 2.428e-05, loss_IC: 2.730e-05, loss_f: 2.306e-03
 => minimum loss: 6.790e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.142e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6010, Mean_loss of pinns: 1.974e-03, loss_BC: 2.771e-05, loss_IC: 3.602e-05, loss_f: 1.910e-03
 => minimum loss: 6.009e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.629e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6020, Mean_loss of pinns: 1.681e-03, loss_BC: 2.935e-05, loss_IC: 4.486e-05, loss_f: 1.607e-03
 => minimum loss: 5.464e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.479e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6030, Mean_loss of pinns: 1.457e-03, loss_BC: 3.055e-05, loss_IC: 5.302e-05, loss_f: 1.373e-03
 => minimum loss: 5.020e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.595e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6040, Mean_loss of pinns: 1.281e-03, loss_BC: 3.204e-05, loss_IC: 6.001e-05, loss_f: 1.189e-03
 => minimum loss: 4.785e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.904e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6050, Mean_loss of pinns: 1.141e-03, loss_BC: 3.255e-05, loss_IC: 6.569e-05, loss_f: 1.043e-03
 => minimum loss: 4.599e-05, corresponding pinn/batch index: 0200
 => maximum loss: 4.354e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

 !!! Scipy optimize: !!! - Epoch:  6050

 ! Scipy iteration number:  1
Processes:  2
Number of pinns to optimize weights:  2
 !!! pinns to optimize ==> 0100, 0300


pinn: 0300, Iter: 100, total_loss: 2.733e-07, loss_BC: 0.000e+00, loss_IC: 1.365e-08,loss_f: 2.516e-07
pinn: 0100, Iter: 100, total_loss: 1.503e-06, loss_BC: 0.000e+00, loss_IC: 1.666e-07,loss_f: 1.107e-06
pinn: 0100, Iter: 200, total_loss: 4.273e-07, loss_BC: 0.000e+00, loss_IC: 4.438e-08,loss_f: 1.718e-07
pinn: 0300, Iter: 200, total_loss: 1.033e-07, loss_BC: 0.000e+00, loss_IC: 1.864e-08,loss_f: 6.945e-08
pinn: 0100, Iter: 300, total_loss: 3.427e-07, loss_BC: 0.000e+00, loss_IC: 3.936e-08,loss_f: 9.465e-08
pinn: 0300, Iter: 300, total_loss: 8.995e-08, loss_BC: 0.000e+00, loss_IC: 1.584e-08,loss_f: 5.924e-08
pinn: 0100, Iter: 400, total_loss: 3.204e-07, loss_BC: 0.000e+00, loss_IC: 3.696e-08,loss_f: 7.957e-08
pinn: 0300, Iter: 400, total_loss: 8.500e-08, loss_BC: 0.000e+00, loss_IC: 1.411e-08,loss_f: 5.720e-08
pinn: 0100, Iter: 500, total_loss: 3.140e-07, loss_BC: 0.000e+00, loss_IC: 3.747e-08,loss_f: 7.534e-08
pinn: 0300, Iter: 500, total_loss: 7.783e-08, loss_BC: 0.000e+00, loss_IC: 1.097e-08,loss_f: 5.520e-08
pinn: 0100, Iter: 600, total_loss: 3.115e-07, loss_BC: 0.000e+00, loss_IC: 3.837e-08,loss_f: 7.217e-08
pinn: 0300, Iter: 600, total_loss: 7.576e-08, loss_BC: 0.000e+00, loss_IC: 1.028e-08,loss_f: 5.430e-08
pinn: 0100, Iter: 700, total_loss: 3.075e-07, loss_BC: 0.000e+00, loss_IC: 3.784e-08,loss_f: 6.992e-08
pinn: 0300, Iter: 700, total_loss: 7.165e-08, loss_BC: 0.000e+00, loss_IC: 8.875e-09,loss_f: 5.296e-08
pinn: 0100, Iter: 800, total_loss: 3.015e-07, loss_BC: 0.000e+00, loss_IC: 3.734e-08,loss_f: 6.597e-08
pinn: 0300, Iter: 800, total_loss: 6.869e-08, loss_BC: 0.000e+00, loss_IC: 8.936e-09,loss_f: 5.036e-08
pinn: 0100, Iter: 900, total_loss: 2.913e-07, loss_BC: 0.000e+00, loss_IC: 3.801e-08,loss_f: 6.735e-08
pinn: 0300, Iter: 900, total_loss: 6.770e-08, loss_BC: 0.000e+00, loss_IC: 8.822e-09,loss_f: 4.969e-08
pinn: 0100, Iter: 1000, total_loss: 2.858e-07, loss_BC: 0.000e+00, loss_IC: 3.882e-08,loss_f: 6.899e-08
pinn: 0300, Iter: 1000, total_loss: 6.611e-08, loss_BC: 0.000e+00, loss_IC: 8.456e-09,loss_f: 4.893e-08
pinn: 0100, Iter: 1100, total_loss: 2.814e-07, loss_BC: 0.000e+00, loss_IC: 3.743e-08,loss_f: 6.955e-08
pinn: 0300, Iter: 1100, total_loss: 6.492e-08, loss_BC: 0.000e+00, loss_IC: 7.665e-09,loss_f: 4.889e-08
pinn: 0100, Iter: 1200, total_loss: 2.736e-07, loss_BC: 0.000e+00, loss_IC: 3.539e-08,loss_f: 7.023e-08
pinn: 0300, Iter: 1200, total_loss: 6.472e-08, loss_BC: 0.000e+00, loss_IC: 7.701e-09,loss_f: 4.866e-08
pinn: 0100, Iter: 1300, total_loss: 2.682e-07, loss_BC: 0.000e+00, loss_IC: 3.611e-08,loss_f: 7.500e-08
pinn: 0300, Iter: 1300, total_loss: 6.376e-08, loss_BC: 0.000e+00, loss_IC: 7.811e-09,loss_f: 4.779e-08
pinn: 0100, Iter: 1400, total_loss: 2.594e-07, loss_BC: 0.000e+00, loss_IC: 3.540e-08,loss_f: 8.150e-08
pinn: 0300, Iter: 1400, total_loss: 6.288e-08, loss_BC: 0.000e+00, loss_IC: 7.697e-09,loss_f: 4.725e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6050, Mean_loss of pinns: 1.600e-07, loss_BC: 0.000e+00, loss_IC: 2.132e-08, loss_f: 6.334e-08
 => minimum loss: 6.262e-08, corresponding pinn index: 0300
 => maximum loss: 2.574e-07, corresponding pinn  index: 0100

 max_loss: 6.897e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6052, total_loss: 3.375e-05, loss_BC: 1.856e-05, loss_IC: 6.997e-07, loss_f: 1.440e-05

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.57000, t_max: 0.58000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6053 0 1

 -------------------------------------------------------------
  -----  Epoch: 6053 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.57000, t_max: 0.58000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6053 !!! 


==> Epoch: 6060, Mean_loss of pinns: 9.401e-03, loss_BC: 1.955e-05, loss_IC: 7.233e-07, loss_f: 9.381e-03
 => minimum loss: 7.450e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.389e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6070, Mean_loss of pinns: 7.845e-03, loss_BC: 2.163e-05, loss_IC: 3.165e-06, loss_f: 7.820e-03
 => minimum loss: 5.998e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.947e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6080, Mean_loss of pinns: 6.601e-03, loss_BC: 2.366e-05, loss_IC: 5.941e-06, loss_f: 6.571e-03
 => minimum loss: 4.868e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.602e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6090, Mean_loss of pinns: 5.598e-03, loss_BC: 2.749e-05, loss_IC: 9.269e-06, loss_f: 5.561e-03
 => minimum loss: 4.029e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.334e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6100, Mean_loss of pinns: 4.789e-03, loss_BC: 3.134e-05, loss_IC: 1.363e-05, loss_f: 4.743e-03
 => minimum loss: 3.391e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.126e-02, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6110, Mean_loss of pinns: 4.128e-03, loss_BC: 3.430e-05, loss_IC: 1.895e-05, loss_f: 4.075e-03
 => minimum loss: 2.890e-05, corresponding pinn/batch index: 0100
 => maximum loss: 9.632e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6120, Mean_loss of pinns: 3.586e-03, loss_BC: 3.785e-05, loss_IC: 2.479e-05, loss_f: 3.524e-03
 => minimum loss: 2.554e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.336e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6130, Mean_loss of pinns: 3.138e-03, loss_BC: 4.000e-05, loss_IC: 3.071e-05, loss_f: 3.067e-03
 => minimum loss: 2.258e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.293e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6140, Mean_loss of pinns: 2.766e-03, loss_BC: 4.258e-05, loss_IC: 3.655e-05, loss_f: 2.687e-03
 => minimum loss: 2.053e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.441e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6150, Mean_loss of pinns: 2.456e-03, loss_BC: 4.456e-05, loss_IC: 4.208e-05, loss_f: 2.370e-03
 => minimum loss: 1.874e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.738e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  6152

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0000, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 4.880e-07, loss_BC: 0.000e+00, loss_IC: 2.386e-08,loss_f: 1.906e-07
pinn: 0000, Iter: 100, total_loss: 1.066e-06, loss_BC: 0.000e+00, loss_IC: 1.810e-08,loss_f: 9.903e-07
pinn: 0200, Iter: 100, total_loss: 1.384e-06, loss_BC: 0.000e+00, loss_IC: 1.050e-07,loss_f: 1.031e-06
pinn: 0000, Iter: 200, total_loss: 2.154e-07, loss_BC: 0.000e+00, loss_IC: 2.711e-08,loss_f: 1.334e-07
pinn: 0300, Iter: 200, total_loss: 3.499e-07, loss_BC: 0.000e+00, loss_IC: 1.224e-08,loss_f: 6.655e-08
pinn: 0200, Iter: 200, total_loss: 5.089e-07, loss_BC: 0.000e+00, loss_IC: 7.405e-08,loss_f: 2.035e-07
pinn: 0300, Iter: 300, total_loss: 3.126e-07, loss_BC: 0.000e+00, loss_IC: 1.507e-08,loss_f: 4.122e-08
pinn: 0000, Iter: 300, total_loss: 1.461e-07, loss_BC: 0.000e+00, loss_IC: 2.459e-08,loss_f: 6.492e-08
pinn: 0200, Iter: 300, total_loss: 3.745e-07, loss_BC: 0.000e+00, loss_IC: 5.373e-08,loss_f: 9.199e-08
pinn: 0000, Iter: 400, total_loss: 1.290e-07, loss_BC: 0.000e+00, loss_IC: 2.379e-08,loss_f: 4.858e-08
pinn: 0300, Iter: 400, total_loss: 2.987e-07, loss_BC: 0.000e+00, loss_IC: 1.549e-08,loss_f: 3.630e-08
pinn: 0200, Iter: 400, total_loss: 3.535e-07, loss_BC: 0.000e+00, loss_IC: 5.582e-08,loss_f: 7.974e-08
pinn: 0300, Iter: 500, total_loss: 2.886e-07, loss_BC: 0.000e+00, loss_IC: 1.489e-08,loss_f: 3.632e-08
pinn: 0000, Iter: 500, total_loss: 1.186e-07, loss_BC: 0.000e+00, loss_IC: 2.366e-08,loss_f: 3.776e-08
pinn: 0200, Iter: 500, total_loss: 3.451e-07, loss_BC: 0.000e+00, loss_IC: 5.642e-08,loss_f: 7.196e-08
pinn: 0300, Iter: 600, total_loss: 2.818e-07, loss_BC: 0.000e+00, loss_IC: 1.378e-08,loss_f: 3.627e-08
pinn: 0000, Iter: 600, total_loss: 1.156e-07, loss_BC: 0.000e+00, loss_IC: 2.405e-08,loss_f: 3.405e-08
pinn: 0200, Iter: 600, total_loss: 3.350e-07, loss_BC: 0.000e+00, loss_IC: 5.656e-08,loss_f: 6.571e-08
pinn: 0300, Iter: 700, total_loss: 2.613e-07, loss_BC: 0.000e+00, loss_IC: 2.105e-08,loss_f: 3.515e-08
pinn: 0000, Iter: 700, total_loss: 1.144e-07, loss_BC: 0.000e+00, loss_IC: 2.396e-08,loss_f: 3.324e-08
pinn: 0200, Iter: 700, total_loss: 3.247e-07, loss_BC: 0.000e+00, loss_IC: 5.784e-08,loss_f: 5.858e-08
pinn: 0300, Iter: 800, total_loss: 2.438e-07, loss_BC: 0.000e+00, loss_IC: 2.639e-08,loss_f: 3.876e-08
pinn: 0000, Iter: 800, total_loss: 1.121e-07, loss_BC: 0.000e+00, loss_IC: 2.408e-08,loss_f: 3.140e-08
pinn: 0200, Iter: 800, total_loss: 3.162e-07, loss_BC: 0.000e+00, loss_IC: 5.546e-08,loss_f: 5.599e-08
pinn: 0300, Iter: 900, total_loss: 2.300e-07, loss_BC: 0.000e+00, loss_IC: 2.737e-08,loss_f: 3.855e-08
pinn: 0000, Iter: 900, total_loss: 1.100e-07, loss_BC: 0.000e+00, loss_IC: 2.374e-08,loss_f: 3.013e-08
pinn: 0200, Iter: 900, total_loss: 3.119e-07, loss_BC: 0.000e+00, loss_IC: 5.522e-08,loss_f: 5.577e-08
pinn: 0300, Iter: 1000, total_loss: 2.198e-07, loss_BC: 0.000e+00, loss_IC: 3.066e-08,loss_f: 3.843e-08
pinn: 0000, Iter: 1000, total_loss: 1.092e-07, loss_BC: 0.000e+00, loss_IC: 2.385e-08,loss_f: 2.919e-08
pinn: 0200, Iter: 1000, total_loss: 3.076e-07, loss_BC: 0.000e+00, loss_IC: 5.672e-08,loss_f: 5.654e-08
pinn: 0300, Iter: 1100, total_loss: 2.133e-07, loss_BC: 0.000e+00, loss_IC: 3.002e-08,loss_f: 3.816e-08
pinn: 0000, Iter: 1100, total_loss: 1.068e-07, loss_BC: 0.000e+00, loss_IC: 2.310e-08,loss_f: 2.803e-08
pinn: 0200, Iter: 1100, total_loss: 3.063e-07, loss_BC: 0.000e+00, loss_IC: 5.560e-08,loss_f: 5.713e-08
pinn: 0300, Iter: 1200, total_loss: 2.105e-07, loss_BC: 0.000e+00, loss_IC: 3.129e-08,loss_f: 3.984e-08
pinn: 0000, Iter: 1200, total_loss: 1.061e-07, loss_BC: 0.000e+00, loss_IC: 2.238e-08,loss_f: 2.840e-08
pinn: 0200, Iter: 1200, total_loss: 2.990e-07, loss_BC: 0.000e+00, loss_IC: 5.461e-08,loss_f: 5.956e-08
pinn: 0300, Iter: 1300, total_loss: 2.003e-07, loss_BC: 0.000e+00, loss_IC: 3.041e-08,loss_f: 4.092e-08
pinn: 0000, Iter: 1300, total_loss: 1.047e-07, loss_BC: 0.000e+00, loss_IC: 2.151e-08,loss_f: 2.801e-08
pinn: 0200, Iter: 1300, total_loss: 2.888e-07, loss_BC: 0.000e+00, loss_IC: 5.286e-08,loss_f: 6.129e-08
pinn: 0300, Iter: 1400, total_loss: 1.984e-07, loss_BC: 0.000e+00, loss_IC: 3.198e-08,loss_f: 4.251e-08
pinn: 0000, Iter: 1400, total_loss: 1.034e-07, loss_BC: 0.000e+00, loss_IC: 2.092e-08,loss_f: 2.847e-08
pinn: 0200, Iter: 1400, total_loss: 2.858e-07, loss_BC: 0.000e+00, loss_IC: 5.212e-08,loss_f: 5.944e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6152, Mean_loss of pinns: 1.944e-07, loss_BC: 0.000e+00, loss_IC: 3.422e-08, loss_f: 4.337e-08
 => minimum loss: 1.029e-07, corresponding pinn index: 0000
 => maximum loss: 2.852e-07, corresponding pinn  index: 0200

 max_loss: 5.422e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6154, total_loss: 2.523e-05, loss_BC: 2.131e-05, loss_IC: 8.339e-08, loss_f: 3.740e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.58000, t_max: 0.59000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6155 0 1

 -------------------------------------------------------------
  -----  Epoch: 6155 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.58000, t_max: 0.59000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6155 !!! 


==> Epoch: 6160, Mean_loss of pinns: 4.491e-03, loss_BC: 2.085e-05, loss_IC: 6.085e-07, loss_f: 4.470e-03
 => minimum loss: 4.718e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.767e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0300

==> Epoch: 6170, Mean_loss of pinns: 3.455e-03, loss_BC: 1.840e-05, loss_IC: 3.639e-06, loss_f: 3.432e-03
 => minimum loss: 4.024e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.358e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6180, Mean_loss of pinns: 2.694e-03, loss_BC: 1.826e-05, loss_IC: 9.251e-06, loss_f: 2.666e-03
 => minimum loss: 3.653e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.057e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6190, Mean_loss of pinns: 2.137e-03, loss_BC: 1.948e-05, loss_IC: 1.647e-05, loss_f: 2.101e-03
 => minimum loss: 3.217e-05, corresponding pinn/batch index: 0200
 => maximum loss: 8.364e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6200, Mean_loss of pinns: 1.735e-03, loss_BC: 2.071e-05, loss_IC: 2.421e-05, loss_f: 1.690e-03
 => minimum loss: 2.883e-05, corresponding pinn/batch index: 0200
 => maximum loss: 6.774e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6210, Mean_loss of pinns: 1.445e-03, loss_BC: 2.319e-05, loss_IC: 3.221e-05, loss_f: 1.389e-03
 => minimum loss: 2.522e-05, corresponding pinn/batch index: 0200
 => maximum loss: 5.621e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6220, Mean_loss of pinns: 1.230e-03, loss_BC: 2.456e-05, loss_IC: 3.989e-05, loss_f: 1.165e-03
 => minimum loss: 2.388e-05, corresponding pinn/batch index: 0200
 => maximum loss: 4.768e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6230, Mean_loss of pinns: 1.067e-03, loss_BC: 2.496e-05, loss_IC: 4.655e-05, loss_f: 9.955e-04
 => minimum loss: 2.162e-05, corresponding pinn/batch index: 0200
 => maximum loss: 4.123e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6240, Mean_loss of pinns: 9.402e-04, loss_BC: 2.462e-05, loss_IC: 5.189e-05, loss_f: 8.636e-04
 => minimum loss: 1.982e-05, corresponding pinn/batch index: 0200
 => maximum loss: 3.623e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6250, Mean_loss of pinns: 8.402e-04, loss_BC: 2.502e-05, loss_IC: 5.608e-05, loss_f: 7.589e-04
 => minimum loss: 1.858e-05, corresponding pinn/batch index: 0200
 => maximum loss: 3.227e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

 !!! Scipy optimize: !!! - Epoch:  6254

 ! Scipy iteration number:  1
Processes:  2
Number of pinns to optimize weights:  2
 !!! pinns to optimize ==> 0100, 0300


pinn: 0300, Iter: 100, total_loss: 2.713e-07, loss_BC: 0.000e+00, loss_IC: 2.389e-08,loss_f: 1.854e-07
pinn: 0100, Iter: 100, total_loss: 1.380e-06, loss_BC: 0.000e+00, loss_IC: 2.617e-07,loss_f: 1.048e-06
pinn: 0300, Iter: 200, total_loss: 1.395e-07, loss_BC: 0.000e+00, loss_IC: 1.614e-08,loss_f: 6.221e-08
pinn: 0100, Iter: 200, total_loss: 2.580e-07, loss_BC: 0.000e+00, loss_IC: 4.416e-08,loss_f: 1.493e-07
pinn: 0300, Iter: 300, total_loss: 1.224e-07, loss_BC: 0.000e+00, loss_IC: 1.194e-08,loss_f: 5.146e-08
pinn: 0100, Iter: 300, total_loss: 1.777e-07, loss_BC: 0.000e+00, loss_IC: 2.649e-08,loss_f: 8.662e-08
pinn: 0300, Iter: 400, total_loss: 1.184e-07, loss_BC: 0.000e+00, loss_IC: 1.144e-08,loss_f: 4.845e-08
pinn: 0100, Iter: 400, total_loss: 1.574e-07, loss_BC: 0.000e+00, loss_IC: 2.106e-08,loss_f: 7.064e-08
pinn: 0300, Iter: 500, total_loss: 1.134e-07, loss_BC: 0.000e+00, loss_IC: 1.012e-08,loss_f: 4.487e-08
pinn: 0100, Iter: 500, total_loss: 1.498e-07, loss_BC: 0.000e+00, loss_IC: 1.841e-08,loss_f: 6.574e-08
pinn: 0300, Iter: 600, total_loss: 1.082e-07, loss_BC: 0.000e+00, loss_IC: 7.590e-09,loss_f: 4.238e-08
pinn: 0100, Iter: 600, total_loss: 1.431e-07, loss_BC: 0.000e+00, loss_IC: 1.896e-08,loss_f: 5.862e-08
pinn: 0300, Iter: 700, total_loss: 1.040e-07, loss_BC: 0.000e+00, loss_IC: 5.761e-09,loss_f: 4.019e-08
pinn: 0100, Iter: 700, total_loss: 1.412e-07, loss_BC: 0.000e+00, loss_IC: 1.902e-08,loss_f: 5.695e-08
pinn: 0300, Iter: 800, total_loss: 1.024e-07, loss_BC: 0.000e+00, loss_IC: 5.324e-09,loss_f: 3.892e-08
pinn: 0100, Iter: 800, total_loss: 1.384e-07, loss_BC: 0.000e+00, loss_IC: 1.940e-08,loss_f: 5.516e-08
pinn: 0300, Iter: 900, total_loss: 9.943e-08, loss_BC: 0.000e+00, loss_IC: 4.480e-09,loss_f: 3.664e-08
pinn: 0100, Iter: 900, total_loss: 1.343e-07, loss_BC: 0.000e+00, loss_IC: 1.956e-08,loss_f: 5.180e-08
pinn: 0300, Iter: 1000, total_loss: 9.849e-08, loss_BC: 0.000e+00, loss_IC: 4.456e-09,loss_f: 3.591e-08
pinn: 0100, Iter: 1000, total_loss: 1.324e-07, loss_BC: 0.000e+00, loss_IC: 2.060e-08,loss_f: 4.959e-08
pinn: 0300, Iter: 1100, total_loss: 9.715e-08, loss_BC: 0.000e+00, loss_IC: 4.193e-09,loss_f: 3.501e-08
pinn: 0100, Iter: 1100, total_loss: 1.315e-07, loss_BC: 0.000e+00, loss_IC: 2.025e-08,loss_f: 4.966e-08
pinn: 0300, Iter: 1200, total_loss: 9.468e-08, loss_BC: 0.000e+00, loss_IC: 3.486e-09,loss_f: 3.386e-08
pinn: 0100, Iter: 1200, total_loss: 1.268e-07, loss_BC: 0.000e+00, loss_IC: 2.144e-08,loss_f: 4.567e-08
pinn: 0300, Iter: 1300, total_loss: 9.351e-08, loss_BC: 0.000e+00, loss_IC: 3.344e-09,loss_f: 3.308e-08
pinn: 0100, Iter: 1300, total_loss: 1.261e-07, loss_BC: 0.000e+00, loss_IC: 2.127e-08,loss_f: 4.553e-08
pinn: 0300, Iter: 1400, total_loss: 9.251e-08, loss_BC: 0.000e+00, loss_IC: 2.976e-09,loss_f: 3.251e-08
pinn: 0100, Iter: 1400, total_loss: 1.226e-07, loss_BC: 0.000e+00, loss_IC: 2.152e-08,loss_f: 4.320e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6254, Mean_loss of pinns: 1.075e-07, loss_BC: 0.000e+00, loss_IC: 1.227e-08, loss_f: 3.777e-08
 => minimum loss: 9.245e-08, corresponding pinn index: 0300
 => maximum loss: 1.225e-07, corresponding pinn  index: 0100

 max_loss: 5.813e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6256, total_loss: 2.433e-05, loss_BC: 1.916e-05, loss_IC: 5.055e-07, loss_f: 4.523e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.59000, t_max: 0.60000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6257 0 1

 -------------------------------------------------------------
  -----  Epoch: 6257 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.59000, t_max: 0.60000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6257 !!! 


==> Epoch: 6260, Mean_loss of pinns: 7.847e-03, loss_BC: 2.004e-05, loss_IC: 2.208e-07, loss_f: 7.826e-03
 => minimum loss: 1.270e-04, corresponding pinn/batch index: 0100
 => maximum loss: 2.099e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6270, Mean_loss of pinns: 6.546e-03, loss_BC: 2.058e-05, loss_IC: 3.075e-06, loss_f: 6.522e-03
 => minimum loss: 9.969e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.785e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6280, Mean_loss of pinns: 5.514e-03, loss_BC: 2.266e-05, loss_IC: 7.460e-06, loss_f: 5.484e-03
 => minimum loss: 7.994e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.533e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6290, Mean_loss of pinns: 4.687e-03, loss_BC: 2.575e-05, loss_IC: 1.197e-05, loss_f: 4.649e-03
 => minimum loss: 6.548e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.325e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6300, Mean_loss of pinns: 4.027e-03, loss_BC: 2.896e-05, loss_IC: 1.656e-05, loss_f: 3.981e-03
 => minimum loss: 5.416e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.154e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6310, Mean_loss of pinns: 3.501e-03, loss_BC: 3.139e-05, loss_IC: 2.078e-05, loss_f: 3.448e-03
 => minimum loss: 4.599e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.015e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6320, Mean_loss of pinns: 3.079e-03, loss_BC: 3.398e-05, loss_IC: 2.431e-05, loss_f: 3.021e-03
 => minimum loss: 4.019e-05, corresponding pinn/batch index: 0100
 => maximum loss: 9.009e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6330, Mean_loss of pinns: 2.737e-03, loss_BC: 3.451e-05, loss_IC: 2.680e-05, loss_f: 2.675e-03
 => minimum loss: 3.575e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.067e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6340, Mean_loss of pinns: 2.455e-03, loss_BC: 3.381e-05, loss_IC: 2.801e-05, loss_f: 2.393e-03
 => minimum loss: 3.178e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.285e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6350, Mean_loss of pinns: 2.221e-03, loss_BC: 3.346e-05, loss_IC: 2.804e-05, loss_f: 2.160e-03
 => minimum loss: 2.859e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.631e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  6356

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0000, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 3.033e-07, loss_BC: 0.000e+00, loss_IC: 2.860e-08,loss_f: 1.984e-07
pinn: 0000, Iter: 100, total_loss: 1.233e-06, loss_BC: 0.000e+00, loss_IC: 6.141e-08,loss_f: 1.064e-06
pinn: 0200, Iter: 100, total_loss: 7.914e-07, loss_BC: 0.000e+00, loss_IC: 3.130e-08,loss_f: 5.093e-07
pinn: 0300, Iter: 200, total_loss: 1.564e-07, loss_BC: 0.000e+00, loss_IC: 1.607e-08,loss_f: 6.524e-08
pinn: 0200, Iter: 200, total_loss: 3.941e-07, loss_BC: 0.000e+00, loss_IC: 3.917e-08,loss_f: 1.124e-07
pinn: 0000, Iter: 200, total_loss: 2.412e-07, loss_BC: 0.000e+00, loss_IC: 2.237e-08,loss_f: 1.128e-07
pinn: 0300, Iter: 300, total_loss: 1.428e-07, loss_BC: 0.000e+00, loss_IC: 1.375e-08,loss_f: 5.657e-08
pinn: 0000, Iter: 300, total_loss: 1.779e-07, loss_BC: 0.000e+00, loss_IC: 2.325e-08,loss_f: 5.065e-08
pinn: 0200, Iter: 300, total_loss: 3.238e-07, loss_BC: 0.000e+00, loss_IC: 3.452e-08,loss_f: 5.242e-08
pinn: 0300, Iter: 400, total_loss: 1.386e-07, loss_BC: 0.000e+00, loss_IC: 1.371e-08,loss_f: 5.444e-08
pinn: 0200, Iter: 400, total_loss: 2.986e-07, loss_BC: 0.000e+00, loss_IC: 3.262e-08,loss_f: 4.644e-08
pinn: 0000, Iter: 400, total_loss: 1.686e-07, loss_BC: 0.000e+00, loss_IC: 2.282e-08,loss_f: 4.227e-08
pinn: 0300, Iter: 500, total_loss: 1.348e-07, loss_BC: 0.000e+00, loss_IC: 1.293e-08,loss_f: 5.268e-08
pinn: 0200, Iter: 500, total_loss: 2.879e-07, loss_BC: 0.000e+00, loss_IC: 3.480e-08,loss_f: 4.062e-08
pinn: 0000, Iter: 500, total_loss: 1.629e-07, loss_BC: 0.000e+00, loss_IC: 2.334e-08,loss_f: 3.659e-08
pinn: 0300, Iter: 600, total_loss: 1.325e-07, loss_BC: 0.000e+00, loss_IC: 1.172e-08,loss_f: 5.173e-08
pinn: 0200, Iter: 600, total_loss: 2.778e-07, loss_BC: 0.000e+00, loss_IC: 3.443e-08,loss_f: 3.827e-08
pinn: 0000, Iter: 600, total_loss: 1.598e-07, loss_BC: 0.000e+00, loss_IC: 2.358e-08,loss_f: 3.401e-08
pinn: 0300, Iter: 700, total_loss: 1.302e-07, loss_BC: 0.000e+00, loss_IC: 1.061e-08,loss_f: 5.058e-08
pinn: 0200, Iter: 700, total_loss: 2.688e-07, loss_BC: 0.000e+00, loss_IC: 3.977e-08,loss_f: 3.650e-08
pinn: 0000, Iter: 700, total_loss: 1.575e-07, loss_BC: 0.000e+00, loss_IC: 2.354e-08,loss_f: 3.282e-08
pinn: 0300, Iter: 800, total_loss: 1.282e-07, loss_BC: 0.000e+00, loss_IC: 9.729e-09,loss_f: 4.968e-08
pinn: 0200, Iter: 800, total_loss: 2.628e-07, loss_BC: 0.000e+00, loss_IC: 3.898e-08,loss_f: 3.455e-08
pinn: 0000, Iter: 800, total_loss: 1.557e-07, loss_BC: 0.000e+00, loss_IC: 2.352e-08,loss_f: 3.235e-08
pinn: 0300, Iter: 900, total_loss: 1.272e-07, loss_BC: 0.000e+00, loss_IC: 9.435e-09,loss_f: 4.896e-08
pinn: 0200, Iter: 900, total_loss: 2.571e-07, loss_BC: 0.000e+00, loss_IC: 4.040e-08,loss_f: 3.575e-08
pinn: 0000, Iter: 900, total_loss: 1.527e-07, loss_BC: 0.000e+00, loss_IC: 2.429e-08,loss_f: 3.193e-08
pinn: 0300, Iter: 1000, total_loss: 1.257e-07, loss_BC: 0.000e+00, loss_IC: 9.537e-09,loss_f: 4.808e-08
pinn: 0200, Iter: 1000, total_loss: 2.531e-07, loss_BC: 0.000e+00, loss_IC: 4.271e-08,loss_f: 3.633e-08
pinn: 0000, Iter: 1000, total_loss: 1.496e-07, loss_BC: 0.000e+00, loss_IC: 2.460e-08,loss_f: 3.166e-08
pinn: 0300, Iter: 1100, total_loss: 1.232e-07, loss_BC: 0.000e+00, loss_IC: 8.799e-09,loss_f: 4.756e-08
pinn: 0200, Iter: 1100, total_loss: 2.433e-07, loss_BC: 0.000e+00, loss_IC: 5.384e-08,loss_f: 3.686e-08
pinn: 0000, Iter: 1100, total_loss: 1.450e-07, loss_BC: 0.000e+00, loss_IC: 2.199e-08,loss_f: 3.328e-08
pinn: 0300, Iter: 1200, total_loss: 1.188e-07, loss_BC: 0.000e+00, loss_IC: 9.079e-09,loss_f: 4.682e-08
pinn: 0200, Iter: 1200, total_loss: 2.404e-07, loss_BC: 0.000e+00, loss_IC: 5.142e-08,loss_f: 3.797e-08
pinn: 0000, Iter: 1200, total_loss: 1.442e-07, loss_BC: 0.000e+00, loss_IC: 2.106e-08,loss_f: 3.389e-08
pinn: 0300, Iter: 1300, total_loss: 1.160e-07, loss_BC: 0.000e+00, loss_IC: 9.679e-09,loss_f: 4.551e-08
pinn: 0200, Iter: 1300, total_loss: 2.320e-07, loss_BC: 0.000e+00, loss_IC: 5.373e-08,loss_f: 4.029e-08
pinn: 0000, Iter: 1300, total_loss: 1.426e-07, loss_BC: 0.000e+00, loss_IC: 2.058e-08,loss_f: 3.440e-08
pinn: 0300, Iter: 1400, total_loss: 1.132e-07, loss_BC: 0.000e+00, loss_IC: 9.802e-09,loss_f: 4.427e-08
pinn: 0200, Iter: 1400, total_loss: 2.320e-07, loss_BC: 0.000e+00, loss_IC: 5.668e-08,loss_f: 4.685e-08
pinn: 0000, Iter: 1400, total_loss: 1.410e-07, loss_BC: 0.000e+00, loss_IC: 1.995e-08,loss_f: 3.381e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6356, Mean_loss of pinns: 1.592e-07, loss_BC: 0.000e+00, loss_IC: 2.767e-08, loss_f: 3.997e-08
 => minimum loss: 1.132e-07, corresponding pinn index: 0300
 => maximum loss: 2.237e-07, corresponding pinn  index: 0200

 max_loss: 5.526e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6358, total_loss: 2.732e-05, loss_BC: 2.161e-05, loss_IC: 1.502e-07, loss_f: 5.442e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.60000, t_max: 0.61000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6359 0 1

 -------------------------------------------------------------
  -----  Epoch: 6359 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.60000, t_max: 0.61000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6359 !!! 


==> Epoch: 6360, Mean_loss of pinns: 4.907e-03, loss_BC: 2.186e-05, loss_IC: 2.934e-08, loss_f: 4.885e-03
 => minimum loss: 9.384e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.883e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6370, Mean_loss of pinns: 4.071e-03, loss_BC: 1.978e-05, loss_IC: 3.009e-06, loss_f: 4.048e-03
 => minimum loss: 8.275e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.566e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6380, Mean_loss of pinns: 3.408e-03, loss_BC: 1.721e-05, loss_IC: 7.880e-06, loss_f: 3.383e-03
 => minimum loss: 6.691e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.313e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6390, Mean_loss of pinns: 2.865e-03, loss_BC: 1.683e-05, loss_IC: 1.345e-05, loss_f: 2.834e-03
 => minimum loss: 5.710e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.103e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6400, Mean_loss of pinns: 2.423e-03, loss_BC: 1.576e-05, loss_IC: 1.910e-05, loss_f: 2.388e-03
 => minimum loss: 4.675e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.335e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6410, Mean_loss of pinns: 2.067e-03, loss_BC: 1.709e-05, loss_IC: 2.491e-05, loss_f: 2.025e-03
 => minimum loss: 4.249e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.956e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6420, Mean_loss of pinns: 1.780e-03, loss_BC: 1.902e-05, loss_IC: 3.129e-05, loss_f: 1.729e-03
 => minimum loss: 4.009e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.837e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6430, Mean_loss of pinns: 1.545e-03, loss_BC: 1.991e-05, loss_IC: 3.787e-05, loss_f: 1.487e-03
 => minimum loss: 3.624e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.924e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6440, Mean_loss of pinns: 1.354e-03, loss_BC: 2.140e-05, loss_IC: 4.406e-05, loss_f: 1.288e-03
 => minimum loss: 3.589e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.179e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

==> Epoch: 6450, Mean_loss of pinns: 1.195e-03, loss_BC: 2.140e-05, loss_IC: 4.922e-05, loss_f: 1.125e-03
 => minimum loss: 3.483e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.564e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0100, 0300

 !!! Scipy optimize: !!! - Epoch:  6458

 ! Scipy iteration number:  1
Processes:  2
Number of pinns to optimize weights:  2
 !!! pinns to optimize ==> 0100, 0300


pinn: 0300, Iter: 100, total_loss: 2.980e-07, loss_BC: 0.000e+00, loss_IC: 2.506e-08,loss_f: 2.533e-07
pinn: 0100, Iter: 100, total_loss: 1.384e-06, loss_BC: 0.000e+00, loss_IC: 9.165e-08,loss_f: 1.189e-06
pinn: 0300, Iter: 200, total_loss: 1.042e-07, loss_BC: 0.000e+00, loss_IC: 1.465e-08,loss_f: 7.035e-08
pinn: 0100, Iter: 200, total_loss: 2.757e-07, loss_BC: 0.000e+00, loss_IC: 4.959e-08,loss_f: 1.302e-07
pinn: 0300, Iter: 300, total_loss: 8.750e-08, loss_BC: 0.000e+00, loss_IC: 1.103e-08,loss_f: 5.769e-08
pinn: 0100, Iter: 300, total_loss: 1.908e-07, loss_BC: 0.000e+00, loss_IC: 3.326e-08,loss_f: 6.088e-08
pinn: 0300, Iter: 400, total_loss: 8.247e-08, loss_BC: 0.000e+00, loss_IC: 1.057e-08,loss_f: 5.336e-08
pinn: 0100, Iter: 400, total_loss: 1.748e-07, loss_BC: 0.000e+00, loss_IC: 2.864e-08,loss_f: 5.002e-08
pinn: 0300, Iter: 500, total_loss: 7.757e-08, loss_BC: 0.000e+00, loss_IC: 1.063e-08,loss_f: 4.825e-08
pinn: 0100, Iter: 500, total_loss: 1.695e-07, loss_BC: 0.000e+00, loss_IC: 2.719e-08,loss_f: 4.592e-08
pinn: 0300, Iter: 600, total_loss: 7.343e-08, loss_BC: 0.000e+00, loss_IC: 1.007e-08,loss_f: 4.474e-08
pinn: 0100, Iter: 600, total_loss: 1.648e-07, loss_BC: 0.000e+00, loss_IC: 2.572e-08,loss_f: 4.279e-08
pinn: 0300, Iter: 700, total_loss: 7.153e-08, loss_BC: 0.000e+00, loss_IC: 9.963e-09,loss_f: 4.289e-08
pinn: 0100, Iter: 700, total_loss: 1.615e-07, loss_BC: 0.000e+00, loss_IC: 2.664e-08,loss_f: 3.968e-08
pinn: 0300, Iter: 800, total_loss: 6.943e-08, loss_BC: 0.000e+00, loss_IC: 9.901e-09,loss_f: 4.095e-08
pinn: 0100, Iter: 800, total_loss: 1.598e-07, loss_BC: 0.000e+00, loss_IC: 2.710e-08,loss_f: 3.880e-08
pinn: 0300, Iter: 900, total_loss: 6.805e-08, loss_BC: 0.000e+00, loss_IC: 9.965e-09,loss_f: 3.951e-08
pinn: 0100, Iter: 900, total_loss: 1.570e-07, loss_BC: 0.000e+00, loss_IC: 2.777e-08,loss_f: 3.736e-08
pinn: 0300, Iter: 1000, total_loss: 6.660e-08, loss_BC: 0.000e+00, loss_IC: 9.801e-09,loss_f: 3.820e-08
pinn: 0100, Iter: 1000, total_loss: 1.532e-07, loss_BC: 0.000e+00, loss_IC: 2.738e-08,loss_f: 3.684e-08
pinn: 0300, Iter: 1100, total_loss: 6.419e-08, loss_BC: 0.000e+00, loss_IC: 9.625e-09,loss_f: 3.590e-08
pinn: 0300, Iter: 1200, total_loss: 6.334e-08, loss_BC: 0.000e+00, loss_IC: 9.538e-09,loss_f: 3.514e-08
pinn: 0100, Iter: 1100, total_loss: 1.491e-07, loss_BC: 0.000e+00, loss_IC: 2.568e-08,loss_f: 3.665e-08
pinn: 0300, Iter: 1300, total_loss: 6.246e-08, loss_BC: 0.000e+00, loss_IC: 9.073e-09,loss_f: 3.477e-08
pinn: 0100, Iter: 1200, total_loss: 1.482e-07, loss_BC: 0.000e+00, loss_IC: 2.545e-08,loss_f: 3.665e-08
pinn: 0300, Iter: 1400, total_loss: 6.228e-08, loss_BC: 0.000e+00, loss_IC: 9.019e-09,loss_f: 3.467e-08
pinn: 0100, Iter: 1300, total_loss: 1.435e-07, loss_BC: 0.000e+00, loss_IC: 2.379e-08,loss_f: 3.560e-08
pinn: 0100, Iter: 1400, total_loss: 1.399e-07, loss_BC: 0.000e+00, loss_IC: 2.249e-08,loss_f: 3.700e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6458, Mean_loss of pinns: 9.959e-08, loss_BC: 0.000e+00, loss_IC: 1.539e-08, loss_f: 3.597e-08
 => minimum loss: 6.176e-08, corresponding pinn index: 0300
 => maximum loss: 1.374e-07, corresponding pinn  index: 0100

==> Epoch: 6460, Mean_loss of pinns: 2.770e-05, loss_BC: 1.868e-05, loss_IC: 6.814e-07, loss_f: 8.264e-06
 => minimum loss: 6.247e-06, corresponding pinn/batch index: 0100
 => maximum loss: 5.900e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 5.900e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6460, total_loss: 2.770e-05, loss_BC: 1.868e-05, loss_IC: 6.814e-07, loss_f: 8.264e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.61000, t_max: 0.62000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6461 0 1

 -------------------------------------------------------------
  -----  Epoch: 6461 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.61000, t_max: 0.62000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6461 !!! 


==> Epoch: 6470, Mean_loss of pinns: 3.138e-03, loss_BC: 2.019e-05, loss_IC: 1.172e-06, loss_f: 3.116e-03
 => minimum loss: 7.310e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.607e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6480, Mean_loss of pinns: 2.622e-03, loss_BC: 2.187e-05, loss_IC: 4.415e-06, loss_f: 2.595e-03
 => minimum loss: 6.005e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.547e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 6490, Mean_loss of pinns: 2.210e-03, loss_BC: 2.521e-05, loss_IC: 8.851e-06, loss_f: 2.175e-03
 => minimum loss: 4.952e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.652e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 6500, Mean_loss of pinns: 1.881e-03, loss_BC: 2.827e-05, loss_IC: 1.305e-05, loss_f: 1.840e-03
 => minimum loss: 4.136e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.897e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 6510, Mean_loss of pinns: 1.617e-03, loss_BC: 3.002e-05, loss_IC: 1.661e-05, loss_f: 1.570e-03
 => minimum loss: 3.532e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.257e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 6520, Mean_loss of pinns: 1.402e-03, loss_BC: 3.150e-05, loss_IC: 1.935e-05, loss_f: 1.351e-03
 => minimum loss: 3.106e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.713e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 6530, Mean_loss of pinns: 1.225e-03, loss_BC: 3.228e-05, loss_IC: 2.101e-05, loss_f: 1.172e-03
 => minimum loss: 2.736e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.254e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 6540, Mean_loss of pinns: 1.078e-03, loss_BC: 3.266e-05, loss_IC: 2.178e-05, loss_f: 1.024e-03
 => minimum loss: 2.517e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.864e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 6550, Mean_loss of pinns: 9.556e-04, loss_BC: 3.273e-05, loss_IC: 2.190e-05, loss_f: 9.007e-04
 => minimum loss: 2.266e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.537e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 6560, Mean_loss of pinns: 8.527e-04, loss_BC: 3.269e-05, loss_IC: 2.149e-05, loss_f: 7.983e-04
 => minimum loss: 2.088e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.260e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

 !!! Scipy optimize: !!! - Epoch:  6560

 ! Scipy iteration number:  1
Processes:  2
Number of pinns to optimize weights:  2
 !!! pinns to optimize ==> 0000, 0200


pinn: 0200, Iter: 100, total_loss: 9.907e-07, loss_BC: 0.000e+00, loss_IC: 5.739e-08,loss_f: 7.298e-07
pinn: 0000, Iter: 100, total_loss: 1.157e-06, loss_BC: 0.000e+00, loss_IC: 1.501e-07,loss_f: 3.429e-07
pinn: 0200, Iter: 200, total_loss: 4.417e-07, loss_BC: 0.000e+00, loss_IC: 7.262e-08,loss_f: 1.764e-07
pinn: 0000, Iter: 200, total_loss: 8.343e-07, loss_BC: 0.000e+00, loss_IC: 4.460e-08,loss_f: 1.117e-07
pinn: 0200, Iter: 300, total_loss: 3.219e-07, loss_BC: 0.000e+00, loss_IC: 6.523e-08,loss_f: 6.730e-08
pinn: 0000, Iter: 300, total_loss: 7.495e-07, loss_BC: 0.000e+00, loss_IC: 5.067e-08,loss_f: 5.638e-08
pinn: 0200, Iter: 400, total_loss: 2.859e-07, loss_BC: 0.000e+00, loss_IC: 5.046e-08,loss_f: 5.438e-08
pinn: 0000, Iter: 400, total_loss: 7.213e-07, loss_BC: 0.000e+00, loss_IC: 6.106e-08,loss_f: 5.987e-08
pinn: 0200, Iter: 500, total_loss: 2.702e-07, loss_BC: 0.000e+00, loss_IC: 5.022e-08,loss_f: 4.621e-08
pinn: 0000, Iter: 500, total_loss: 6.835e-07, loss_BC: 0.000e+00, loss_IC: 5.102e-08,loss_f: 6.834e-08
pinn: 0200, Iter: 600, total_loss: 2.610e-07, loss_BC: 0.000e+00, loss_IC: 4.336e-08,loss_f: 4.526e-08
pinn: 0000, Iter: 600, total_loss: 6.228e-07, loss_BC: 0.000e+00, loss_IC: 4.552e-08,loss_f: 8.925e-08
pinn: 0200, Iter: 700, total_loss: 2.509e-07, loss_BC: 0.000e+00, loss_IC: 4.071e-08,loss_f: 4.230e-08
pinn: 0000, Iter: 700, total_loss: 5.583e-07, loss_BC: 0.000e+00, loss_IC: 5.333e-08,loss_f: 1.080e-07
pinn: 0200, Iter: 800, total_loss: 2.455e-07, loss_BC: 0.000e+00, loss_IC: 3.823e-08,loss_f: 4.072e-08
pinn: 0000, Iter: 800, total_loss: 5.006e-07, loss_BC: 0.000e+00, loss_IC: 6.654e-08,loss_f: 9.940e-08
pinn: 0200, Iter: 900, total_loss: 2.425e-07, loss_BC: 0.000e+00, loss_IC: 3.651e-08,loss_f: 4.105e-08
pinn: 0000, Iter: 900, total_loss: 4.341e-07, loss_BC: 0.000e+00, loss_IC: 8.308e-08,loss_f: 8.680e-08
pinn: 0200, Iter: 1000, total_loss: 2.385e-07, loss_BC: 0.000e+00, loss_IC: 3.605e-08,loss_f: 4.161e-08
pinn: 0000, Iter: 1000, total_loss: 4.236e-07, loss_BC: 0.000e+00, loss_IC: 8.074e-08,loss_f: 8.641e-08
pinn: 0200, Iter: 1100, total_loss: 2.338e-07, loss_BC: 0.000e+00, loss_IC: 3.560e-08,loss_f: 4.254e-08
pinn: 0000, Iter: 1100, total_loss: 3.876e-07, loss_BC: 0.000e+00, loss_IC: 7.214e-08,loss_f: 9.012e-08
pinn: 0200, Iter: 1200, total_loss: 2.287e-07, loss_BC: 0.000e+00, loss_IC: 3.546e-08,loss_f: 4.605e-08
pinn: 0000, Iter: 1200, total_loss: 3.738e-07, loss_BC: 0.000e+00, loss_IC: 7.084e-08,loss_f: 8.991e-08
pinn: 0200, Iter: 1300, total_loss: 2.264e-07, loss_BC: 0.000e+00, loss_IC: 3.563e-08,loss_f: 4.504e-08
pinn: 0000, Iter: 1300, total_loss: 3.522e-07, loss_BC: 0.000e+00, loss_IC: 7.163e-08,loss_f: 9.135e-08
pinn: 0200, Iter: 1400, total_loss: 2.234e-07, loss_BC: 0.000e+00, loss_IC: 3.530e-08,loss_f: 4.659e-08
pinn: 0000, Iter: 1400, total_loss: 3.479e-07, loss_BC: 0.000e+00, loss_IC: 7.273e-08,loss_f: 9.181e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6560, Mean_loss of pinns: 2.841e-07, loss_BC: 0.000e+00, loss_IC: 5.366e-08, loss_f: 6.978e-08
 => minimum loss: 2.216e-07, corresponding pinn index: 0200
 => maximum loss: 3.467e-07, corresponding pinn  index: 0000

 max_loss: 5.479e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6562, total_loss: 3.159e-05, loss_BC: 2.237e-05, loss_IC: 1.391e-06, loss_f: 7.709e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.62000, t_max: 0.63000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6563 0 1

 -------------------------------------------------------------
  -----  Epoch: 6563 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.62000, t_max: 0.63000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6563 !!! 


==> Epoch: 6570, Mean_loss of pinns: 2.799e-03, loss_BC: 2.058e-05, loss_IC: 2.055e-06, loss_f: 2.776e-03
 => minimum loss: 1.690e-04, corresponding pinn/batch index: 0000
 => maximum loss: 7.773e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6580, Mean_loss of pinns: 2.054e-03, loss_BC: 1.915e-05, loss_IC: 9.771e-06, loss_f: 2.025e-03
 => minimum loss: 1.410e-04, corresponding pinn/batch index: 0000
 => maximum loss: 5.604e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6590, Mean_loss of pinns: 1.611e-03, loss_BC: 2.262e-05, loss_IC: 2.010e-05, loss_f: 1.568e-03
 => minimum loss: 1.188e-04, corresponding pinn/batch index: 0000
 => maximum loss: 4.391e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6600, Mean_loss of pinns: 1.301e-03, loss_BC: 2.233e-05, loss_IC: 3.105e-05, loss_f: 1.248e-03
 => minimum loss: 1.043e-04, corresponding pinn/batch index: 0000
 => maximum loss: 3.530e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6610, Mean_loss of pinns: 1.079e-03, loss_BC: 2.081e-05, loss_IC: 4.081e-05, loss_f: 1.018e-03
 => minimum loss: 8.868e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.903e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6620, Mean_loss of pinns: 9.253e-04, loss_BC: 2.181e-05, loss_IC: 4.838e-05, loss_f: 8.551e-04
 => minimum loss: 7.829e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.472e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6630, Mean_loss of pinns: 8.101e-04, loss_BC: 2.174e-05, loss_IC: 5.313e-05, loss_f: 7.351e-04
 => minimum loss: 7.184e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.159e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6640, Mean_loss of pinns: 7.228e-04, loss_BC: 2.354e-05, loss_IC: 5.543e-05, loss_f: 6.438e-04
 => minimum loss: 6.629e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.916e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6650, Mean_loss of pinns: 6.512e-04, loss_BC: 2.275e-05, loss_IC: 5.586e-05, loss_f: 5.726e-04
 => minimum loss: 6.397e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.731e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6660, Mean_loss of pinns: 5.936e-04, loss_BC: 2.320e-05, loss_IC: 5.501e-05, loss_f: 5.153e-04
 => minimum loss: 5.951e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.584e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  6662

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 9.499e-07, loss_BC: 0.000e+00, loss_IC: 9.072e-08,loss_f: 8.319e-07
pinn: 0200, Iter: 100, total_loss: 3.421e-07, loss_BC: 0.000e+00, loss_IC: 4.339e-08,loss_f: 1.972e-07
pinn: 0100, Iter: 100, total_loss: 7.895e-07, loss_BC: 0.000e+00, loss_IC: 8.741e-08,loss_f: 6.605e-07
pinn: 0200, Iter: 200, total_loss: 2.475e-07, loss_BC: 0.000e+00, loss_IC: 4.027e-08,loss_f: 1.039e-07
pinn: 0300, Iter: 200, total_loss: 2.676e-07, loss_BC: 0.000e+00, loss_IC: 3.624e-08,loss_f: 2.045e-07
pinn: 0100, Iter: 200, total_loss: 1.853e-07, loss_BC: 0.000e+00, loss_IC: 2.790e-08,loss_f: 1.183e-07
pinn: 0300, Iter: 300, total_loss: 1.173e-07, loss_BC: 0.000e+00, loss_IC: 1.869e-08,loss_f: 7.314e-08
pinn: 0200, Iter: 300, total_loss: 2.072e-07, loss_BC: 0.000e+00, loss_IC: 3.770e-08,loss_f: 6.931e-08
pinn: 0100, Iter: 300, total_loss: 1.143e-07, loss_BC: 0.000e+00, loss_IC: 2.398e-08,loss_f: 5.157e-08
pinn: 0300, Iter: 400, total_loss: 1.030e-07, loss_BC: 0.000e+00, loss_IC: 1.690e-08,loss_f: 6.105e-08
pinn: 0200, Iter: 400, total_loss: 1.877e-07, loss_BC: 0.000e+00, loss_IC: 3.076e-08,loss_f: 5.936e-08
pinn: 0100, Iter: 400, total_loss: 9.564e-08, loss_BC: 0.000e+00, loss_IC: 1.627e-08,loss_f: 4.062e-08
pinn: 0300, Iter: 500, total_loss: 9.577e-08, loss_BC: 0.000e+00, loss_IC: 1.541e-08,loss_f: 5.559e-08
pinn: 0200, Iter: 500, total_loss: 1.814e-07, loss_BC: 0.000e+00, loss_IC: 2.834e-08,loss_f: 5.576e-08
pinn: 0100, Iter: 500, total_loss: 9.296e-08, loss_BC: 0.000e+00, loss_IC: 1.575e-08,loss_f: 3.830e-08
pinn: 0200, Iter: 600, total_loss: 1.782e-07, loss_BC: 0.000e+00, loss_IC: 2.779e-08,loss_f: 5.301e-08
pinn: 0300, Iter: 600, total_loss: 8.826e-08, loss_BC: 0.000e+00, loss_IC: 1.415e-08,loss_f: 4.926e-08
pinn: 0100, Iter: 600, total_loss: 8.837e-08, loss_BC: 0.000e+00, loss_IC: 1.693e-08,loss_f: 3.216e-08
pinn: 0200, Iter: 700, total_loss: 1.740e-07, loss_BC: 0.000e+00, loss_IC: 2.731e-08,loss_f: 5.058e-08
pinn: 0300, Iter: 700, total_loss: 8.360e-08, loss_BC: 0.000e+00, loss_IC: 1.230e-08,loss_f: 4.659e-08
pinn: 0100, Iter: 700, total_loss: 8.543e-08, loss_BC: 0.000e+00, loss_IC: 1.589e-08,loss_f: 3.018e-08
pinn: 0200, Iter: 800, total_loss: 1.714e-07, loss_BC: 0.000e+00, loss_IC: 2.787e-08,loss_f: 4.879e-08
pinn: 0300, Iter: 800, total_loss: 8.022e-08, loss_BC: 0.000e+00, loss_IC: 1.193e-08,loss_f: 4.381e-08
pinn: 0100, Iter: 800, total_loss: 8.235e-08, loss_BC: 0.000e+00, loss_IC: 1.454e-08,loss_f: 2.895e-08
pinn: 0200, Iter: 900, total_loss: 1.696e-07, loss_BC: 0.000e+00, loss_IC: 2.794e-08,loss_f: 4.800e-08
pinn: 0300, Iter: 900, total_loss: 7.934e-08, loss_BC: 0.000e+00, loss_IC: 1.224e-08,loss_f: 4.267e-08
pinn: 0100, Iter: 900, total_loss: 8.015e-08, loss_BC: 0.000e+00, loss_IC: 1.372e-08,loss_f: 2.787e-08
pinn: 0300, Iter: 1000, total_loss: 7.663e-08, loss_BC: 0.000e+00, loss_IC: 1.163e-08,loss_f: 4.050e-08
pinn: 0200, Iter: 1000, total_loss: 1.660e-07, loss_BC: 0.000e+00, loss_IC: 2.614e-08,loss_f: 4.755e-08
pinn: 0100, Iter: 1000, total_loss: 7.945e-08, loss_BC: 0.000e+00, loss_IC: 1.353e-08,loss_f: 2.742e-08
pinn: 0200, Iter: 1100, total_loss: 1.635e-07, loss_BC: 0.000e+00, loss_IC: 2.551e-08,loss_f: 4.686e-08
pinn: 0300, Iter: 1100, total_loss: 7.606e-08, loss_BC: 0.000e+00, loss_IC: 1.162e-08,loss_f: 3.994e-08
pinn: 0100, Iter: 1100, total_loss: 7.805e-08, loss_BC: 0.000e+00, loss_IC: 1.320e-08,loss_f: 2.644e-08
pinn: 0200, Iter: 1200, total_loss: 1.629e-07, loss_BC: 0.000e+00, loss_IC: 2.519e-08,loss_f: 4.639e-08
pinn: 0300, Iter: 1200, total_loss: 7.453e-08, loss_BC: 0.000e+00, loss_IC: 1.175e-08,loss_f: 3.816e-08
pinn: 0100, Iter: 1200, total_loss: 7.689e-08, loss_BC: 0.000e+00, loss_IC: 1.297e-08,loss_f: 2.586e-08
pinn: 0200, Iter: 1300, total_loss: 1.604e-07, loss_BC: 0.000e+00, loss_IC: 2.344e-08,loss_f: 4.789e-08
pinn: 0300, Iter: 1300, total_loss: 7.331e-08, loss_BC: 0.000e+00, loss_IC: 1.152e-08,loss_f: 3.732e-08
pinn: 0100, Iter: 1300, total_loss: 7.542e-08, loss_BC: 0.000e+00, loss_IC: 1.225e-08,loss_f: 2.532e-08
pinn: 0200, Iter: 1400, total_loss: 1.593e-07, loss_BC: 0.000e+00, loss_IC: 2.328e-08,loss_f: 4.767e-08
pinn: 0300, Iter: 1400, total_loss: 7.133e-08, loss_BC: 0.000e+00, loss_IC: 1.092e-08,loss_f: 3.619e-08
pinn: 0100, Iter: 1400, total_loss: 7.478e-08, loss_BC: 0.000e+00, loss_IC: 1.163e-08,loss_f: 2.556e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6662, Mean_loss of pinns: 1.012e-07, loss_BC: 0.000e+00, loss_IC: 1.505e-08, loss_f: 3.629e-08
 => minimum loss: 7.116e-08, corresponding pinn index: 0300
 => maximum loss: 1.592e-07, corresponding pinn  index: 0200

==> Epoch: 6670, Mean_loss of pinns: 2.477e-05, loss_BC: 1.631e-05, loss_IC: 8.893e-07, loss_f: 7.515e-06
 => minimum loss: 5.305e-06, corresponding pinn/batch index: 0100
 => maximum loss: 7.143e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6680, Mean_loss of pinns: 2.397e-05, loss_BC: 1.531e-05, loss_IC: 1.668e-06, loss_f: 6.937e-06
 => minimum loss: 5.372e-06, corresponding pinn/batch index: 0100
 => maximum loss: 6.974e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 6.969e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6681, total_loss: 2.382e-05, loss_BC: 1.523e-05, loss_IC: 1.677e-06, loss_f: 6.872e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.63000, t_max: 0.64000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6682 0 1

 -------------------------------------------------------------
  -----  Epoch: 6682 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.63000, t_max: 0.64000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6682 !!! 


==> Epoch: 6690, Mean_loss of pinns: 2.169e-03, loss_BC: 1.543e-05, loss_IC: 5.713e-07, loss_f: 2.153e-03
 => minimum loss: 4.389e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.524e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6700, Mean_loss of pinns: 1.868e-03, loss_BC: 1.553e-05, loss_IC: 4.723e-07, loss_f: 1.851e-03
 => minimum loss: 3.711e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.344e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6710, Mean_loss of pinns: 1.622e-03, loss_BC: 1.582e-05, loss_IC: 9.344e-07, loss_f: 1.605e-03
 => minimum loss: 3.081e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.384e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6720, Mean_loss of pinns: 1.413e-03, loss_BC: 1.735e-05, loss_IC: 1.437e-06, loss_f: 1.394e-03
 => minimum loss: 2.621e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.563e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6730, Mean_loss of pinns: 1.236e-03, loss_BC: 1.762e-05, loss_IC: 2.224e-06, loss_f: 1.216e-03
 => minimum loss: 2.253e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.869e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6740, Mean_loss of pinns: 1.085e-03, loss_BC: 1.857e-05, loss_IC: 3.197e-06, loss_f: 1.063e-03
 => minimum loss: 1.976e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.275e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6750, Mean_loss of pinns: 9.566e-04, loss_BC: 1.953e-05, loss_IC: 4.354e-06, loss_f: 9.326e-04
 => minimum loss: 1.748e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.767e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6760, Mean_loss of pinns: 8.464e-04, loss_BC: 2.038e-05, loss_IC: 5.669e-06, loss_f: 8.202e-04
 => minimum loss: 1.564e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.333e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6770, Mean_loss of pinns: 7.525e-04, loss_BC: 2.125e-05, loss_IC: 7.013e-06, loss_f: 7.241e-04
 => minimum loss: 1.415e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.962e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6780, Mean_loss of pinns: 6.720e-04, loss_BC: 2.169e-05, loss_IC: 8.253e-06, loss_f: 6.420e-04
 => minimum loss: 1.240e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.645e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  6781

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 1.449e-06, loss_BC: 0.000e+00, loss_IC: 1.763e-07,loss_f: 1.230e-06
pinn: 0000, Iter: 200, total_loss: 2.554e-07, loss_BC: 0.000e+00, loss_IC: 3.677e-08,loss_f: 1.758e-07
pinn: 0000, Iter: 300, total_loss: 1.781e-07, loss_BC: 0.000e+00, loss_IC: 3.119e-08,loss_f: 1.054e-07
pinn: 0000, Iter: 400, total_loss: 1.386e-07, loss_BC: 0.000e+00, loss_IC: 2.133e-08,loss_f: 7.765e-08
pinn: 0000, Iter: 500, total_loss: 1.284e-07, loss_BC: 0.000e+00, loss_IC: 1.884e-08,loss_f: 7.021e-08
pinn: 0000, Iter: 600, total_loss: 1.177e-07, loss_BC: 0.000e+00, loss_IC: 1.914e-08,loss_f: 5.942e-08
pinn: 0000, Iter: 700, total_loss: 1.070e-07, loss_BC: 0.000e+00, loss_IC: 1.730e-08,loss_f: 5.074e-08
pinn: 0000, Iter: 800, total_loss: 1.045e-07, loss_BC: 0.000e+00, loss_IC: 1.698e-08,loss_f: 4.861e-08
pinn: 0000, Iter: 900, total_loss: 1.026e-07, loss_BC: 0.000e+00, loss_IC: 1.610e-08,loss_f: 4.752e-08
pinn: 0000, Iter: 1000, total_loss: 1.010e-07, loss_BC: 0.000e+00, loss_IC: 1.610e-08,loss_f: 4.604e-08
pinn: 0000, Iter: 1100, total_loss: 9.978e-08, loss_BC: 0.000e+00, loss_IC: 1.640e-08,loss_f: 4.484e-08
pinn: 0000, Iter: 1200, total_loss: 9.880e-08, loss_BC: 0.000e+00, loss_IC: 1.626e-08,loss_f: 4.410e-08
pinn: 0000, Iter: 1300, total_loss: 9.745e-08, loss_BC: 0.000e+00, loss_IC: 1.628e-08,loss_f: 4.312e-08
pinn: 0000, Iter: 1400, total_loss: 9.651e-08, loss_BC: 0.000e+00, loss_IC: 1.616e-08,loss_f: 4.230e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6781, Mean_loss of pinns: 9.646e-08, loss_BC: 0.000e+00, loss_IC: 1.612e-08, loss_f: 4.231e-08
 => minimum loss: 9.646e-08, corresponding pinn index: 0000
 => maximum loss: 9.646e-08, corresponding pinn  index: 0000

 max_loss: 4.787e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6783, total_loss: 2.262e-05, loss_BC: 1.490e-05, loss_IC: 3.302e-07, loss_f: 7.250e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.64000, t_max: 0.65000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6784 0 1

 -------------------------------------------------------------
  -----  Epoch: 6784 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.64000, t_max: 0.65000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6784 !!! 


==> Epoch: 6790, Mean_loss of pinns: 7.021e-03, loss_BC: 1.454e-05, loss_IC: 1.590e-06, loss_f: 7.005e-03
 => minimum loss: 7.928e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.695e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6800, Mean_loss of pinns: 5.545e-03, loss_BC: 1.432e-05, loss_IC: 1.013e-05, loss_f: 5.521e-03
 => minimum loss: 7.283e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.337e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 6810, Mean_loss of pinns: 4.464e-03, loss_BC: 1.346e-05, loss_IC: 2.338e-05, loss_f: 4.427e-03
 => minimum loss: 6.516e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.079e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6820, Mean_loss of pinns: 3.646e-03, loss_BC: 1.133e-05, loss_IC: 3.863e-05, loss_f: 3.596e-03
 => minimum loss: 5.706e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.820e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6830, Mean_loss of pinns: 3.034e-03, loss_BC: 1.180e-05, loss_IC: 5.372e-05, loss_f: 2.968e-03
 => minimum loss: 5.067e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.330e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6840, Mean_loss of pinns: 2.572e-03, loss_BC: 1.225e-05, loss_IC: 6.755e-05, loss_f: 2.492e-03
 => minimum loss: 4.770e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.201e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6850, Mean_loss of pinns: 2.217e-03, loss_BC: 1.268e-05, loss_IC: 7.963e-05, loss_f: 2.124e-03
 => minimum loss: 4.351e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.333e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6860, Mean_loss of pinns: 1.938e-03, loss_BC: 1.362e-05, loss_IC: 8.948e-05, loss_f: 1.835e-03
 => minimum loss: 3.929e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.654e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6870, Mean_loss of pinns: 1.716e-03, loss_BC: 1.463e-05, loss_IC: 9.689e-05, loss_f: 1.604e-03
 => minimum loss: 3.655e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.112e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 6880, Mean_loss of pinns: 1.535e-03, loss_BC: 1.657e-05, loss_IC: 1.020e-04, loss_f: 1.417e-03
 => minimum loss: 3.483e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.676e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  6883

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.107e-06, loss_BC: 0.000e+00, loss_IC: 4.663e-08,loss_f: 9.341e-07
pinn: 0300, Iter: 100, total_loss: 2.024e-06, loss_BC: 0.000e+00, loss_IC: 1.692e-07,loss_f: 1.749e-06
pinn: 0200, Iter: 100, total_loss: 6.891e-07, loss_BC: 0.000e+00, loss_IC: 7.432e-08,loss_f: 4.999e-07
pinn: 0300, Iter: 200, total_loss: 3.360e-07, loss_BC: 0.000e+00, loss_IC: 2.683e-08,loss_f: 2.086e-07
pinn: 0200, Iter: 200, total_loss: 3.030e-07, loss_BC: 0.000e+00, loss_IC: 4.439e-08,loss_f: 1.488e-07
pinn: 0100, Iter: 200, total_loss: 2.857e-07, loss_BC: 0.000e+00, loss_IC: 2.962e-08,loss_f: 1.365e-07
pinn: 0300, Iter: 300, total_loss: 2.073e-07, loss_BC: 0.000e+00, loss_IC: 2.638e-08,loss_f: 8.505e-08
pinn: 0200, Iter: 300, total_loss: 1.976e-07, loss_BC: 0.000e+00, loss_IC: 2.585e-08,loss_f: 6.263e-08
pinn: 0100, Iter: 300, total_loss: 2.100e-07, loss_BC: 0.000e+00, loss_IC: 2.782e-08,loss_f: 6.498e-08
pinn: 0300, Iter: 400, total_loss: 1.669e-07, loss_BC: 0.000e+00, loss_IC: 2.113e-08,loss_f: 5.483e-08
pinn: 0100, Iter: 400, total_loss: 1.963e-07, loss_BC: 0.000e+00, loss_IC: 2.485e-08,loss_f: 5.666e-08
pinn: 0200, Iter: 400, total_loss: 1.766e-07, loss_BC: 0.000e+00, loss_IC: 1.849e-08,loss_f: 5.391e-08
pinn: 0300, Iter: 500, total_loss: 1.555e-07, loss_BC: 0.000e+00, loss_IC: 2.166e-08,loss_f: 4.546e-08
pinn: 0100, Iter: 500, total_loss: 1.908e-07, loss_BC: 0.000e+00, loss_IC: 2.526e-08,loss_f: 5.210e-08
pinn: 0200, Iter: 500, total_loss: 1.701e-07, loss_BC: 0.000e+00, loss_IC: 1.789e-08,loss_f: 4.948e-08
pinn: 0300, Iter: 600, total_loss: 1.516e-07, loss_BC: 0.000e+00, loss_IC: 2.060e-08,loss_f: 4.250e-08
pinn: 0100, Iter: 600, total_loss: 1.852e-07, loss_BC: 0.000e+00, loss_IC: 2.462e-08,loss_f: 4.655e-08
pinn: 0200, Iter: 600, total_loss: 1.631e-07, loss_BC: 0.000e+00, loss_IC: 1.702e-08,loss_f: 4.451e-08
pinn: 0300, Iter: 700, total_loss: 1.471e-07, loss_BC: 0.000e+00, loss_IC: 1.881e-08,loss_f: 4.012e-08
pinn: 0100, Iter: 700, total_loss: 1.808e-07, loss_BC: 0.000e+00, loss_IC: 2.401e-08,loss_f: 4.409e-08
pinn: 0200, Iter: 700, total_loss: 1.594e-07, loss_BC: 0.000e+00, loss_IC: 1.628e-08,loss_f: 4.236e-08
pinn: 0300, Iter: 800, total_loss: 1.440e-07, loss_BC: 0.000e+00, loss_IC: 1.858e-08,loss_f: 3.848e-08
pinn: 0100, Iter: 800, total_loss: 1.751e-07, loss_BC: 0.000e+00, loss_IC: 2.432e-08,loss_f: 4.276e-08
pinn: 0200, Iter: 800, total_loss: 1.567e-07, loss_BC: 0.000e+00, loss_IC: 1.731e-08,loss_f: 4.079e-08
pinn: 0300, Iter: 900, total_loss: 1.403e-07, loss_BC: 0.000e+00, loss_IC: 1.949e-08,loss_f: 3.567e-08
pinn: 0100, Iter: 900, total_loss: 1.721e-07, loss_BC: 0.000e+00, loss_IC: 2.361e-08,loss_f: 4.235e-08
pinn: 0200, Iter: 900, total_loss: 1.545e-07, loss_BC: 0.000e+00, loss_IC: 1.768e-08,loss_f: 3.990e-08
pinn: 0300, Iter: 1000, total_loss: 1.362e-07, loss_BC: 0.000e+00, loss_IC: 1.700e-08,loss_f: 3.462e-08
pinn: 0200, Iter: 1000, total_loss: 1.522e-07, loss_BC: 0.000e+00, loss_IC: 1.822e-08,loss_f: 3.869e-08
pinn: 0100, Iter: 1000, total_loss: 1.701e-07, loss_BC: 0.000e+00, loss_IC: 2.292e-08,loss_f: 4.282e-08
pinn: 0300, Iter: 1100, total_loss: 1.321e-07, loss_BC: 0.000e+00, loss_IC: 1.729e-08,loss_f: 3.327e-08
pinn: 0100, Iter: 1100, total_loss: 1.649e-07, loss_BC: 0.000e+00, loss_IC: 2.089e-08,loss_f: 4.325e-08
pinn: 0200, Iter: 1100, total_loss: 1.508e-07, loss_BC: 0.000e+00, loss_IC: 1.813e-08,loss_f: 3.857e-08
pinn: 0300, Iter: 1200, total_loss: 1.299e-07, loss_BC: 0.000e+00, loss_IC: 1.671e-08,loss_f: 3.303e-08
pinn: 0200, Iter: 1200, total_loss: 1.496e-07, loss_BC: 0.000e+00, loss_IC: 1.790e-08,loss_f: 3.806e-08
pinn: 0100, Iter: 1200, total_loss: 1.640e-07, loss_BC: 0.000e+00, loss_IC: 2.047e-08,loss_f: 4.398e-08
pinn: 0300, Iter: 1300, total_loss: 1.282e-07, loss_BC: 0.000e+00, loss_IC: 1.600e-08,loss_f: 3.287e-08
pinn: 0200, Iter: 1300, total_loss: 1.473e-07, loss_BC: 0.000e+00, loss_IC: 1.862e-08,loss_f: 3.834e-08
pinn: 0100, Iter: 1300, total_loss: 1.540e-07, loss_BC: 0.000e+00, loss_IC: 1.825e-08,loss_f: 4.769e-08
pinn: 0300, Iter: 1400, total_loss: 1.253e-07, loss_BC: 0.000e+00, loss_IC: 1.530e-08,loss_f: 3.404e-08
pinn: 0200, Iter: 1400, total_loss: 1.464e-07, loss_BC: 0.000e+00, loss_IC: 1.824e-08,loss_f: 3.819e-08
pinn: 0100, Iter: 1400, total_loss: 1.499e-07, loss_BC: 0.000e+00, loss_IC: 1.730e-08,loss_f: 4.813e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6883, Mean_loss of pinns: 1.394e-07, loss_BC: 0.000e+00, loss_IC: 1.692e-08, loss_f: 3.991e-08
 => minimum loss: 1.250e-07, corresponding pinn index: 0300
 => maximum loss: 1.473e-07, corresponding pinn  index: 0100

 max_loss: 4.993e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6885, total_loss: 1.555e-05, loss_BC: 1.217e-05, loss_IC: 5.478e-07, loss_f: 2.730e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.65000, t_max: 0.66000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6886 0 1

 -------------------------------------------------------------
  -----  Epoch: 6886 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.65000, t_max: 0.66000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6886 !!! 


==> Epoch: 6890, Mean_loss of pinns: 1.840e-03, loss_BC: 1.213e-05, loss_IC: 3.987e-07, loss_f: 1.828e-03
 => minimum loss: 3.986e-05, corresponding pinn/batch index: 0300
 => maximum loss: 7.153e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0100, 0200

==> Epoch: 6900, Mean_loss of pinns: 1.471e-03, loss_BC: 1.341e-05, loss_IC: 1.311e-06, loss_f: 1.456e-03
 => minimum loss: 3.060e-05, corresponding pinn/batch index: 0300
 => maximum loss: 5.720e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0100

==> Epoch: 6910, Mean_loss of pinns: 1.204e-03, loss_BC: 1.530e-05, loss_IC: 2.207e-06, loss_f: 1.187e-03
 => minimum loss: 2.588e-05, corresponding pinn/batch index: 0300
 => maximum loss: 4.687e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6920, Mean_loss of pinns: 9.978e-04, loss_BC: 1.789e-05, loss_IC: 3.644e-06, loss_f: 9.762e-04
 => minimum loss: 2.212e-05, corresponding pinn/batch index: 0300
 => maximum loss: 3.886e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6930, Mean_loss of pinns: 8.426e-04, loss_BC: 2.020e-05, loss_IC: 5.318e-06, loss_f: 8.170e-04
 => minimum loss: 1.926e-05, corresponding pinn/batch index: 0300
 => maximum loss: 3.282e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6940, Mean_loss of pinns: 7.226e-04, loss_BC: 2.156e-05, loss_IC: 6.908e-06, loss_f: 6.940e-04
 => minimum loss: 1.667e-05, corresponding pinn/batch index: 0300
 => maximum loss: 2.815e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6950, Mean_loss of pinns: 6.285e-04, loss_BC: 2.209e-05, loss_IC: 8.032e-06, loss_f: 5.983e-04
 => minimum loss: 1.468e-05, corresponding pinn/batch index: 0300
 => maximum loss: 2.449e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6960, Mean_loss of pinns: 5.540e-04, loss_BC: 2.287e-05, loss_IC: 8.807e-06, loss_f: 5.223e-04
 => minimum loss: 1.355e-05, corresponding pinn/batch index: 0300
 => maximum loss: 2.158e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6970, Mean_loss of pinns: 4.930e-04, loss_BC: 2.272e-05, loss_IC: 9.139e-06, loss_f: 4.611e-04
 => minimum loss: 1.197e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.920e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 6980, Mean_loss of pinns: 4.427e-04, loss_BC: 2.260e-05, loss_IC: 9.067e-06, loss_f: 4.110e-04
 => minimum loss: 1.125e-05, corresponding pinn/batch index: 0300
 => maximum loss: 1.724e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  6985

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 9.861e-07, loss_BC: 0.000e+00, loss_IC: 1.116e-07,loss_f: 7.806e-07
pinn: 0000, Iter: 200, total_loss: 3.090e-07, loss_BC: 0.000e+00, loss_IC: 5.121e-08,loss_f: 1.547e-07
pinn: 0000, Iter: 300, total_loss: 2.467e-07, loss_BC: 0.000e+00, loss_IC: 3.949e-08,loss_f: 1.049e-07
pinn: 0000, Iter: 400, total_loss: 2.321e-07, loss_BC: 0.000e+00, loss_IC: 3.258e-08,loss_f: 9.940e-08
pinn: 0000, Iter: 500, total_loss: 2.155e-07, loss_BC: 0.000e+00, loss_IC: 3.336e-08,loss_f: 8.766e-08
pinn: 0000, Iter: 600, total_loss: 2.037e-07, loss_BC: 0.000e+00, loss_IC: 3.117e-08,loss_f: 8.111e-08
pinn: 0000, Iter: 700, total_loss: 1.981e-07, loss_BC: 0.000e+00, loss_IC: 3.116e-08,loss_f: 7.665e-08
pinn: 0000, Iter: 800, total_loss: 1.950e-07, loss_BC: 0.000e+00, loss_IC: 3.045e-08,loss_f: 7.543e-08
pinn: 0000, Iter: 900, total_loss: 1.870e-07, loss_BC: 0.000e+00, loss_IC: 2.772e-08,loss_f: 7.227e-08
pinn: 0000, Iter: 1000, total_loss: 1.815e-07, loss_BC: 0.000e+00, loss_IC: 2.548e-08,loss_f: 7.227e-08
pinn: 0000, Iter: 1100, total_loss: 1.787e-07, loss_BC: 0.000e+00, loss_IC: 2.452e-08,loss_f: 7.204e-08
pinn: 0000, Iter: 1200, total_loss: 1.757e-07, loss_BC: 0.000e+00, loss_IC: 2.367e-08,loss_f: 7.113e-08
pinn: 0000, Iter: 1300, total_loss: 1.737e-07, loss_BC: 0.000e+00, loss_IC: 2.244e-08,loss_f: 7.109e-08
pinn: 0000, Iter: 1400, total_loss: 1.718e-07, loss_BC: 0.000e+00, loss_IC: 2.138e-08,loss_f: 7.111e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 6985, Mean_loss of pinns: 1.717e-07, loss_BC: 0.000e+00, loss_IC: 2.136e-08, loss_f: 7.111e-08
 => minimum loss: 1.717e-07, corresponding pinn index: 0000
 => maximum loss: 1.717e-07, corresponding pinn  index: 0000

 max_loss: 4.617e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 6987, total_loss: 2.268e-05, loss_BC: 1.345e-05, loss_IC: 3.292e-07, loss_f: 8.827e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.66000, t_max: 0.67000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  6988 0 1

 -------------------------------------------------------------
  -----  Epoch: 6988 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.66000, t_max: 0.67000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  6988 !!! 


==> Epoch: 6990, Mean_loss of pinns: 7.185e-03, loss_BC: 1.376e-05, loss_IC: 1.599e-07, loss_f: 7.171e-03
 => minimum loss: 9.953e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.077e-02, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7000, Mean_loss of pinns: 5.507e-03, loss_BC: 1.224e-05, loss_IC: 5.470e-06, loss_f: 5.489e-03
 => minimum loss: 8.689e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.460e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7010, Mean_loss of pinns: 4.353e-03, loss_BC: 1.024e-05, loss_IC: 1.700e-05, loss_f: 4.326e-03
 => minimum loss: 7.245e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.730e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7020, Mean_loss of pinns: 3.510e-03, loss_BC: 9.774e-06, loss_IC: 3.309e-05, loss_f: 3.467e-03
 => minimum loss: 6.122e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.426e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7030, Mean_loss of pinns: 2.881e-03, loss_BC: 9.035e-06, loss_IC: 5.120e-05, loss_f: 2.821e-03
 => minimum loss: 5.394e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.460e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7040, Mean_loss of pinns: 2.419e-03, loss_BC: 9.684e-06, loss_IC: 6.889e-05, loss_f: 2.340e-03
 => minimum loss: 5.101e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.743e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7050, Mean_loss of pinns: 2.072e-03, loss_BC: 1.018e-05, loss_IC: 8.446e-05, loss_f: 1.977e-03
 => minimum loss: 4.818e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.202e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7060, Mean_loss of pinns: 1.805e-03, loss_BC: 1.022e-05, loss_IC: 9.687e-05, loss_f: 1.698e-03
 => minimum loss: 4.504e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.787e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7070, Mean_loss of pinns: 1.595e-03, loss_BC: 9.634e-06, loss_IC: 1.056e-04, loss_f: 1.479e-03
 => minimum loss: 4.240e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.461e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7080, Mean_loss of pinns: 1.426e-03, loss_BC: 9.531e-06, loss_IC: 1.109e-04, loss_f: 1.305e-03
 => minimum loss: 3.898e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.198e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  7087

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 9.442e-07, loss_BC: 0.000e+00, loss_IC: 1.756e-07,loss_f: 5.988e-07
pinn: 0100, Iter: 100, total_loss: 1.189e-06, loss_BC: 0.000e+00, loss_IC: 5.323e-08,loss_f: 9.852e-07
pinn: 0300, Iter: 100, total_loss: 1.073e-06, loss_BC: 0.000e+00, loss_IC: 5.504e-08,loss_f: 9.317e-07
pinn: 0200, Iter: 200, total_loss: 4.106e-07, loss_BC: 0.000e+00, loss_IC: 9.324e-08,loss_f: 1.522e-07
pinn: 0100, Iter: 200, total_loss: 2.696e-07, loss_BC: 0.000e+00, loss_IC: 2.394e-08,loss_f: 1.047e-07
pinn: 0300, Iter: 200, total_loss: 2.486e-07, loss_BC: 0.000e+00, loss_IC: 2.679e-08,loss_f: 1.378e-07
pinn: 0200, Iter: 300, total_loss: 3.165e-07, loss_BC: 0.000e+00, loss_IC: 7.640e-08,loss_f: 8.487e-08
pinn: 0100, Iter: 300, total_loss: 2.146e-07, loss_BC: 0.000e+00, loss_IC: 1.761e-08,loss_f: 5.851e-08
pinn: 0300, Iter: 300, total_loss: 1.480e-07, loss_BC: 0.000e+00, loss_IC: 1.413e-08,loss_f: 5.514e-08
pinn: 0200, Iter: 400, total_loss: 2.964e-07, loss_BC: 0.000e+00, loss_IC: 7.239e-08,loss_f: 7.380e-08
pinn: 0100, Iter: 400, total_loss: 1.909e-07, loss_BC: 0.000e+00, loss_IC: 1.635e-08,loss_f: 4.228e-08
pinn: 0300, Iter: 400, total_loss: 1.262e-07, loss_BC: 0.000e+00, loss_IC: 1.309e-08,loss_f: 3.566e-08
pinn: 0200, Iter: 500, total_loss: 2.795e-07, loss_BC: 0.000e+00, loss_IC: 6.345e-08,loss_f: 6.682e-08
pinn: 0100, Iter: 500, total_loss: 1.858e-07, loss_BC: 0.000e+00, loss_IC: 1.426e-08,loss_f: 4.040e-08
pinn: 0300, Iter: 500, total_loss: 1.197e-07, loss_BC: 0.000e+00, loss_IC: 1.192e-08,loss_f: 3.141e-08
pinn: 0200, Iter: 600, total_loss: 2.715e-07, loss_BC: 0.000e+00, loss_IC: 5.627e-08,loss_f: 6.642e-08
pinn: 0100, Iter: 600, total_loss: 1.822e-07, loss_BC: 0.000e+00, loss_IC: 1.229e-08,loss_f: 3.825e-08
pinn: 0300, Iter: 600, total_loss: 1.162e-07, loss_BC: 0.000e+00, loss_IC: 1.110e-08,loss_f: 2.932e-08
pinn: 0200, Iter: 700, total_loss: 2.639e-07, loss_BC: 0.000e+00, loss_IC: 5.244e-08,loss_f: 6.430e-08
pinn: 0100, Iter: 700, total_loss: 1.758e-07, loss_BC: 0.000e+00, loss_IC: 1.215e-08,loss_f: 3.473e-08
pinn: 0300, Iter: 700, total_loss: 1.145e-07, loss_BC: 0.000e+00, loss_IC: 1.111e-08,loss_f: 2.874e-08
pinn: 0200, Iter: 800, total_loss: 2.588e-07, loss_BC: 0.000e+00, loss_IC: 4.782e-08,loss_f: 6.593e-08
pinn: 0100, Iter: 800, total_loss: 1.723e-07, loss_BC: 0.000e+00, loss_IC: 1.227e-08,loss_f: 3.313e-08
pinn: 0300, Iter: 800, total_loss: 1.117e-07, loss_BC: 0.000e+00, loss_IC: 1.181e-08,loss_f: 2.805e-08
pinn: 0200, Iter: 900, total_loss: 2.481e-07, loss_BC: 0.000e+00, loss_IC: 3.949e-08,loss_f: 6.629e-08
pinn: 0100, Iter: 900, total_loss: 1.657e-07, loss_BC: 0.000e+00, loss_IC: 1.604e-08,loss_f: 2.956e-08
pinn: 0300, Iter: 900, total_loss: 1.085e-07, loss_BC: 0.000e+00, loss_IC: 1.142e-08,loss_f: 2.721e-08
pinn: 0200, Iter: 1000, total_loss: 2.383e-07, loss_BC: 0.000e+00, loss_IC: 3.463e-08,loss_f: 6.679e-08
pinn: 0100, Iter: 1000, total_loss: 1.597e-07, loss_BC: 0.000e+00, loss_IC: 1.765e-08,loss_f: 2.721e-08
pinn: 0300, Iter: 1000, total_loss: 1.054e-07, loss_BC: 0.000e+00, loss_IC: 1.146e-08,loss_f: 2.664e-08
pinn: 0200, Iter: 1100, total_loss: 2.339e-07, loss_BC: 0.000e+00, loss_IC: 3.269e-08,loss_f: 6.688e-08
pinn: 0100, Iter: 1100, total_loss: 1.534e-07, loss_BC: 0.000e+00, loss_IC: 1.821e-08,loss_f: 2.600e-08
pinn: 0300, Iter: 1100, total_loss: 1.001e-07, loss_BC: 0.000e+00, loss_IC: 9.382e-09,loss_f: 2.698e-08
pinn: 0200, Iter: 1200, total_loss: 2.295e-07, loss_BC: 0.000e+00, loss_IC: 3.060e-08,loss_f: 6.782e-08
pinn: 0100, Iter: 1200, total_loss: 1.495e-07, loss_BC: 0.000e+00, loss_IC: 1.858e-08,loss_f: 2.537e-08
pinn: 0300, Iter: 1200, total_loss: 9.609e-08, loss_BC: 0.000e+00, loss_IC: 9.328e-09,loss_f: 2.754e-08
pinn: 0200, Iter: 1300, total_loss: 2.289e-07, loss_BC: 0.000e+00, loss_IC: 3.040e-08,loss_f: 6.766e-08
pinn: 0100, Iter: 1300, total_loss: 1.484e-07, loss_BC: 0.000e+00, loss_IC: 1.879e-08,loss_f: 2.646e-08
pinn: 0300, Iter: 1300, total_loss: 9.388e-08, loss_BC: 0.000e+00, loss_IC: 9.043e-09,loss_f: 2.795e-08
pinn: 0200, Iter: 1400, total_loss: 2.245e-07, loss_BC: 0.000e+00, loss_IC: 2.806e-08,loss_f: 6.834e-08
pinn: 0100, Iter: 1400, total_loss: 1.458e-07, loss_BC: 0.000e+00, loss_IC: 1.868e-08,loss_f: 2.689e-08
pinn: 0300, Iter: 1400, total_loss: 8.998e-08, loss_BC: 0.000e+00, loss_IC: 7.408e-09,loss_f: 2.819e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7087, Mean_loss of pinns: 1.519e-07, loss_BC: 0.000e+00, loss_IC: 1.829e-08, loss_f: 4.125e-08
 => minimum loss: 8.820e-08, corresponding pinn index: 0300
 => maximum loss: 2.222e-07, corresponding pinn  index: 0200

 max_loss: 5.379e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7089, total_loss: 1.580e-05, loss_BC: 1.170e-05, loss_IC: 7.395e-07, loss_f: 3.273e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.67000, t_max: 0.68000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7090 0 1

 -------------------------------------------------------------
  -----  Epoch: 7090 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.67000, t_max: 0.68000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7090 !!! 


==> Epoch: 7090, Mean_loss of pinns: 3.197e-03, loss_BC: 1.219e-05, loss_IC: 0.000e+00, loss_f: 3.184e-03
 => minimum loss: 3.410e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.255e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 7100, Mean_loss of pinns: 2.561e-03, loss_BC: 1.263e-05, loss_IC: 7.499e-07, loss_f: 2.548e-03
 => minimum loss: 2.638e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.008e-02, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0300

==> Epoch: 7110, Mean_loss of pinns: 2.091e-03, loss_BC: 1.465e-05, loss_IC: 1.488e-06, loss_f: 2.075e-03
 => minimum loss: 2.199e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.231e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7120, Mean_loss of pinns: 1.723e-03, loss_BC: 1.674e-05, loss_IC: 2.930e-06, loss_f: 1.703e-03
 => minimum loss: 1.914e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.782e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7130, Mean_loss of pinns: 1.438e-03, loss_BC: 1.885e-05, loss_IC: 4.756e-06, loss_f: 1.414e-03
 => minimum loss: 1.601e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.662e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7140, Mean_loss of pinns: 1.218e-03, loss_BC: 2.116e-05, loss_IC: 6.708e-06, loss_f: 1.190e-03
 => minimum loss: 1.429e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.798e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7150, Mean_loss of pinns: 1.046e-03, loss_BC: 2.206e-05, loss_IC: 8.490e-06, loss_f: 1.016e-03
 => minimum loss: 1.257e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.120e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7160, Mean_loss of pinns: 9.111e-04, loss_BC: 2.351e-05, loss_IC: 9.968e-06, loss_f: 8.774e-04
 => minimum loss: 1.187e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.587e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7170, Mean_loss of pinns: 8.025e-04, loss_BC: 2.463e-05, loss_IC: 1.104e-05, loss_f: 7.667e-04
 => minimum loss: 1.050e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.159e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7180, Mean_loss of pinns: 7.128e-04, loss_BC: 2.408e-05, loss_IC: 1.167e-05, loss_f: 6.769e-04
 => minimum loss: 1.005e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.806e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  7189

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 5.703e-07, loss_BC: 0.000e+00, loss_IC: 1.010e-07,loss_f: 3.265e-07
pinn: 0000, Iter: 200, total_loss: 2.814e-07, loss_BC: 0.000e+00, loss_IC: 1.926e-08,loss_f: 1.147e-07
pinn: 0000, Iter: 300, total_loss: 2.378e-07, loss_BC: 0.000e+00, loss_IC: 1.852e-08,loss_f: 7.650e-08
pinn: 0000, Iter: 400, total_loss: 2.236e-07, loss_BC: 0.000e+00, loss_IC: 1.840e-08,loss_f: 6.806e-08
pinn: 0000, Iter: 500, total_loss: 2.136e-07, loss_BC: 0.000e+00, loss_IC: 1.818e-08,loss_f: 6.066e-08
pinn: 0000, Iter: 600, total_loss: 2.022e-07, loss_BC: 0.000e+00, loss_IC: 1.935e-08,loss_f: 5.055e-08
pinn: 0000, Iter: 700, total_loss: 1.979e-07, loss_BC: 0.000e+00, loss_IC: 2.051e-08,loss_f: 4.703e-08
pinn: 0000, Iter: 800, total_loss: 1.941e-07, loss_BC: 0.000e+00, loss_IC: 2.204e-08,loss_f: 4.525e-08
pinn: 0000, Iter: 900, total_loss: 1.906e-07, loss_BC: 0.000e+00, loss_IC: 2.276e-08,loss_f: 4.408e-08
pinn: 0000, Iter: 1000, total_loss: 1.842e-07, loss_BC: 0.000e+00, loss_IC: 2.120e-08,loss_f: 4.518e-08
pinn: 0000, Iter: 1100, total_loss: 1.815e-07, loss_BC: 0.000e+00, loss_IC: 1.982e-08,loss_f: 4.503e-08
pinn: 0000, Iter: 1200, total_loss: 1.783e-07, loss_BC: 0.000e+00, loss_IC: 2.031e-08,loss_f: 4.411e-08
pinn: 0000, Iter: 1300, total_loss: 1.747e-07, loss_BC: 0.000e+00, loss_IC: 2.133e-08,loss_f: 4.388e-08
pinn: 0000, Iter: 1400, total_loss: 1.728e-07, loss_BC: 0.000e+00, loss_IC: 2.066e-08,loss_f: 4.457e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7189, Mean_loss of pinns: 1.724e-07, loss_BC: 0.000e+00, loss_IC: 2.073e-08, loss_f: 4.482e-08
 => minimum loss: 1.724e-07, corresponding pinn index: 0000
 => maximum loss: 1.724e-07, corresponding pinn  index: 0000

==> Epoch: 7190, Mean_loss of pinns: 2.096e-05, loss_BC: 1.188e-05, loss_IC: 2.235e-07, loss_f: 8.714e-06
 => minimum loss: 9.009e-06, corresponding pinn/batch index: 0100
 => maximum loss: 4.260e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 4.470e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7191, total_loss: 2.158e-05, loss_BC: 1.259e-05, loss_IC: 2.230e-07, loss_f: 8.632e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.68000, t_max: 0.69000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7192 0 1

 -------------------------------------------------------------
  -----  Epoch: 7192 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.68000, t_max: 0.69000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7192 !!! 


==> Epoch: 7200, Mean_loss of pinns: 5.083e-03, loss_BC: 1.326e-05, loss_IC: 3.361e-06, loss_f: 5.066e-03
 => minimum loss: 6.116e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.350e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7210, Mean_loss of pinns: 3.830e-03, loss_BC: 9.228e-06, loss_IC: 1.430e-05, loss_f: 3.806e-03
 => minimum loss: 5.266e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.930e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7220, Mean_loss of pinns: 2.979e-03, loss_BC: 8.594e-06, loss_IC: 2.941e-05, loss_f: 2.941e-03
 => minimum loss: 4.404e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.593e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7230, Mean_loss of pinns: 2.379e-03, loss_BC: 9.566e-06, loss_IC: 4.562e-05, loss_f: 2.324e-03
 => minimum loss: 3.957e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.960e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7240, Mean_loss of pinns: 1.948e-03, loss_BC: 8.630e-06, loss_IC: 6.019e-05, loss_f: 1.879e-03
 => minimum loss: 3.612e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.803e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7250, Mean_loss of pinns: 1.639e-03, loss_BC: 8.286e-06, loss_IC: 7.198e-05, loss_f: 1.559e-03
 => minimum loss: 3.165e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.992e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7260, Mean_loss of pinns: 1.411e-03, loss_BC: 9.273e-06, loss_IC: 8.069e-05, loss_f: 1.321e-03
 => minimum loss: 3.033e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.408e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7270, Mean_loss of pinns: 1.237e-03, loss_BC: 1.055e-05, loss_IC: 8.650e-05, loss_f: 1.140e-03
 => minimum loss: 2.765e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.976e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7280, Mean_loss of pinns: 1.102e-03, loss_BC: 1.351e-05, loss_IC: 8.978e-05, loss_f: 9.988e-04
 => minimum loss: 2.794e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.649e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7290, Mean_loss of pinns: 9.927e-04, loss_BC: 1.504e-05, loss_IC: 9.102e-05, loss_f: 8.865e-04
 => minimum loss: 2.577e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.391e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  7291

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 1.224e-06, loss_BC: 0.000e+00, loss_IC: 8.340e-08,loss_f: 1.032e-06
pinn: 0200, Iter: 100, total_loss: 8.838e-07, loss_BC: 0.000e+00, loss_IC: 7.967e-08,loss_f: 4.812e-07
pinn: 0100, Iter: 100, total_loss: 7.933e-07, loss_BC: 0.000e+00, loss_IC: 7.543e-08,loss_f: 6.362e-07
pinn: 0300, Iter: 200, total_loss: 3.172e-07, loss_BC: 0.000e+00, loss_IC: 2.785e-08,loss_f: 1.850e-07
pinn: 0200, Iter: 200, total_loss: 4.798e-07, loss_BC: 0.000e+00, loss_IC: 3.946e-08,loss_f: 1.325e-07
pinn: 0100, Iter: 200, total_loss: 2.801e-07, loss_BC: 0.000e+00, loss_IC: 5.872e-08,loss_f: 1.412e-07
pinn: 0300, Iter: 300, total_loss: 1.674e-07, loss_BC: 0.000e+00, loss_IC: 2.167e-08,loss_f: 4.857e-08
pinn: 0200, Iter: 300, total_loss: 4.096e-07, loss_BC: 0.000e+00, loss_IC: 3.121e-08,loss_f: 7.600e-08
pinn: 0100, Iter: 300, total_loss: 2.115e-07, loss_BC: 0.000e+00, loss_IC: 5.123e-08,loss_f: 8.285e-08
pinn: 0300, Iter: 400, total_loss: 1.507e-07, loss_BC: 0.000e+00, loss_IC: 1.749e-08,loss_f: 4.132e-08
pinn: 0100, Iter: 400, total_loss: 1.942e-07, loss_BC: 0.000e+00, loss_IC: 3.845e-08,loss_f: 8.083e-08
pinn: 0200, Iter: 400, total_loss: 3.787e-07, loss_BC: 0.000e+00, loss_IC: 3.655e-08,loss_f: 6.029e-08
pinn: 0300, Iter: 500, total_loss: 1.428e-07, loss_BC: 0.000e+00, loss_IC: 1.527e-08,loss_f: 3.932e-08
pinn: 0100, Iter: 500, total_loss: 1.774e-07, loss_BC: 0.000e+00, loss_IC: 3.401e-08,loss_f: 6.941e-08
pinn: 0200, Iter: 500, total_loss: 3.581e-07, loss_BC: 0.000e+00, loss_IC: 3.028e-08,loss_f: 5.135e-08
pinn: 0300, Iter: 600, total_loss: 1.389e-07, loss_BC: 0.000e+00, loss_IC: 1.320e-08,loss_f: 3.847e-08
pinn: 0100, Iter: 600, total_loss: 1.647e-07, loss_BC: 0.000e+00, loss_IC: 3.260e-08,loss_f: 5.730e-08
pinn: 0200, Iter: 600, total_loss: 3.320e-07, loss_BC: 0.000e+00, loss_IC: 2.915e-08,loss_f: 4.338e-08
pinn: 0300, Iter: 700, total_loss: 1.330e-07, loss_BC: 0.000e+00, loss_IC: 1.228e-08,loss_f: 3.480e-08
pinn: 0100, Iter: 700, total_loss: 1.563e-07, loss_BC: 0.000e+00, loss_IC: 3.083e-08,loss_f: 5.205e-08
pinn: 0200, Iter: 700, total_loss: 3.162e-07, loss_BC: 0.000e+00, loss_IC: 3.918e-08,loss_f: 4.346e-08
pinn: 0300, Iter: 800, total_loss: 1.307e-07, loss_BC: 0.000e+00, loss_IC: 1.186e-08,loss_f: 3.474e-08
pinn: 0200, Iter: 800, total_loss: 2.906e-07, loss_BC: 0.000e+00, loss_IC: 4.737e-08,loss_f: 4.934e-08
pinn: 0100, Iter: 800, total_loss: 1.504e-07, loss_BC: 0.000e+00, loss_IC: 2.929e-08,loss_f: 4.844e-08
pinn: 0300, Iter: 900, total_loss: 1.283e-07, loss_BC: 0.000e+00, loss_IC: 1.173e-08,loss_f: 3.461e-08
pinn: 0200, Iter: 900, total_loss: 2.783e-07, loss_BC: 0.000e+00, loss_IC: 5.432e-08,loss_f: 5.369e-08
pinn: 0100, Iter: 900, total_loss: 1.456e-07, loss_BC: 0.000e+00, loss_IC: 2.848e-08,loss_f: 4.477e-08
pinn: 0300, Iter: 1000, total_loss: 1.242e-07, loss_BC: 0.000e+00, loss_IC: 1.297e-08,loss_f: 3.468e-08
pinn: 0200, Iter: 1000, total_loss: 2.688e-07, loss_BC: 0.000e+00, loss_IC: 6.004e-08,loss_f: 5.334e-08
pinn: 0100, Iter: 1000, total_loss: 1.437e-07, loss_BC: 0.000e+00, loss_IC: 2.773e-08,loss_f: 4.418e-08
pinn: 0300, Iter: 1100, total_loss: 1.203e-07, loss_BC: 0.000e+00, loss_IC: 1.241e-08,loss_f: 3.436e-08
pinn: 0200, Iter: 1100, total_loss: 2.534e-07, loss_BC: 0.000e+00, loss_IC: 6.358e-08,loss_f: 4.932e-08
pinn: 0100, Iter: 1100, total_loss: 1.405e-07, loss_BC: 0.000e+00, loss_IC: 2.688e-08,loss_f: 4.240e-08
pinn: 0300, Iter: 1200, total_loss: 1.179e-07, loss_BC: 0.000e+00, loss_IC: 1.272e-08,loss_f: 3.432e-08
pinn: 0200, Iter: 1200, total_loss: 2.447e-07, loss_BC: 0.000e+00, loss_IC: 6.663e-08,loss_f: 5.011e-08
pinn: 0100, Iter: 1200, total_loss: 1.391e-07, loss_BC: 0.000e+00, loss_IC: 2.599e-08,loss_f: 4.233e-08
pinn: 0300, Iter: 1300, total_loss: 1.145e-07, loss_BC: 0.000e+00, loss_IC: 1.217e-08,loss_f: 3.499e-08
pinn: 0200, Iter: 1300, total_loss: 2.403e-07, loss_BC: 0.000e+00, loss_IC: 6.338e-08,loss_f: 5.066e-08
pinn: 0100, Iter: 1300, total_loss: 1.354e-07, loss_BC: 0.000e+00, loss_IC: 2.401e-08,loss_f: 4.361e-08
pinn: 0300, Iter: 1400, total_loss: 1.138e-07, loss_BC: 0.000e+00, loss_IC: 1.209e-08,loss_f: 3.477e-08
pinn: 0200, Iter: 1400, total_loss: 2.322e-07, loss_BC: 0.000e+00, loss_IC: 6.253e-08,loss_f: 4.998e-08
pinn: 0100, Iter: 1400, total_loss: 1.339e-07, loss_BC: 0.000e+00, loss_IC: 2.267e-08,loss_f: 4.397e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7291, Mean_loss of pinns: 1.597e-07, loss_BC: 0.000e+00, loss_IC: 3.241e-08, loss_f: 4.305e-08
 => minimum loss: 1.133e-07, corresponding pinn index: 0300
 => maximum loss: 2.320e-07, corresponding pinn  index: 0200

 max_loss: 4.297e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7293, total_loss: 1.289e-05, loss_BC: 1.039e-05, loss_IC: 3.936e-07, loss_f: 2.012e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.69000, t_max: 0.70000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7294 0 1

 -------------------------------------------------------------
  -----  Epoch: 7294 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.69000, t_max: 0.70000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7294 !!! 


==> Epoch: 7300, Mean_loss of pinns: 2.396e-03, loss_BC: 1.075e-05, loss_IC: 5.403e-07, loss_f: 2.385e-03
 => minimum loss: 4.964e-05, corresponding pinn/batch index: 0100
 => maximum loss: 9.378e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0300

==> Epoch: 7310, Mean_loss of pinns: 1.989e-03, loss_BC: 1.195e-05, loss_IC: 1.322e-06, loss_f: 1.975e-03
 => minimum loss: 3.962e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.793e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0300

==> Epoch: 7320, Mean_loss of pinns: 1.681e-03, loss_BC: 1.391e-05, loss_IC: 1.850e-06, loss_f: 1.665e-03
 => minimum loss: 3.193e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.593e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7330, Mean_loss of pinns: 1.441e-03, loss_BC: 1.607e-05, loss_IC: 2.635e-06, loss_f: 1.422e-03
 => minimum loss: 2.665e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.656e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7340, Mean_loss of pinns: 1.253e-03, loss_BC: 1.718e-05, loss_IC: 3.452e-06, loss_f: 1.232e-03
 => minimum loss: 2.215e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.924e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7350, Mean_loss of pinns: 1.102e-03, loss_BC: 1.764e-05, loss_IC: 4.088e-06, loss_f: 1.080e-03
 => minimum loss: 1.911e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.331e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7360, Mean_loss of pinns: 9.779e-04, loss_BC: 1.798e-05, loss_IC: 4.546e-06, loss_f: 9.552e-04
 => minimum loss: 1.685e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.846e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7370, Mean_loss of pinns: 8.740e-04, loss_BC: 1.794e-05, loss_IC: 4.827e-06, loss_f: 8.512e-04
 => minimum loss: 1.506e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.439e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7380, Mean_loss of pinns: 7.865e-04, loss_BC: 1.843e-05, loss_IC: 4.937e-06, loss_f: 7.630e-04
 => minimum loss: 1.330e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.095e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7390, Mean_loss of pinns: 7.104e-04, loss_BC: 1.786e-05, loss_IC: 4.920e-06, loss_f: 6.875e-04
 => minimum loss: 1.201e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.796e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  7393

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 8.238e-07, loss_BC: 0.000e+00, loss_IC: 1.118e-07,loss_f: 5.288e-07
pinn: 0000, Iter: 200, total_loss: 3.338e-07, loss_BC: 0.000e+00, loss_IC: 3.081e-08,loss_f: 1.246e-07
pinn: 0000, Iter: 300, total_loss: 2.504e-07, loss_BC: 0.000e+00, loss_IC: 3.150e-08,loss_f: 5.690e-08
pinn: 0000, Iter: 400, total_loss: 2.302e-07, loss_BC: 0.000e+00, loss_IC: 3.257e-08,loss_f: 4.448e-08
pinn: 0000, Iter: 500, total_loss: 2.256e-07, loss_BC: 0.000e+00, loss_IC: 3.319e-08,loss_f: 4.085e-08
pinn: 0000, Iter: 600, total_loss: 2.217e-07, loss_BC: 0.000e+00, loss_IC: 3.226e-08,loss_f: 3.927e-08
pinn: 0000, Iter: 700, total_loss: 2.103e-07, loss_BC: 0.000e+00, loss_IC: 2.841e-08,loss_f: 3.380e-08
pinn: 0000, Iter: 800, total_loss: 2.043e-07, loss_BC: 0.000e+00, loss_IC: 2.854e-08,loss_f: 3.284e-08
pinn: 0000, Iter: 900, total_loss: 2.000e-07, loss_BC: 0.000e+00, loss_IC: 3.016e-08,loss_f: 3.247e-08
pinn: 0000, Iter: 1000, total_loss: 1.947e-07, loss_BC: 0.000e+00, loss_IC: 2.789e-08,loss_f: 3.461e-08
pinn: 0000, Iter: 1100, total_loss: 1.772e-07, loss_BC: 0.000e+00, loss_IC: 2.237e-08,loss_f: 3.990e-08
pinn: 0000, Iter: 1200, total_loss: 1.729e-07, loss_BC: 0.000e+00, loss_IC: 2.089e-08,loss_f: 3.899e-08
pinn: 0000, Iter: 1300, total_loss: 1.700e-07, loss_BC: 0.000e+00, loss_IC: 2.074e-08,loss_f: 4.047e-08
pinn: 0000, Iter: 1400, total_loss: 1.670e-07, loss_BC: 0.000e+00, loss_IC: 2.085e-08,loss_f: 4.156e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7393, Mean_loss of pinns: 1.668e-07, loss_BC: 0.000e+00, loss_IC: 2.075e-08, loss_f: 4.126e-08
 => minimum loss: 1.668e-07, corresponding pinn index: 0000
 => maximum loss: 1.668e-07, corresponding pinn  index: 0000

 max_loss: 4.549e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7395, total_loss: 2.245e-05, loss_BC: 1.238e-05, loss_IC: 2.795e-07, loss_f: 9.686e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.70000, t_max: 0.71000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7396 0 1

 -------------------------------------------------------------
  -----  Epoch: 7396 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.70000, t_max: 0.71000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7396 !!! 


==> Epoch: 7400, Mean_loss of pinns: 1.062e-02, loss_BC: 1.149e-05, loss_IC: 7.256e-07, loss_f: 1.061e-02
 => minimum loss: 1.115e-04, corresponding pinn/batch index: 0000
 => maximum loss: 2.953e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7410, Mean_loss of pinns: 8.192e-03, loss_BC: 9.636e-06, loss_IC: 8.061e-06, loss_f: 8.175e-03
 => minimum loss: 9.255e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.262e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7420, Mean_loss of pinns: 6.424e-03, loss_BC: 9.015e-06, loss_IC: 2.183e-05, loss_f: 6.393e-03
 => minimum loss: 7.716e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.765e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7430, Mean_loss of pinns: 5.138e-03, loss_BC: 9.092e-06, loss_IC: 4.028e-05, loss_f: 5.089e-03
 => minimum loss: 6.593e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.405e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7440, Mean_loss of pinns: 4.194e-03, loss_BC: 7.919e-06, loss_IC: 6.023e-05, loss_f: 4.126e-03
 => minimum loss: 5.928e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.140e-02, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7450, Mean_loss of pinns: 3.497e-03, loss_BC: 8.276e-06, loss_IC: 7.933e-05, loss_f: 3.409e-03
 => minimum loss: 5.281e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.447e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7460, Mean_loss of pinns: 2.973e-03, loss_BC: 8.856e-06, loss_IC: 9.603e-05, loss_f: 2.868e-03
 => minimum loss: 4.973e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.986e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7470, Mean_loss of pinns: 2.570e-03, loss_BC: 9.687e-06, loss_IC: 1.097e-04, loss_f: 2.451e-03
 => minimum loss: 4.648e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.865e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7480, Mean_loss of pinns: 2.255e-03, loss_BC: 1.061e-05, loss_IC: 1.202e-04, loss_f: 2.124e-03
 => minimum loss: 4.397e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.998e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7490, Mean_loss of pinns: 2.002e-03, loss_BC: 1.125e-05, loss_IC: 1.280e-04, loss_f: 1.862e-03
 => minimum loss: 4.018e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.306e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  7495

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 7.200e-07, loss_BC: 0.000e+00, loss_IC: 1.462e-07,loss_f: 4.508e-07
pinn: 0300, Iter: 100, total_loss: 1.478e-06, loss_BC: 0.000e+00, loss_IC: 1.991e-07,loss_f: 1.157e-06
pinn: 0100, Iter: 100, total_loss: 8.261e-07, loss_BC: 0.000e+00, loss_IC: 6.191e-08,loss_f: 5.825e-07
pinn: 0200, Iter: 200, total_loss: 4.180e-07, loss_BC: 0.000e+00, loss_IC: 1.140e-07,loss_f: 1.795e-07
pinn: 0100, Iter: 200, total_loss: 2.948e-07, loss_BC: 0.000e+00, loss_IC: 3.003e-08,loss_f: 9.179e-08
pinn: 0300, Iter: 200, total_loss: 2.865e-07, loss_BC: 0.000e+00, loss_IC: 4.097e-08,loss_f: 1.323e-07
pinn: 0200, Iter: 300, total_loss: 3.134e-07, loss_BC: 0.000e+00, loss_IC: 6.294e-08,loss_f: 1.361e-07
pinn: 0100, Iter: 300, total_loss: 2.413e-07, loss_BC: 0.000e+00, loss_IC: 2.336e-08,loss_f: 5.367e-08
pinn: 0300, Iter: 300, total_loss: 1.886e-07, loss_BC: 0.000e+00, loss_IC: 1.686e-08,loss_f: 6.911e-08
pinn: 0200, Iter: 400, total_loss: 2.556e-07, loss_BC: 0.000e+00, loss_IC: 5.281e-08,loss_f: 9.436e-08
pinn: 0100, Iter: 400, total_loss: 2.272e-07, loss_BC: 0.000e+00, loss_IC: 1.991e-08,loss_f: 4.978e-08
pinn: 0300, Iter: 400, total_loss: 1.603e-07, loss_BC: 0.000e+00, loss_IC: 1.666e-08,loss_f: 5.019e-08
pinn: 0200, Iter: 500, total_loss: 2.240e-07, loss_BC: 0.000e+00, loss_IC: 3.897e-08,loss_f: 7.534e-08
pinn: 0100, Iter: 500, total_loss: 2.214e-07, loss_BC: 0.000e+00, loss_IC: 1.876e-08,loss_f: 4.796e-08
pinn: 0300, Iter: 500, total_loss: 1.557e-07, loss_BC: 0.000e+00, loss_IC: 1.628e-08,loss_f: 4.694e-08
pinn: 0200, Iter: 600, total_loss: 2.128e-07, loss_BC: 0.000e+00, loss_IC: 3.702e-08,loss_f: 6.737e-08
pinn: 0100, Iter: 600, total_loss: 2.153e-07, loss_BC: 0.000e+00, loss_IC: 2.008e-08,loss_f: 4.265e-08
pinn: 0300, Iter: 600, total_loss: 1.495e-07, loss_BC: 0.000e+00, loss_IC: 1.303e-08,loss_f: 4.500e-08
pinn: 0200, Iter: 700, total_loss: 2.087e-07, loss_BC: 0.000e+00, loss_IC: 3.687e-08,loss_f: 6.580e-08
pinn: 0100, Iter: 700, total_loss: 2.072e-07, loss_BC: 0.000e+00, loss_IC: 2.162e-08,loss_f: 4.041e-08
pinn: 0300, Iter: 700, total_loss: 1.437e-07, loss_BC: 0.000e+00, loss_IC: 1.291e-08,loss_f: 4.157e-08
pinn: 0200, Iter: 800, total_loss: 2.020e-07, loss_BC: 0.000e+00, loss_IC: 3.544e-08,loss_f: 6.324e-08
pinn: 0100, Iter: 800, total_loss: 2.011e-07, loss_BC: 0.000e+00, loss_IC: 2.199e-08,loss_f: 4.120e-08
pinn: 0300, Iter: 800, total_loss: 1.408e-07, loss_BC: 0.000e+00, loss_IC: 1.251e-08,loss_f: 3.956e-08
pinn: 0200, Iter: 900, total_loss: 1.944e-07, loss_BC: 0.000e+00, loss_IC: 3.169e-08,loss_f: 6.188e-08
pinn: 0100, Iter: 900, total_loss: 1.953e-07, loss_BC: 0.000e+00, loss_IC: 2.238e-08,loss_f: 4.326e-08
pinn: 0300, Iter: 900, total_loss: 1.377e-07, loss_BC: 0.000e+00, loss_IC: 1.298e-08,loss_f: 3.818e-08
pinn: 0200, Iter: 1000, total_loss: 1.933e-07, loss_BC: 0.000e+00, loss_IC: 3.088e-08,loss_f: 6.176e-08
pinn: 0100, Iter: 1000, total_loss: 1.937e-07, loss_BC: 0.000e+00, loss_IC: 2.154e-08,loss_f: 4.348e-08
pinn: 0300, Iter: 1000, total_loss: 1.341e-07, loss_BC: 0.000e+00, loss_IC: 1.412e-08,loss_f: 3.689e-08
pinn: 0200, Iter: 1100, total_loss: 1.890e-07, loss_BC: 0.000e+00, loss_IC: 2.908e-08,loss_f: 6.033e-08
pinn: 0100, Iter: 1100, total_loss: 1.785e-07, loss_BC: 0.000e+00, loss_IC: 2.349e-08,loss_f: 4.702e-08
pinn: 0300, Iter: 1100, total_loss: 1.331e-07, loss_BC: 0.000e+00, loss_IC: 1.406e-08,loss_f: 3.655e-08
pinn: 0200, Iter: 1200, total_loss: 1.846e-07, loss_BC: 0.000e+00, loss_IC: 2.607e-08,loss_f: 6.093e-08
pinn: 0100, Iter: 1200, total_loss: 1.644e-07, loss_BC: 0.000e+00, loss_IC: 2.188e-08,loss_f: 5.116e-08
pinn: 0300, Iter: 1200, total_loss: 1.302e-07, loss_BC: 0.000e+00, loss_IC: 1.479e-08,loss_f: 3.606e-08
pinn: 0200, Iter: 1300, total_loss: 1.826e-07, loss_BC: 0.000e+00, loss_IC: 2.512e-08,loss_f: 6.063e-08
pinn: 0100, Iter: 1300, total_loss: 1.559e-07, loss_BC: 0.000e+00, loss_IC: 2.029e-08,loss_f: 5.021e-08
pinn: 0300, Iter: 1300, total_loss: 1.263e-07, loss_BC: 0.000e+00, loss_IC: 1.704e-08,loss_f: 3.566e-08
pinn: 0200, Iter: 1400, total_loss: 1.815e-07, loss_BC: 0.000e+00, loss_IC: 2.565e-08,loss_f: 6.014e-08
pinn: 0100, Iter: 1400, total_loss: 1.542e-07, loss_BC: 0.000e+00, loss_IC: 1.953e-08,loss_f: 5.312e-08
pinn: 0300, Iter: 1400, total_loss: 1.241e-07, loss_BC: 0.000e+00, loss_IC: 1.659e-08,loss_f: 3.444e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7495, Mean_loss of pinns: 1.522e-07, loss_BC: 0.000e+00, loss_IC: 2.037e-08, loss_f: 4.907e-08
 => minimum loss: 1.240e-07, corresponding pinn index: 0300
 => maximum loss: 1.800e-07, corresponding pinn  index: 0200

 max_loss: 5.385e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7497, total_loss: 1.445e-05, loss_BC: 9.690e-06, loss_IC: 5.375e-07, loss_f: 4.138e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.71000, t_max: 0.72000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7498 0 1

 -------------------------------------------------------------
  -----  Epoch: 7498 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.71000, t_max: 0.72000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7498 !!! 


==> Epoch: 7500, Mean_loss of pinns: 1.577e-03, loss_BC: 1.011e-05, loss_IC: 8.596e-08, loss_f: 1.567e-03
 => minimum loss: 4.351e-05, corresponding pinn/batch index: 0100
 => maximum loss: 6.129e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 7510, Mean_loss of pinns: 1.279e-03, loss_BC: 1.084e-05, loss_IC: 7.991e-07, loss_f: 1.268e-03
 => minimum loss: 3.363e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.979e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7520, Mean_loss of pinns: 1.056e-03, loss_BC: 1.313e-05, loss_IC: 1.541e-06, loss_f: 1.041e-03
 => minimum loss: 2.721e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.112e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7530, Mean_loss of pinns: 8.774e-04, loss_BC: 1.587e-05, loss_IC: 2.683e-06, loss_f: 8.587e-04
 => minimum loss: 2.243e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.421e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7540, Mean_loss of pinns: 7.384e-04, loss_BC: 1.774e-05, loss_IC: 3.990e-06, loss_f: 7.165e-04
 => minimum loss: 1.898e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.880e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7550, Mean_loss of pinns: 6.288e-04, loss_BC: 1.855e-05, loss_IC: 5.183e-06, loss_f: 6.049e-04
 => minimum loss: 1.605e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.453e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7560, Mean_loss of pinns: 5.431e-04, loss_BC: 1.967e-05, loss_IC: 6.034e-06, loss_f: 5.173e-04
 => minimum loss: 1.419e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.119e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7570, Mean_loss of pinns: 4.745e-04, loss_BC: 2.013e-05, loss_IC: 6.448e-06, loss_f: 4.478e-04
 => minimum loss: 1.291e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.850e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7580, Mean_loss of pinns: 4.179e-04, loss_BC: 1.922e-05, loss_IC: 6.426e-06, loss_f: 3.921e-04
 => minimum loss: 1.136e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.630e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7590, Mean_loss of pinns: 3.719e-04, loss_BC: 1.895e-05, loss_IC: 6.083e-06, loss_f: 3.468e-04
 => minimum loss: 1.076e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.449e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  7597

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 9.223e-07, loss_BC: 0.000e+00, loss_IC: 6.886e-08,loss_f: 7.684e-07
pinn: 0000, Iter: 200, total_loss: 3.038e-07, loss_BC: 0.000e+00, loss_IC: 4.710e-08,loss_f: 1.711e-07
pinn: 0000, Iter: 300, total_loss: 2.261e-07, loss_BC: 0.000e+00, loss_IC: 3.026e-08,loss_f: 1.146e-07
pinn: 0000, Iter: 400, total_loss: 2.048e-07, loss_BC: 0.000e+00, loss_IC: 2.699e-08,loss_f: 9.936e-08
pinn: 0000, Iter: 500, total_loss: 1.820e-07, loss_BC: 0.000e+00, loss_IC: 2.572e-08,loss_f: 7.801e-08
pinn: 0000, Iter: 600, total_loss: 1.716e-07, loss_BC: 0.000e+00, loss_IC: 2.333e-08,loss_f: 7.142e-08
pinn: 0000, Iter: 700, total_loss: 1.662e-07, loss_BC: 0.000e+00, loss_IC: 2.341e-08,loss_f: 6.756e-08
pinn: 0000, Iter: 800, total_loss: 1.627e-07, loss_BC: 0.000e+00, loss_IC: 2.433e-08,loss_f: 6.429e-08
pinn: 0000, Iter: 900, total_loss: 1.612e-07, loss_BC: 0.000e+00, loss_IC: 2.317e-08,loss_f: 6.364e-08
pinn: 0000, Iter: 1000, total_loss: 1.552e-07, loss_BC: 0.000e+00, loss_IC: 2.153e-08,loss_f: 6.113e-08
pinn: 0000, Iter: 1100, total_loss: 1.492e-07, loss_BC: 0.000e+00, loss_IC: 1.976e-08,loss_f: 5.759e-08
pinn: 0000, Iter: 1200, total_loss: 1.434e-07, loss_BC: 0.000e+00, loss_IC: 1.952e-08,loss_f: 5.416e-08
pinn: 0000, Iter: 1300, total_loss: 1.413e-07, loss_BC: 0.000e+00, loss_IC: 1.885e-08,loss_f: 5.382e-08
pinn: 0000, Iter: 1400, total_loss: 1.397e-07, loss_BC: 0.000e+00, loss_IC: 1.795e-08,loss_f: 5.399e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7597, Mean_loss of pinns: 1.397e-07, loss_BC: 0.000e+00, loss_IC: 1.787e-08, loss_f: 5.406e-08
 => minimum loss: 1.397e-07, corresponding pinn index: 0000
 => maximum loss: 1.397e-07, corresponding pinn  index: 0000

 max_loss: 4.320e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7599, total_loss: 1.971e-05, loss_BC: 1.142e-05, loss_IC: 2.255e-07, loss_f: 7.955e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.72000, t_max: 0.73000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7600 0 1

 -------------------------------------------------------------
  -----  Epoch: 7600 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.72000, t_max: 0.73000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7600 !!! 


==> Epoch: 7600, Mean_loss of pinns: 3.647e-03, loss_BC: 1.259e-05, loss_IC: 0.000e+00, loss_f: 3.634e-03
 => minimum loss: 1.042e-04, corresponding pinn/batch index: 0000
 => maximum loss: 7.851e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7610, Mean_loss of pinns: 2.604e-03, loss_BC: 8.696e-06, loss_IC: 5.343e-06, loss_f: 2.590e-03
 => minimum loss: 8.345e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.464e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7620, Mean_loss of pinns: 2.009e-03, loss_BC: 8.107e-06, loss_IC: 1.713e-05, loss_f: 1.984e-03
 => minimum loss: 7.120e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.259e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7630, Mean_loss of pinns: 1.613e-03, loss_BC: 8.194e-06, loss_IC: 3.090e-05, loss_f: 1.574e-03
 => minimum loss: 5.809e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.472e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7640, Mean_loss of pinns: 1.331e-03, loss_BC: 6.449e-06, loss_IC: 4.325e-05, loss_f: 1.281e-03
 => minimum loss: 5.017e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.887e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7650, Mean_loss of pinns: 1.133e-03, loss_BC: 5.477e-06, loss_IC: 5.246e-05, loss_f: 1.075e-03
 => minimum loss: 4.340e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.479e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7660, Mean_loss of pinns: 9.864e-04, loss_BC: 5.325e-06, loss_IC: 5.847e-05, loss_f: 9.225e-04
 => minimum loss: 4.065e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.174e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7670, Mean_loss of pinns: 8.732e-04, loss_BC: 5.830e-06, loss_IC: 6.165e-05, loss_f: 8.056e-04
 => minimum loss: 3.668e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.939e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7680, Mean_loss of pinns: 7.828e-04, loss_BC: 6.834e-06, loss_IC: 6.252e-05, loss_f: 7.134e-04
 => minimum loss: 3.494e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.752e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7690, Mean_loss of pinns: 7.069e-04, loss_BC: 6.592e-06, loss_IC: 6.171e-05, loss_f: 6.386e-04
 => minimum loss: 3.250e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.596e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  7699

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.979e-06, loss_BC: 0.000e+00, loss_IC: 3.264e-07,loss_f: 1.540e-06
pinn: 0300, Iter: 100, total_loss: 8.022e-07, loss_BC: 0.000e+00, loss_IC: 5.791e-08,loss_f: 6.585e-07
pinn: 0200, Iter: 100, total_loss: 5.714e-07, loss_BC: 0.000e+00, loss_IC: 6.550e-08,loss_f: 3.962e-07
pinn: 0300, Iter: 200, total_loss: 1.962e-07, loss_BC: 0.000e+00, loss_IC: 3.245e-08,loss_f: 8.370e-08
pinn: 0100, Iter: 200, total_loss: 2.961e-07, loss_BC: 0.000e+00, loss_IC: 3.278e-08,loss_f: 1.596e-07
pinn: 0200, Iter: 200, total_loss: 2.955e-07, loss_BC: 0.000e+00, loss_IC: 5.412e-08,loss_f: 1.319e-07
pinn: 0100, Iter: 300, total_loss: 1.942e-07, loss_BC: 0.000e+00, loss_IC: 2.498e-08,loss_f: 7.022e-08
pinn: 0300, Iter: 300, total_loss: 1.389e-07, loss_BC: 0.000e+00, loss_IC: 1.615e-08,loss_f: 4.750e-08
pinn: 0200, Iter: 300, total_loss: 2.138e-07, loss_BC: 0.000e+00, loss_IC: 3.277e-08,loss_f: 7.763e-08
pinn: 0300, Iter: 400, total_loss: 1.275e-07, loss_BC: 0.000e+00, loss_IC: 1.046e-08,loss_f: 4.552e-08
pinn: 0100, Iter: 400, total_loss: 1.730e-07, loss_BC: 0.000e+00, loss_IC: 1.584e-08,loss_f: 6.419e-08
pinn: 0200, Iter: 400, total_loss: 1.882e-07, loss_BC: 0.000e+00, loss_IC: 3.041e-08,loss_f: 5.871e-08
pinn: 0300, Iter: 500, total_loss: 1.201e-07, loss_BC: 0.000e+00, loss_IC: 9.493e-09,loss_f: 3.963e-08
pinn: 0100, Iter: 500, total_loss: 1.625e-07, loss_BC: 0.000e+00, loss_IC: 1.677e-08,loss_f: 5.253e-08
pinn: 0200, Iter: 500, total_loss: 1.812e-07, loss_BC: 0.000e+00, loss_IC: 2.865e-08,loss_f: 5.442e-08
pinn: 0300, Iter: 600, total_loss: 1.132e-07, loss_BC: 0.000e+00, loss_IC: 9.525e-09,loss_f: 3.320e-08
pinn: 0100, Iter: 600, total_loss: 1.572e-07, loss_BC: 0.000e+00, loss_IC: 1.759e-08,loss_f: 4.726e-08
pinn: 0200, Iter: 600, total_loss: 1.722e-07, loss_BC: 0.000e+00, loss_IC: 2.428e-08,loss_f: 4.917e-08
pinn: 0300, Iter: 700, total_loss: 1.119e-07, loss_BC: 0.000e+00, loss_IC: 9.493e-09,loss_f: 3.260e-08
pinn: 0100, Iter: 700, total_loss: 1.521e-07, loss_BC: 0.000e+00, loss_IC: 1.806e-08,loss_f: 4.326e-08
pinn: 0200, Iter: 700, total_loss: 1.690e-07, loss_BC: 0.000e+00, loss_IC: 2.378e-08,loss_f: 4.781e-08
pinn: 0300, Iter: 800, total_loss: 1.096e-07, loss_BC: 0.000e+00, loss_IC: 9.497e-09,loss_f: 3.158e-08
pinn: 0100, Iter: 800, total_loss: 1.485e-07, loss_BC: 0.000e+00, loss_IC: 1.693e-08,loss_f: 4.184e-08
pinn: 0200, Iter: 800, total_loss: 1.660e-07, loss_BC: 0.000e+00, loss_IC: 2.438e-08,loss_f: 4.626e-08
pinn: 0300, Iter: 900, total_loss: 1.059e-07, loss_BC: 0.000e+00, loss_IC: 9.471e-09,loss_f: 3.044e-08
pinn: 0100, Iter: 900, total_loss: 1.469e-07, loss_BC: 0.000e+00, loss_IC: 1.707e-08,loss_f: 4.088e-08
pinn: 0200, Iter: 900, total_loss: 1.631e-07, loss_BC: 0.000e+00, loss_IC: 2.287e-08,loss_f: 4.618e-08
pinn: 0300, Iter: 1000, total_loss: 1.042e-07, loss_BC: 0.000e+00, loss_IC: 9.650e-09,loss_f: 2.983e-08
pinn: 0100, Iter: 1000, total_loss: 1.453e-07, loss_BC: 0.000e+00, loss_IC: 1.690e-08,loss_f: 4.094e-08
pinn: 0200, Iter: 1000, total_loss: 1.608e-07, loss_BC: 0.000e+00, loss_IC: 2.294e-08,loss_f: 4.530e-08
pinn: 0300, Iter: 1100, total_loss: 9.976e-08, loss_BC: 0.000e+00, loss_IC: 8.455e-09,loss_f: 2.998e-08
pinn: 0100, Iter: 1100, total_loss: 1.404e-07, loss_BC: 0.000e+00, loss_IC: 1.879e-08,loss_f: 3.929e-08
pinn: 0200, Iter: 1100, total_loss: 1.569e-07, loss_BC: 0.000e+00, loss_IC: 2.312e-08,loss_f: 4.571e-08
pinn: 0300, Iter: 1200, total_loss: 9.447e-08, loss_BC: 0.000e+00, loss_IC: 7.269e-09,loss_f: 3.060e-08
pinn: 0100, Iter: 1200, total_loss: 1.375e-07, loss_BC: 0.000e+00, loss_IC: 1.763e-08,loss_f: 3.932e-08
pinn: 0200, Iter: 1200, total_loss: 1.541e-07, loss_BC: 0.000e+00, loss_IC: 2.240e-08,loss_f: 4.458e-08
pinn: 0100, Iter: 1300, total_loss: 1.343e-07, loss_BC: 0.000e+00, loss_IC: 1.701e-08,loss_f: 3.930e-08
pinn: 0300, Iter: 1300, total_loss: 9.080e-08, loss_BC: 0.000e+00, loss_IC: 6.483e-09,loss_f: 3.066e-08
pinn: 0200, Iter: 1300, total_loss: 1.529e-07, loss_BC: 0.000e+00, loss_IC: 2.219e-08,loss_f: 4.463e-08
pinn: 0300, Iter: 1400, total_loss: 8.962e-08, loss_BC: 0.000e+00, loss_IC: 6.442e-09,loss_f: 3.060e-08
pinn: 0100, Iter: 1400, total_loss: 1.331e-07, loss_BC: 0.000e+00, loss_IC: 1.610e-08,loss_f: 3.935e-08
pinn: 0200, Iter: 1400, total_loss: 1.482e-07, loss_BC: 0.000e+00, loss_IC: 2.182e-08,loss_f: 4.422e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7699, Mean_loss of pinns: 1.222e-07, loss_BC: 0.000e+00, loss_IC: 1.467e-08, loss_f: 3.817e-08
 => minimum loss: 8.843e-08, corresponding pinn index: 0300
 => maximum loss: 1.479e-07, corresponding pinn  index: 0200

==> Epoch: 7700, Mean_loss of pinns: 1.277e-05, loss_BC: 9.031e-06, loss_IC: 2.892e-07, loss_f: 3.368e-06
 => minimum loss: 1.082e-06, corresponding pinn/batch index: 0100
 => maximum loss: 4.653e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 4.571e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7701, total_loss: 1.244e-05, loss_BC: 8.708e-06, loss_IC: 3.115e-07, loss_f: 3.345e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.73000, t_max: 0.74000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7702 0 1

 -------------------------------------------------------------
  -----  Epoch: 7702 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.73000, t_max: 0.74000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7702 !!! 


==> Epoch: 7710, Mean_loss of pinns: 1.784e-04, loss_BC: 9.100e-06, loss_IC: 9.933e-07, loss_f: 1.682e-04
 => minimum loss: 5.234e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.476e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 7720, Mean_loss of pinns: 1.465e-04, loss_BC: 9.295e-06, loss_IC: 1.875e-06, loss_f: 1.352e-04
 => minimum loss: 4.181e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.764e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 7730, Mean_loss of pinns: 1.242e-04, loss_BC: 1.037e-05, loss_IC: 1.317e-06, loss_f: 1.124e-04
 => minimum loss: 3.338e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.309e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 7740, Mean_loss of pinns: 1.066e-04, loss_BC: 1.047e-05, loss_IC: 7.975e-07, loss_f: 9.520e-05
 => minimum loss: 2.752e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.917e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7750, Mean_loss of pinns: 9.194e-05, loss_BC: 9.574e-06, loss_IC: 7.152e-07, loss_f: 8.152e-05
 => minimum loss: 2.306e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.556e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7760, Mean_loss of pinns: 8.043e-05, loss_BC: 8.967e-06, loss_IC: 7.643e-07, loss_f: 7.057e-05
 => minimum loss: 2.019e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.260e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7770, Mean_loss of pinns: 7.116e-05, loss_BC: 8.503e-06, loss_IC: 7.631e-07, loss_f: 6.177e-05
 => minimum loss: 1.760e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.018e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7780, Mean_loss of pinns: 6.339e-05, loss_BC: 7.938e-06, loss_IC: 7.768e-07, loss_f: 5.455e-05
 => minimum loss: 1.594e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.804e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7790, Mean_loss of pinns: 5.727e-05, loss_BC: 7.762e-06, loss_IC: 7.963e-07, loss_f: 4.858e-05
 => minimum loss: 1.436e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.639e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7800, Mean_loss of pinns: 5.204e-05, loss_BC: 7.496e-06, loss_IC: 8.032e-07, loss_f: 4.361e-05
 => minimum loss: 1.319e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.490e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  7801

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 6.881e-07, loss_BC: 0.000e+00, loss_IC: 5.273e-08,loss_f: 5.247e-07
pinn: 0000, Iter: 200, total_loss: 2.711e-07, loss_BC: 0.000e+00, loss_IC: 1.917e-08,loss_f: 1.431e-07
pinn: 0000, Iter: 300, total_loss: 2.369e-07, loss_BC: 0.000e+00, loss_IC: 1.736e-08,loss_f: 1.141e-07
pinn: 0000, Iter: 400, total_loss: 2.082e-07, loss_BC: 0.000e+00, loss_IC: 1.421e-08,loss_f: 9.156e-08
pinn: 0000, Iter: 500, total_loss: 1.950e-07, loss_BC: 0.000e+00, loss_IC: 1.550e-08,loss_f: 7.852e-08
pinn: 0000, Iter: 600, total_loss: 1.861e-07, loss_BC: 0.000e+00, loss_IC: 1.525e-08,loss_f: 7.066e-08
pinn: 0000, Iter: 700, total_loss: 1.795e-07, loss_BC: 0.000e+00, loss_IC: 1.450e-08,loss_f: 6.963e-08
pinn: 0000, Iter: 800, total_loss: 1.784e-07, loss_BC: 0.000e+00, loss_IC: 1.449e-08,loss_f: 6.870e-08
pinn: 0000, Iter: 900, total_loss: 1.720e-07, loss_BC: 0.000e+00, loss_IC: 1.331e-08,loss_f: 6.590e-08
pinn: 0000, Iter: 1000, total_loss: 1.698e-07, loss_BC: 0.000e+00, loss_IC: 1.349e-08,loss_f: 6.527e-08
pinn: 0000, Iter: 1100, total_loss: 1.641e-07, loss_BC: 0.000e+00, loss_IC: 1.225e-08,loss_f: 6.375e-08
pinn: 0000, Iter: 1200, total_loss: 1.569e-07, loss_BC: 0.000e+00, loss_IC: 1.226e-08,loss_f: 6.312e-08
pinn: 0000, Iter: 1300, total_loss: 1.471e-07, loss_BC: 0.000e+00, loss_IC: 1.055e-08,loss_f: 6.113e-08
pinn: 0000, Iter: 1400, total_loss: 1.427e-07, loss_BC: 0.000e+00, loss_IC: 1.138e-08,loss_f: 6.047e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7801, Mean_loss of pinns: 1.353e-07, loss_BC: 0.000e+00, loss_IC: 9.795e-09, loss_f: 5.895e-08
 => minimum loss: 1.353e-07, corresponding pinn index: 0000
 => maximum loss: 1.353e-07, corresponding pinn  index: 0000

 max_loss: 3.845e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7803, total_loss: 2.400e-05, loss_BC: 1.025e-05, loss_IC: 4.899e-07, loss_f: 1.315e-05

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.74000, t_max: 0.75000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7804 0 1

 -------------------------------------------------------------
  -----  Epoch: 7804 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.74000, t_max: 0.75000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7804 !!! 


==> Epoch: 7810, Mean_loss of pinns: 2.702e-03, loss_BC: 9.156e-06, loss_IC: 2.205e-06, loss_f: 2.691e-03
 => minimum loss: 7.850e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.116e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 7820, Mean_loss of pinns: 2.073e-03, loss_BC: 7.338e-06, loss_IC: 1.226e-05, loss_f: 2.053e-03
 => minimum loss: 6.817e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.428e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7830, Mean_loss of pinns: 1.648e-03, loss_BC: 7.406e-06, loss_IC: 2.590e-05, loss_f: 1.614e-03
 => minimum loss: 5.903e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.299e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7840, Mean_loss of pinns: 1.340e-03, loss_BC: 7.455e-06, loss_IC: 3.936e-05, loss_f: 1.293e-03
 => minimum loss: 5.195e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.469e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7850, Mean_loss of pinns: 1.120e-03, loss_BC: 8.322e-06, loss_IC: 4.964e-05, loss_f: 1.062e-03
 => minimum loss: 4.826e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.884e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7860, Mean_loss of pinns: 9.584e-04, loss_BC: 1.036e-05, loss_IC: 5.666e-05, loss_f: 8.913e-04
 => minimum loss: 4.643e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.460e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7870, Mean_loss of pinns: 8.356e-04, loss_BC: 1.189e-05, loss_IC: 6.093e-05, loss_f: 7.626e-04
 => minimum loss: 4.269e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.145e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7880, Mean_loss of pinns: 7.397e-04, loss_BC: 1.303e-05, loss_IC: 6.320e-05, loss_f: 6.633e-04
 => minimum loss: 4.044e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.906e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7890, Mean_loss of pinns: 6.627e-04, loss_BC: 1.382e-05, loss_IC: 6.394e-05, loss_f: 5.848e-04
 => minimum loss: 3.744e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.714e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 7900, Mean_loss of pinns: 5.998e-04, loss_BC: 1.492e-05, loss_IC: 6.339e-05, loss_f: 5.214e-04
 => minimum loss: 3.767e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.558e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  7903

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 2.133e-06, loss_BC: 0.000e+00, loss_IC: 4.690e-07,loss_f: 1.550e-06
pinn: 0100, Iter: 100, total_loss: 7.991e-07, loss_BC: 0.000e+00, loss_IC: 7.032e-08,loss_f: 6.295e-07
pinn: 0200, Iter: 100, total_loss: 8.133e-07, loss_BC: 0.000e+00, loss_IC: 8.016e-08,loss_f: 4.288e-07
pinn: 0300, Iter: 200, total_loss: 2.921e-07, loss_BC: 0.000e+00, loss_IC: 3.947e-08,loss_f: 1.487e-07
pinn: 0200, Iter: 200, total_loss: 4.657e-07, loss_BC: 0.000e+00, loss_IC: 5.811e-08,loss_f: 1.169e-07
pinn: 0100, Iter: 200, total_loss: 2.434e-07, loss_BC: 0.000e+00, loss_IC: 3.260e-08,loss_f: 1.161e-07
pinn: 0300, Iter: 300, total_loss: 1.759e-07, loss_BC: 0.000e+00, loss_IC: 1.693e-08,loss_f: 6.392e-08
pinn: 0200, Iter: 300, total_loss: 3.741e-07, loss_BC: 0.000e+00, loss_IC: 4.341e-08,loss_f: 6.941e-08
pinn: 0100, Iter: 300, total_loss: 1.654e-07, loss_BC: 0.000e+00, loss_IC: 2.564e-08,loss_f: 4.967e-08
pinn: 0300, Iter: 400, total_loss: 1.464e-07, loss_BC: 0.000e+00, loss_IC: 9.837e-09,loss_f: 4.769e-08
pinn: 0100, Iter: 400, total_loss: 1.496e-07, loss_BC: 0.000e+00, loss_IC: 1.738e-08,loss_f: 4.668e-08
pinn: 0200, Iter: 400, total_loss: 3.518e-07, loss_BC: 0.000e+00, loss_IC: 4.844e-08,loss_f: 5.481e-08
pinn: 0300, Iter: 500, total_loss: 1.381e-07, loss_BC: 0.000e+00, loss_IC: 7.621e-09,loss_f: 4.406e-08
pinn: 0100, Iter: 500, total_loss: 1.433e-07, loss_BC: 0.000e+00, loss_IC: 1.768e-08,loss_f: 4.171e-08
pinn: 0200, Iter: 500, total_loss: 3.400e-07, loss_BC: 0.000e+00, loss_IC: 4.489e-08,loss_f: 4.936e-08
pinn: 0300, Iter: 600, total_loss: 1.304e-07, loss_BC: 0.000e+00, loss_IC: 7.377e-09,loss_f: 3.751e-08
pinn: 0100, Iter: 600, total_loss: 1.387e-07, loss_BC: 0.000e+00, loss_IC: 1.714e-08,loss_f: 3.909e-08
pinn: 0200, Iter: 600, total_loss: 3.273e-07, loss_BC: 0.000e+00, loss_IC: 3.978e-08,loss_f: 4.909e-08
pinn: 0300, Iter: 700, total_loss: 1.264e-07, loss_BC: 0.000e+00, loss_IC: 7.585e-09,loss_f: 3.476e-08
pinn: 0100, Iter: 700, total_loss: 1.332e-07, loss_BC: 0.000e+00, loss_IC: 1.592e-08,loss_f: 3.530e-08
pinn: 0200, Iter: 700, total_loss: 3.155e-07, loss_BC: 0.000e+00, loss_IC: 3.961e-08,loss_f: 4.794e-08
pinn: 0300, Iter: 800, total_loss: 1.240e-07, loss_BC: 0.000e+00, loss_IC: 6.998e-09,loss_f: 3.431e-08
pinn: 0100, Iter: 800, total_loss: 1.313e-07, loss_BC: 0.000e+00, loss_IC: 1.487e-08,loss_f: 3.543e-08
pinn: 0200, Iter: 800, total_loss: 3.016e-07, loss_BC: 0.000e+00, loss_IC: 4.468e-08,loss_f: 5.152e-08
pinn: 0300, Iter: 900, total_loss: 1.202e-07, loss_BC: 0.000e+00, loss_IC: 7.975e-09,loss_f: 3.296e-08
pinn: 0100, Iter: 900, total_loss: 1.298e-07, loss_BC: 0.000e+00, loss_IC: 1.469e-08,loss_f: 3.553e-08
pinn: 0200, Iter: 900, total_loss: 2.785e-07, loss_BC: 0.000e+00, loss_IC: 4.417e-08,loss_f: 5.509e-08
pinn: 0300, Iter: 1000, total_loss: 1.175e-07, loss_BC: 0.000e+00, loss_IC: 7.868e-09,loss_f: 3.287e-08
pinn: 0200, Iter: 1000, total_loss: 2.548e-07, loss_BC: 0.000e+00, loss_IC: 4.215e-08,loss_f: 6.406e-08
pinn: 0100, Iter: 1000, total_loss: 1.274e-07, loss_BC: 0.000e+00, loss_IC: 1.453e-08,loss_f: 3.517e-08
pinn: 0300, Iter: 1100, total_loss: 1.161e-07, loss_BC: 0.000e+00, loss_IC: 7.792e-09,loss_f: 3.269e-08
pinn: 0200, Iter: 1100, total_loss: 2.396e-07, loss_BC: 0.000e+00, loss_IC: 4.845e-08,loss_f: 6.498e-08
pinn: 0100, Iter: 1100, total_loss: 1.248e-07, loss_BC: 0.000e+00, loss_IC: 1.548e-08,loss_f: 3.441e-08
pinn: 0300, Iter: 1200, total_loss: 1.134e-07, loss_BC: 0.000e+00, loss_IC: 7.331e-09,loss_f: 3.261e-08
pinn: 0200, Iter: 1200, total_loss: 2.231e-07, loss_BC: 0.000e+00, loss_IC: 4.236e-08,loss_f: 6.382e-08
pinn: 0100, Iter: 1200, total_loss: 1.183e-07, loss_BC: 0.000e+00, loss_IC: 1.252e-08,loss_f: 3.453e-08
pinn: 0300, Iter: 1300, total_loss: 1.130e-07, loss_BC: 0.000e+00, loss_IC: 7.195e-09,loss_f: 3.233e-08
pinn: 0200, Iter: 1300, total_loss: 2.194e-07, loss_BC: 0.000e+00, loss_IC: 4.193e-08,loss_f: 6.769e-08
pinn: 0100, Iter: 1300, total_loss: 1.176e-07, loss_BC: 0.000e+00, loss_IC: 1.142e-08,loss_f: 3.470e-08
pinn: 0300, Iter: 1400, total_loss: 1.086e-07, loss_BC: 0.000e+00, loss_IC: 8.922e-09,loss_f: 3.241e-08
pinn: 0200, Iter: 1400, total_loss: 2.074e-07, loss_BC: 0.000e+00, loss_IC: 4.008e-08,loss_f: 6.392e-08
pinn: 0100, Iter: 1400, total_loss: 1.123e-07, loss_BC: 0.000e+00, loss_IC: 9.218e-09,loss_f: 3.585e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 7903, Mean_loss of pinns: 1.414e-07, loss_BC: 0.000e+00, loss_IC: 1.961e-08, loss_f: 4.438e-08
 => minimum loss: 1.083e-07, corresponding pinn index: 0300
 => maximum loss: 2.038e-07, corresponding pinn  index: 0200

 max_loss: 4.109e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 7905, total_loss: 1.156e-05, loss_BC: 7.375e-06, loss_IC: 8.790e-07, loss_f: 3.206e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.75000, t_max: 0.76000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  7906 0 1

 -------------------------------------------------------------
  -----  Epoch: 7906 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.75000, t_max: 0.76000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  7906 !!! 


==> Epoch: 7910, Mean_loss of pinns: 1.294e-03, loss_BC: 7.930e-06, loss_IC: 2.636e-07, loss_f: 1.285e-03
 => minimum loss: 4.669e-05, corresponding pinn/batch index: 0300
 => maximum loss: 5.027e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7920, Mean_loss of pinns: 1.056e-03, loss_BC: 9.201e-06, loss_IC: 9.230e-07, loss_f: 1.045e-03
 => minimum loss: 3.652e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.109e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7930, Mean_loss of pinns: 8.699e-04, loss_BC: 1.130e-05, loss_IC: 1.776e-06, loss_f: 8.567e-04
 => minimum loss: 2.847e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.389e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7940, Mean_loss of pinns: 7.237e-04, loss_BC: 1.294e-05, loss_IC: 3.145e-06, loss_f: 7.075e-04
 => minimum loss: 2.279e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.822e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7950, Mean_loss of pinns: 6.105e-04, loss_BC: 1.465e-05, loss_IC: 4.652e-06, loss_f: 5.912e-04
 => minimum loss: 1.879e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.381e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7960, Mean_loss of pinns: 5.222e-04, loss_BC: 1.567e-05, loss_IC: 5.927e-06, loss_f: 5.006e-04
 => minimum loss: 1.600e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.037e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7970, Mean_loss of pinns: 4.530e-04, loss_BC: 1.659e-05, loss_IC: 6.789e-06, loss_f: 4.295e-04
 => minimum loss: 1.398e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.766e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7980, Mean_loss of pinns: 3.971e-04, loss_BC: 1.655e-05, loss_IC: 7.156e-06, loss_f: 3.733e-04
 => minimum loss: 1.241e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.548e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 7990, Mean_loss of pinns: 3.512e-04, loss_BC: 1.594e-05, loss_IC: 7.051e-06, loss_f: 3.281e-04
 => minimum loss: 1.114e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.368e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8000, Mean_loss of pinns: 3.138e-04, loss_BC: 1.578e-05, loss_IC: 6.603e-06, loss_f: 2.913e-04
 => minimum loss: 1.010e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.222e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  8005

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 8.959e-07, loss_BC: 0.000e+00, loss_IC: 5.038e-08,loss_f: 6.945e-07
pinn: 0000, Iter: 200, total_loss: 2.719e-07, loss_BC: 0.000e+00, loss_IC: 1.255e-08,loss_f: 1.146e-07
pinn: 0000, Iter: 300, total_loss: 2.101e-07, loss_BC: 0.000e+00, loss_IC: 1.612e-08,loss_f: 5.950e-08
pinn: 0000, Iter: 400, total_loss: 1.949e-07, loss_BC: 0.000e+00, loss_IC: 1.731e-08,loss_f: 4.678e-08
pinn: 0000, Iter: 500, total_loss: 1.883e-07, loss_BC: 0.000e+00, loss_IC: 1.641e-08,loss_f: 4.190e-08
pinn: 0000, Iter: 600, total_loss: 1.804e-07, loss_BC: 0.000e+00, loss_IC: 1.507e-08,loss_f: 3.958e-08
pinn: 0000, Iter: 700, total_loss: 1.763e-07, loss_BC: 0.000e+00, loss_IC: 1.621e-08,loss_f: 3.878e-08
pinn: 0000, Iter: 800, total_loss: 1.717e-07, loss_BC: 0.000e+00, loss_IC: 1.622e-08,loss_f: 3.940e-08
pinn: 0000, Iter: 900, total_loss: 1.672e-07, loss_BC: 0.000e+00, loss_IC: 1.411e-08,loss_f: 4.030e-08
pinn: 0000, Iter: 1000, total_loss: 1.550e-07, loss_BC: 0.000e+00, loss_IC: 1.571e-08,loss_f: 4.360e-08
pinn: 0000, Iter: 1100, total_loss: 1.493e-07, loss_BC: 0.000e+00, loss_IC: 1.501e-08,loss_f: 4.665e-08
pinn: 0000, Iter: 1200, total_loss: 1.422e-07, loss_BC: 0.000e+00, loss_IC: 1.300e-08,loss_f: 4.696e-08
pinn: 0000, Iter: 1300, total_loss: 1.390e-07, loss_BC: 0.000e+00, loss_IC: 1.344e-08,loss_f: 4.729e-08
pinn: 0000, Iter: 1400, total_loss: 1.375e-07, loss_BC: 0.000e+00, loss_IC: 1.371e-08,loss_f: 4.801e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8005, Mean_loss of pinns: 1.373e-07, loss_BC: 0.000e+00, loss_IC: 1.356e-08, loss_f: 4.843e-08
 => minimum loss: 1.373e-07, corresponding pinn index: 0000
 => maximum loss: 1.373e-07, corresponding pinn  index: 0000

 max_loss: 3.045e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8007, total_loss: 1.560e-05, loss_BC: 8.644e-06, loss_IC: 1.942e-07, loss_f: 6.680e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.76000, t_max: 0.77000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8008 0 1

 -------------------------------------------------------------
  -----  Epoch: 8008 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.76000, t_max: 0.77000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8008 !!! 


==> Epoch: 8010, Mean_loss of pinns: 3.859e-03, loss_BC: 9.346e-06, loss_IC: 2.304e-07, loss_f: 3.849e-03
 => minimum loss: 1.075e-04, corresponding pinn/batch index: 0000
 => maximum loss: 9.075e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 8020, Mean_loss of pinns: 2.862e-03, loss_BC: 6.819e-06, loss_IC: 7.400e-06, loss_f: 2.847e-03
 => minimum loss: 8.710e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.632e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 8030, Mean_loss of pinns: 2.208e-03, loss_BC: 6.139e-06, loss_IC: 2.179e-05, loss_f: 2.180e-03
 => minimum loss: 7.179e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.111e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 8040, Mean_loss of pinns: 1.745e-03, loss_BC: 5.622e-06, loss_IC: 3.932e-05, loss_f: 1.700e-03
 => minimum loss: 6.066e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.012e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8050, Mean_loss of pinns: 1.417e-03, loss_BC: 6.136e-06, loss_IC: 5.569e-05, loss_f: 1.355e-03
 => minimum loss: 5.534e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.219e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8060, Mean_loss of pinns: 1.185e-03, loss_BC: 6.045e-06, loss_IC: 6.874e-05, loss_f: 1.110e-03
 => minimum loss: 4.861e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.670e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8070, Mean_loss of pinns: 1.017e-03, loss_BC: 6.910e-06, loss_IC: 7.757e-05, loss_f: 9.319e-04
 => minimum loss: 4.376e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.280e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8080, Mean_loss of pinns: 8.895e-04, loss_BC: 7.637e-06, loss_IC: 8.231e-05, loss_f: 7.995e-04
 => minimum loss: 3.877e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.996e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8090, Mean_loss of pinns: 7.912e-04, loss_BC: 8.938e-06, loss_IC: 8.360e-05, loss_f: 6.986e-04
 => minimum loss: 3.693e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.781e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8100, Mean_loss of pinns: 7.117e-04, loss_BC: 9.741e-06, loss_IC: 8.239e-05, loss_f: 6.195e-04
 => minimum loss: 3.456e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.612e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  8107

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.082e-06, loss_BC: 0.000e+00, loss_IC: 7.022e-08,loss_f: 7.938e-07
pinn: 0200, Iter: 100, total_loss: 7.096e-07, loss_BC: 0.000e+00, loss_IC: 7.443e-08,loss_f: 5.333e-07
pinn: 0300, Iter: 100, total_loss: 8.764e-07, loss_BC: 0.000e+00, loss_IC: 7.238e-08,loss_f: 6.773e-07
pinn: 0300, Iter: 200, total_loss: 2.649e-07, loss_BC: 0.000e+00, loss_IC: 4.623e-08,loss_f: 9.921e-08
pinn: 0100, Iter: 200, total_loss: 3.630e-07, loss_BC: 0.000e+00, loss_IC: 4.948e-08,loss_f: 1.059e-07
pinn: 0200, Iter: 200, total_loss: 3.290e-07, loss_BC: 0.000e+00, loss_IC: 8.938e-08,loss_f: 1.407e-07
pinn: 0300, Iter: 300, total_loss: 1.805e-07, loss_BC: 0.000e+00, loss_IC: 2.599e-08,loss_f: 5.215e-08
pinn: 0200, Iter: 300, total_loss: 2.323e-07, loss_BC: 0.000e+00, loss_IC: 3.299e-08,loss_f: 1.085e-07
pinn: 0100, Iter: 300, total_loss: 2.653e-07, loss_BC: 0.000e+00, loss_IC: 2.173e-08,loss_f: 5.881e-08
pinn: 0100, Iter: 400, total_loss: 2.492e-07, loss_BC: 0.000e+00, loss_IC: 1.965e-08,loss_f: 5.970e-08
pinn: 0200, Iter: 400, total_loss: 2.086e-07, loss_BC: 0.000e+00, loss_IC: 3.089e-08,loss_f: 8.867e-08
pinn: 0300, Iter: 400, total_loss: 1.657e-07, loss_BC: 0.000e+00, loss_IC: 2.139e-08,loss_f: 5.056e-08
pinn: 0300, Iter: 500, total_loss: 1.611e-07, loss_BC: 0.000e+00, loss_IC: 2.095e-08,loss_f: 4.747e-08
pinn: 0200, Iter: 500, total_loss: 1.970e-07, loss_BC: 0.000e+00, loss_IC: 2.860e-08,loss_f: 8.025e-08
pinn: 0100, Iter: 500, total_loss: 2.392e-07, loss_BC: 0.000e+00, loss_IC: 2.123e-08,loss_f: 5.572e-08
pinn: 0200, Iter: 600, total_loss: 1.892e-07, loss_BC: 0.000e+00, loss_IC: 2.762e-08,loss_f: 7.261e-08
pinn: 0300, Iter: 600, total_loss: 1.541e-07, loss_BC: 0.000e+00, loss_IC: 1.920e-08,loss_f: 4.407e-08
pinn: 0100, Iter: 600, total_loss: 2.326e-07, loss_BC: 0.000e+00, loss_IC: 2.266e-08,loss_f: 5.128e-08
pinn: 0300, Iter: 700, total_loss: 1.454e-07, loss_BC: 0.000e+00, loss_IC: 1.664e-08,loss_f: 4.466e-08
pinn: 0200, Iter: 700, total_loss: 1.859e-07, loss_BC: 0.000e+00, loss_IC: 2.768e-08,loss_f: 6.964e-08
pinn: 0100, Iter: 700, total_loss: 2.236e-07, loss_BC: 0.000e+00, loss_IC: 2.674e-08,loss_f: 4.771e-08
pinn: 0300, Iter: 800, total_loss: 1.384e-07, loss_BC: 0.000e+00, loss_IC: 1.473e-08,loss_f: 4.516e-08
pinn: 0100, Iter: 800, total_loss: 2.172e-07, loss_BC: 0.000e+00, loss_IC: 2.818e-08,loss_f: 4.668e-08
pinn: 0200, Iter: 800, total_loss: 1.845e-07, loss_BC: 0.000e+00, loss_IC: 2.730e-08,loss_f: 6.952e-08
pinn: 0300, Iter: 900, total_loss: 1.317e-07, loss_BC: 0.000e+00, loss_IC: 1.429e-08,loss_f: 4.598e-08
pinn: 0200, Iter: 900, total_loss: 1.810e-07, loss_BC: 0.000e+00, loss_IC: 2.697e-08,loss_f: 6.828e-08
pinn: 0100, Iter: 900, total_loss: 2.138e-07, loss_BC: 0.000e+00, loss_IC: 2.751e-08,loss_f: 4.743e-08
pinn: 0200, Iter: 1000, total_loss: 1.782e-07, loss_BC: 0.000e+00, loss_IC: 2.504e-08,loss_f: 6.816e-08
pinn: 0300, Iter: 1000, total_loss: 1.260e-07, loss_BC: 0.000e+00, loss_IC: 1.259e-08,loss_f: 4.649e-08
pinn: 0100, Iter: 1000, total_loss: 2.068e-07, loss_BC: 0.000e+00, loss_IC: 2.489e-08,loss_f: 5.086e-08
pinn: 0300, Iter: 1100, total_loss: 1.226e-07, loss_BC: 0.000e+00, loss_IC: 1.197e-08,loss_f: 4.693e-08
pinn: 0200, Iter: 1100, total_loss: 1.750e-07, loss_BC: 0.000e+00, loss_IC: 2.408e-08,loss_f: 6.762e-08
pinn: 0100, Iter: 1100, total_loss: 2.052e-07, loss_BC: 0.000e+00, loss_IC: 2.638e-08,loss_f: 5.165e-08
pinn: 0200, Iter: 1200, total_loss: 1.727e-07, loss_BC: 0.000e+00, loss_IC: 2.392e-08,loss_f: 6.765e-08
pinn: 0300, Iter: 1200, total_loss: 1.207e-07, loss_BC: 0.000e+00, loss_IC: 1.240e-08,loss_f: 4.766e-08
pinn: 0100, Iter: 1200, total_loss: 1.989e-07, loss_BC: 0.000e+00, loss_IC: 2.413e-08,loss_f: 5.372e-08
pinn: 0200, Iter: 1300, total_loss: 1.716e-07, loss_BC: 0.000e+00, loss_IC: 2.328e-08,loss_f: 6.820e-08
pinn: 0300, Iter: 1300, total_loss: 1.186e-07, loss_BC: 0.000e+00, loss_IC: 1.246e-08,loss_f: 4.720e-08
pinn: 0100, Iter: 1300, total_loss: 1.817e-07, loss_BC: 0.000e+00, loss_IC: 2.346e-08,loss_f: 5.986e-08
pinn: 0300, Iter: 1400, total_loss: 1.123e-07, loss_BC: 0.000e+00, loss_IC: 1.402e-08,loss_f: 4.604e-08
pinn: 0200, Iter: 1400, total_loss: 1.696e-07, loss_BC: 0.000e+00, loss_IC: 2.257e-08,loss_f: 6.749e-08
pinn: 0100, Iter: 1400, total_loss: 1.772e-07, loss_BC: 0.000e+00, loss_IC: 2.319e-08,loss_f: 6.550e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8107, Mean_loss of pinns: 1.514e-07, loss_BC: 0.000e+00, loss_IC: 2.003e-08, loss_f: 5.878e-08
 => minimum loss: 1.115e-07, corresponding pinn index: 0300
 => maximum loss: 1.735e-07, corresponding pinn  index: 0100

 max_loss: 4.288e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8109, total_loss: 1.225e-05, loss_BC: 7.731e-06, loss_IC: 1.212e-07, loss_f: 4.334e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.77000, t_max: 0.78000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8110 0 1

 -------------------------------------------------------------
  -----  Epoch: 8110 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.77000, t_max: 0.78000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8110 !!! 


==> Epoch: 8110, Mean_loss of pinns: 1.974e-03, loss_BC: 8.481e-06, loss_IC: 0.000e+00, loss_f: 1.966e-03
 => minimum loss: 1.723e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.702e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0000, 0200, 0300

==> Epoch: 8120, Mean_loss of pinns: 1.524e-03, loss_BC: 9.393e-06, loss_IC: 8.289e-07, loss_f: 1.514e-03
 => minimum loss: 1.102e-05, corresponding pinn/batch index: 0100
 => maximum loss: 5.956e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8130, Mean_loss of pinns: 1.211e-03, loss_BC: 1.099e-05, loss_IC: 2.056e-06, loss_f: 1.198e-03
 => minimum loss: 9.274e-06, corresponding pinn/batch index: 0100
 => maximum loss: 4.729e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8140, Mean_loss of pinns: 9.764e-04, loss_BC: 1.346e-05, loss_IC: 3.670e-06, loss_f: 9.592e-04
 => minimum loss: 8.111e-06, corresponding pinn/batch index: 0100
 => maximum loss: 3.813e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8150, Mean_loss of pinns: 8.057e-04, loss_BC: 1.608e-05, loss_IC: 5.628e-06, loss_f: 7.839e-04
 => minimum loss: 7.107e-06, corresponding pinn/batch index: 0100
 => maximum loss: 3.146e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8160, Mean_loss of pinns: 6.789e-04, loss_BC: 1.811e-05, loss_IC: 7.490e-06, loss_f: 6.532e-04
 => minimum loss: 6.414e-06, corresponding pinn/batch index: 0100
 => maximum loss: 2.650e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8170, Mean_loss of pinns: 5.827e-04, loss_BC: 1.924e-05, loss_IC: 8.908e-06, loss_f: 5.545e-04
 => minimum loss: 5.988e-06, corresponding pinn/batch index: 0100
 => maximum loss: 2.274e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8180, Mean_loss of pinns: 5.071e-04, loss_BC: 1.901e-05, loss_IC: 9.779e-06, loss_f: 4.783e-04
 => minimum loss: 5.541e-06, corresponding pinn/batch index: 0100
 => maximum loss: 1.979e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8190, Mean_loss of pinns: 4.480e-04, loss_BC: 1.956e-05, loss_IC: 1.011e-05, loss_f: 4.183e-04
 => minimum loss: 5.160e-06, corresponding pinn/batch index: 0100
 => maximum loss: 1.747e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8200, Mean_loss of pinns: 3.994e-04, loss_BC: 1.933e-05, loss_IC: 9.963e-06, loss_f: 3.701e-04
 => minimum loss: 4.731e-06, corresponding pinn/batch index: 0100
 => maximum loss: 1.557e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  8209

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 7.844e-07, loss_BC: 0.000e+00, loss_IC: 5.528e-08,loss_f: 6.319e-07
pinn: 0000, Iter: 200, total_loss: 2.513e-07, loss_BC: 0.000e+00, loss_IC: 2.576e-08,loss_f: 1.304e-07
pinn: 0000, Iter: 300, total_loss: 1.736e-07, loss_BC: 0.000e+00, loss_IC: 2.432e-08,loss_f: 6.342e-08
pinn: 0000, Iter: 400, total_loss: 1.576e-07, loss_BC: 0.000e+00, loss_IC: 2.395e-08,loss_f: 5.077e-08
pinn: 0000, Iter: 500, total_loss: 1.527e-07, loss_BC: 0.000e+00, loss_IC: 2.183e-08,loss_f: 4.738e-08
pinn: 0000, Iter: 600, total_loss: 1.444e-07, loss_BC: 0.000e+00, loss_IC: 2.073e-08,loss_f: 4.141e-08
pinn: 0000, Iter: 700, total_loss: 1.398e-07, loss_BC: 0.000e+00, loss_IC: 2.056e-08,loss_f: 3.741e-08
pinn: 0000, Iter: 800, total_loss: 1.366e-07, loss_BC: 0.000e+00, loss_IC: 1.962e-08,loss_f: 3.627e-08
pinn: 0000, Iter: 900, total_loss: 1.331e-07, loss_BC: 0.000e+00, loss_IC: 1.927e-08,loss_f: 3.590e-08
pinn: 0000, Iter: 1000, total_loss: 1.303e-07, loss_BC: 0.000e+00, loss_IC: 1.931e-08,loss_f: 3.537e-08
pinn: 0000, Iter: 1100, total_loss: 1.253e-07, loss_BC: 0.000e+00, loss_IC: 1.878e-08,loss_f: 3.380e-08
pinn: 0000, Iter: 1200, total_loss: 1.198e-07, loss_BC: 0.000e+00, loss_IC: 1.636e-08,loss_f: 3.455e-08
pinn: 0000, Iter: 1300, total_loss: 1.189e-07, loss_BC: 0.000e+00, loss_IC: 1.674e-08,loss_f: 3.466e-08
pinn: 0000, Iter: 1400, total_loss: 1.146e-07, loss_BC: 0.000e+00, loss_IC: 1.469e-08,loss_f: 3.543e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8209, Mean_loss of pinns: 1.144e-07, loss_BC: 0.000e+00, loss_IC: 1.428e-08, loss_f: 3.597e-08
 => minimum loss: 1.144e-07, corresponding pinn index: 0000
 => maximum loss: 1.144e-07, corresponding pinn  index: 0000

==> Epoch: 8210, Mean_loss of pinns: 1.740e-05, loss_BC: 9.244e-06, loss_IC: 2.510e-07, loss_f: 7.859e-06
 => minimum loss: 4.613e-06, corresponding pinn/batch index: 0100
 => maximum loss: 3.257e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 3.265e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8211, total_loss: 1.736e-05, loss_BC: 9.279e-06, loss_IC: 2.495e-07, loss_f: 7.785e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.78000, t_max: 0.79000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8212 0 1

 -------------------------------------------------------------
  -----  Epoch: 8212 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.78000, t_max: 0.79000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8212 !!! 


==> Epoch: 8220, Mean_loss of pinns: 2.851e-03, loss_BC: 7.152e-06, loss_IC: 3.937e-06, loss_f: 2.840e-03
 => minimum loss: 5.451e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.598e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8230, Mean_loss of pinns: 2.217e-03, loss_BC: 6.855e-06, loss_IC: 1.608e-05, loss_f: 2.194e-03
 => minimum loss: 4.728e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.251e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8240, Mean_loss of pinns: 1.744e-03, loss_BC: 5.028e-06, loss_IC: 3.280e-05, loss_f: 1.706e-03
 => minimum loss: 3.712e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.282e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8250, Mean_loss of pinns: 1.407e-03, loss_BC: 4.986e-06, loss_IC: 5.034e-05, loss_f: 1.351e-03
 => minimum loss: 3.293e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.616e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8260, Mean_loss of pinns: 1.169e-03, loss_BC: 6.488e-06, loss_IC: 6.630e-05, loss_f: 1.096e-03
 => minimum loss: 3.069e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.160e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8270, Mean_loss of pinns: 9.980e-04, loss_BC: 6.972e-06, loss_IC: 7.923e-05, loss_f: 9.117e-04
 => minimum loss: 2.737e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.837e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8280, Mean_loss of pinns: 8.726e-04, loss_BC: 8.454e-06, loss_IC: 8.794e-05, loss_f: 7.761e-04
 => minimum loss: 2.507e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.602e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8290, Mean_loss of pinns: 7.752e-04, loss_BC: 8.877e-06, loss_IC: 9.223e-05, loss_f: 6.740e-04
 => minimum loss: 2.319e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.423e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8300, Mean_loss of pinns: 6.976e-04, loss_BC: 9.838e-06, loss_IC: 9.262e-05, loss_f: 5.951e-04
 => minimum loss: 2.207e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.279e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8310, Mean_loss of pinns: 6.315e-04, loss_BC: 9.167e-06, loss_IC: 8.992e-05, loss_f: 5.324e-04
 => minimum loss: 1.939e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.160e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  8311

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 5.028e-07, loss_BC: 0.000e+00, loss_IC: 4.527e-08,loss_f: 3.760e-07
pinn: 0100, Iter: 100, total_loss: 7.389e-07, loss_BC: 0.000e+00, loss_IC: 1.447e-07,loss_f: 5.235e-07
pinn: 0300, Iter: 100, total_loss: 9.000e-07, loss_BC: 0.000e+00, loss_IC: 1.095e-07,loss_f: 7.497e-07
pinn: 0200, Iter: 200, total_loss: 2.505e-07, loss_BC: 0.000e+00, loss_IC: 4.596e-08,loss_f: 1.232e-07
pinn: 0100, Iter: 200, total_loss: 2.049e-07, loss_BC: 0.000e+00, loss_IC: 4.477e-08,loss_f: 9.202e-08
pinn: 0300, Iter: 200, total_loss: 2.166e-07, loss_BC: 0.000e+00, loss_IC: 4.388e-08,loss_f: 1.340e-07
pinn: 0200, Iter: 300, total_loss: 1.968e-07, loss_BC: 0.000e+00, loss_IC: 2.442e-08,loss_f: 9.422e-08
pinn: 0300, Iter: 300, total_loss: 1.409e-07, loss_BC: 0.000e+00, loss_IC: 1.695e-08,loss_f: 8.756e-08
pinn: 0100, Iter: 300, total_loss: 1.625e-07, loss_BC: 0.000e+00, loss_IC: 2.278e-08,loss_f: 7.625e-08
pinn: 0200, Iter: 400, total_loss: 1.719e-07, loss_BC: 0.000e+00, loss_IC: 2.360e-08,loss_f: 7.097e-08
pinn: 0300, Iter: 400, total_loss: 1.143e-07, loss_BC: 0.000e+00, loss_IC: 9.514e-09,loss_f: 6.954e-08
pinn: 0100, Iter: 400, total_loss: 1.475e-07, loss_BC: 0.000e+00, loss_IC: 1.901e-08,loss_f: 6.756e-08
pinn: 0200, Iter: 500, total_loss: 1.595e-07, loss_BC: 0.000e+00, loss_IC: 2.086e-08,loss_f: 6.205e-08
pinn: 0300, Iter: 500, total_loss: 1.017e-07, loss_BC: 0.000e+00, loss_IC: 8.035e-09,loss_f: 5.859e-08
pinn: 0100, Iter: 500, total_loss: 1.362e-07, loss_BC: 0.000e+00, loss_IC: 1.814e-08,loss_f: 5.644e-08
pinn: 0200, Iter: 600, total_loss: 1.546e-07, loss_BC: 0.000e+00, loss_IC: 1.835e-08,loss_f: 5.978e-08
pinn: 0100, Iter: 600, total_loss: 1.313e-07, loss_BC: 0.000e+00, loss_IC: 1.846e-08,loss_f: 5.129e-08
pinn: 0300, Iter: 600, total_loss: 9.537e-08, loss_BC: 0.000e+00, loss_IC: 7.323e-09,loss_f: 5.304e-08
pinn: 0200, Iter: 700, total_loss: 1.520e-07, loss_BC: 0.000e+00, loss_IC: 1.812e-08,loss_f: 5.816e-08
pinn: 0100, Iter: 700, total_loss: 1.295e-07, loss_BC: 0.000e+00, loss_IC: 1.793e-08,loss_f: 5.039e-08
pinn: 0300, Iter: 700, total_loss: 9.114e-08, loss_BC: 0.000e+00, loss_IC: 6.847e-09,loss_f: 4.974e-08
pinn: 0200, Iter: 800, total_loss: 1.503e-07, loss_BC: 0.000e+00, loss_IC: 1.769e-08,loss_f: 5.787e-08
pinn: 0300, Iter: 800, total_loss: 8.747e-08, loss_BC: 0.000e+00, loss_IC: 6.629e-09,loss_f: 4.650e-08
pinn: 0100, Iter: 800, total_loss: 1.268e-07, loss_BC: 0.000e+00, loss_IC: 1.759e-08,loss_f: 4.852e-08
pinn: 0200, Iter: 900, total_loss: 1.476e-07, loss_BC: 0.000e+00, loss_IC: 1.713e-08,loss_f: 5.750e-08
pinn: 0100, Iter: 900, total_loss: 1.242e-07, loss_BC: 0.000e+00, loss_IC: 1.733e-08,loss_f: 4.704e-08
pinn: 0300, Iter: 900, total_loss: 8.232e-08, loss_BC: 0.000e+00, loss_IC: 6.428e-09,loss_f: 4.208e-08
pinn: 0200, Iter: 1000, total_loss: 1.456e-07, loss_BC: 0.000e+00, loss_IC: 1.584e-08,loss_f: 5.738e-08
pinn: 0100, Iter: 1000, total_loss: 1.213e-07, loss_BC: 0.000e+00, loss_IC: 1.654e-08,loss_f: 4.662e-08
pinn: 0300, Iter: 1000, total_loss: 8.012e-08, loss_BC: 0.000e+00, loss_IC: 5.795e-09,loss_f: 4.045e-08
pinn: 0200, Iter: 1100, total_loss: 1.417e-07, loss_BC: 0.000e+00, loss_IC: 1.532e-08,loss_f: 5.629e-08
pinn: 0100, Iter: 1100, total_loss: 1.156e-07, loss_BC: 0.000e+00, loss_IC: 1.619e-08,loss_f: 4.338e-08
pinn: 0300, Iter: 1100, total_loss: 7.780e-08, loss_BC: 0.000e+00, loss_IC: 5.777e-09,loss_f: 3.858e-08
pinn: 0200, Iter: 1200, total_loss: 1.413e-07, loss_BC: 0.000e+00, loss_IC: 1.496e-08,loss_f: 5.655e-08
pinn: 0100, Iter: 1200, total_loss: 1.118e-07, loss_BC: 0.000e+00, loss_IC: 1.566e-08,loss_f: 4.237e-08
pinn: 0300, Iter: 1200, total_loss: 7.383e-08, loss_BC: 0.000e+00, loss_IC: 6.209e-09,loss_f: 3.480e-08
pinn: 0200, Iter: 1300, total_loss: 1.383e-07, loss_BC: 0.000e+00, loss_IC: 1.501e-08,loss_f: 5.639e-08
pinn: 0300, Iter: 1300, total_loss: 7.100e-08, loss_BC: 0.000e+00, loss_IC: 6.355e-09,loss_f: 3.256e-08
pinn: 0100, Iter: 1300, total_loss: 1.106e-07, loss_BC: 0.000e+00, loss_IC: 1.554e-08,loss_f: 4.258e-08
pinn: 0200, Iter: 1400, total_loss: 1.370e-07, loss_BC: 0.000e+00, loss_IC: 1.459e-08,loss_f: 5.607e-08
pinn: 0100, Iter: 1400, total_loss: 1.074e-07, loss_BC: 0.000e+00, loss_IC: 1.513e-08,loss_f: 4.133e-08
pinn: 0300, Iter: 1400, total_loss: 6.930e-08, loss_BC: 0.000e+00, loss_IC: 6.779e-09,loss_f: 3.065e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8311, Mean_loss of pinns: 1.042e-07, loss_BC: 0.000e+00, loss_IC: 1.188e-08, loss_f: 4.272e-08
 => minimum loss: 6.913e-08, corresponding pinn index: 0300
 => maximum loss: 1.361e-07, corresponding pinn  index: 0200

 max_loss: 3.893e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8313, total_loss: 1.134e-05, loss_BC: 9.166e-06, loss_IC: 6.413e-08, loss_f: 2.060e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.79000, t_max: 0.80000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8314 0 1

 -------------------------------------------------------------
  -----  Epoch: 8314 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.79000, t_max: 0.80000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8314 !!! 


==> Epoch: 8320, Mean_loss of pinns: 9.132e-04, loss_BC: 1.022e-05, loss_IC: 4.915e-07, loss_f: 9.024e-04
 => minimum loss: 3.361e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.467e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 8330, Mean_loss of pinns: 7.570e-04, loss_BC: 1.162e-05, loss_IC: 1.281e-06, loss_f: 7.441e-04
 => minimum loss: 2.489e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.884e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 8340, Mean_loss of pinns: 6.307e-04, loss_BC: 1.379e-05, loss_IC: 1.896e-06, loss_f: 6.149e-04
 => minimum loss: 1.925e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.411e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8350, Mean_loss of pinns: 5.303e-04, loss_BC: 1.516e-05, loss_IC: 2.685e-06, loss_f: 5.124e-04
 => minimum loss: 1.550e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.031e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8360, Mean_loss of pinns: 4.505e-04, loss_BC: 1.563e-05, loss_IC: 3.337e-06, loss_f: 4.314e-04
 => minimum loss: 1.307e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.727e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8370, Mean_loss of pinns: 3.865e-04, loss_BC: 1.532e-05, loss_IC: 3.596e-06, loss_f: 3.675e-04
 => minimum loss: 1.142e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.482e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8380, Mean_loss of pinns: 3.354e-04, loss_BC: 1.524e-05, loss_IC: 3.444e-06, loss_f: 3.167e-04
 => minimum loss: 1.037e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.286e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8390, Mean_loss of pinns: 2.933e-04, loss_BC: 1.429e-05, loss_IC: 3.112e-06, loss_f: 2.758e-04
 => minimum loss: 9.449e-06, corresponding pinn/batch index: 0100
 => maximum loss: 1.123e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8400, Mean_loss of pinns: 2.583e-04, loss_BC: 1.317e-05, loss_IC: 2.680e-06, loss_f: 2.424e-04
 => minimum loss: 8.519e-06, corresponding pinn/batch index: 0100
 => maximum loss: 9.889e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8410, Mean_loss of pinns: 2.293e-04, loss_BC: 1.218e-05, loss_IC: 2.256e-06, loss_f: 2.148e-04
 => minimum loss: 7.760e-06, corresponding pinn/batch index: 0100
 => maximum loss: 8.768e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  8413

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 8.809e-07, loss_BC: 0.000e+00, loss_IC: 5.915e-08,loss_f: 7.514e-07
pinn: 0000, Iter: 200, total_loss: 2.486e-07, loss_BC: 0.000e+00, loss_IC: 2.713e-08,loss_f: 1.517e-07
pinn: 0000, Iter: 300, total_loss: 1.700e-07, loss_BC: 0.000e+00, loss_IC: 1.774e-08,loss_f: 8.645e-08
pinn: 0000, Iter: 400, total_loss: 1.419e-07, loss_BC: 0.000e+00, loss_IC: 1.463e-08,loss_f: 6.402e-08
pinn: 0000, Iter: 500, total_loss: 1.320e-07, loss_BC: 0.000e+00, loss_IC: 1.560e-08,loss_f: 5.247e-08
pinn: 0000, Iter: 600, total_loss: 1.262e-07, loss_BC: 0.000e+00, loss_IC: 1.361e-08,loss_f: 4.935e-08
pinn: 0000, Iter: 700, total_loss: 1.219e-07, loss_BC: 0.000e+00, loss_IC: 1.271e-08,loss_f: 4.739e-08
pinn: 0000, Iter: 800, total_loss: 1.178e-07, loss_BC: 0.000e+00, loss_IC: 1.230e-08,loss_f: 4.540e-08
pinn: 0000, Iter: 900, total_loss: 1.147e-07, loss_BC: 0.000e+00, loss_IC: 1.175e-08,loss_f: 4.361e-08
pinn: 0000, Iter: 1000, total_loss: 1.115e-07, loss_BC: 0.000e+00, loss_IC: 1.109e-08,loss_f: 4.239e-08
pinn: 0000, Iter: 1100, total_loss: 1.101e-07, loss_BC: 0.000e+00, loss_IC: 1.086e-08,loss_f: 4.191e-08
pinn: 0000, Iter: 1200, total_loss: 1.067e-07, loss_BC: 0.000e+00, loss_IC: 1.062e-08,loss_f: 4.148e-08
pinn: 0000, Iter: 1300, total_loss: 1.057e-07, loss_BC: 0.000e+00, loss_IC: 1.002e-08,loss_f: 4.120e-08
pinn: 0000, Iter: 1400, total_loss: 1.029e-07, loss_BC: 0.000e+00, loss_IC: 8.945e-09,loss_f: 4.141e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8413, Mean_loss of pinns: 1.027e-07, loss_BC: 0.000e+00, loss_IC: 8.783e-09, loss_f: 4.137e-08
 => minimum loss: 1.027e-07, corresponding pinn index: 0000
 => maximum loss: 1.027e-07, corresponding pinn  index: 0000

 max_loss: 3.621e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8415, total_loss: 1.878e-05, loss_BC: 1.043e-05, loss_IC: 2.951e-07, loss_f: 7.984e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.80000, t_max: 0.81000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8416 0 1

 -------------------------------------------------------------
  -----  Epoch: 8416 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.80000, t_max: 0.81000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8416 !!! 


==> Epoch: 8420, Mean_loss of pinns: 2.790e-03, loss_BC: 8.651e-06, loss_IC: 1.275e-06, loss_f: 2.780e-03
 => minimum loss: 6.315e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.758e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8430, Mean_loss of pinns: 2.017e-03, loss_BC: 7.442e-06, loss_IC: 1.248e-05, loss_f: 1.997e-03
 => minimum loss: 5.386e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.759e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8440, Mean_loss of pinns: 1.535e-03, loss_BC: 5.880e-06, loss_IC: 2.927e-05, loss_f: 1.499e-03
 => minimum loss: 4.203e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.576e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8450, Mean_loss of pinns: 1.209e-03, loss_BC: 5.314e-06, loss_IC: 4.606e-05, loss_f: 1.158e-03
 => minimum loss: 3.699e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.768e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8460, Mean_loss of pinns: 9.913e-04, loss_BC: 5.156e-06, loss_IC: 5.936e-05, loss_f: 9.267e-04
 => minimum loss: 3.041e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.242e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8470, Mean_loss of pinns: 8.428e-04, loss_BC: 6.274e-06, loss_IC: 6.866e-05, loss_f: 7.678e-04
 => minimum loss: 2.717e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.895e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8480, Mean_loss of pinns: 7.346e-04, loss_BC: 7.116e-06, loss_IC: 7.401e-05, loss_f: 6.534e-04
 => minimum loss: 2.498e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.650e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8490, Mean_loss of pinns: 6.527e-04, loss_BC: 8.216e-06, loss_IC: 7.578e-05, loss_f: 5.686e-04
 => minimum loss: 2.342e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.471e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8500, Mean_loss of pinns: 5.871e-04, loss_BC: 8.862e-06, loss_IC: 7.473e-05, loss_f: 5.034e-04
 => minimum loss: 2.240e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.331e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8510, Mean_loss of pinns: 5.327e-04, loss_BC: 9.196e-06, loss_IC: 7.175e-05, loss_f: 4.516e-04
 => minimum loss: 2.221e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.217e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  8515

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.036e-06, loss_BC: 0.000e+00, loss_IC: 8.245e-08,loss_f: 8.557e-07
pinn: 0300, Iter: 100, total_loss: 1.092e-06, loss_BC: 0.000e+00, loss_IC: 1.203e-07,loss_f: 8.938e-07
pinn: 0200, Iter: 100, total_loss: 1.216e-06, loss_BC: 0.000e+00, loss_IC: 8.019e-08,loss_f: 9.520e-07
pinn: 0200, Iter: 200, total_loss: 3.431e-07, loss_BC: 0.000e+00, loss_IC: 3.293e-08,loss_f: 1.394e-07
pinn: 0100, Iter: 200, total_loss: 2.858e-07, loss_BC: 0.000e+00, loss_IC: 5.028e-08,loss_f: 1.472e-07
pinn: 0300, Iter: 200, total_loss: 2.560e-07, loss_BC: 0.000e+00, loss_IC: 4.412e-08,loss_f: 1.376e-07
pinn: 0100, Iter: 300, total_loss: 1.871e-07, loss_BC: 0.000e+00, loss_IC: 3.526e-08,loss_f: 6.986e-08
pinn: 0300, Iter: 300, total_loss: 1.491e-07, loss_BC: 0.000e+00, loss_IC: 2.898e-08,loss_f: 5.471e-08
pinn: 0200, Iter: 300, total_loss: 2.565e-07, loss_BC: 0.000e+00, loss_IC: 2.529e-08,loss_f: 7.124e-08
pinn: 0200, Iter: 400, total_loss: 2.262e-07, loss_BC: 0.000e+00, loss_IC: 2.333e-08,loss_f: 5.171e-08
pinn: 0300, Iter: 400, total_loss: 1.176e-07, loss_BC: 0.000e+00, loss_IC: 1.981e-08,loss_f: 3.905e-08
pinn: 0100, Iter: 400, total_loss: 1.623e-07, loss_BC: 0.000e+00, loss_IC: 2.331e-08,loss_f: 6.194e-08
pinn: 0200, Iter: 500, total_loss: 2.103e-07, loss_BC: 0.000e+00, loss_IC: 2.016e-08,loss_f: 4.398e-08
pinn: 0100, Iter: 500, total_loss: 1.478e-07, loss_BC: 0.000e+00, loss_IC: 2.569e-08,loss_f: 5.077e-08
pinn: 0300, Iter: 500, total_loss: 1.063e-07, loss_BC: 0.000e+00, loss_IC: 1.749e-08,loss_f: 3.357e-08
pinn: 0100, Iter: 600, total_loss: 1.369e-07, loss_BC: 0.000e+00, loss_IC: 2.623e-08,loss_f: 4.162e-08
pinn: 0300, Iter: 600, total_loss: 1.038e-07, loss_BC: 0.000e+00, loss_IC: 1.623e-08,loss_f: 3.232e-08
pinn: 0200, Iter: 600, total_loss: 2.022e-07, loss_BC: 0.000e+00, loss_IC: 1.800e-08,loss_f: 4.054e-08
pinn: 0100, Iter: 700, total_loss: 1.327e-07, loss_BC: 0.000e+00, loss_IC: 2.574e-08,loss_f: 3.884e-08
pinn: 0300, Iter: 700, total_loss: 9.845e-08, loss_BC: 0.000e+00, loss_IC: 1.395e-08,loss_f: 2.991e-08
pinn: 0200, Iter: 700, total_loss: 1.961e-07, loss_BC: 0.000e+00, loss_IC: 1.975e-08,loss_f: 3.641e-08
pinn: 0100, Iter: 800, total_loss: 1.304e-07, loss_BC: 0.000e+00, loss_IC: 2.518e-08,loss_f: 3.758e-08
pinn: 0200, Iter: 800, total_loss: 1.871e-07, loss_BC: 0.000e+00, loss_IC: 2.567e-08,loss_f: 3.623e-08
pinn: 0300, Iter: 800, total_loss: 9.721e-08, loss_BC: 0.000e+00, loss_IC: 1.355e-08,loss_f: 2.946e-08
pinn: 0100, Iter: 900, total_loss: 1.266e-07, loss_BC: 0.000e+00, loss_IC: 2.631e-08,loss_f: 3.516e-08
pinn: 0300, Iter: 900, total_loss: 9.620e-08, loss_BC: 0.000e+00, loss_IC: 1.340e-08,loss_f: 2.920e-08
pinn: 0200, Iter: 900, total_loss: 1.830e-07, loss_BC: 0.000e+00, loss_IC: 2.755e-08,loss_f: 3.598e-08
pinn: 0100, Iter: 1000, total_loss: 1.246e-07, loss_BC: 0.000e+00, loss_IC: 2.569e-08,loss_f: 3.481e-08
pinn: 0200, Iter: 1000, total_loss: 1.756e-07, loss_BC: 0.000e+00, loss_IC: 2.929e-08,loss_f: 3.391e-08
pinn: 0300, Iter: 1000, total_loss: 9.528e-08, loss_BC: 0.000e+00, loss_IC: 1.333e-08,loss_f: 2.892e-08
pinn: 0100, Iter: 1100, total_loss: 1.215e-07, loss_BC: 0.000e+00, loss_IC: 2.452e-08,loss_f: 3.408e-08
pinn: 0200, Iter: 1100, total_loss: 1.662e-07, loss_BC: 0.000e+00, loss_IC: 3.085e-08,loss_f: 3.529e-08
pinn: 0300, Iter: 1100, total_loss: 9.188e-08, loss_BC: 0.000e+00, loss_IC: 1.340e-08,loss_f: 2.780e-08
pinn: 0100, Iter: 1200, total_loss: 1.170e-07, loss_BC: 0.000e+00, loss_IC: 2.349e-08,loss_f: 3.363e-08
pinn: 0200, Iter: 1200, total_loss: 1.636e-07, loss_BC: 0.000e+00, loss_IC: 3.148e-08,loss_f: 3.435e-08
pinn: 0300, Iter: 1200, total_loss: 9.114e-08, loss_BC: 0.000e+00, loss_IC: 1.308e-08,loss_f: 2.780e-08
pinn: 0100, Iter: 1300, total_loss: 1.127e-07, loss_BC: 0.000e+00, loss_IC: 2.291e-08,loss_f: 3.340e-08
pinn: 0200, Iter: 1300, total_loss: 1.583e-07, loss_BC: 0.000e+00, loss_IC: 3.475e-08,loss_f: 3.456e-08
pinn: 0300, Iter: 1300, total_loss: 8.882e-08, loss_BC: 0.000e+00, loss_IC: 1.264e-08,loss_f: 2.862e-08
pinn: 0100, Iter: 1400, total_loss: 1.096e-07, loss_BC: 0.000e+00, loss_IC: 2.082e-08,loss_f: 3.489e-08
pinn: 0200, Iter: 1400, total_loss: 1.574e-07, loss_BC: 0.000e+00, loss_IC: 3.398e-08,loss_f: 3.530e-08
pinn: 0300, Iter: 1400, total_loss: 8.640e-08, loss_BC: 0.000e+00, loss_IC: 1.218e-08,loss_f: 2.916e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8515, Mean_loss of pinns: 1.166e-07, loss_BC: 0.000e+00, loss_IC: 2.280e-08, loss_f: 3.274e-08
 => minimum loss: 8.589e-08, corresponding pinn index: 0300
 => maximum loss: 1.561e-07, corresponding pinn  index: 0200

 max_loss: 3.775e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8517, total_loss: 1.181e-05, loss_BC: 9.360e-06, loss_IC: 2.155e-07, loss_f: 2.169e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.81000, t_max: 0.82000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8518 0 1

 -------------------------------------------------------------
  -----  Epoch: 8518 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.81000, t_max: 0.82000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8518 !!! 


==> Epoch: 8520, Mean_loss of pinns: 1.601e-03, loss_BC: 9.895e-06, loss_IC: 7.709e-08, loss_f: 1.591e-03
 => minimum loss: 2.633e-05, corresponding pinn/batch index: 0300
 => maximum loss: 6.250e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0100

==> Epoch: 8530, Mean_loss of pinns: 1.319e-03, loss_BC: 9.998e-06, loss_IC: 8.925e-07, loss_f: 1.308e-03
 => minimum loss: 2.022e-05, corresponding pinn/batch index: 0300
 => maximum loss: 5.159e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8540, Mean_loss of pinns: 1.093e-03, loss_BC: 1.184e-05, loss_IC: 1.579e-06, loss_f: 1.080e-03
 => minimum loss: 1.698e-05, corresponding pinn/batch index: 0300
 => maximum loss: 4.277e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8550, Mean_loss of pinns: 9.114e-04, loss_BC: 1.427e-05, loss_IC: 2.847e-06, loss_f: 8.942e-04
 => minimum loss: 1.459e-05, corresponding pinn/batch index: 0300
 => maximum loss: 3.567e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8560, Mean_loss of pinns: 7.662e-04, loss_BC: 1.598e-05, loss_IC: 4.566e-06, loss_f: 7.456e-04
 => minimum loss: 1.267e-05, corresponding pinn/batch index: 0300
 => maximum loss: 2.999e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8570, Mean_loss of pinns: 6.516e-04, loss_BC: 1.737e-05, loss_IC: 6.165e-06, loss_f: 6.280e-04
 => minimum loss: 1.097e-05, corresponding pinn/batch index: 0300
 => maximum loss: 2.550e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8580, Mean_loss of pinns: 5.612e-04, loss_BC: 1.875e-05, loss_IC: 7.336e-06, loss_f: 5.351e-04
 => minimum loss: 1.043e-05, corresponding pinn/batch index: 0300
 => maximum loss: 2.194e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8590, Mean_loss of pinns: 4.885e-04, loss_BC: 1.920e-05, loss_IC: 7.976e-06, loss_f: 4.613e-04
 => minimum loss: 9.473e-06, corresponding pinn/batch index: 0300
 => maximum loss: 1.908e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8600, Mean_loss of pinns: 4.293e-04, loss_BC: 1.901e-05, loss_IC: 8.068e-06, loss_f: 4.021e-04
 => minimum loss: 8.984e-06, corresponding pinn/batch index: 0300
 => maximum loss: 1.676e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8610, Mean_loss of pinns: 3.804e-04, loss_BC: 1.844e-05, loss_IC: 7.747e-06, loss_f: 3.541e-04
 => minimum loss: 8.547e-06, corresponding pinn/batch index: 0300
 => maximum loss: 1.483e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  8617

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 7.714e-07, loss_BC: 0.000e+00, loss_IC: 7.352e-08,loss_f: 6.052e-07
pinn: 0000, Iter: 200, total_loss: 2.376e-07, loss_BC: 0.000e+00, loss_IC: 2.343e-08,loss_f: 1.226e-07
pinn: 0000, Iter: 300, total_loss: 1.845e-07, loss_BC: 0.000e+00, loss_IC: 1.410e-08,loss_f: 8.520e-08
pinn: 0000, Iter: 400, total_loss: 1.717e-07, loss_BC: 0.000e+00, loss_IC: 1.511e-08,loss_f: 7.221e-08
pinn: 0000, Iter: 500, total_loss: 1.587e-07, loss_BC: 0.000e+00, loss_IC: 1.475e-08,loss_f: 5.890e-08
pinn: 0000, Iter: 600, total_loss: 1.543e-07, loss_BC: 0.000e+00, loss_IC: 1.403e-08,loss_f: 5.614e-08
pinn: 0000, Iter: 700, total_loss: 1.493e-07, loss_BC: 0.000e+00, loss_IC: 1.437e-08,loss_f: 5.349e-08
pinn: 0000, Iter: 800, total_loss: 1.460e-07, loss_BC: 0.000e+00, loss_IC: 1.388e-08,loss_f: 5.187e-08
pinn: 0000, Iter: 900, total_loss: 1.435e-07, loss_BC: 0.000e+00, loss_IC: 1.323e-08,loss_f: 5.076e-08
pinn: 0000, Iter: 1000, total_loss: 1.413e-07, loss_BC: 0.000e+00, loss_IC: 1.262e-08,loss_f: 5.070e-08
pinn: 0000, Iter: 1100, total_loss: 1.386e-07, loss_BC: 0.000e+00, loss_IC: 1.172e-08,loss_f: 5.061e-08
pinn: 0000, Iter: 1200, total_loss: 1.378e-07, loss_BC: 0.000e+00, loss_IC: 1.175e-08,loss_f: 5.004e-08
pinn: 0000, Iter: 1300, total_loss: 1.344e-07, loss_BC: 0.000e+00, loss_IC: 1.173e-08,loss_f: 4.994e-08
pinn: 0000, Iter: 1400, total_loss: 1.338e-07, loss_BC: 0.000e+00, loss_IC: 1.171e-08,loss_f: 5.017e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8617, Mean_loss of pinns: 1.337e-07, loss_BC: 0.000e+00, loss_IC: 1.156e-08, loss_f: 5.038e-08
 => minimum loss: 1.337e-07, corresponding pinn index: 0000
 => maximum loss: 1.337e-07, corresponding pinn  index: 0000

 max_loss: 3.311e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8619, total_loss: 1.719e-05, loss_BC: 1.021e-05, loss_IC: 2.420e-07, loss_f: 6.664e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.82000, t_max: 0.83000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8620 0 1

 -------------------------------------------------------------
  -----  Epoch: 8620 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.82000, t_max: 0.83000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8620 !!! 


==> Epoch: 8620, Mean_loss of pinns: 1.781e-03, loss_BC: 1.250e-05, loss_IC: 0.000e+00, loss_f: 1.768e-03
 => minimum loss: 5.057e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.703e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8630, Mean_loss of pinns: 1.270e-03, loss_BC: 8.755e-06, loss_IC: 6.082e-06, loss_f: 1.255e-03
 => minimum loss: 3.802e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.862e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8640, Mean_loss of pinns: 9.825e-04, loss_BC: 7.771e-06, loss_IC: 1.864e-05, loss_f: 9.560e-04
 => minimum loss: 3.067e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.449e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8650, Mean_loss of pinns: 7.806e-04, loss_BC: 7.129e-06, loss_IC: 3.242e-05, loss_f: 7.409e-04
 => minimum loss: 2.765e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.157e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8660, Mean_loss of pinns: 6.477e-04, loss_BC: 6.343e-06, loss_IC: 4.299e-05, loss_f: 5.983e-04
 => minimum loss: 2.520e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.570e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8670, Mean_loss of pinns: 5.528e-04, loss_BC: 5.757e-06, loss_IC: 4.877e-05, loss_f: 4.982e-04
 => minimum loss: 2.328e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.296e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8680, Mean_loss of pinns: 4.829e-04, loss_BC: 6.342e-06, loss_IC: 4.952e-05, loss_f: 4.269e-04
 => minimum loss: 2.351e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.398e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8690, Mean_loss of pinns: 4.259e-04, loss_BC: 5.906e-06, loss_IC: 4.648e-05, loss_f: 3.734e-04
 => minimum loss: 2.120e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.659e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8700, Mean_loss of pinns: 3.795e-04, loss_BC: 6.249e-06, loss_IC: 4.155e-05, loss_f: 3.316e-04
 => minimum loss: 2.074e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.038e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8710, Mean_loss of pinns: 3.396e-04, loss_BC: 5.847e-06, loss_IC: 3.599e-05, loss_f: 2.976e-04
 => minimum loss: 2.058e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.490e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  8719

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 6.962e-07, loss_BC: 0.000e+00, loss_IC: 1.681e-07,loss_f: 3.791e-07
pinn: 0300, Iter: 100, total_loss: 7.936e-07, loss_BC: 0.000e+00, loss_IC: 1.503e-07,loss_f: 5.754e-07
pinn: 0100, Iter: 100, total_loss: 7.650e-07, loss_BC: 0.000e+00, loss_IC: 1.021e-07,loss_f: 5.106e-07
pinn: 0200, Iter: 200, total_loss: 4.173e-07, loss_BC: 0.000e+00, loss_IC: 8.765e-08,loss_f: 1.851e-07
pinn: 0100, Iter: 200, total_loss: 3.370e-07, loss_BC: 0.000e+00, loss_IC: 6.218e-08,loss_f: 1.175e-07
pinn: 0300, Iter: 200, total_loss: 2.914e-07, loss_BC: 0.000e+00, loss_IC: 4.655e-08,loss_f: 1.778e-07
pinn: 0200, Iter: 300, total_loss: 2.869e-07, loss_BC: 0.000e+00, loss_IC: 3.481e-08,loss_f: 1.177e-07
pinn: 0300, Iter: 300, total_loss: 1.599e-07, loss_BC: 0.000e+00, loss_IC: 2.223e-08,loss_f: 7.716e-08
pinn: 0100, Iter: 300, total_loss: 2.752e-07, loss_BC: 0.000e+00, loss_IC: 3.072e-08,loss_f: 9.988e-08
pinn: 0200, Iter: 400, total_loss: 2.620e-07, loss_BC: 0.000e+00, loss_IC: 2.779e-08,loss_f: 1.019e-07
pinn: 0100, Iter: 400, total_loss: 2.544e-07, loss_BC: 0.000e+00, loss_IC: 2.174e-08,loss_f: 9.769e-08
pinn: 0300, Iter: 400, total_loss: 1.332e-07, loss_BC: 0.000e+00, loss_IC: 1.065e-08,loss_f: 6.511e-08
pinn: 0200, Iter: 500, total_loss: 2.478e-07, loss_BC: 0.000e+00, loss_IC: 2.329e-08,loss_f: 9.165e-08
pinn: 0100, Iter: 500, total_loss: 2.300e-07, loss_BC: 0.000e+00, loss_IC: 2.296e-08,loss_f: 7.104e-08
pinn: 0300, Iter: 500, total_loss: 1.160e-07, loss_BC: 0.000e+00, loss_IC: 8.629e-09,loss_f: 4.937e-08
pinn: 0200, Iter: 600, total_loss: 2.340e-07, loss_BC: 0.000e+00, loss_IC: 2.205e-08,loss_f: 8.273e-08
pinn: 0300, Iter: 600, total_loss: 1.112e-07, loss_BC: 0.000e+00, loss_IC: 8.232e-09,loss_f: 4.604e-08
pinn: 0100, Iter: 600, total_loss: 2.194e-07, loss_BC: 0.000e+00, loss_IC: 2.278e-08,loss_f: 6.788e-08
pinn: 0200, Iter: 700, total_loss: 2.232e-07, loss_BC: 0.000e+00, loss_IC: 2.034e-08,loss_f: 7.822e-08
pinn: 0300, Iter: 700, total_loss: 1.071e-07, loss_BC: 0.000e+00, loss_IC: 7.644e-09,loss_f: 4.320e-08
pinn: 0100, Iter: 700, total_loss: 2.164e-07, loss_BC: 0.000e+00, loss_IC: 2.347e-08,loss_f: 6.671e-08
pinn: 0200, Iter: 800, total_loss: 2.094e-07, loss_BC: 0.000e+00, loss_IC: 1.694e-08,loss_f: 7.229e-08
pinn: 0300, Iter: 800, total_loss: 1.004e-07, loss_BC: 0.000e+00, loss_IC: 6.511e-09,loss_f: 3.888e-08
pinn: 0100, Iter: 800, total_loss: 2.078e-07, loss_BC: 0.000e+00, loss_IC: 2.312e-08,loss_f: 6.337e-08
pinn: 0200, Iter: 900, total_loss: 1.972e-07, loss_BC: 0.000e+00, loss_IC: 1.513e-08,loss_f: 7.163e-08
pinn: 0100, Iter: 900, total_loss: 1.993e-07, loss_BC: 0.000e+00, loss_IC: 2.136e-08,loss_f: 6.367e-08
pinn: 0300, Iter: 900, total_loss: 9.737e-08, loss_BC: 0.000e+00, loss_IC: 6.098e-09,loss_f: 3.699e-08
pinn: 0200, Iter: 1000, total_loss: 1.958e-07, loss_BC: 0.000e+00, loss_IC: 1.508e-08,loss_f: 7.107e-08
pinn: 0100, Iter: 1000, total_loss: 1.887e-07, loss_BC: 0.000e+00, loss_IC: 1.680e-08,loss_f: 6.696e-08
pinn: 0300, Iter: 1000, total_loss: 9.522e-08, loss_BC: 0.000e+00, loss_IC: 6.537e-09,loss_f: 3.630e-08
pinn: 0200, Iter: 1100, total_loss: 1.891e-07, loss_BC: 0.000e+00, loss_IC: 1.426e-08,loss_f: 7.059e-08
pinn: 0100, Iter: 1100, total_loss: 1.768e-07, loss_BC: 0.000e+00, loss_IC: 1.699e-08,loss_f: 6.301e-08
pinn: 0300, Iter: 1100, total_loss: 9.235e-08, loss_BC: 0.000e+00, loss_IC: 7.321e-09,loss_f: 3.467e-08
pinn: 0200, Iter: 1200, total_loss: 1.833e-07, loss_BC: 0.000e+00, loss_IC: 1.442e-08,loss_f: 7.035e-08
pinn: 0100, Iter: 1200, total_loss: 1.729e-07, loss_BC: 0.000e+00, loss_IC: 1.631e-08,loss_f: 6.431e-08
pinn: 0300, Iter: 1200, total_loss: 8.850e-08, loss_BC: 0.000e+00, loss_IC: 7.154e-09,loss_f: 3.388e-08
pinn: 0200, Iter: 1300, total_loss: 1.777e-07, loss_BC: 0.000e+00, loss_IC: 1.395e-08,loss_f: 7.063e-08
pinn: 0100, Iter: 1300, total_loss: 1.591e-07, loss_BC: 0.000e+00, loss_IC: 1.587e-08,loss_f: 6.499e-08
pinn: 0300, Iter: 1300, total_loss: 8.771e-08, loss_BC: 0.000e+00, loss_IC: 7.156e-09,loss_f: 3.359e-08
pinn: 0200, Iter: 1400, total_loss: 1.733e-07, loss_BC: 0.000e+00, loss_IC: 1.528e-08,loss_f: 7.138e-08
pinn: 0100, Iter: 1400, total_loss: 1.572e-07, loss_BC: 0.000e+00, loss_IC: 1.553e-08,loss_f: 6.452e-08
pinn: 0300, Iter: 1400, total_loss: 8.553e-08, loss_BC: 0.000e+00, loss_IC: 6.660e-09,loss_f: 3.389e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8719, Mean_loss of pinns: 1.379e-07, loss_BC: 0.000e+00, loss_IC: 1.206e-08, loss_f: 5.707e-08
 => minimum loss: 8.525e-08, corresponding pinn index: 0300
 => maximum loss: 1.722e-07, corresponding pinn  index: 0200

==> Epoch: 8720, Mean_loss of pinns: 1.017e-05, loss_BC: 8.657e-06, loss_IC: 3.942e-07, loss_f: 1.038e-06
 => minimum loss: 1.417e-06, corresponding pinn/batch index: 0100
 => maximum loss: 3.045e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 2.988e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8721, total_loss: 1.022e-05, loss_BC: 8.681e-06, loss_IC: 4.199e-07, loss_f: 1.037e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.83000, t_max: 0.84000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8722 0 1

 -------------------------------------------------------------
  -----  Epoch: 8722 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.83000, t_max: 0.84000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8722 !!! 


==> Epoch: 8730, Mean_loss of pinns: 1.186e-03, loss_BC: 9.852e-06, loss_IC: 9.586e-07, loss_f: 1.175e-03
 => minimum loss: 3.768e-05, corresponding pinn/batch index: 0100
 => maximum loss: 4.579e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 8740, Mean_loss of pinns: 9.787e-04, loss_BC: 1.160e-05, loss_IC: 1.810e-06, loss_f: 9.652e-04
 => minimum loss: 3.009e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.782e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8750, Mean_loss of pinns: 8.140e-04, loss_BC: 1.441e-05, loss_IC: 2.655e-06, loss_f: 7.968e-04
 => minimum loss: 2.478e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.148e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8760, Mean_loss of pinns: 6.839e-04, loss_BC: 1.586e-05, loss_IC: 4.125e-06, loss_f: 6.638e-04
 => minimum loss: 2.064e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.646e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8770, Mean_loss of pinns: 5.817e-04, loss_BC: 1.682e-05, loss_IC: 5.372e-06, loss_f: 5.594e-04
 => minimum loss: 1.766e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.250e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8780, Mean_loss of pinns: 5.010e-04, loss_BC: 1.768e-05, loss_IC: 6.137e-06, loss_f: 4.771e-04
 => minimum loss: 1.569e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.937e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8790, Mean_loss of pinns: 4.355e-04, loss_BC: 1.732e-05, loss_IC: 6.356e-06, loss_f: 4.118e-04
 => minimum loss: 1.388e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.683e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8800, Mean_loss of pinns: 3.821e-04, loss_BC: 1.663e-05, loss_IC: 6.185e-06, loss_f: 3.592e-04
 => minimum loss: 1.241e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.476e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8810, Mean_loss of pinns: 3.383e-04, loss_BC: 1.610e-05, loss_IC: 5.712e-06, loss_f: 3.164e-04
 => minimum loss: 1.133e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.304e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8820, Mean_loss of pinns: 3.011e-04, loss_BC: 1.493e-05, loss_IC: 5.111e-06, loss_f: 2.810e-04
 => minimum loss: 1.050e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.160e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  8821

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 5.728e-07, loss_BC: 0.000e+00, loss_IC: 6.114e-08,loss_f: 4.026e-07
pinn: 0000, Iter: 200, total_loss: 2.195e-07, loss_BC: 0.000e+00, loss_IC: 1.856e-08,loss_f: 9.165e-08
pinn: 0000, Iter: 300, total_loss: 1.735e-07, loss_BC: 0.000e+00, loss_IC: 1.610e-08,loss_f: 5.655e-08
pinn: 0000, Iter: 400, total_loss: 1.637e-07, loss_BC: 0.000e+00, loss_IC: 1.587e-08,loss_f: 4.818e-08
pinn: 0000, Iter: 500, total_loss: 1.584e-07, loss_BC: 0.000e+00, loss_IC: 1.537e-08,loss_f: 4.327e-08
pinn: 0000, Iter: 600, total_loss: 1.551e-07, loss_BC: 0.000e+00, loss_IC: 1.521e-08,loss_f: 4.088e-08
pinn: 0000, Iter: 700, total_loss: 1.521e-07, loss_BC: 0.000e+00, loss_IC: 1.556e-08,loss_f: 4.046e-08
pinn: 0000, Iter: 800, total_loss: 1.494e-07, loss_BC: 0.000e+00, loss_IC: 1.679e-08,loss_f: 4.011e-08
pinn: 0000, Iter: 900, total_loss: 1.455e-07, loss_BC: 0.000e+00, loss_IC: 1.607e-08,loss_f: 4.077e-08
pinn: 0000, Iter: 1000, total_loss: 1.405e-07, loss_BC: 0.000e+00, loss_IC: 1.683e-08,loss_f: 4.083e-08
pinn: 0000, Iter: 1100, total_loss: 1.336e-07, loss_BC: 0.000e+00, loss_IC: 1.594e-08,loss_f: 4.228e-08
pinn: 0000, Iter: 1200, total_loss: 1.292e-07, loss_BC: 0.000e+00, loss_IC: 1.478e-08,loss_f: 4.265e-08
pinn: 0000, Iter: 1300, total_loss: 1.231e-07, loss_BC: 0.000e+00, loss_IC: 1.379e-08,loss_f: 4.373e-08
pinn: 0000, Iter: 1400, total_loss: 1.211e-07, loss_BC: 0.000e+00, loss_IC: 1.435e-08,loss_f: 4.578e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8821, Mean_loss of pinns: 1.199e-07, loss_BC: 0.000e+00, loss_IC: 1.425e-08, loss_f: 4.569e-08
 => minimum loss: 1.199e-07, corresponding pinn index: 0000
 => maximum loss: 1.199e-07, corresponding pinn  index: 0000

 max_loss: 3.152e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8823, total_loss: 1.869e-05, loss_BC: 9.859e-06, loss_IC: 3.754e-07, loss_f: 8.394e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.84000, t_max: 0.85000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8824 0 1

 -------------------------------------------------------------
  -----  Epoch: 8824 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.84000, t_max: 0.85000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8824 !!! 


==> Epoch: 8830, Mean_loss of pinns: 1.633e-03, loss_BC: 9.731e-06, loss_IC: 2.769e-06, loss_f: 1.621e-03
 => minimum loss: 9.551e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.540e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 8840, Mean_loss of pinns: 1.222e-03, loss_BC: 8.281e-06, loss_IC: 1.606e-05, loss_f: 1.198e-03
 => minimum loss: 7.736e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.850e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 8850, Mean_loss of pinns: 9.435e-04, loss_BC: 7.349e-06, loss_IC: 3.442e-05, loss_f: 9.016e-04
 => minimum loss: 6.389e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.441e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8860, Mean_loss of pinns: 7.636e-04, loss_BC: 6.597e-06, loss_IC: 5.104e-05, loss_f: 7.059e-04
 => minimum loss: 5.353e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.167e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8870, Mean_loss of pinns: 6.422e-04, loss_BC: 5.625e-06, loss_IC: 6.186e-05, loss_f: 5.746e-04
 => minimum loss: 4.522e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.816e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8880, Mean_loss of pinns: 5.556e-04, loss_BC: 5.347e-06, loss_IC: 6.605e-05, loss_f: 4.841e-04
 => minimum loss: 3.919e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.482e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8890, Mean_loss of pinns: 4.887e-04, loss_BC: 5.077e-06, loss_IC: 6.477e-05, loss_f: 4.187e-04
 => minimum loss: 3.528e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.452e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8900, Mean_loss of pinns: 4.342e-04, loss_BC: 4.809e-06, loss_IC: 5.993e-05, loss_f: 3.693e-04
 => minimum loss: 3.211e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.614e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8910, Mean_loss of pinns: 3.892e-04, loss_BC: 5.287e-06, loss_IC: 5.326e-05, loss_f: 3.305e-04
 => minimum loss: 3.104e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.913e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 8920, Mean_loss of pinns: 3.505e-04, loss_BC: 5.325e-06, loss_IC: 4.627e-05, loss_f: 2.988e-04
 => minimum loss: 2.950e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.358e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  8923

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.034e-06, loss_BC: 0.000e+00, loss_IC: 1.160e-07,loss_f: 8.463e-07
pinn: 0200, Iter: 100, total_loss: 7.118e-07, loss_BC: 0.000e+00, loss_IC: 8.085e-08,loss_f: 5.077e-07
pinn: 0300, Iter: 100, total_loss: 7.471e-07, loss_BC: 0.000e+00, loss_IC: 9.949e-08,loss_f: 5.817e-07
pinn: 0100, Iter: 200, total_loss: 3.180e-07, loss_BC: 0.000e+00, loss_IC: 4.207e-08,loss_f: 2.047e-07
pinn: 0300, Iter: 200, total_loss: 1.804e-07, loss_BC: 0.000e+00, loss_IC: 2.323e-08,loss_f: 9.487e-08
pinn: 0200, Iter: 200, total_loss: 3.893e-07, loss_BC: 0.000e+00, loss_IC: 5.644e-08,loss_f: 2.125e-07
pinn: 0100, Iter: 300, total_loss: 2.382e-07, loss_BC: 0.000e+00, loss_IC: 2.705e-08,loss_f: 1.460e-07
pinn: 0200, Iter: 300, total_loss: 2.850e-07, loss_BC: 0.000e+00, loss_IC: 3.324e-08,loss_f: 1.355e-07
pinn: 0300, Iter: 300, total_loss: 1.110e-07, loss_BC: 0.000e+00, loss_IC: 1.229e-08,loss_f: 4.132e-08
pinn: 0100, Iter: 400, total_loss: 2.091e-07, loss_BC: 0.000e+00, loss_IC: 1.407e-08,loss_f: 1.321e-07
pinn: 0300, Iter: 400, total_loss: 9.166e-08, loss_BC: 0.000e+00, loss_IC: 5.984e-09,loss_f: 3.294e-08
pinn: 0200, Iter: 400, total_loss: 2.330e-07, loss_BC: 0.000e+00, loss_IC: 2.320e-08,loss_f: 9.675e-08
pinn: 0100, Iter: 500, total_loss: 1.644e-07, loss_BC: 0.000e+00, loss_IC: 1.146e-08,loss_f: 9.048e-08
pinn: 0200, Iter: 500, total_loss: 2.065e-07, loss_BC: 0.000e+00, loss_IC: 2.142e-08,loss_f: 7.317e-08
pinn: 0300, Iter: 500, total_loss: 8.775e-08, loss_BC: 0.000e+00, loss_IC: 4.523e-09,loss_f: 3.040e-08
pinn: 0100, Iter: 600, total_loss: 1.623e-07, loss_BC: 0.000e+00, loss_IC: 1.144e-08,loss_f: 8.805e-08
pinn: 0200, Iter: 600, total_loss: 2.040e-07, loss_BC: 0.000e+00, loss_IC: 2.094e-08,loss_f: 7.195e-08
pinn: 0300, Iter: 600, total_loss: 8.289e-08, loss_BC: 0.000e+00, loss_IC: 3.321e-09,loss_f: 2.679e-08
pinn: 0100, Iter: 700, total_loss: 1.590e-07, loss_BC: 0.000e+00, loss_IC: 1.059e-08,loss_f: 8.561e-08
pinn: 0200, Iter: 700, total_loss: 2.004e-07, loss_BC: 0.000e+00, loss_IC: 2.083e-08,loss_f: 7.105e-08
pinn: 0300, Iter: 700, total_loss: 8.011e-08, loss_BC: 0.000e+00, loss_IC: 3.110e-09,loss_f: 2.461e-08
pinn: 0100, Iter: 800, total_loss: 1.558e-07, loss_BC: 0.000e+00, loss_IC: 9.362e-09,loss_f: 8.529e-08
pinn: 0200, Iter: 800, total_loss: 1.879e-07, loss_BC: 0.000e+00, loss_IC: 2.292e-08,loss_f: 6.509e-08
pinn: 0300, Iter: 800, total_loss: 7.907e-08, loss_BC: 0.000e+00, loss_IC: 3.511e-09,loss_f: 2.403e-08
pinn: 0100, Iter: 900, total_loss: 1.517e-07, loss_BC: 0.000e+00, loss_IC: 9.148e-09,loss_f: 8.247e-08
pinn: 0200, Iter: 900, total_loss: 1.807e-07, loss_BC: 0.000e+00, loss_IC: 2.194e-08,loss_f: 6.444e-08
pinn: 0300, Iter: 900, total_loss: 7.693e-08, loss_BC: 0.000e+00, loss_IC: 3.818e-09,loss_f: 2.351e-08
pinn: 0100, Iter: 1000, total_loss: 1.501e-07, loss_BC: 0.000e+00, loss_IC: 8.839e-09,loss_f: 8.155e-08
pinn: 0200, Iter: 1000, total_loss: 1.727e-07, loss_BC: 0.000e+00, loss_IC: 2.110e-08,loss_f: 6.290e-08
pinn: 0300, Iter: 1000, total_loss: 7.664e-08, loss_BC: 0.000e+00, loss_IC: 3.604e-09,loss_f: 2.353e-08
pinn: 0100, Iter: 1100, total_loss: 1.477e-07, loss_BC: 0.000e+00, loss_IC: 8.782e-09,loss_f: 8.053e-08
pinn: 0200, Iter: 1100, total_loss: 1.686e-07, loss_BC: 0.000e+00, loss_IC: 1.933e-08,loss_f: 6.386e-08
pinn: 0300, Iter: 1100, total_loss: 7.460e-08, loss_BC: 0.000e+00, loss_IC: 3.456e-09,loss_f: 2.301e-08
pinn: 0100, Iter: 1200, total_loss: 1.445e-07, loss_BC: 0.000e+00, loss_IC: 8.969e-09,loss_f: 7.831e-08
pinn: 0200, Iter: 1200, total_loss: 1.659e-07, loss_BC: 0.000e+00, loss_IC: 1.902e-08,loss_f: 6.329e-08
pinn: 0300, Iter: 1200, total_loss: 7.427e-08, loss_BC: 0.000e+00, loss_IC: 3.611e-09,loss_f: 2.330e-08
pinn: 0100, Iter: 1300, total_loss: 1.423e-07, loss_BC: 0.000e+00, loss_IC: 8.662e-09,loss_f: 7.739e-08
pinn: 0200, Iter: 1300, total_loss: 1.593e-07, loss_BC: 0.000e+00, loss_IC: 1.827e-08,loss_f: 6.212e-08
pinn: 0300, Iter: 1300, total_loss: 7.176e-08, loss_BC: 0.000e+00, loss_IC: 3.978e-09,loss_f: 2.300e-08
pinn: 0100, Iter: 1400, total_loss: 1.400e-07, loss_BC: 0.000e+00, loss_IC: 9.225e-09,loss_f: 7.647e-08
pinn: 0200, Iter: 1400, total_loss: 1.585e-07, loss_BC: 0.000e+00, loss_IC: 1.775e-08,loss_f: 6.305e-08
pinn: 0300, Iter: 1400, total_loss: 6.583e-08, loss_BC: 0.000e+00, loss_IC: 4.364e-09,loss_f: 2.303e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 8923, Mean_loss of pinns: 1.211e-07, loss_BC: 0.000e+00, loss_IC: 1.031e-08, loss_f: 5.430e-08
 => minimum loss: 6.569e-08, corresponding pinn index: 0300
 => maximum loss: 1.577e-07, corresponding pinn  index: 0200

 max_loss: 4.136e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 8925, total_loss: 1.313e-05, loss_BC: 9.288e-06, loss_IC: 1.411e-07, loss_f: 3.603e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.85000, t_max: 0.86000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  8926 0 1

 -------------------------------------------------------------
  -----  Epoch: 8926 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.85000, t_max: 0.86000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  8926 !!! 


==> Epoch: 8930, Mean_loss of pinns: 7.213e-04, loss_BC: 1.046e-05, loss_IC: 2.430e-07, loss_f: 7.105e-04
 => minimum loss: 3.845e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.718e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 8940, Mean_loss of pinns: 6.039e-04, loss_BC: 1.039e-05, loss_IC: 9.685e-07, loss_f: 5.925e-04
 => minimum loss: 3.104e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.285e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8950, Mean_loss of pinns: 5.095e-04, loss_BC: 1.173e-05, loss_IC: 1.059e-06, loss_f: 4.966e-04
 => minimum loss: 2.476e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.933e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8960, Mean_loss of pinns: 4.346e-04, loss_BC: 1.275e-05, loss_IC: 1.418e-06, loss_f: 4.203e-04
 => minimum loss: 2.056e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.652e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8970, Mean_loss of pinns: 3.736e-04, loss_BC: 1.344e-05, loss_IC: 1.913e-06, loss_f: 3.582e-04
 => minimum loss: 1.744e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.421e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8980, Mean_loss of pinns: 3.233e-04, loss_BC: 1.369e-05, loss_IC: 2.217e-06, loss_f: 3.074e-04
 => minimum loss: 1.519e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.230e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 8990, Mean_loss of pinns: 2.817e-04, loss_BC: 1.339e-05, loss_IC: 2.297e-06, loss_f: 2.659e-04
 => minimum loss: 1.348e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.071e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9000, Mean_loss of pinns: 2.468e-04, loss_BC: 1.274e-05, loss_IC: 2.169e-06, loss_f: 2.319e-04
 => minimum loss: 1.211e-05, corresponding pinn/batch index: 0100
 => maximum loss: 9.374e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9010, Mean_loss of pinns: 2.182e-04, loss_BC: 1.251e-05, loss_IC: 1.947e-06, loss_f: 2.037e-04
 => minimum loss: 1.103e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.270e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9020, Mean_loss of pinns: 1.937e-04, loss_BC: 1.171e-05, loss_IC: 1.682e-06, loss_f: 1.802e-04
 => minimum loss: 1.011e-05, corresponding pinn/batch index: 0100
 => maximum loss: 7.329e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  9025

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 5.736e-07, loss_BC: 0.000e+00, loss_IC: 4.164e-08,loss_f: 4.391e-07
pinn: 0000, Iter: 200, total_loss: 2.127e-07, loss_BC: 0.000e+00, loss_IC: 2.055e-08,loss_f: 1.025e-07
pinn: 0000, Iter: 300, total_loss: 1.623e-07, loss_BC: 0.000e+00, loss_IC: 1.432e-08,loss_f: 6.633e-08
pinn: 0000, Iter: 400, total_loss: 1.527e-07, loss_BC: 0.000e+00, loss_IC: 1.522e-08,loss_f: 5.716e-08
pinn: 0000, Iter: 500, total_loss: 1.465e-07, loss_BC: 0.000e+00, loss_IC: 1.521e-08,loss_f: 4.997e-08
pinn: 0000, Iter: 600, total_loss: 1.385e-07, loss_BC: 0.000e+00, loss_IC: 1.452e-08,loss_f: 4.572e-08
pinn: 0000, Iter: 700, total_loss: 1.338e-07, loss_BC: 0.000e+00, loss_IC: 1.401e-08,loss_f: 4.392e-08
pinn: 0000, Iter: 800, total_loss: 1.311e-07, loss_BC: 0.000e+00, loss_IC: 1.394e-08,loss_f: 4.329e-08
pinn: 0000, Iter: 900, total_loss: 1.286e-07, loss_BC: 0.000e+00, loss_IC: 1.400e-08,loss_f: 4.314e-08
pinn: 0000, Iter: 1000, total_loss: 1.255e-07, loss_BC: 0.000e+00, loss_IC: 1.318e-08,loss_f: 4.286e-08
pinn: 0000, Iter: 1100, total_loss: 1.223e-07, loss_BC: 0.000e+00, loss_IC: 1.204e-08,loss_f: 4.343e-08
pinn: 0000, Iter: 1200, total_loss: 1.195e-07, loss_BC: 0.000e+00, loss_IC: 1.168e-08,loss_f: 4.290e-08
pinn: 0000, Iter: 1300, total_loss: 1.190e-07, loss_BC: 0.000e+00, loss_IC: 1.200e-08,loss_f: 4.297e-08
pinn: 0000, Iter: 1400, total_loss: 1.112e-07, loss_BC: 0.000e+00, loss_IC: 1.350e-08,loss_f: 4.323e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9025, Mean_loss of pinns: 1.110e-07, loss_BC: 0.000e+00, loss_IC: 1.351e-08, loss_f: 4.298e-08
 => minimum loss: 1.110e-07, corresponding pinn index: 0000
 => maximum loss: 1.110e-07, corresponding pinn  index: 0000

 max_loss: 3.418e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9027, total_loss: 1.836e-05, loss_BC: 1.055e-05, loss_IC: 3.222e-07, loss_f: 7.414e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.86000, t_max: 0.87000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9028 0 1

 -------------------------------------------------------------
  -----  Epoch: 9028 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.86000, t_max: 0.87000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9028 !!! 


==> Epoch: 9030, Mean_loss of pinns: 1.193e-03, loss_BC: 1.059e-05, loss_IC: 2.896e-07, loss_f: 1.182e-03
 => minimum loss: 9.812e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.166e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 9040, Mean_loss of pinns: 8.652e-04, loss_BC: 9.339e-06, loss_IC: 9.176e-06, loss_f: 8.466e-04
 => minimum loss: 7.946e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.590e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 9050, Mean_loss of pinns: 6.671e-04, loss_BC: 7.996e-06, loss_IC: 2.401e-05, loss_f: 6.350e-04
 => minimum loss: 6.194e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.207e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9060, Mean_loss of pinns: 5.427e-04, loss_BC: 7.304e-06, loss_IC: 3.647e-05, loss_f: 4.988e-04
 => minimum loss: 5.023e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.686e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9070, Mean_loss of pinns: 4.580e-04, loss_BC: 6.401e-06, loss_IC: 4.332e-05, loss_f: 4.081e-04
 => minimum loss: 4.274e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.123e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9080, Mean_loss of pinns: 3.976e-04, loss_BC: 6.246e-06, loss_IC: 4.426e-05, loss_f: 3.470e-04
 => minimum loss: 3.809e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.030e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9090, Mean_loss of pinns: 3.497e-04, loss_BC: 5.687e-06, loss_IC: 4.097e-05, loss_f: 3.029e-04
 => minimum loss: 3.285e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.168e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9100, Mean_loss of pinns: 3.114e-04, loss_BC: 6.712e-06, loss_IC: 3.598e-05, loss_f: 2.687e-04
 => minimum loss: 3.198e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.465e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9110, Mean_loss of pinns: 2.774e-04, loss_BC: 5.891e-06, loss_IC: 3.052e-05, loss_f: 2.409e-04
 => minimum loss: 2.901e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.865e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9120, Mean_loss of pinns: 2.498e-04, loss_BC: 6.691e-06, loss_IC: 2.543e-05, loss_f: 2.176e-04
 => minimum loss: 2.847e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.363e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  9127

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 1.316e-06, loss_BC: 0.000e+00, loss_IC: 1.779e-07,loss_f: 1.102e-06
pinn: 0300, Iter: 100, total_loss: 5.279e-07, loss_BC: 0.000e+00, loss_IC: 4.036e-08,loss_f: 3.767e-07
pinn: 0200, Iter: 100, total_loss: 7.099e-07, loss_BC: 0.000e+00, loss_IC: 6.907e-08,loss_f: 5.490e-07
pinn: 0100, Iter: 200, total_loss: 2.625e-07, loss_BC: 0.000e+00, loss_IC: 4.267e-08,loss_f: 1.843e-07
pinn: 0300, Iter: 200, total_loss: 2.243e-07, loss_BC: 0.000e+00, loss_IC: 1.293e-08,loss_f: 1.060e-07
pinn: 0200, Iter: 200, total_loss: 2.720e-07, loss_BC: 0.000e+00, loss_IC: 3.629e-08,loss_f: 1.443e-07
pinn: 0100, Iter: 300, total_loss: 1.801e-07, loss_BC: 0.000e+00, loss_IC: 2.896e-08,loss_f: 1.169e-07
pinn: 0200, Iter: 300, total_loss: 1.917e-07, loss_BC: 0.000e+00, loss_IC: 1.492e-08,loss_f: 8.802e-08
pinn: 0300, Iter: 300, total_loss: 1.456e-07, loss_BC: 0.000e+00, loss_IC: 8.198e-09,loss_f: 4.380e-08
pinn: 0100, Iter: 400, total_loss: 1.640e-07, loss_BC: 0.000e+00, loss_IC: 1.647e-08,loss_f: 1.147e-07
pinn: 0300, Iter: 400, total_loss: 1.302e-07, loss_BC: 0.000e+00, loss_IC: 5.569e-09,loss_f: 3.692e-08
pinn: 0200, Iter: 400, total_loss: 1.768e-07, loss_BC: 0.000e+00, loss_IC: 1.093e-08,loss_f: 7.923e-08
pinn: 0100, Iter: 500, total_loss: 1.406e-07, loss_BC: 0.000e+00, loss_IC: 1.460e-08,loss_f: 9.349e-08
pinn: 0300, Iter: 500, total_loss: 1.218e-07, loss_BC: 0.000e+00, loss_IC: 4.106e-09,loss_f: 3.041e-08
pinn: 0200, Iter: 500, total_loss: 1.636e-07, loss_BC: 0.000e+00, loss_IC: 7.308e-09,loss_f: 6.972e-08
pinn: 0100, Iter: 600, total_loss: 1.359e-07, loss_BC: 0.000e+00, loss_IC: 1.507e-08,loss_f: 8.790e-08
pinn: 0200, Iter: 600, total_loss: 1.561e-07, loss_BC: 0.000e+00, loss_IC: 7.278e-09,loss_f: 6.338e-08
pinn: 0300, Iter: 600, total_loss: 1.152e-07, loss_BC: 0.000e+00, loss_IC: 2.970e-09,loss_f: 2.695e-08
pinn: 0100, Iter: 700, total_loss: 1.326e-07, loss_BC: 0.000e+00, loss_IC: 1.367e-08,loss_f: 8.659e-08
pinn: 0300, Iter: 700, total_loss: 1.122e-07, loss_BC: 0.000e+00, loss_IC: 3.878e-09,loss_f: 2.659e-08
pinn: 0200, Iter: 700, total_loss: 1.543e-07, loss_BC: 0.000e+00, loss_IC: 7.474e-09,loss_f: 6.281e-08
pinn: 0100, Iter: 800, total_loss: 1.292e-07, loss_BC: 0.000e+00, loss_IC: 1.346e-08,loss_f: 8.393e-08
pinn: 0300, Iter: 800, total_loss: 1.080e-07, loss_BC: 0.000e+00, loss_IC: 3.092e-09,loss_f: 2.660e-08
pinn: 0200, Iter: 800, total_loss: 1.507e-07, loss_BC: 0.000e+00, loss_IC: 9.326e-09,loss_f: 6.047e-08
pinn: 0100, Iter: 900, total_loss: 1.227e-07, loss_BC: 0.000e+00, loss_IC: 1.339e-08,loss_f: 7.799e-08
pinn: 0300, Iter: 900, total_loss: 9.954e-08, loss_BC: 0.000e+00, loss_IC: 3.315e-09,loss_f: 2.610e-08
pinn: 0200, Iter: 900, total_loss: 1.430e-07, loss_BC: 0.000e+00, loss_IC: 9.655e-09,loss_f: 5.831e-08
pinn: 0100, Iter: 1000, total_loss: 1.200e-07, loss_BC: 0.000e+00, loss_IC: 1.324e-08,loss_f: 7.563e-08
pinn: 0300, Iter: 1000, total_loss: 9.486e-08, loss_BC: 0.000e+00, loss_IC: 3.470e-09,loss_f: 2.759e-08
pinn: 0200, Iter: 1000, total_loss: 1.377e-07, loss_BC: 0.000e+00, loss_IC: 8.566e-09,loss_f: 5.881e-08
pinn: 0100, Iter: 1100, total_loss: 1.172e-07, loss_BC: 0.000e+00, loss_IC: 1.276e-08,loss_f: 7.336e-08
pinn: 0300, Iter: 1100, total_loss: 9.112e-08, loss_BC: 0.000e+00, loss_IC: 3.434e-09,loss_f: 2.587e-08
pinn: 0200, Iter: 1100, total_loss: 1.354e-07, loss_BC: 0.000e+00, loss_IC: 7.651e-09,loss_f: 5.901e-08
pinn: 0100, Iter: 1200, total_loss: 1.103e-07, loss_BC: 0.000e+00, loss_IC: 1.289e-08,loss_f: 6.688e-08
pinn: 0300, Iter: 1200, total_loss: 8.494e-08, loss_BC: 0.000e+00, loss_IC: 5.250e-09,loss_f: 2.748e-08
pinn: 0200, Iter: 1200, total_loss: 1.321e-07, loss_BC: 0.000e+00, loss_IC: 8.091e-09,loss_f: 5.772e-08
pinn: 0100, Iter: 1300, total_loss: 1.086e-07, loss_BC: 0.000e+00, loss_IC: 1.323e-08,loss_f: 6.526e-08
pinn: 0300, Iter: 1300, total_loss: 8.416e-08, loss_BC: 0.000e+00, loss_IC: 5.354e-09,loss_f: 2.756e-08
pinn: 0200, Iter: 1300, total_loss: 1.289e-07, loss_BC: 0.000e+00, loss_IC: 7.741e-09,loss_f: 5.762e-08
pinn: 0100, Iter: 1400, total_loss: 1.022e-07, loss_BC: 0.000e+00, loss_IC: 1.301e-08,loss_f: 5.989e-08
pinn: 0300, Iter: 1400, total_loss: 7.403e-08, loss_BC: 0.000e+00, loss_IC: 6.825e-09,loss_f: 2.486e-08
pinn: 0200, Iter: 1400, total_loss: 1.282e-07, loss_BC: 0.000e+00, loss_IC: 8.035e-09,loss_f: 5.766e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9127, Mean_loss of pinns: 1.008e-07, loss_BC: 0.000e+00, loss_IC: 9.315e-09, loss_f: 4.746e-08
 => minimum loss: 7.298e-08, corresponding pinn index: 0300
 => maximum loss: 1.274e-07, corresponding pinn  index: 0200

 max_loss: 4.008e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9129, total_loss: 1.292e-05, loss_BC: 9.478e-06, loss_IC: 2.329e-07, loss_f: 3.147e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.87000, t_max: 0.88000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9130 0 1

 -------------------------------------------------------------
  -----  Epoch: 9130 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.87000, t_max: 0.88000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9130 !!! 


==> Epoch: 9130, Mean_loss of pinns: 1.650e-03, loss_BC: 1.145e-05, loss_IC: 0.000e+00, loss_f: 1.638e-03
 => minimum loss: 4.393e-05, corresponding pinn/batch index: 0300
 => maximum loss: 6.373e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 9140, Mean_loss of pinns: 1.299e-03, loss_BC: 1.137e-05, loss_IC: 1.446e-06, loss_f: 1.287e-03
 => minimum loss: 3.400e-05, corresponding pinn/batch index: 0300
 => maximum loss: 5.029e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 9150, Mean_loss of pinns: 1.039e-03, loss_BC: 1.401e-05, loss_IC: 2.307e-06, loss_f: 1.023e-03
 => minimum loss: 2.806e-05, corresponding pinn/batch index: 0300
 => maximum loss: 4.025e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 2
pinns above Threshold: 0000, 0200

==> Epoch: 9160, Mean_loss of pinns: 8.415e-04, loss_BC: 1.615e-05, loss_IC: 4.050e-06, loss_f: 8.212e-04
 => minimum loss: 2.255e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.261e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9170, Mean_loss of pinns: 6.940e-04, loss_BC: 1.859e-05, loss_IC: 6.202e-06, loss_f: 6.691e-04
 => minimum loss: 1.857e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.689e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9180, Mean_loss of pinns: 5.832e-04, loss_BC: 2.061e-05, loss_IC: 7.913e-06, loss_f: 5.546e-04
 => minimum loss: 1.606e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.258e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9190, Mean_loss of pinns: 4.979e-04, loss_BC: 2.121e-05, loss_IC: 9.020e-06, loss_f: 4.675e-04
 => minimum loss: 1.421e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.926e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9200, Mean_loss of pinns: 4.310e-04, loss_BC: 2.100e-05, loss_IC: 9.399e-06, loss_f: 4.004e-04
 => minimum loss: 1.267e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.666e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9210, Mean_loss of pinns: 3.771e-04, loss_BC: 2.007e-05, loss_IC: 9.165e-06, loss_f: 3.478e-04
 => minimum loss: 1.150e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.456e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9220, Mean_loss of pinns: 3.339e-04, loss_BC: 1.964e-05, loss_IC: 8.531e-06, loss_f: 3.056e-04
 => minimum loss: 1.046e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.288e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  9229

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 7.104e-07, loss_BC: 0.000e+00, loss_IC: 6.300e-08,loss_f: 4.806e-07
pinn: 0000, Iter: 200, total_loss: 2.897e-07, loss_BC: 0.000e+00, loss_IC: 1.863e-08,loss_f: 1.083e-07
pinn: 0000, Iter: 300, total_loss: 2.405e-07, loss_BC: 0.000e+00, loss_IC: 1.751e-08,loss_f: 7.428e-08
pinn: 0000, Iter: 400, total_loss: 2.218e-07, loss_BC: 0.000e+00, loss_IC: 1.747e-08,loss_f: 6.259e-08
pinn: 0000, Iter: 500, total_loss: 2.137e-07, loss_BC: 0.000e+00, loss_IC: 1.591e-08,loss_f: 5.510e-08
pinn: 0000, Iter: 600, total_loss: 2.056e-07, loss_BC: 0.000e+00, loss_IC: 1.676e-08,loss_f: 5.074e-08
pinn: 0000, Iter: 700, total_loss: 1.992e-07, loss_BC: 0.000e+00, loss_IC: 1.749e-08,loss_f: 4.983e-08
pinn: 0000, Iter: 800, total_loss: 1.930e-07, loss_BC: 0.000e+00, loss_IC: 1.634e-08,loss_f: 5.230e-08
pinn: 0000, Iter: 900, total_loss: 1.759e-07, loss_BC: 0.000e+00, loss_IC: 1.651e-08,loss_f: 5.543e-08
pinn: 0000, Iter: 1000, total_loss: 1.660e-07, loss_BC: 0.000e+00, loss_IC: 1.458e-08,loss_f: 6.026e-08
pinn: 0000, Iter: 1100, total_loss: 1.599e-07, loss_BC: 0.000e+00, loss_IC: 1.395e-08,loss_f: 5.953e-08
pinn: 0000, Iter: 1200, total_loss: 1.474e-07, loss_BC: 0.000e+00, loss_IC: 1.479e-08,loss_f: 6.206e-08
pinn: 0000, Iter: 1300, total_loss: 1.370e-07, loss_BC: 0.000e+00, loss_IC: 1.355e-08,loss_f: 5.890e-08
pinn: 0000, Iter: 1400, total_loss: 1.355e-07, loss_BC: 0.000e+00, loss_IC: 1.366e-08,loss_f: 6.088e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9229, Mean_loss of pinns: 1.343e-07, loss_BC: 0.000e+00, loss_IC: 1.380e-08, loss_f: 6.229e-08
 => minimum loss: 1.343e-07, corresponding pinn index: 0000
 => maximum loss: 1.343e-07, corresponding pinn  index: 0000

==> Epoch: 9230, Mean_loss of pinns: 1.932e-05, loss_BC: 1.058e-05, loss_IC: 4.443e-07, loss_f: 8.222e-06
 => minimum loss: 9.607e-06, corresponding pinn/batch index: 0100
 => maximum loss: 3.362e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 3.202e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9231, total_loss: 1.892e-05, loss_BC: 1.026e-05, loss_IC: 4.427e-07, loss_f: 8.144e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.88000, t_max: 0.89000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9232 0 1

 -------------------------------------------------------------
  -----  Epoch: 9232 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.88000, t_max: 0.89000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9232 !!! 


==> Epoch: 9240, Mean_loss of pinns: 1.129e-03, loss_BC: 8.881e-06, loss_IC: 4.807e-06, loss_f: 1.116e-03
 => minimum loss: 6.328e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.835e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9250, Mean_loss of pinns: 8.506e-04, loss_BC: 7.971e-06, loss_IC: 1.852e-05, loss_f: 8.240e-04
 => minimum loss: 5.232e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.374e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9260, Mean_loss of pinns: 6.690e-04, loss_BC: 6.785e-06, loss_IC: 3.469e-05, loss_f: 6.274e-04
 => minimum loss: 4.406e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.072e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9270, Mean_loss of pinns: 5.516e-04, loss_BC: 6.357e-06, loss_IC: 4.682e-05, loss_f: 4.983e-04
 => minimum loss: 3.834e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.853e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9280, Mean_loss of pinns: 4.705e-04, loss_BC: 6.190e-06, loss_IC: 5.181e-05, loss_f: 4.124e-04
 => minimum loss: 3.446e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.642e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9290, Mean_loss of pinns: 4.093e-04, loss_BC: 6.207e-06, loss_IC: 5.041e-05, loss_f: 3.526e-04
 => minimum loss: 3.206e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.749e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9300, Mean_loss of pinns: 3.600e-04, loss_BC: 6.241e-06, loss_IC: 4.519e-05, loss_f: 3.085e-04
 => minimum loss: 2.976e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.036e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9310, Mean_loss of pinns: 3.194e-04, loss_BC: 6.388e-06, loss_IC: 3.850e-05, loss_f: 2.744e-04
 => minimum loss: 2.897e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.420e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9320, Mean_loss of pinns: 2.854e-04, loss_BC: 6.493e-06, loss_IC: 3.206e-05, loss_f: 2.467e-04
 => minimum loss: 2.881e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.883e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9330, Mean_loss of pinns: 2.569e-04, loss_BC: 6.719e-06, loss_IC: 2.670e-05, loss_f: 2.234e-04
 => minimum loss: 3.011e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.416e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  9331

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 7.939e-07, loss_BC: 0.000e+00, loss_IC: 2.433e-07,loss_f: 4.448e-07
pinn: 0200, Iter: 100, total_loss: 7.108e-07, loss_BC: 0.000e+00, loss_IC: 1.205e-07,loss_f: 3.978e-07
pinn: 0300, Iter: 100, total_loss: 1.171e-06, loss_BC: 0.000e+00, loss_IC: 3.832e-07,loss_f: 6.887e-07
pinn: 0100, Iter: 200, total_loss: 2.645e-07, loss_BC: 0.000e+00, loss_IC: 3.089e-08,loss_f: 1.238e-07
pinn: 0200, Iter: 200, total_loss: 3.557e-07, loss_BC: 0.000e+00, loss_IC: 5.160e-08,loss_f: 1.297e-07
pinn: 0300, Iter: 200, total_loss: 2.353e-07, loss_BC: 0.000e+00, loss_IC: 3.921e-08,loss_f: 1.029e-07
pinn: 0200, Iter: 300, total_loss: 2.873e-07, loss_BC: 0.000e+00, loss_IC: 3.213e-08,loss_f: 8.621e-08
pinn: 0100, Iter: 300, total_loss: 2.048e-07, loss_BC: 0.000e+00, loss_IC: 1.914e-08,loss_f: 8.459e-08
pinn: 0300, Iter: 300, total_loss: 1.584e-07, loss_BC: 0.000e+00, loss_IC: 1.944e-08,loss_f: 5.710e-08
pinn: 0200, Iter: 400, total_loss: 2.538e-07, loss_BC: 0.000e+00, loss_IC: 2.513e-08,loss_f: 6.383e-08
pinn: 0100, Iter: 400, total_loss: 1.915e-07, loss_BC: 0.000e+00, loss_IC: 1.899e-08,loss_f: 7.667e-08
pinn: 0300, Iter: 400, total_loss: 1.426e-07, loss_BC: 0.000e+00, loss_IC: 1.294e-08,loss_f: 5.316e-08
pinn: 0200, Iter: 500, total_loss: 2.437e-07, loss_BC: 0.000e+00, loss_IC: 2.302e-08,loss_f: 6.015e-08
pinn: 0100, Iter: 500, total_loss: 1.811e-07, loss_BC: 0.000e+00, loss_IC: 1.757e-08,loss_f: 6.869e-08
pinn: 0300, Iter: 500, total_loss: 1.363e-07, loss_BC: 0.000e+00, loss_IC: 1.008e-08,loss_f: 5.040e-08
pinn: 0200, Iter: 600, total_loss: 2.358e-07, loss_BC: 0.000e+00, loss_IC: 2.324e-08,loss_f: 5.951e-08
pinn: 0100, Iter: 600, total_loss: 1.733e-07, loss_BC: 0.000e+00, loss_IC: 1.717e-08,loss_f: 6.319e-08
pinn: 0300, Iter: 600, total_loss: 1.294e-07, loss_BC: 0.000e+00, loss_IC: 7.203e-09,loss_f: 4.699e-08
pinn: 0200, Iter: 700, total_loss: 2.305e-07, loss_BC: 0.000e+00, loss_IC: 2.308e-08,loss_f: 6.060e-08
pinn: 0100, Iter: 700, total_loss: 1.708e-07, loss_BC: 0.000e+00, loss_IC: 1.740e-08,loss_f: 6.197e-08
pinn: 0300, Iter: 700, total_loss: 1.236e-07, loss_BC: 0.000e+00, loss_IC: 6.497e-09,loss_f: 4.268e-08
pinn: 0200, Iter: 800, total_loss: 2.148e-07, loss_BC: 0.000e+00, loss_IC: 2.109e-08,loss_f: 5.874e-08
pinn: 0300, Iter: 800, total_loss: 1.202e-07, loss_BC: 0.000e+00, loss_IC: 6.106e-09,loss_f: 4.143e-08
pinn: 0100, Iter: 800, total_loss: 1.578e-07, loss_BC: 0.000e+00, loss_IC: 1.730e-08,loss_f: 5.952e-08
pinn: 0200, Iter: 900, total_loss: 1.960e-07, loss_BC: 0.000e+00, loss_IC: 1.691e-08,loss_f: 6.616e-08
pinn: 0100, Iter: 900, total_loss: 1.478e-07, loss_BC: 0.000e+00, loss_IC: 1.682e-08,loss_f: 6.071e-08
pinn: 0300, Iter: 900, total_loss: 1.175e-07, loss_BC: 0.000e+00, loss_IC: 6.100e-09,loss_f: 4.103e-08
pinn: 0100, Iter: 1000, total_loss: 1.425e-07, loss_BC: 0.000e+00, loss_IC: 1.514e-08,loss_f: 6.061e-08
pinn: 0200, Iter: 1000, total_loss: 1.865e-07, loss_BC: 0.000e+00, loss_IC: 1.472e-08,loss_f: 6.781e-08
pinn: 0300, Iter: 1000, total_loss: 1.126e-07, loss_BC: 0.000e+00, loss_IC: 6.214e-09,loss_f: 4.098e-08
pinn: 0100, Iter: 1100, total_loss: 1.411e-07, loss_BC: 0.000e+00, loss_IC: 1.484e-08,loss_f: 6.083e-08
pinn: 0200, Iter: 1100, total_loss: 1.795e-07, loss_BC: 0.000e+00, loss_IC: 1.484e-08,loss_f: 6.882e-08
pinn: 0300, Iter: 1100, total_loss: 1.078e-07, loss_BC: 0.000e+00, loss_IC: 6.088e-09,loss_f: 4.198e-08
pinn: 0100, Iter: 1200, total_loss: 1.357e-07, loss_BC: 0.000e+00, loss_IC: 1.401e-08,loss_f: 6.163e-08
pinn: 0200, Iter: 1200, total_loss: 1.768e-07, loss_BC: 0.000e+00, loss_IC: 1.494e-08,loss_f: 7.105e-08
pinn: 0300, Iter: 1200, total_loss: 1.018e-07, loss_BC: 0.000e+00, loss_IC: 7.351e-09,loss_f: 4.080e-08
pinn: 0100, Iter: 1300, total_loss: 1.352e-07, loss_BC: 0.000e+00, loss_IC: 1.362e-08,loss_f: 6.114e-08
pinn: 0200, Iter: 1300, total_loss: 1.692e-07, loss_BC: 0.000e+00, loss_IC: 1.353e-08,loss_f: 7.339e-08
pinn: 0300, Iter: 1300, total_loss: 1.002e-07, loss_BC: 0.000e+00, loss_IC: 7.782e-09,loss_f: 3.985e-08
pinn: 0200, Iter: 1400, total_loss: 1.646e-07, loss_BC: 0.000e+00, loss_IC: 1.354e-08,loss_f: 7.346e-08
pinn: 0100, Iter: 1400, total_loss: 1.336e-07, loss_BC: 0.000e+00, loss_IC: 1.357e-08,loss_f: 6.166e-08
pinn: 0300, Iter: 1400, total_loss: 9.330e-08, loss_BC: 0.000e+00, loss_IC: 8.962e-09,loss_f: 3.950e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9331, Mean_loss of pinns: 1.286e-07, loss_BC: 0.000e+00, loss_IC: 1.196e-08, loss_f: 5.774e-08
 => minimum loss: 9.177e-08, corresponding pinn index: 0300
 => maximum loss: 1.616e-07, corresponding pinn  index: 0200

 max_loss: 3.561e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9333, total_loss: 1.231e-05, loss_BC: 9.324e-06, loss_IC: 5.163e-07, loss_f: 2.415e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.89000, t_max: 0.90000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9334 0 1

 -------------------------------------------------------------
  -----  Epoch: 9334 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.89000, t_max: 0.90000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9334 !!! 


==> Epoch: 9340, Mean_loss of pinns: 1.103e-03, loss_BC: 1.028e-05, loss_IC: 4.940e-07, loss_f: 1.092e-03
 => minimum loss: 3.654e-05, corresponding pinn/batch index: 0300
 => maximum loss: 4.291e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9350, Mean_loss of pinns: 9.005e-04, loss_BC: 1.094e-05, loss_IC: 1.415e-06, loss_f: 8.881e-04
 => minimum loss: 3.010e-05, corresponding pinn/batch index: 0200
 => maximum loss: 3.504e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9360, Mean_loss of pinns: 7.379e-04, loss_BC: 1.363e-05, loss_IC: 2.406e-06, loss_f: 7.218e-04
 => minimum loss: 2.467e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.871e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9370, Mean_loss of pinns: 6.119e-04, loss_BC: 1.581e-05, loss_IC: 4.247e-06, loss_f: 5.918e-04
 => minimum loss: 2.083e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.379e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9380, Mean_loss of pinns: 5.146e-04, loss_BC: 1.768e-05, loss_IC: 6.161e-06, loss_f: 4.907e-04
 => minimum loss: 1.767e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.000e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9390, Mean_loss of pinns: 4.395e-04, loss_BC: 1.880e-05, loss_IC: 7.661e-06, loss_f: 4.130e-04
 => minimum loss: 1.591e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.707e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9400, Mean_loss of pinns: 3.809e-04, loss_BC: 1.971e-05, loss_IC: 8.600e-06, loss_f: 3.526e-04
 => minimum loss: 1.417e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.477e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9410, Mean_loss of pinns: 3.332e-04, loss_BC: 1.906e-05, loss_IC: 8.879e-06, loss_f: 3.053e-04
 => minimum loss: 1.294e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.291e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9420, Mean_loss of pinns: 2.954e-04, loss_BC: 1.910e-05, loss_IC: 8.562e-06, loss_f: 2.677e-04
 => minimum loss: 1.222e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.142e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9430, Mean_loss of pinns: 2.630e-04, loss_BC: 1.784e-05, loss_IC: 7.864e-06, loss_f: 2.373e-04
 => minimum loss: 1.111e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.017e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  9433

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 8.235e-07, loss_BC: 0.000e+00, loss_IC: 9.130e-08,loss_f: 6.063e-07
pinn: 0000, Iter: 200, total_loss: 2.695e-07, loss_BC: 0.000e+00, loss_IC: 2.705e-08,loss_f: 1.218e-07
pinn: 0000, Iter: 300, total_loss: 2.116e-07, loss_BC: 0.000e+00, loss_IC: 1.574e-08,loss_f: 8.864e-08
pinn: 0000, Iter: 400, total_loss: 1.842e-07, loss_BC: 0.000e+00, loss_IC: 1.223e-08,loss_f: 6.881e-08
pinn: 0000, Iter: 500, total_loss: 1.763e-07, loss_BC: 0.000e+00, loss_IC: 1.194e-08,loss_f: 6.169e-08
pinn: 0000, Iter: 600, total_loss: 1.660e-07, loss_BC: 0.000e+00, loss_IC: 1.251e-08,loss_f: 5.363e-08
pinn: 0000, Iter: 700, total_loss: 1.590e-07, loss_BC: 0.000e+00, loss_IC: 1.235e-08,loss_f: 5.204e-08
pinn: 0000, Iter: 800, total_loss: 1.557e-07, loss_BC: 0.000e+00, loss_IC: 1.198e-08,loss_f: 5.223e-08
pinn: 0000, Iter: 900, total_loss: 1.521e-07, loss_BC: 0.000e+00, loss_IC: 1.233e-08,loss_f: 5.187e-08
pinn: 0000, Iter: 1000, total_loss: 1.481e-07, loss_BC: 0.000e+00, loss_IC: 1.335e-08,loss_f: 5.119e-08
pinn: 0000, Iter: 1100, total_loss: 1.379e-07, loss_BC: 0.000e+00, loss_IC: 1.533e-08,loss_f: 4.802e-08
pinn: 0000, Iter: 1200, total_loss: 1.318e-07, loss_BC: 0.000e+00, loss_IC: 1.473e-08,loss_f: 4.735e-08
pinn: 0000, Iter: 1300, total_loss: 1.268e-07, loss_BC: 0.000e+00, loss_IC: 1.430e-08,loss_f: 4.894e-08
pinn: 0000, Iter: 1400, total_loss: 1.257e-07, loss_BC: 0.000e+00, loss_IC: 1.434e-08,loss_f: 4.882e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9433, Mean_loss of pinns: 1.249e-07, loss_BC: 0.000e+00, loss_IC: 1.495e-08, loss_f: 4.903e-08
 => minimum loss: 1.249e-07, corresponding pinn index: 0000
 => maximum loss: 1.249e-07, corresponding pinn  index: 0000

 max_loss: 3.091e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9435, total_loss: 1.627e-05, loss_BC: 1.012e-05, loss_IC: 3.191e-07, loss_f: 5.806e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.90000, t_max: 0.91000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9436 0 1

 -------------------------------------------------------------
  -----  Epoch: 9436 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.90000, t_max: 0.91000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9436 !!! 


==> Epoch: 9440, Mean_loss of pinns: 8.965e-04, loss_BC: 1.053e-05, loss_IC: 1.212e-06, loss_f: 8.847e-04
 => minimum loss: 7.171e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.072e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 4
pinns above Threshold: 0000, 0100, 0200, 0300

==> Epoch: 9450, Mean_loss of pinns: 6.873e-04, loss_BC: 9.618e-06, loss_IC: 1.043e-05, loss_f: 6.672e-04
 => minimum loss: 5.879e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.636e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9460, Mean_loss of pinns: 5.451e-04, loss_BC: 9.215e-06, loss_IC: 2.189e-05, loss_f: 5.139e-04
 => minimum loss: 5.028e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.312e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9470, Mean_loss of pinns: 4.507e-04, loss_BC: 9.203e-06, loss_IC: 3.077e-05, loss_f: 4.107e-04
 => minimum loss: 4.366e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.074e-03, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9480, Mean_loss of pinns: 3.834e-04, loss_BC: 9.421e-06, loss_IC: 3.275e-05, loss_f: 3.412e-04
 => minimum loss: 3.912e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.975e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9490, Mean_loss of pinns: 3.316e-04, loss_BC: 1.029e-05, loss_IC: 3.007e-05, loss_f: 2.912e-04
 => minimum loss: 3.704e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.644e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9500, Mean_loss of pinns: 2.891e-04, loss_BC: 1.030e-05, loss_IC: 2.554e-05, loss_f: 2.532e-04
 => minimum loss: 3.461e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.578e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9510, Mean_loss of pinns: 2.538e-04, loss_BC: 9.847e-06, loss_IC: 2.080e-05, loss_f: 2.231e-04
 => minimum loss: 3.259e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.723e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9520, Mean_loss of pinns: 2.246e-04, loss_BC: 9.290e-06, loss_IC: 1.684e-05, loss_f: 1.984e-04
 => minimum loss: 3.067e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.021e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9530, Mean_loss of pinns: 2.004e-04, loss_BC: 8.911e-06, loss_IC: 1.373e-05, loss_f: 1.777e-04
 => minimum loss: 2.953e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.443e-04, corresponding pinn/batch  index: 0200
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  9535

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0300, Iter: 100, total_loss: 5.364e-07, loss_BC: 0.000e+00, loss_IC: 9.223e-08,loss_f: 4.442e-07
pinn: 0100, Iter: 100, total_loss: 5.538e-07, loss_BC: 0.000e+00, loss_IC: 9.734e-08,loss_f: 4.565e-07
pinn: 0200, Iter: 100, total_loss: 8.198e-07, loss_BC: 0.000e+00, loss_IC: 1.348e-07,loss_f: 5.957e-07
pinn: 0300, Iter: 200, total_loss: 1.498e-07, loss_BC: 0.000e+00, loss_IC: 1.729e-08,loss_f: 1.325e-07
pinn: 0100, Iter: 200, total_loss: 1.537e-07, loss_BC: 0.000e+00, loss_IC: 2.674e-08,loss_f: 1.269e-07
pinn: 0200, Iter: 200, total_loss: 2.873e-07, loss_BC: 0.000e+00, loss_IC: 4.313e-08,loss_f: 1.614e-07
pinn: 0300, Iter: 300, total_loss: 5.431e-08, loss_BC: 0.000e+00, loss_IC: 1.522e-08,loss_f: 3.908e-08
pinn: 0100, Iter: 300, total_loss: 8.884e-08, loss_BC: 0.000e+00, loss_IC: 1.638e-08,loss_f: 7.246e-08
pinn: 0200, Iter: 300, total_loss: 1.953e-07, loss_BC: 0.000e+00, loss_IC: 2.651e-08,loss_f: 8.921e-08
pinn: 0300, Iter: 400, total_loss: 3.640e-08, loss_BC: 0.000e+00, loss_IC: 4.826e-09,loss_f: 3.157e-08
pinn: 0100, Iter: 400, total_loss: 7.978e-08, loss_BC: 0.000e+00, loss_IC: 1.325e-08,loss_f: 6.654e-08
pinn: 0200, Iter: 400, total_loss: 1.744e-07, loss_BC: 0.000e+00, loss_IC: 2.044e-08,loss_f: 7.595e-08
pinn: 0300, Iter: 500, total_loss: 3.151e-08, loss_BC: 0.000e+00, loss_IC: 3.620e-09,loss_f: 2.789e-08
pinn: 0100, Iter: 500, total_loss: 6.618e-08, loss_BC: 0.000e+00, loss_IC: 1.217e-08,loss_f: 5.401e-08
pinn: 0200, Iter: 500, total_loss: 1.633e-07, loss_BC: 0.000e+00, loss_IC: 1.593e-08,loss_f: 6.887e-08
pinn: 0300, Iter: 600, total_loss: 2.801e-08, loss_BC: 0.000e+00, loss_IC: 2.476e-09,loss_f: 2.554e-08
pinn: 0100, Iter: 600, total_loss: 6.021e-08, loss_BC: 0.000e+00, loss_IC: 1.096e-08,loss_f: 4.925e-08
pinn: 0200, Iter: 600, total_loss: 1.576e-07, loss_BC: 0.000e+00, loss_IC: 1.553e-08,loss_f: 6.487e-08
pinn: 0300, Iter: 700, total_loss: 2.532e-08, loss_BC: 0.000e+00, loss_IC: 1.872e-09,loss_f: 2.345e-08
pinn: 0100, Iter: 700, total_loss: 5.506e-08, loss_BC: 0.000e+00, loss_IC: 1.071e-08,loss_f: 4.435e-08
pinn: 0200, Iter: 700, total_loss: 1.546e-07, loss_BC: 0.000e+00, loss_IC: 1.570e-08,loss_f: 6.334e-08
pinn: 0300, Iter: 800, total_loss: 2.321e-08, loss_BC: 0.000e+00, loss_IC: 1.933e-09,loss_f: 2.128e-08
pinn: 0100, Iter: 800, total_loss: 5.117e-08, loss_BC: 0.000e+00, loss_IC: 9.424e-09,loss_f: 4.175e-08
pinn: 0200, Iter: 800, total_loss: 1.521e-07, loss_BC: 0.000e+00, loss_IC: 1.611e-08,loss_f: 6.125e-08
pinn: 0300, Iter: 900, total_loss: 2.170e-08, loss_BC: 0.000e+00, loss_IC: 1.958e-09,loss_f: 1.975e-08
pinn: 0100, Iter: 900, total_loss: 4.997e-08, loss_BC: 0.000e+00, loss_IC: 9.279e-09,loss_f: 4.069e-08
pinn: 0200, Iter: 900, total_loss: 1.495e-07, loss_BC: 0.000e+00, loss_IC: 1.600e-08,loss_f: 6.022e-08
pinn: 0300, Iter: 1000, total_loss: 2.037e-08, loss_BC: 0.000e+00, loss_IC: 1.932e-09,loss_f: 1.844e-08
pinn: 0100, Iter: 1000, total_loss: 4.761e-08, loss_BC: 0.000e+00, loss_IC: 8.735e-09,loss_f: 3.888e-08
pinn: 0200, Iter: 1000, total_loss: 1.454e-07, loss_BC: 0.000e+00, loss_IC: 1.372e-08,loss_f: 5.963e-08
pinn: 0300, Iter: 1100, total_loss: 2.007e-08, loss_BC: 0.000e+00, loss_IC: 1.962e-09,loss_f: 1.811e-08
pinn: 0100, Iter: 1100, total_loss: 4.573e-08, loss_BC: 0.000e+00, loss_IC: 8.148e-09,loss_f: 3.758e-08
pinn: 0200, Iter: 1100, total_loss: 1.423e-07, loss_BC: 0.000e+00, loss_IC: 1.310e-08,loss_f: 5.935e-08
pinn: 0300, Iter: 1200, total_loss: 1.944e-08, loss_BC: 0.000e+00, loss_IC: 2.048e-09,loss_f: 1.739e-08
pinn: 0100, Iter: 1200, total_loss: 4.538e-08, loss_BC: 0.000e+00, loss_IC: 8.082e-09,loss_f: 3.730e-08
pinn: 0200, Iter: 1200, total_loss: 1.410e-07, loss_BC: 0.000e+00, loss_IC: 1.258e-08,loss_f: 5.952e-08
pinn: 0300, Iter: 1300, total_loss: 1.933e-08, loss_BC: 0.000e+00, loss_IC: 2.088e-09,loss_f: 1.724e-08
pinn: 0100, Iter: 1300, total_loss: 4.325e-08, loss_BC: 0.000e+00, loss_IC: 7.650e-09,loss_f: 3.560e-08
pinn: 0200, Iter: 1300, total_loss: 1.367e-07, loss_BC: 0.000e+00, loss_IC: 1.325e-08,loss_f: 5.839e-08
pinn: 0300, Iter: 1400, total_loss: 1.867e-08, loss_BC: 0.000e+00, loss_IC: 2.012e-09,loss_f: 1.665e-08
pinn: 0100, Iter: 1400, total_loss: 4.282e-08, loss_BC: 0.000e+00, loss_IC: 7.353e-09,loss_f: 3.546e-08
pinn: 0200, Iter: 1400, total_loss: 1.335e-07, loss_BC: 0.000e+00, loss_IC: 1.304e-08,loss_f: 5.749e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9535, Mean_loss of pinns: 6.485e-08, loss_BC: 0.000e+00, loss_IC: 7.396e-09, loss_f: 3.651e-08
 => minimum loss: 1.859e-08, corresponding pinn index: 0300
 => maximum loss: 1.332e-07, corresponding pinn  index: 0200

 max_loss: 3.478e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9537, total_loss: 1.224e-05, loss_BC: 9.470e-06, loss_IC: 4.179e-07, loss_f: 2.332e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.91000, t_max: 0.92000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9538 0 1

 -------------------------------------------------------------
  -----  Epoch: 9538 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.91000, t_max: 0.92000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9538 !!! 


==> Epoch: 9540, Mean_loss of pinns: 2.275e-04, loss_BC: 1.192e-05, loss_IC: 1.170e-07, loss_f: 2.154e-04
 => minimum loss: 3.408e-05, corresponding pinn/batch index: 0200
 => maximum loss: 7.826e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9550, Mean_loss of pinns: 1.780e-04, loss_BC: 1.174e-05, loss_IC: 1.187e-06, loss_f: 1.650e-04
 => minimum loss: 2.588e-05, corresponding pinn/batch index: 0200
 => maximum loss: 6.115e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9560, Mean_loss of pinns: 1.454e-04, loss_BC: 1.401e-05, loss_IC: 1.569e-06, loss_f: 1.297e-04
 => minimum loss: 2.151e-05, corresponding pinn/batch index: 0200
 => maximum loss: 4.996e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9570, Mean_loss of pinns: 1.206e-04, loss_BC: 1.399e-05, loss_IC: 1.878e-06, loss_f: 1.047e-04
 => minimum loss: 1.766e-05, corresponding pinn/batch index: 0200
 => maximum loss: 4.142e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9580, Mean_loss of pinns: 1.022e-04, loss_BC: 1.376e-05, loss_IC: 1.595e-06, loss_f: 8.679e-05
 => minimum loss: 1.544e-05, corresponding pinn/batch index: 0200
 => maximum loss: 3.495e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9590, Mean_loss of pinns: 8.757e-05, loss_BC: 1.279e-05, loss_IC: 1.087e-06, loss_f: 7.362e-05
 => minimum loss: 1.366e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.978e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9600, Mean_loss of pinns: 7.571e-05, loss_BC: 1.147e-05, loss_IC: 7.124e-07, loss_f: 6.345e-05
 => minimum loss: 1.247e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.557e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9610, Mean_loss of pinns: 6.630e-05, loss_BC: 1.046e-05, loss_IC: 5.592e-07, loss_f: 5.521e-05
 => minimum loss: 1.226e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.214e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9620, Mean_loss of pinns: 5.921e-05, loss_BC: 1.025e-05, loss_IC: 5.201e-07, loss_f: 4.837e-05
 => minimum loss: 1.160e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.960e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9630, Mean_loss of pinns: 5.308e-05, loss_BC: 9.783e-06, loss_IC: 5.130e-07, loss_f: 4.271e-05
 => minimum loss: 1.064e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.748e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  9637

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 7.414e-07, loss_BC: 0.000e+00, loss_IC: 1.624e-07,loss_f: 5.791e-07
pinn: 0000, Iter: 200, total_loss: 1.085e-07, loss_BC: 0.000e+00, loss_IC: 1.051e-08,loss_f: 9.796e-08
pinn: 0000, Iter: 300, total_loss: 4.891e-08, loss_BC: 0.000e+00, loss_IC: 7.711e-09,loss_f: 4.120e-08
pinn: 0000, Iter: 400, total_loss: 2.879e-08, loss_BC: 0.000e+00, loss_IC: 3.408e-09,loss_f: 2.538e-08
pinn: 0000, Iter: 500, total_loss: 2.324e-08, loss_BC: 0.000e+00, loss_IC: 3.292e-09,loss_f: 1.995e-08
pinn: 0000, Iter: 600, total_loss: 2.140e-08, loss_BC: 0.000e+00, loss_IC: 3.045e-09,loss_f: 1.835e-08
pinn: 0000, Iter: 700, total_loss: 2.035e-08, loss_BC: 0.000e+00, loss_IC: 3.085e-09,loss_f: 1.727e-08
pinn: 0000, Iter: 800, total_loss: 1.972e-08, loss_BC: 0.000e+00, loss_IC: 3.051e-09,loss_f: 1.667e-08
pinn: 0000, Iter: 900, total_loss: 1.855e-08, loss_BC: 0.000e+00, loss_IC: 2.927e-09,loss_f: 1.562e-08
pinn: 0000, Iter: 1000, total_loss: 1.793e-08, loss_BC: 0.000e+00, loss_IC: 2.897e-09,loss_f: 1.503e-08
pinn: 0000, Iter: 1100, total_loss: 1.680e-08, loss_BC: 0.000e+00, loss_IC: 3.021e-09,loss_f: 1.378e-08
pinn: 0000, Iter: 1200, total_loss: 1.601e-08, loss_BC: 0.000e+00, loss_IC: 3.006e-09,loss_f: 1.300e-08
pinn: 0000, Iter: 1300, total_loss: 1.590e-08, loss_BC: 0.000e+00, loss_IC: 3.008e-09,loss_f: 1.289e-08
pinn: 0000, Iter: 1400, total_loss: 1.551e-08, loss_BC: 0.000e+00, loss_IC: 2.969e-09,loss_f: 1.254e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9637, Mean_loss of pinns: 1.549e-08, loss_BC: 0.000e+00, loss_IC: 2.944e-09, loss_f: 1.254e-08
 => minimum loss: 1.549e-08, corresponding pinn index: 0000
 => maximum loss: 1.549e-08, corresponding pinn  index: 0000

 max_loss: 3.158e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9639, total_loss: 1.652e-05, loss_BC: 1.088e-05, loss_IC: 3.329e-07, loss_f: 5.229e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.92000, t_max: 0.93000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9640 0 1

 -------------------------------------------------------------
  -----  Epoch: 9640 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.92000, t_max: 0.93000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9640 !!! 


==> Epoch: 9640, Mean_loss of pinns: 1.416e-03, loss_BC: 1.272e-05, loss_IC: 0.000e+00, loss_f: 1.403e-03
 => minimum loss: 6.717e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.679e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9650, Mean_loss of pinns: 1.015e-03, loss_BC: 1.006e-05, loss_IC: 8.004e-06, loss_f: 9.968e-04
 => minimum loss: 5.164e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.911e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9660, Mean_loss of pinns: 7.639e-04, loss_BC: 8.330e-06, loss_IC: 2.582e-05, loss_f: 7.297e-04
 => minimum loss: 4.068e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.416e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9670, Mean_loss of pinns: 6.086e-04, loss_BC: 7.528e-06, loss_IC: 4.432e-05, loss_f: 5.567e-04
 => minimum loss: 3.454e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.113e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9680, Mean_loss of pinns: 5.088e-04, loss_BC: 7.661e-06, loss_IC: 5.600e-05, loss_f: 4.451e-04
 => minimum loss: 3.033e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.267e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9690, Mean_loss of pinns: 4.396e-04, loss_BC: 8.269e-06, loss_IC: 5.927e-05, loss_f: 3.720e-04
 => minimum loss: 2.809e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.049e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9700, Mean_loss of pinns: 3.851e-04, loss_BC: 7.871e-06, loss_IC: 5.605e-05, loss_f: 3.212e-04
 => minimum loss: 2.464e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.125e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9710, Mean_loss of pinns: 3.408e-04, loss_BC: 7.852e-06, loss_IC: 4.932e-05, loss_f: 2.836e-04
 => minimum loss: 2.440e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.360e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9720, Mean_loss of pinns: 3.039e-04, loss_BC: 8.128e-06, loss_IC: 4.154e-05, loss_f: 2.542e-04
 => minimum loss: 2.471e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.711e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9730, Mean_loss of pinns: 2.718e-04, loss_BC: 7.502e-06, loss_IC: 3.440e-05, loss_f: 2.299e-04
 => minimum loss: 2.338e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.141e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  9739

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 1.102e-06, loss_BC: 0.000e+00, loss_IC: 1.319e-07,loss_f: 9.701e-07
pinn: 0300, Iter: 100, total_loss: 7.058e-07, loss_BC: 0.000e+00, loss_IC: 1.587e-07,loss_f: 5.471e-07
pinn: 0100, Iter: 100, total_loss: 5.752e-07, loss_BC: 0.000e+00, loss_IC: 1.230e-07,loss_f: 4.521e-07
pinn: 0200, Iter: 200, total_loss: 2.457e-07, loss_BC: 0.000e+00, loss_IC: 5.974e-08,loss_f: 1.860e-07
pinn: 0300, Iter: 200, total_loss: 1.464e-07, loss_BC: 0.000e+00, loss_IC: 2.214e-08,loss_f: 1.243e-07
pinn: 0100, Iter: 200, total_loss: 2.895e-07, loss_BC: 0.000e+00, loss_IC: 2.682e-08,loss_f: 2.627e-07
pinn: 0200, Iter: 300, total_loss: 1.024e-07, loss_BC: 0.000e+00, loss_IC: 2.819e-08,loss_f: 7.416e-08
pinn: 0300, Iter: 300, total_loss: 5.086e-08, loss_BC: 0.000e+00, loss_IC: 1.184e-08,loss_f: 3.902e-08
pinn: 0100, Iter: 300, total_loss: 4.948e-08, loss_BC: 0.000e+00, loss_IC: 5.689e-09,loss_f: 4.379e-08
pinn: 0200, Iter: 400, total_loss: 7.701e-08, loss_BC: 0.000e+00, loss_IC: 1.903e-08,loss_f: 5.798e-08
pinn: 0300, Iter: 400, total_loss: 2.856e-08, loss_BC: 0.000e+00, loss_IC: 6.009e-09,loss_f: 2.255e-08
pinn: 0100, Iter: 400, total_loss: 3.873e-08, loss_BC: 0.000e+00, loss_IC: 6.003e-09,loss_f: 3.273e-08
pinn: 0200, Iter: 500, total_loss: 6.325e-08, loss_BC: 0.000e+00, loss_IC: 1.730e-08,loss_f: 4.595e-08
pinn: 0300, Iter: 500, total_loss: 2.466e-08, loss_BC: 0.000e+00, loss_IC: 5.927e-09,loss_f: 1.874e-08
pinn: 0100, Iter: 500, total_loss: 3.398e-08, loss_BC: 0.000e+00, loss_IC: 7.048e-09,loss_f: 2.694e-08
pinn: 0200, Iter: 600, total_loss: 6.009e-08, loss_BC: 0.000e+00, loss_IC: 1.668e-08,loss_f: 4.340e-08
pinn: 0300, Iter: 600, total_loss: 2.276e-08, loss_BC: 0.000e+00, loss_IC: 5.120e-09,loss_f: 1.764e-08
pinn: 0100, Iter: 600, total_loss: 3.290e-08, loss_BC: 0.000e+00, loss_IC: 7.125e-09,loss_f: 2.578e-08
pinn: 0200, Iter: 700, total_loss: 5.920e-08, loss_BC: 0.000e+00, loss_IC: 1.645e-08,loss_f: 4.275e-08
pinn: 0300, Iter: 700, total_loss: 2.126e-08, loss_BC: 0.000e+00, loss_IC: 4.688e-09,loss_f: 1.657e-08
pinn: 0100, Iter: 700, total_loss: 3.073e-08, loss_BC: 0.000e+00, loss_IC: 7.805e-09,loss_f: 2.292e-08
pinn: 0200, Iter: 800, total_loss: 5.867e-08, loss_BC: 0.000e+00, loss_IC: 1.625e-08,loss_f: 4.242e-08
pinn: 0300, Iter: 800, total_loss: 2.009e-08, loss_BC: 0.000e+00, loss_IC: 4.449e-09,loss_f: 1.564e-08
pinn: 0100, Iter: 800, total_loss: 3.034e-08, loss_BC: 0.000e+00, loss_IC: 7.932e-09,loss_f: 2.241e-08
pinn: 0200, Iter: 900, total_loss: 5.743e-08, loss_BC: 0.000e+00, loss_IC: 1.541e-08,loss_f: 4.202e-08
pinn: 0300, Iter: 900, total_loss: 1.913e-08, loss_BC: 0.000e+00, loss_IC: 4.189e-09,loss_f: 1.494e-08
pinn: 0100, Iter: 900, total_loss: 2.970e-08, loss_BC: 0.000e+00, loss_IC: 8.022e-09,loss_f: 2.168e-08
pinn: 0200, Iter: 1000, total_loss: 5.674e-08, loss_BC: 0.000e+00, loss_IC: 1.524e-08,loss_f: 4.150e-08
pinn: 0300, Iter: 1000, total_loss: 1.878e-08, loss_BC: 0.000e+00, loss_IC: 4.073e-09,loss_f: 1.471e-08
pinn: 0100, Iter: 1000, total_loss: 2.962e-08, loss_BC: 0.000e+00, loss_IC: 7.943e-09,loss_f: 2.167e-08
pinn: 0200, Iter: 1100, total_loss: 5.615e-08, loss_BC: 0.000e+00, loss_IC: 1.472e-08,loss_f: 4.143e-08
pinn: 0300, Iter: 1100, total_loss: 1.809e-08, loss_BC: 0.000e+00, loss_IC: 3.761e-09,loss_f: 1.433e-08
pinn: 0100, Iter: 1100, total_loss: 2.794e-08, loss_BC: 0.000e+00, loss_IC: 7.608e-09,loss_f: 2.033e-08
pinn: 0200, Iter: 1200, total_loss: 5.489e-08, loss_BC: 0.000e+00, loss_IC: 1.446e-08,loss_f: 4.043e-08
pinn: 0300, Iter: 1200, total_loss: 1.785e-08, loss_BC: 0.000e+00, loss_IC: 3.742e-09,loss_f: 1.411e-08
pinn: 0100, Iter: 1200, total_loss: 2.774e-08, loss_BC: 0.000e+00, loss_IC: 7.339e-09,loss_f: 2.040e-08
pinn: 0200, Iter: 1300, total_loss: 5.366e-08, loss_BC: 0.000e+00, loss_IC: 1.363e-08,loss_f: 4.003e-08
pinn: 0300, Iter: 1300, total_loss: 1.758e-08, loss_BC: 0.000e+00, loss_IC: 3.520e-09,loss_f: 1.406e-08
pinn: 0100, Iter: 1300, total_loss: 2.726e-08, loss_BC: 0.000e+00, loss_IC: 7.144e-09,loss_f: 2.011e-08
pinn: 0200, Iter: 1400, total_loss: 5.331e-08, loss_BC: 0.000e+00, loss_IC: 1.330e-08,loss_f: 4.001e-08
pinn: 0300, Iter: 1400, total_loss: 1.744e-08, loss_BC: 0.000e+00, loss_IC: 3.443e-09,loss_f: 1.400e-08
pinn: 0100, Iter: 1400, total_loss: 2.660e-08, loss_BC: 0.000e+00, loss_IC: 6.923e-09,loss_f: 1.968e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9739, Mean_loss of pinns: 3.188e-08, loss_BC: 0.000e+00, loss_IC: 7.648e-09, loss_f: 2.423e-08
 => minimum loss: 1.654e-08, corresponding pinn index: 0300
 => maximum loss: 5.250e-08, corresponding pinn  index: 0200

==> Epoch: 9740, Mean_loss of pinns: 1.181e-05, loss_BC: 1.002e-05, loss_IC: 1.817e-07, loss_f: 1.617e-06
 => minimum loss: 2.475e-06, corresponding pinn/batch index: 0100
 => maximum loss: 3.283e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 3.228e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9741, total_loss: 1.191e-05, loss_BC: 1.009e-05, loss_IC: 2.143e-07, loss_f: 1.607e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.93000, t_max: 0.94000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9742 0 1

 -------------------------------------------------------------
  -----  Epoch: 9742 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.93000, t_max: 0.94000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9742 !!! 


==> Epoch: 9750, Mean_loss of pinns: 8.667e-04, loss_BC: 1.266e-05, loss_IC: 3.777e-07, loss_f: 8.537e-04
 => minimum loss: 1.687e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.400e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9760, Mean_loss of pinns: 7.026e-04, loss_BC: 1.399e-05, loss_IC: 1.301e-06, loss_f: 6.873e-04
 => minimum loss: 1.432e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.754e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9770, Mean_loss of pinns: 5.742e-04, loss_BC: 1.598e-05, loss_IC: 2.859e-06, loss_f: 5.554e-04
 => minimum loss: 1.266e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.248e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9780, Mean_loss of pinns: 4.755e-04, loss_BC: 1.755e-05, loss_IC: 4.510e-06, loss_f: 4.534e-04
 => minimum loss: 1.089e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.859e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9790, Mean_loss of pinns: 3.990e-04, loss_BC: 1.756e-05, loss_IC: 5.614e-06, loss_f: 3.758e-04
 => minimum loss: 9.990e-06, corresponding pinn/batch index: 0100
 => maximum loss: 1.558e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9800, Mean_loss of pinns: 3.409e-04, loss_BC: 1.813e-05, loss_IC: 5.969e-06, loss_f: 3.168e-04
 => minimum loss: 9.201e-06, corresponding pinn/batch index: 0100
 => maximum loss: 1.328e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9810, Mean_loss of pinns: 2.945e-04, loss_BC: 1.756e-05, loss_IC: 5.709e-06, loss_f: 2.712e-04
 => minimum loss: 8.318e-06, corresponding pinn/batch index: 0100
 => maximum loss: 1.146e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9820, Mean_loss of pinns: 2.566e-04, loss_BC: 1.604e-05, loss_IC: 5.126e-06, loss_f: 2.354e-04
 => minimum loss: 7.648e-06, corresponding pinn/batch index: 0100
 => maximum loss: 9.961e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9830, Mean_loss of pinns: 2.257e-04, loss_BC: 1.461e-05, loss_IC: 4.437e-06, loss_f: 2.067e-04
 => minimum loss: 7.257e-06, corresponding pinn/batch index: 0100
 => maximum loss: 8.750e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9840, Mean_loss of pinns: 2.011e-04, loss_BC: 1.417e-05, loss_IC: 3.763e-06, loss_f: 1.832e-04
 => minimum loss: 6.885e-06, corresponding pinn/batch index: 0100
 => maximum loss: 7.772e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  9841

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 5.666e-07, loss_BC: 0.000e+00, loss_IC: 1.056e-07,loss_f: 4.610e-07
pinn: 0000, Iter: 200, total_loss: 1.492e-07, loss_BC: 0.000e+00, loss_IC: 5.583e-08,loss_f: 9.342e-08
pinn: 0000, Iter: 300, total_loss: 9.659e-08, loss_BC: 0.000e+00, loss_IC: 2.969e-08,loss_f: 6.690e-08
pinn: 0000, Iter: 400, total_loss: 7.287e-08, loss_BC: 0.000e+00, loss_IC: 2.020e-08,loss_f: 5.267e-08
pinn: 0000, Iter: 500, total_loss: 6.011e-08, loss_BC: 0.000e+00, loss_IC: 1.821e-08,loss_f: 4.190e-08
pinn: 0000, Iter: 600, total_loss: 5.478e-08, loss_BC: 0.000e+00, loss_IC: 1.636e-08,loss_f: 3.842e-08
pinn: 0000, Iter: 700, total_loss: 5.220e-08, loss_BC: 0.000e+00, loss_IC: 1.516e-08,loss_f: 3.704e-08
pinn: 0000, Iter: 800, total_loss: 4.947e-08, loss_BC: 0.000e+00, loss_IC: 1.432e-08,loss_f: 3.515e-08
pinn: 0000, Iter: 900, total_loss: 4.787e-08, loss_BC: 0.000e+00, loss_IC: 1.389e-08,loss_f: 3.398e-08
pinn: 0000, Iter: 1000, total_loss: 4.694e-08, loss_BC: 0.000e+00, loss_IC: 1.361e-08,loss_f: 3.334e-08
pinn: 0000, Iter: 1100, total_loss: 4.685e-08, loss_BC: 0.000e+00, loss_IC: 1.356e-08,loss_f: 3.329e-08
pinn: 0000, Iter: 1200, total_loss: 4.562e-08, loss_BC: 0.000e+00, loss_IC: 1.310e-08,loss_f: 3.252e-08
pinn: 0000, Iter: 1300, total_loss: 4.552e-08, loss_BC: 0.000e+00, loss_IC: 1.313e-08,loss_f: 3.239e-08
pinn: 0000, Iter: 1400, total_loss: 4.297e-08, loss_BC: 0.000e+00, loss_IC: 1.189e-08,loss_f: 3.108e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9841, Mean_loss of pinns: 4.237e-08, loss_BC: 0.000e+00, loss_IC: 1.161e-08, loss_f: 3.076e-08
 => minimum loss: 4.237e-08, corresponding pinn index: 0000
 => maximum loss: 4.237e-08, corresponding pinn  index: 0000

 max_loss: 3.048e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9843, total_loss: 1.422e-05, loss_BC: 1.059e-05, loss_IC: 2.713e-07, loss_f: 3.356e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.94000, t_max: 0.95000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9844 0 1

 -------------------------------------------------------------
  -----  Epoch: 9844 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.94000, t_max: 0.95000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9844 !!! 


==> Epoch: 9850, Mean_loss of pinns: 7.518e-04, loss_BC: 1.070e-05, loss_IC: 2.836e-06, loss_f: 7.383e-04
 => minimum loss: 5.974e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.551e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9860, Mean_loss of pinns: 5.732e-04, loss_BC: 9.635e-06, loss_IC: 1.491e-05, loss_f: 5.487e-04
 => minimum loss: 4.825e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.177e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9870, Mean_loss of pinns: 4.540e-04, loss_BC: 8.544e-06, loss_IC: 2.832e-05, loss_f: 4.171e-04
 => minimum loss: 3.941e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.114e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9880, Mean_loss of pinns: 3.782e-04, loss_BC: 8.562e-06, loss_IC: 3.651e-05, loss_f: 3.331e-04
 => minimum loss: 3.426e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.533e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9890, Mean_loss of pinns: 3.246e-04, loss_BC: 8.735e-06, loss_IC: 3.809e-05, loss_f: 2.778e-04
 => minimum loss: 2.899e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.496e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9900, Mean_loss of pinns: 2.834e-04, loss_BC: 9.119e-06, loss_IC: 3.481e-05, loss_f: 2.395e-04
 => minimum loss: 2.712e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.727e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9910, Mean_loss of pinns: 2.494e-04, loss_BC: 8.862e-06, loss_IC: 2.951e-05, loss_f: 2.110e-04
 => minimum loss: 2.593e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.091e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9920, Mean_loss of pinns: 2.212e-04, loss_BC: 8.769e-06, loss_IC: 2.413e-05, loss_f: 1.883e-04
 => minimum loss: 2.595e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.544e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9930, Mean_loss of pinns: 1.973e-04, loss_BC: 8.420e-06, loss_IC: 1.953e-05, loss_f: 1.694e-04
 => minimum loss: 2.614e-05, corresponding pinn/batch index: 0000
 => maximum loss: 4.064e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 9940, Mean_loss of pinns: 1.773e-04, loss_BC: 8.261e-06, loss_IC: 1.605e-05, loss_f: 1.530e-04
 => minimum loss: 2.592e-05, corresponding pinn/batch index: 0000
 => maximum loss: 3.658e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  9943

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0200, Iter: 100, total_loss: 7.080e-07, loss_BC: 0.000e+00, loss_IC: 1.615e-07,loss_f: 5.465e-07
pinn: 0300, Iter: 100, total_loss: 3.959e-07, loss_BC: 0.000e+00, loss_IC: 1.450e-07,loss_f: 2.508e-07
pinn: 0100, Iter: 100, total_loss: 8.017e-07, loss_BC: 0.000e+00, loss_IC: 2.249e-07,loss_f: 5.768e-07
pinn: 0200, Iter: 200, total_loss: 1.653e-07, loss_BC: 0.000e+00, loss_IC: 5.936e-08,loss_f: 1.060e-07
pinn: 0300, Iter: 200, total_loss: 1.037e-07, loss_BC: 0.000e+00, loss_IC: 3.350e-08,loss_f: 7.021e-08
pinn: 0100, Iter: 200, total_loss: 9.234e-08, loss_BC: 0.000e+00, loss_IC: 1.226e-08,loss_f: 8.009e-08
pinn: 0200, Iter: 300, total_loss: 7.915e-08, loss_BC: 0.000e+00, loss_IC: 2.616e-08,loss_f: 5.298e-08
pinn: 0300, Iter: 300, total_loss: 6.532e-08, loss_BC: 0.000e+00, loss_IC: 1.878e-08,loss_f: 4.654e-08
pinn: 0100, Iter: 300, total_loss: 5.191e-08, loss_BC: 0.000e+00, loss_IC: 1.108e-08,loss_f: 4.083e-08
pinn: 0200, Iter: 400, total_loss: 5.929e-08, loss_BC: 0.000e+00, loss_IC: 2.044e-08,loss_f: 3.885e-08
pinn: 0300, Iter: 400, total_loss: 5.840e-08, loss_BC: 0.000e+00, loss_IC: 1.424e-08,loss_f: 4.416e-08
pinn: 0100, Iter: 400, total_loss: 3.655e-08, loss_BC: 0.000e+00, loss_IC: 7.775e-09,loss_f: 2.877e-08
pinn: 0200, Iter: 500, total_loss: 5.049e-08, loss_BC: 0.000e+00, loss_IC: 1.426e-08,loss_f: 3.623e-08
pinn: 0300, Iter: 500, total_loss: 5.143e-08, loss_BC: 0.000e+00, loss_IC: 1.154e-08,loss_f: 3.989e-08
pinn: 0100, Iter: 500, total_loss: 3.387e-08, loss_BC: 0.000e+00, loss_IC: 8.030e-09,loss_f: 2.584e-08
pinn: 0200, Iter: 600, total_loss: 4.521e-08, loss_BC: 0.000e+00, loss_IC: 1.155e-08,loss_f: 3.366e-08
pinn: 0300, Iter: 600, total_loss: 4.419e-08, loss_BC: 0.000e+00, loss_IC: 6.092e-09,loss_f: 3.810e-08
pinn: 0100, Iter: 600, total_loss: 3.180e-08, loss_BC: 0.000e+00, loss_IC: 7.676e-09,loss_f: 2.413e-08
pinn: 0200, Iter: 700, total_loss: 4.354e-08, loss_BC: 0.000e+00, loss_IC: 1.093e-08,loss_f: 3.261e-08
pinn: 0300, Iter: 700, total_loss: 4.295e-08, loss_BC: 0.000e+00, loss_IC: 5.662e-09,loss_f: 3.729e-08
pinn: 0100, Iter: 700, total_loss: 2.870e-08, loss_BC: 0.000e+00, loss_IC: 7.112e-09,loss_f: 2.159e-08
pinn: 0200, Iter: 800, total_loss: 4.303e-08, loss_BC: 0.000e+00, loss_IC: 1.048e-08,loss_f: 3.256e-08
pinn: 0300, Iter: 800, total_loss: 4.045e-08, loss_BC: 0.000e+00, loss_IC: 5.162e-09,loss_f: 3.529e-08
pinn: 0100, Iter: 800, total_loss: 2.816e-08, loss_BC: 0.000e+00, loss_IC: 7.219e-09,loss_f: 2.094e-08
pinn: 0200, Iter: 900, total_loss: 4.229e-08, loss_BC: 0.000e+00, loss_IC: 1.034e-08,loss_f: 3.195e-08
pinn: 0300, Iter: 900, total_loss: 3.778e-08, loss_BC: 0.000e+00, loss_IC: 4.806e-09,loss_f: 3.297e-08
pinn: 0100, Iter: 900, total_loss: 2.734e-08, loss_BC: 0.000e+00, loss_IC: 6.974e-09,loss_f: 2.036e-08
pinn: 0200, Iter: 1000, total_loss: 4.167e-08, loss_BC: 0.000e+00, loss_IC: 1.023e-08,loss_f: 3.144e-08
pinn: 0300, Iter: 1000, total_loss: 3.505e-08, loss_BC: 0.000e+00, loss_IC: 4.223e-09,loss_f: 3.083e-08
pinn: 0100, Iter: 1000, total_loss: 2.680e-08, loss_BC: 0.000e+00, loss_IC: 6.477e-09,loss_f: 2.032e-08
pinn: 0200, Iter: 1100, total_loss: 4.023e-08, loss_BC: 0.000e+00, loss_IC: 1.015e-08,loss_f: 3.008e-08
pinn: 0300, Iter: 1100, total_loss: 3.470e-08, loss_BC: 0.000e+00, loss_IC: 4.117e-09,loss_f: 3.059e-08
pinn: 0100, Iter: 1100, total_loss: 2.580e-08, loss_BC: 0.000e+00, loss_IC: 6.063e-09,loss_f: 1.973e-08
pinn: 0200, Iter: 1200, total_loss: 3.904e-08, loss_BC: 0.000e+00, loss_IC: 9.933e-09,loss_f: 2.911e-08
pinn: 0300, Iter: 1200, total_loss: 3.349e-08, loss_BC: 0.000e+00, loss_IC: 4.164e-09,loss_f: 2.933e-08
pinn: 0100, Iter: 1200, total_loss: 2.553e-08, loss_BC: 0.000e+00, loss_IC: 5.817e-09,loss_f: 1.971e-08
pinn: 0200, Iter: 1300, total_loss: 3.891e-08, loss_BC: 0.000e+00, loss_IC: 9.831e-09,loss_f: 2.908e-08
pinn: 0300, Iter: 1300, total_loss: 3.174e-08, loss_BC: 0.000e+00, loss_IC: 3.655e-09,loss_f: 2.809e-08
pinn: 0200, Iter: 1400, total_loss: 3.762e-08, loss_BC: 0.000e+00, loss_IC: 9.322e-09,loss_f: 2.830e-08
pinn: 0100, Iter: 1300, total_loss: 2.536e-08, loss_BC: 0.000e+00, loss_IC: 5.607e-09,loss_f: 1.975e-08
pinn: 0300, Iter: 1400, total_loss: 3.077e-08, loss_BC: 0.000e+00, loss_IC: 3.545e-09,loss_f: 2.723e-08
pinn: 0100, Iter: 1400, total_loss: 2.449e-08, loss_BC: 0.000e+00, loss_IC: 5.300e-09,loss_f: 1.919e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 9943, Mean_loss of pinns: 3.094e-08, loss_BC: 0.000e+00, loss_IC: 6.052e-09, loss_f: 2.489e-08
 => minimum loss: 2.448e-08, corresponding pinn index: 0100
 => maximum loss: 3.760e-08, corresponding pinn  index: 0200

 max_loss: 3.407e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 9945, total_loss: 1.352e-05, loss_BC: 1.168e-05, loss_IC: 3.071e-07, loss_f: 1.538e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.95000, t_max: 0.96000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  9946 0 1

 -------------------------------------------------------------
  -----  Epoch: 9946 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.95000, t_max: 0.96000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  9946 !!! 


==> Epoch: 9950, Mean_loss of pinns: 6.621e-04, loss_BC: 1.355e-05, loss_IC: 2.175e-07, loss_f: 6.483e-04
 => minimum loss: 2.253e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.557e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9960, Mean_loss of pinns: 5.256e-04, loss_BC: 1.408e-05, loss_IC: 1.102e-06, loss_f: 5.104e-04
 => minimum loss: 1.851e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.025e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9970, Mean_loss of pinns: 4.230e-04, loss_BC: 1.550e-05, loss_IC: 2.330e-06, loss_f: 4.052e-04
 => minimum loss: 1.701e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.626e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9980, Mean_loss of pinns: 3.473e-04, loss_BC: 1.684e-05, loss_IC: 3.722e-06, loss_f: 3.267e-04
 => minimum loss: 1.450e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.330e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 9990, Mean_loss of pinns: 2.905e-04, loss_BC: 1.745e-05, loss_IC: 4.475e-06, loss_f: 2.686e-04
 => minimum loss: 1.356e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.109e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10000, Mean_loss of pinns: 2.468e-04, loss_BC: 1.707e-05, loss_IC: 4.492e-06, loss_f: 2.253e-04
 => minimum loss: 1.149e-05, corresponding pinn/batch index: 0200
 => maximum loss: 9.404e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10010, Mean_loss of pinns: 2.119e-04, loss_BC: 1.552e-05, loss_IC: 3.982e-06, loss_f: 1.924e-04
 => minimum loss: 1.110e-05, corresponding pinn/batch index: 0200
 => maximum loss: 8.047e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10020, Mean_loss of pinns: 1.844e-04, loss_BC: 1.436e-05, loss_IC: 3.263e-06, loss_f: 1.668e-04
 => minimum loss: 1.048e-05, corresponding pinn/batch index: 0200
 => maximum loss: 6.975e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10030, Mean_loss of pinns: 1.622e-04, loss_BC: 1.341e-05, loss_IC: 2.592e-06, loss_f: 1.462e-04
 => minimum loss: 9.628e-06, corresponding pinn/batch index: 0200
 => maximum loss: 6.120e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10040, Mean_loss of pinns: 1.436e-04, loss_BC: 1.219e-05, loss_IC: 2.071e-06, loss_f: 1.293e-04
 => minimum loss: 9.783e-06, corresponding pinn/batch index: 0200
 => maximum loss: 5.394e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  10045

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 8.818e-07, loss_BC: 0.000e+00, loss_IC: 3.936e-07,loss_f: 4.882e-07
pinn: 0000, Iter: 200, total_loss: 1.165e-07, loss_BC: 0.000e+00, loss_IC: 2.411e-08,loss_f: 9.235e-08
pinn: 0000, Iter: 300, total_loss: 5.855e-08, loss_BC: 0.000e+00, loss_IC: 9.640e-09,loss_f: 4.891e-08
pinn: 0000, Iter: 400, total_loss: 4.859e-08, loss_BC: 0.000e+00, loss_IC: 8.176e-09,loss_f: 4.042e-08
pinn: 0000, Iter: 500, total_loss: 4.534e-08, loss_BC: 0.000e+00, loss_IC: 7.418e-09,loss_f: 3.792e-08
pinn: 0000, Iter: 600, total_loss: 4.187e-08, loss_BC: 0.000e+00, loss_IC: 7.274e-09,loss_f: 3.459e-08
pinn: 0000, Iter: 700, total_loss: 4.028e-08, loss_BC: 0.000e+00, loss_IC: 7.539e-09,loss_f: 3.274e-08
pinn: 0000, Iter: 800, total_loss: 3.672e-08, loss_BC: 0.000e+00, loss_IC: 7.294e-09,loss_f: 2.942e-08
pinn: 0000, Iter: 900, total_loss: 3.595e-08, loss_BC: 0.000e+00, loss_IC: 7.538e-09,loss_f: 2.842e-08
pinn: 0000, Iter: 1000, total_loss: 3.416e-08, loss_BC: 0.000e+00, loss_IC: 6.750e-09,loss_f: 2.741e-08
pinn: 0000, Iter: 1100, total_loss: 3.340e-08, loss_BC: 0.000e+00, loss_IC: 6.698e-09,loss_f: 2.670e-08
pinn: 0000, Iter: 1200, total_loss: 3.177e-08, loss_BC: 0.000e+00, loss_IC: 5.973e-09,loss_f: 2.580e-08
pinn: 0000, Iter: 1300, total_loss: 3.044e-08, loss_BC: 0.000e+00, loss_IC: 5.417e-09,loss_f: 2.503e-08
pinn: 0000, Iter: 1400, total_loss: 2.950e-08, loss_BC: 0.000e+00, loss_IC: 5.018e-09,loss_f: 2.448e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 10045, Mean_loss of pinns: 2.940e-08, loss_BC: 0.000e+00, loss_IC: 4.968e-09, loss_f: 2.444e-08
 => minimum loss: 2.940e-08, corresponding pinn index: 0000
 => maximum loss: 2.940e-08, corresponding pinn  index: 0000

 max_loss: 2.801e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 10047, total_loss: 1.538e-05, loss_BC: 1.088e-05, loss_IC: 3.538e-07, loss_f: 4.145e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.96000, t_max: 0.97000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  10048 0 1

 -------------------------------------------------------------
  -----  Epoch: 10048 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.96000, t_max: 0.97000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  10048 !!! 


==> Epoch: 10050, Mean_loss of pinns: 1.255e-03, loss_BC: 1.267e-05, loss_IC: 4.080e-07, loss_f: 1.242e-03
 => minimum loss: 6.295e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.648e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10060, Mean_loss of pinns: 9.120e-04, loss_BC: 1.080e-05, loss_IC: 1.109e-05, loss_f: 8.901e-04
 => minimum loss: 5.146e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.886e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10070, Mean_loss of pinns: 6.914e-04, loss_BC: 1.036e-05, loss_IC: 2.996e-05, loss_f: 6.511e-04
 => minimum loss: 4.390e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.396e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10080, Mean_loss of pinns: 5.563e-04, loss_BC: 1.050e-05, loss_IC: 4.735e-05, loss_f: 4.985e-04
 => minimum loss: 3.833e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.105e-03, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10090, Mean_loss of pinns: 4.687e-04, loss_BC: 1.094e-05, loss_IC: 5.729e-05, loss_f: 4.004e-04
 => minimum loss: 3.403e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.264e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10100, Mean_loss of pinns: 4.057e-04, loss_BC: 1.133e-05, loss_IC: 5.828e-05, loss_f: 3.361e-04
 => minimum loss: 3.002e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.061e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10110, Mean_loss of pinns: 3.559e-04, loss_BC: 1.135e-05, loss_IC: 5.319e-05, loss_f: 2.914e-04
 => minimum loss: 2.793e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.131e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10120, Mean_loss of pinns: 3.147e-04, loss_BC: 1.100e-05, loss_IC: 4.552e-05, loss_f: 2.582e-04
 => minimum loss: 2.651e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.357e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10130, Mean_loss of pinns: 2.804e-04, loss_BC: 1.081e-05, loss_IC: 3.787e-05, loss_f: 2.317e-04
 => minimum loss: 2.535e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.703e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10140, Mean_loss of pinns: 2.514e-04, loss_BC: 1.038e-05, loss_IC: 3.141e-05, loss_f: 2.096e-04
 => minimum loss: 2.503e-05, corresponding pinn/batch index: 0000
 => maximum loss: 5.133e-04, corresponding pinn/batch  index: 0300
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  10147

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 6.724e-07, loss_BC: 0.000e+00, loss_IC: 3.655e-07,loss_f: 3.069e-07
pinn: 0300, Iter: 100, total_loss: 7.892e-07, loss_BC: 0.000e+00, loss_IC: 2.974e-07,loss_f: 4.918e-07
pinn: 0200, Iter: 100, total_loss: 1.134e-06, loss_BC: 0.000e+00, loss_IC: 1.914e-07,loss_f: 9.429e-07
pinn: 0200, Iter: 200, total_loss: 2.180e-07, loss_BC: 0.000e+00, loss_IC: 5.858e-08,loss_f: 1.594e-07
pinn: 0100, Iter: 200, total_loss: 1.395e-07, loss_BC: 0.000e+00, loss_IC: 3.462e-08,loss_f: 1.049e-07
pinn: 0300, Iter: 200, total_loss: 1.618e-07, loss_BC: 0.000e+00, loss_IC: 2.221e-08,loss_f: 1.396e-07
pinn: 0200, Iter: 300, total_loss: 1.163e-07, loss_BC: 0.000e+00, loss_IC: 3.098e-08,loss_f: 8.530e-08
pinn: 0100, Iter: 300, total_loss: 9.815e-08, loss_BC: 0.000e+00, loss_IC: 1.666e-08,loss_f: 8.149e-08
pinn: 0300, Iter: 300, total_loss: 5.610e-08, loss_BC: 0.000e+00, loss_IC: 1.423e-08,loss_f: 4.187e-08
pinn: 0200, Iter: 400, total_loss: 9.210e-08, loss_BC: 0.000e+00, loss_IC: 2.422e-08,loss_f: 6.787e-08
pinn: 0100, Iter: 400, total_loss: 8.322e-08, loss_BC: 0.000e+00, loss_IC: 1.405e-08,loss_f: 6.916e-08
pinn: 0300, Iter: 400, total_loss: 4.192e-08, loss_BC: 0.000e+00, loss_IC: 1.227e-08,loss_f: 2.964e-08
pinn: 0300, Iter: 500, total_loss: 3.769e-08, loss_BC: 0.000e+00, loss_IC: 1.251e-08,loss_f: 2.517e-08
pinn: 0100, Iter: 500, total_loss: 7.015e-08, loss_BC: 0.000e+00, loss_IC: 1.366e-08,loss_f: 5.649e-08
pinn: 0200, Iter: 500, total_loss: 7.629e-08, loss_BC: 0.000e+00, loss_IC: 1.796e-08,loss_f: 5.833e-08
pinn: 0100, Iter: 600, total_loss: 6.623e-08, loss_BC: 0.000e+00, loss_IC: 1.340e-08,loss_f: 5.283e-08
pinn: 0300, Iter: 600, total_loss: 3.223e-08, loss_BC: 0.000e+00, loss_IC: 8.920e-09,loss_f: 2.332e-08
pinn: 0200, Iter: 600, total_loss: 7.147e-08, loss_BC: 0.000e+00, loss_IC: 1.550e-08,loss_f: 5.597e-08
pinn: 0100, Iter: 700, total_loss: 6.020e-08, loss_BC: 0.000e+00, loss_IC: 1.164e-08,loss_f: 4.857e-08
pinn: 0300, Iter: 700, total_loss: 3.111e-08, loss_BC: 0.000e+00, loss_IC: 8.633e-09,loss_f: 2.247e-08
pinn: 0200, Iter: 700, total_loss: 6.817e-08, loss_BC: 0.000e+00, loss_IC: 1.385e-08,loss_f: 5.431e-08
pinn: 0100, Iter: 800, total_loss: 5.796e-08, loss_BC: 0.000e+00, loss_IC: 1.131e-08,loss_f: 4.665e-08
pinn: 0300, Iter: 800, total_loss: 2.953e-08, loss_BC: 0.000e+00, loss_IC: 8.036e-09,loss_f: 2.149e-08
pinn: 0200, Iter: 800, total_loss: 6.052e-08, loss_BC: 0.000e+00, loss_IC: 1.385e-08,loss_f: 4.667e-08
pinn: 0100, Iter: 900, total_loss: 5.590e-08, loss_BC: 0.000e+00, loss_IC: 1.134e-08,loss_f: 4.456e-08
pinn: 0300, Iter: 900, total_loss: 2.897e-08, loss_BC: 0.000e+00, loss_IC: 7.749e-09,loss_f: 2.123e-08
pinn: 0200, Iter: 900, total_loss: 5.474e-08, loss_BC: 0.000e+00, loss_IC: 1.289e-08,loss_f: 4.184e-08
pinn: 0100, Iter: 1000, total_loss: 5.351e-08, loss_BC: 0.000e+00, loss_IC: 1.066e-08,loss_f: 4.285e-08
pinn: 0300, Iter: 1000, total_loss: 2.698e-08, loss_BC: 0.000e+00, loss_IC: 6.878e-09,loss_f: 2.010e-08
pinn: 0200, Iter: 1000, total_loss: 5.339e-08, loss_BC: 0.000e+00, loss_IC: 1.240e-08,loss_f: 4.099e-08
pinn: 0100, Iter: 1100, total_loss: 5.134e-08, loss_BC: 0.000e+00, loss_IC: 8.875e-09,loss_f: 4.246e-08
pinn: 0200, Iter: 1100, total_loss: 5.236e-08, loss_BC: 0.000e+00, loss_IC: 1.206e-08,loss_f: 4.030e-08
pinn: 0300, Iter: 1100, total_loss: 2.576e-08, loss_BC: 0.000e+00, loss_IC: 6.412e-09,loss_f: 1.935e-08
pinn: 0100, Iter: 1200, total_loss: 4.894e-08, loss_BC: 0.000e+00, loss_IC: 8.556e-09,loss_f: 4.038e-08
pinn: 0300, Iter: 1200, total_loss: 2.442e-08, loss_BC: 0.000e+00, loss_IC: 5.656e-09,loss_f: 1.876e-08
pinn: 0200, Iter: 1200, total_loss: 4.973e-08, loss_BC: 0.000e+00, loss_IC: 1.131e-08,loss_f: 3.842e-08
pinn: 0100, Iter: 1300, total_loss: 4.876e-08, loss_BC: 0.000e+00, loss_IC: 8.493e-09,loss_f: 4.027e-08
pinn: 0300, Iter: 1300, total_loss: 2.428e-08, loss_BC: 0.000e+00, loss_IC: 5.540e-09,loss_f: 1.874e-08
pinn: 0200, Iter: 1300, total_loss: 4.930e-08, loss_BC: 0.000e+00, loss_IC: 1.111e-08,loss_f: 3.819e-08
pinn: 0100, Iter: 1400, total_loss: 4.802e-08, loss_BC: 0.000e+00, loss_IC: 8.414e-09,loss_f: 3.960e-08
pinn: 0300, Iter: 1400, total_loss: 2.349e-08, loss_BC: 0.000e+00, loss_IC: 5.588e-09,loss_f: 1.791e-08
pinn: 0200, Iter: 1400, total_loss: 4.749e-08, loss_BC: 0.000e+00, loss_IC: 1.107e-08,loss_f: 3.642e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 10147, Mean_loss of pinns: 3.901e-08, loss_BC: 0.000e+00, loss_IC: 8.145e-09, loss_f: 3.087e-08
 => minimum loss: 2.347e-08, corresponding pinn index: 0300
 => maximum loss: 4.705e-08, corresponding pinn  index: 0100

 max_loss: 3.307e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 10149, total_loss: 1.355e-05, loss_BC: 1.176e-05, loss_IC: 1.420e-07, loss_f: 1.642e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.97000, t_max: 0.98000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  10150 0 1

 -------------------------------------------------------------
  -----  Epoch: 10150 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.97000, t_max: 0.98000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  10150 !!! 


==> Epoch: 10150, Mean_loss of pinns: 8.508e-04, loss_BC: 1.521e-05, loss_IC: 0.000e+00, loss_f: 8.356e-04
 => minimum loss: 1.963e-05, corresponding pinn/batch index: 0100
 => maximum loss: 3.324e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10160, Mean_loss of pinns: 6.628e-04, loss_BC: 1.460e-05, loss_IC: 7.649e-07, loss_f: 6.475e-04
 => minimum loss: 1.676e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.587e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10170, Mean_loss of pinns: 5.249e-04, loss_BC: 1.703e-05, loss_IC: 2.292e-06, loss_f: 5.056e-04
 => minimum loss: 1.507e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.043e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10180, Mean_loss of pinns: 4.228e-04, loss_BC: 1.800e-05, loss_IC: 4.362e-06, loss_f: 4.004e-04
 => minimum loss: 1.384e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.639e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10190, Mean_loss of pinns: 3.492e-04, loss_BC: 1.970e-05, loss_IC: 6.036e-06, loss_f: 3.235e-04
 => minimum loss: 1.259e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.352e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10200, Mean_loss of pinns: 2.934e-04, loss_BC: 1.924e-05, loss_IC: 6.799e-06, loss_f: 2.674e-04
 => minimum loss: 1.167e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.133e-03, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10210, Mean_loss of pinns: 2.508e-04, loss_BC: 1.838e-05, loss_IC: 6.589e-06, loss_f: 2.259e-04
 => minimum loss: 1.110e-05, corresponding pinn/batch index: 0100
 => maximum loss: 9.649e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10220, Mean_loss of pinns: 2.180e-04, loss_BC: 1.786e-05, loss_IC: 5.776e-06, loss_f: 1.944e-04
 => minimum loss: 1.025e-05, corresponding pinn/batch index: 0100
 => maximum loss: 8.365e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10230, Mean_loss of pinns: 1.910e-04, loss_BC: 1.657e-05, loss_IC: 4.779e-06, loss_f: 1.697e-04
 => minimum loss: 9.183e-06, corresponding pinn/batch index: 0100
 => maximum loss: 7.308e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10240, Mean_loss of pinns: 1.684e-04, loss_BC: 1.483e-05, loss_IC: 3.859e-06, loss_f: 1.497e-04
 => minimum loss: 9.022e-06, corresponding pinn/batch index: 0100
 => maximum loss: 6.420e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  10249

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 7.502e-07, loss_BC: 0.000e+00, loss_IC: 2.893e-07,loss_f: 4.608e-07
pinn: 0000, Iter: 200, total_loss: 7.482e-08, loss_BC: 0.000e+00, loss_IC: 1.441e-08,loss_f: 6.041e-08
pinn: 0000, Iter: 300, total_loss: 4.313e-08, loss_BC: 0.000e+00, loss_IC: 7.377e-09,loss_f: 3.575e-08
pinn: 0000, Iter: 400, total_loss: 3.059e-08, loss_BC: 0.000e+00, loss_IC: 6.077e-09,loss_f: 2.451e-08
pinn: 0000, Iter: 500, total_loss: 2.859e-08, loss_BC: 0.000e+00, loss_IC: 5.746e-09,loss_f: 2.284e-08
pinn: 0000, Iter: 600, total_loss: 2.619e-08, loss_BC: 0.000e+00, loss_IC: 5.595e-09,loss_f: 2.059e-08
pinn: 0000, Iter: 700, total_loss: 2.426e-08, loss_BC: 0.000e+00, loss_IC: 6.011e-09,loss_f: 1.825e-08
pinn: 0000, Iter: 800, total_loss: 2.312e-08, loss_BC: 0.000e+00, loss_IC: 5.977e-09,loss_f: 1.714e-08
pinn: 0000, Iter: 900, total_loss: 2.225e-08, loss_BC: 0.000e+00, loss_IC: 6.269e-09,loss_f: 1.598e-08
pinn: 0000, Iter: 1000, total_loss: 2.136e-08, loss_BC: 0.000e+00, loss_IC: 6.140e-09,loss_f: 1.522e-08
pinn: 0000, Iter: 1100, total_loss: 2.115e-08, loss_BC: 0.000e+00, loss_IC: 6.111e-09,loss_f: 1.504e-08
pinn: 0000, Iter: 1200, total_loss: 2.051e-08, loss_BC: 0.000e+00, loss_IC: 6.018e-09,loss_f: 1.449e-08
pinn: 0000, Iter: 1300, total_loss: 2.039e-08, loss_BC: 0.000e+00, loss_IC: 6.111e-09,loss_f: 1.428e-08
pinn: 0000, Iter: 1400, total_loss: 1.917e-08, loss_BC: 0.000e+00, loss_IC: 5.589e-09,loss_f: 1.358e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 10249, Mean_loss of pinns: 1.915e-08, loss_BC: 0.000e+00, loss_IC: 5.534e-09, loss_f: 1.361e-08
 => minimum loss: 1.915e-08, corresponding pinn index: 0000
 => maximum loss: 1.915e-08, corresponding pinn  index: 0000

==> Epoch: 10250, Mean_loss of pinns: 1.476e-05, loss_BC: 1.160e-05, loss_IC: 4.147e-07, loss_f: 2.744e-06
 => minimum loss: 8.575e-06, corresponding pinn/batch index: 0100
 => maximum loss: 2.857e-05, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 0
pinns above Threshold: 

 max_loss: 2.883e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 10251, total_loss: 1.482e-05, loss_BC: 1.168e-05, loss_IC: 4.151e-07, loss_f: 2.723e-06

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.98000, t_max: 0.99000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  10252 0 1

 -------------------------------------------------------------
  -----  Epoch: 10252 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.98000, t_max: 0.99000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  10252 !!! 


==> Epoch: 10260, Mean_loss of pinns: 1.172e-03, loss_BC: 1.203e-05, loss_IC: 5.227e-06, loss_f: 1.154e-03
 => minimum loss: 3.906e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.932e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10270, Mean_loss of pinns: 8.967e-04, loss_BC: 9.723e-06, loss_IC: 2.108e-05, loss_f: 8.659e-04
 => minimum loss: 3.180e-05, corresponding pinn/batch index: 0000
 => maximum loss: 2.204e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10280, Mean_loss of pinns: 7.115e-04, loss_BC: 8.725e-06, loss_IC: 3.868e-05, loss_f: 6.641e-04
 => minimum loss: 2.623e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.704e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10290, Mean_loss of pinns: 5.916e-04, loss_BC: 8.787e-06, loss_IC: 5.267e-05, loss_f: 5.301e-04
 => minimum loss: 2.427e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.389e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10300, Mean_loss of pinns: 5.086e-04, loss_BC: 9.405e-06, loss_IC: 5.906e-05, loss_f: 4.402e-04
 => minimum loss: 2.296e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.181e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10310, Mean_loss of pinns: 4.468e-04, loss_BC: 9.934e-06, loss_IC: 5.924e-05, loss_f: 3.776e-04
 => minimum loss: 2.102e-05, corresponding pinn/batch index: 0000
 => maximum loss: 1.034e-03, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10320, Mean_loss of pinns: 3.966e-04, loss_BC: 9.742e-06, loss_IC: 5.535e-05, loss_f: 3.315e-04
 => minimum loss: 1.841e-05, corresponding pinn/batch index: 0000
 => maximum loss: 9.202e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10330, Mean_loss of pinns: 3.554e-04, loss_BC: 1.013e-05, loss_IC: 4.943e-05, loss_f: 2.959e-04
 => minimum loss: 1.749e-05, corresponding pinn/batch index: 0000
 => maximum loss: 8.265e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10340, Mean_loss of pinns: 3.198e-04, loss_BC: 9.863e-06, loss_IC: 4.312e-05, loss_f: 2.669e-04
 => minimum loss: 1.719e-05, corresponding pinn/batch index: 0000
 => maximum loss: 7.454e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

==> Epoch: 10350, Mean_loss of pinns: 2.889e-04, loss_BC: 9.322e-06, loss_IC: 3.720e-05, loss_f: 2.424e-04
 => minimum loss: 1.580e-05, corresponding pinn/batch index: 0000
 => maximum loss: 6.744e-04, corresponding pinn/batch  index: 0100
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 3
pinns above Threshold: 0100, 0200, 0300

 !!! Scipy optimize: !!! - Epoch:  10351

 ! Scipy iteration number:  1
Processes:  3
Number of pinns to optimize weights:  3
 !!! pinns to optimize ==> 0100, 0200, 0300


pinn: 0100, Iter: 100, total_loss: 7.600e-07, loss_BC: 0.000e+00, loss_IC: 4.126e-07,loss_f: 3.475e-07
pinn: 0300, Iter: 100, total_loss: 5.684e-07, loss_BC: 0.000e+00, loss_IC: 2.849e-07,loss_f: 2.835e-07
pinn: 0200, Iter: 100, total_loss: 8.924e-07, loss_BC: 0.000e+00, loss_IC: 1.028e-07,loss_f: 7.896e-07
pinn: 0100, Iter: 200, total_loss: 1.023e-07, loss_BC: 0.000e+00, loss_IC: 1.730e-08,loss_f: 8.496e-08
pinn: 0300, Iter: 200, total_loss: 9.077e-08, loss_BC: 0.000e+00, loss_IC: 1.233e-08,loss_f: 7.845e-08
pinn: 0200, Iter: 200, total_loss: 1.539e-07, loss_BC: 0.000e+00, loss_IC: 3.612e-08,loss_f: 1.178e-07
pinn: 0100, Iter: 300, total_loss: 5.079e-08, loss_BC: 0.000e+00, loss_IC: 1.059e-08,loss_f: 4.020e-08
pinn: 0200, Iter: 300, total_loss: 7.417e-08, loss_BC: 0.000e+00, loss_IC: 2.026e-08,loss_f: 5.391e-08
pinn: 0300, Iter: 300, total_loss: 4.742e-08, loss_BC: 0.000e+00, loss_IC: 6.506e-09,loss_f: 4.092e-08
pinn: 0100, Iter: 400, total_loss: 4.076e-08, loss_BC: 0.000e+00, loss_IC: 1.050e-08,loss_f: 3.027e-08
pinn: 0300, Iter: 400, total_loss: 3.081e-08, loss_BC: 0.000e+00, loss_IC: 6.793e-09,loss_f: 2.401e-08
pinn: 0200, Iter: 400, total_loss: 5.920e-08, loss_BC: 0.000e+00, loss_IC: 1.887e-08,loss_f: 4.034e-08
pinn: 0100, Iter: 500, total_loss: 3.897e-08, loss_BC: 0.000e+00, loss_IC: 1.035e-08,loss_f: 2.862e-08
pinn: 0300, Iter: 500, total_loss: 2.289e-08, loss_BC: 0.000e+00, loss_IC: 7.709e-09,loss_f: 1.518e-08
pinn: 0200, Iter: 500, total_loss: 4.974e-08, loss_BC: 0.000e+00, loss_IC: 1.784e-08,loss_f: 3.190e-08
pinn: 0100, Iter: 600, total_loss: 3.817e-08, loss_BC: 0.000e+00, loss_IC: 1.061e-08,loss_f: 2.756e-08
pinn: 0300, Iter: 600, total_loss: 1.995e-08, loss_BC: 0.000e+00, loss_IC: 6.639e-09,loss_f: 1.331e-08
pinn: 0200, Iter: 600, total_loss: 4.737e-08, loss_BC: 0.000e+00, loss_IC: 1.827e-08,loss_f: 2.910e-08
pinn: 0100, Iter: 700, total_loss: 3.690e-08, loss_BC: 0.000e+00, loss_IC: 9.941e-09,loss_f: 2.695e-08
pinn: 0300, Iter: 700, total_loss: 1.887e-08, loss_BC: 0.000e+00, loss_IC: 6.578e-09,loss_f: 1.229e-08
pinn: 0200, Iter: 700, total_loss: 4.321e-08, loss_BC: 0.000e+00, loss_IC: 1.673e-08,loss_f: 2.649e-08
pinn: 0100, Iter: 800, total_loss: 3.651e-08, loss_BC: 0.000e+00, loss_IC: 9.554e-09,loss_f: 2.695e-08
pinn: 0300, Iter: 800, total_loss: 1.763e-08, loss_BC: 0.000e+00, loss_IC: 6.468e-09,loss_f: 1.116e-08
pinn: 0200, Iter: 800, total_loss: 4.114e-08, loss_BC: 0.000e+00, loss_IC: 1.564e-08,loss_f: 2.550e-08
pinn: 0100, Iter: 900, total_loss: 3.617e-08, loss_BC: 0.000e+00, loss_IC: 9.329e-09,loss_f: 2.684e-08
pinn: 0300, Iter: 900, total_loss: 1.564e-08, loss_BC: 0.000e+00, loss_IC: 6.006e-09,loss_f: 9.631e-09
pinn: 0200, Iter: 900, total_loss: 3.958e-08, loss_BC: 0.000e+00, loss_IC: 1.454e-08,loss_f: 2.504e-08
pinn: 0100, Iter: 1000, total_loss: 3.507e-08, loss_BC: 0.000e+00, loss_IC: 9.013e-09,loss_f: 2.606e-08
pinn: 0300, Iter: 1000, total_loss: 1.546e-08, loss_BC: 0.000e+00, loss_IC: 5.825e-09,loss_f: 9.638e-09
pinn: 0200, Iter: 1000, total_loss: 3.537e-08, loss_BC: 0.000e+00, loss_IC: 1.129e-08,loss_f: 2.408e-08
pinn: 0100, Iter: 1100, total_loss: 3.470e-08, loss_BC: 0.000e+00, loss_IC: 8.884e-09,loss_f: 2.582e-08
pinn: 0300, Iter: 1100, total_loss: 1.506e-08, loss_BC: 0.000e+00, loss_IC: 5.669e-09,loss_f: 9.389e-09
pinn: 0200, Iter: 1100, total_loss: 3.104e-08, loss_BC: 0.000e+00, loss_IC: 9.368e-09,loss_f: 2.167e-08
pinn: 0100, Iter: 1200, total_loss: 3.452e-08, loss_BC: 0.000e+00, loss_IC: 8.802e-09,loss_f: 2.571e-08
pinn: 0200, Iter: 1200, total_loss: 2.971e-08, loss_BC: 0.000e+00, loss_IC: 9.243e-09,loss_f: 2.047e-08
pinn: 0300, Iter: 1200, total_loss: 1.504e-08, loss_BC: 0.000e+00, loss_IC: 5.685e-09,loss_f: 9.351e-09
pinn: 0100, Iter: 1300, total_loss: 3.286e-08, loss_BC: 0.000e+00, loss_IC: 8.440e-09,loss_f: 2.442e-08
pinn: 0200, Iter: 1300, total_loss: 2.763e-08, loss_BC: 0.000e+00, loss_IC: 7.729e-09,loss_f: 1.990e-08
pinn: 0300, Iter: 1300, total_loss: 1.432e-08, loss_BC: 0.000e+00, loss_IC: 5.277e-09,loss_f: 9.044e-09
pinn: 0100, Iter: 1400, total_loss: 3.282e-08, loss_BC: 0.000e+00, loss_IC: 8.357e-09,loss_f: 2.446e-08
pinn: 0200, Iter: 1400, total_loss: 2.756e-08, loss_BC: 0.000e+00, loss_IC: 7.511e-09,loss_f: 2.005e-08
pinn: 0300, Iter: 1400, total_loss: 1.379e-08, loss_BC: 0.000e+00, loss_IC: 4.975e-09,loss_f: 8.816e-09

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 10351, Mean_loss of pinns: 2.466e-08, loss_BC: 0.000e+00, loss_IC: 6.880e-09, loss_f: 1.778e-08
 => minimum loss: 1.377e-08, corresponding pinn index: 0300
 => maximum loss: 3.279e-08, corresponding pinn  index: 0100

 max_loss: 3.455e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 pinns to pinns Prediction ===> next time interval 
Increase time interval ==> Epoch: 10353, total_loss: 1.558e-05, loss_BC: 1.454e-05, loss_IC: 6.339e-08, loss_f: 9.759e-07

 

 ===================================================> 
 
  Change the time domain to:  t_min: 0.99000, t_max: 1.00000

 ===================================================> 
 

 ! Re-Initilization of all workers pinns 

debug:epoch, flag_reduce_batches, flag:  10354 0 1

 -------------------------------------------------------------
  -----  Epoch: 10354 <==> N_batches: 4, self.pinns: 4    -------
 time domain:  t_min: 0.99000, t_max: 1.00000
--------------------------------------------------------------


 ! set initial weights for self.pinns! 

shapes:  (4225, 3) (4225, 1)
quarters_max_indices: 0000, 0100, 0200, 0300
dict_quarters_infos: {'Phase_0': {'quarter1': [{'idx_pinn': '0000',
                           'limits': ListWrapper([0.0, 0.5, 0.0, 0.5])}],
             'quarter2': [{'idx_pinn': '0100',
                           'limits': ListWrapper([0.0, 0.5, 0.5, 1.0])}],
             'quarter3': [{'idx_pinn': '0200',
                           'limits': ListWrapper([0.5, 1.0, 0.0, 0.5])}],
             'quarter4': [{'idx_pinn': '0300',
                           'limits': ListWrapper([0.5, 1.0, 0.5, 1.0])}]}}
 
 !!! updating Collocation points at epoch  10354 !!! 


==> Epoch: 10360, Mean_loss of pinns: 2.117e-04, loss_BC: 1.602e-05, loss_IC: 4.238e-07, loss_f: 1.953e-04
 => minimum loss: 2.369e-05, corresponding pinn/batch index: 0300
 => maximum loss: 7.668e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10370, Mean_loss of pinns: 1.728e-04, loss_BC: 1.784e-05, loss_IC: 1.063e-06, loss_f: 1.539e-04
 => minimum loss: 2.186e-05, corresponding pinn/batch index: 0300
 => maximum loss: 6.195e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10380, Mean_loss of pinns: 1.420e-04, loss_BC: 1.747e-05, loss_IC: 1.511e-06, loss_f: 1.230e-04
 => minimum loss: 2.056e-05, corresponding pinn/batch index: 0300
 => maximum loss: 5.049e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10390, Mean_loss of pinns: 1.185e-04, loss_BC: 1.664e-05, loss_IC: 1.366e-06, loss_f: 1.005e-04
 => minimum loss: 1.827e-05, corresponding pinn/batch index: 0200
 => maximum loss: 4.178e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10400, Mean_loss of pinns: 1.008e-04, loss_BC: 1.597e-05, loss_IC: 9.546e-07, loss_f: 8.387e-05
 => minimum loss: 1.715e-05, corresponding pinn/batch index: 0200
 => maximum loss: 3.511e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10410, Mean_loss of pinns: 8.655e-05, loss_BC: 1.472e-05, loss_IC: 7.457e-07, loss_f: 7.108e-05
 => minimum loss: 1.597e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.979e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10420, Mean_loss of pinns: 7.556e-05, loss_BC: 1.396e-05, loss_IC: 7.052e-07, loss_f: 6.090e-05
 => minimum loss: 1.401e-05, corresponding pinn/batch index: 0100
 => maximum loss: 2.575e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10430, Mean_loss of pinns: 6.688e-05, loss_BC: 1.344e-05, loss_IC: 7.250e-07, loss_f: 5.272e-05
 => minimum loss: 1.328e-05, corresponding pinn/batch index: 0200
 => maximum loss: 2.247e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10440, Mean_loss of pinns: 5.954e-05, loss_BC: 1.264e-05, loss_IC: 7.573e-07, loss_f: 4.614e-05
 => minimum loss: 1.262e-05, corresponding pinn/batch index: 0200
 => maximum loss: 1.980e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

==> Epoch: 10450, Mean_loss of pinns: 5.390e-05, loss_BC: 1.227e-05, loss_IC: 8.020e-07, loss_f: 4.084e-05
 => minimum loss: 1.178e-05, corresponding pinn/batch index: 0100
 => maximum loss: 1.781e-04, corresponding pinn/batch  index: 0000
 => In : Number of pinns to train: 4
 => Out : Number of pinns above Threshold: 1
pinns above Threshold: 0000

 !!! Scipy optimize: !!! - Epoch:  10453

 ! Scipy iteration number:  1
Processes:  1
Number of pinns to optimize weights:  1
 !!! pinns to optimize ==> 0000


pinn: 0000, Iter: 100, total_loss: 9.888e-07, loss_BC: 0.000e+00, loss_IC: 4.150e-07,loss_f: 5.738e-07
pinn: 0000, Iter: 200, total_loss: 1.263e-07, loss_BC: 0.000e+00, loss_IC: 1.389e-08,loss_f: 1.124e-07
pinn: 0000, Iter: 300, total_loss: 4.557e-08, loss_BC: 0.000e+00, loss_IC: 8.733e-09,loss_f: 3.683e-08
pinn: 0000, Iter: 400, total_loss: 3.700e-08, loss_BC: 0.000e+00, loss_IC: 7.829e-09,loss_f: 2.917e-08
pinn: 0000, Iter: 500, total_loss: 3.384e-08, loss_BC: 0.000e+00, loss_IC: 7.398e-09,loss_f: 2.644e-08
pinn: 0000, Iter: 600, total_loss: 3.036e-08, loss_BC: 0.000e+00, loss_IC: 6.687e-09,loss_f: 2.367e-08
pinn: 0000, Iter: 700, total_loss: 2.831e-08, loss_BC: 0.000e+00, loss_IC: 6.567e-09,loss_f: 2.174e-08
pinn: 0000, Iter: 800, total_loss: 2.464e-08, loss_BC: 0.000e+00, loss_IC: 6.579e-09,loss_f: 1.806e-08
pinn: 0000, Iter: 900, total_loss: 2.183e-08, loss_BC: 0.000e+00, loss_IC: 5.548e-09,loss_f: 1.628e-08
pinn: 0000, Iter: 1000, total_loss: 2.122e-08, loss_BC: 0.000e+00, loss_IC: 5.425e-09,loss_f: 1.579e-08
pinn: 0000, Iter: 1100, total_loss: 2.076e-08, loss_BC: 0.000e+00, loss_IC: 5.021e-09,loss_f: 1.574e-08
pinn: 0000, Iter: 1200, total_loss: 2.061e-08, loss_BC: 0.000e+00, loss_IC: 5.003e-09,loss_f: 1.561e-08
pinn: 0000, Iter: 1300, total_loss: 2.014e-08, loss_BC: 0.000e+00, loss_IC: 4.756e-09,loss_f: 1.539e-08
pinn: 0000, Iter: 1400, total_loss: 2.002e-08, loss_BC: 0.000e+00, loss_IC: 4.704e-09,loss_f: 1.532e-08

 !!! number of pinns above the Treshhold:  0

 !!! pinns above the Treshhold ==> 

 !!! Scipy optimization done !!!
 
==> loss after L-BFGS-B optimization for Epoch: 10453, Mean_loss of pinns: 1.997e-08, loss_BC: 0.000e+00, loss_IC: 4.665e-09, loss_f: 1.530e-08
 => minimum loss: 1.997e-08, corresponding pinn index: 0000
 => maximum loss: 1.997e-08, corresponding pinn  index: 0000

 max_loss: 2.759e-05 < Threshold: 7.000e-05


 !!!  saving weights of self.pinns in progress !!! 


     ! saving complete ! 

remind ,  N_batches  4

 !!!  saving predictions of pinns in progress !!! 


        ! saving complete ! 


 